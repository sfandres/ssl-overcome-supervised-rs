IP Head: 192.168.7.53:6379
STARTING HEAD at aap04
2024-01-07 02:23:13,192	INFO usage_lib.py:461 -- Usage stats collection is enabled by default without user confirmation because this terminal is detected to be non-interactive. To disable this, add `--disable-usage-stats` to the command that starts the cluster, or run the following command: `ray disable-usage-stats` before starting the cluster. See https://docs.ray.io/en/master/cluster/usage-stats.html for more details.
2024-01-07 02:23:13,192	INFO scripts.py:710 -- Local node IP: 192.168.7.53
2024-01-07 02:23:15,936	SUCC scripts.py:747 -- --------------------
2024-01-07 02:23:15,936	SUCC scripts.py:748 -- Ray runtime started.
2024-01-07 02:23:15,936	SUCC scripts.py:749 -- --------------------
2024-01-07 02:23:15,936	INFO scripts.py:751 -- Next steps
2024-01-07 02:23:15,936	INFO scripts.py:752 -- To connect to this Ray runtime from another node, run
2024-01-07 02:23:15,936	INFO scripts.py:755 --   ray start --address='192.168.7.53:6379'
2024-01-07 02:23:15,936	INFO scripts.py:771 -- Alternatively, use the following Python code:
2024-01-07 02:23:15,936	INFO scripts.py:773 -- import ray
2024-01-07 02:23:15,937	INFO scripts.py:777 -- ray.init(address='auto', _node_ip_address='192.168.7.53')
2024-01-07 02:23:15,937	INFO scripts.py:790 -- To see the status of the cluster, use
2024-01-07 02:23:15,937	INFO scripts.py:791 --   ray status
2024-01-07 02:23:15,937	INFO scripts.py:801 -- If connection fails, check your firewall settings and network configuration.
2024-01-07 02:23:15,937	INFO scripts.py:809 -- To terminate the Ray runtime, run
2024-01-07 02:23:15,937	INFO scripts.py:810 --   ray stop
2024-01-07 02:23:15,937	INFO scripts.py:891 -- --block
2024-01-07 02:23:15,937	INFO scripts.py:892 -- This command will now block forever until terminated by a signal.
2024-01-07 02:23:15,937	INFO scripts.py:895 -- Running subprocesses are monitored and a message will be printed if any of them terminate unexpectedly. Subprocesses exit with SIGTERM will be treated as graceful, thus NOT reported.

torch initial seed:              15082422103031215088
torch current seed:              42
torch.cuda.is_available():       True
torch.cuda.device_count():       4
torch.cuda.current_device():     0
torch.cuda.device(0):            <torch.cuda.device object at 0x7fe06776b100>
torch.cuda.get_device_name(0):   Tesla V100-PCIE-32GB
torch.backends.cudnn.benchmark:  False
os.sched_getaffinity:            72
os.cpu_count():                  72

model_name:          Supervised
task_name:           multiclass
backbone_name:       resnet18
input_data:          None
dataset_name:        Sentinel2AndaluciaLULC
dataset_level:       Level_N2
train_rate:          5
epochs:              100
learning_rate:       0.01
save_every:          5
batch_size:          32
num_workers:         4
ini_weights:         random
seed:                42
dropout:             None
transfer_learning:   FT
show:                False
verbose:             False
balanced_dataset:    False
torch_compile:       False
distributed:         False
ray_tune:            gridsearch
load_best_hyperparameters: False
grace_period:        75
num_samples_trials:  1
gpus_per_trial:      1

Initial imbalanced dataset:
Diff. classes --> [ 1 21 22 23 31 35 41 42 47 51]
Samples/class --> [5 5 5 5 5 5 5 5 5 5]

Creating the sample distribution plot...
Sample distribution computation in train dataset (s): 1.97
Resulting balanced dataloader:
Diff. classes     --> [0 1 2 3 4 5 6 7 8 9]
New samples/class --> [5 5 5 5 5 5 5 5 5 5]
Done!

Supervised model resnet18 with random weights
Old final fully-connected layer: Linear(in_features=512, out_features=1000, bias=True)
No dropout layer
New final fully-connected layer: Linear(in_features=512, out_features=10, bias=True)
Fine-tuning adjusted
Device: 0

Setting a new configuration using tune.grid_search

2024-01-07 02:23:58,250	INFO worker.py:1364 -- Connecting to existing Ray cluster at address: 192.168.7.53:6379...
2024-01-07 02:23:58,262	INFO worker.py:1553 -- Connected to Ray cluster.
2024-01-07 02:24:19,080	WARNING worker.py:1866 -- Warning: The actor ImplicitFunc is very large (44 MiB). Check that its definition is not implicitly capturing a large array or other object in scope. Tip: use ray.put() to put large objects in the Ray object store.
== Status ==
Current time: 2024-01-07 02:24:19 (running for 00:00:20.79)
Memory usage on this node: 13.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (23 PENDING, 1 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |
|-------------------+----------+--------------------+--------+------------+----------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |
| train_6ed81_00001 | PENDING  |                    | 0.001  |       0.99 |         0      |
| train_6ed81_00002 | PENDING  |                    | 0.01   |       0.99 |         0      |
| train_6ed81_00003 | PENDING  |                    | 0.1    |       0.99 |         0      |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |
+-------------------+----------+--------------------+--------+------------+----------------+
... 4 more trials not shown (4 PENDING)

[2m[36m(func pid=38305)[0m Dataloader to compute accuracy: val

[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=38305)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=38305)[0m Configuration completed!
[2m[36m(func pid=38305)[0m New optimizer parameters:
[2m[36m(func pid=38305)[0m SGD (
[2m[36m(func pid=38305)[0m Parameter Group 0
[2m[36m(func pid=38305)[0m     dampening: 0
[2m[36m(func pid=38305)[0m     differentiable: False
[2m[36m(func pid=38305)[0m     foreach: None
[2m[36m(func pid=38305)[0m     lr: 0.0001
[2m[36m(func pid=38305)[0m     maximize: False
[2m[36m(func pid=38305)[0m     momentum: 0.99
[2m[36m(func pid=38305)[0m     nesterov: False
[2m[36m(func pid=38305)[0m     weight_decay: 0
[2m[36m(func pid=38305)[0m )
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 3.1248 | Steps: 2 | Val loss: 2.3706 | Batch size: 32 | lr: 0.0001 | Duration: 5.85s
[2m[36m(func pid=38305)[0m top1: 0.06669776119402986
[2m[36m(func pid=38305)[0m top5: 0.37966417910447764
[2m[36m(func pid=38305)[0m f1_micro: 0.06669776119402986
[2m[36m(func pid=38305)[0m f1_macro: 0.022596774819274194
[2m[36m(func pid=38305)[0m f1_weighted: 0.021192243515546865
[2m[36m(func pid=38305)[0m f1_per_class: [0.0, 0.005, 0.0, 0.046, 0.0, 0.0, 0.0, 0.118, 0.0, 0.057]
== Status ==
Current time: 2024-01-07 02:24:29 (running for 00:00:30.55)
Memory usage on this node: 15.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (22 PENDING, 2 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |
|-------------------+----------+--------------------+--------+------------+----------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |
| train_6ed81_00002 | PENDING  |                    | 0.01   |       0.99 |         0      |
| train_6ed81_00003 | PENDING  |                    | 0.1    |       0.99 |         0      |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |
+-------------------+----------+--------------------+--------+------------+----------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38679)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=38679)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=38679)[0m Configuration completed!
[2m[36m(func pid=38679)[0m New optimizer parameters:
[2m[36m(func pid=38679)[0m SGD (
[2m[36m(func pid=38679)[0m Parameter Group 0
[2m[36m(func pid=38679)[0m     dampening: 0
[2m[36m(func pid=38679)[0m     differentiable: False
[2m[36m(func pid=38679)[0m     foreach: None
[2m[36m(func pid=38679)[0m     lr: 0.001
[2m[36m(func pid=38679)[0m     maximize: False
[2m[36m(func pid=38679)[0m     momentum: 0.99
[2m[36m(func pid=38679)[0m     nesterov: False
[2m[36m(func pid=38679)[0m     weight_decay: 0
[2m[36m(func pid=38679)[0m )
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 3.0396 | Steps: 2 | Val loss: 2.3737 | Batch size: 32 | lr: 0.001 | Duration: 4.50s
[2m[36m(func pid=38679)[0m top1: 0.07369402985074627
[2m[36m(func pid=38679)[0m top5: 0.31902985074626866
[2m[36m(func pid=38679)[0m f1_micro: 0.07369402985074627
[2m[36m(func pid=38679)[0m f1_macro: 0.0214927799698169
[2m[36m(func pid=38679)[0m f1_weighted: 0.03131031432599456
[2m[36m(func pid=38679)[0m f1_per_class: [0.0, 0.005, 0.0, 0.083, 0.0, 0.0, 0.0, 0.127, 0.0, 0.0]
== Status ==
Current time: 2024-01-07 02:24:38 (running for 00:00:39.28)
Memory usage on this node: 17.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (21 PENDING, 3 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |
|-------------------+----------+--------------------+--------+------------+----------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |
| train_6ed81_00003 | PENDING  |                    | 0.1    |       0.99 |         0      |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |
+-------------------+----------+--------------------+--------+------------+----------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=39098)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=39098)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=39098)[0m Configuration completed!
[2m[36m(func pid=39098)[0m New optimizer parameters:
[2m[36m(func pid=39098)[0m SGD (
[2m[36m(func pid=39098)[0m Parameter Group 0
[2m[36m(func pid=39098)[0m     dampening: 0
[2m[36m(func pid=39098)[0m     differentiable: False
[2m[36m(func pid=39098)[0m     foreach: None
[2m[36m(func pid=39098)[0m     lr: 0.01
[2m[36m(func pid=39098)[0m     maximize: False
[2m[36m(func pid=39098)[0m     momentum: 0.99
[2m[36m(func pid=39098)[0m     nesterov: False
[2m[36m(func pid=39098)[0m     weight_decay: 0
[2m[36m(func pid=39098)[0m )
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 2.9966 | Steps: 2 | Val loss: 2.6166 | Batch size: 32 | lr: 0.01 | Duration: 4.66s
[2m[36m(func pid=39098)[0m top1: 0.006063432835820896
[2m[36m(func pid=39098)[0m top5: 0.3824626865671642
[2m[36m(func pid=39098)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=39098)[0m f1_macro: 0.001205377839592026
[2m[36m(func pid=39098)[0m f1_weighted: 7.308727572153144e-05
[2m[36m(func pid=39098)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
== Status ==
Current time: 2024-01-07 02:24:47 (running for 00:00:48.34)
Memory usage on this node: 20.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |
|-------------------+----------+--------------------+--------+------------+----------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |
+-------------------+----------+--------------------+--------+------------+----------------+
... 4 more trials not shown (4 PENDING)


== Status ==
Current time: 2024-01-07 02:24:55 (running for 00:00:56.51)
Memory usage on this node: 22.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |        |            |                      |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |        |            |                      |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  2.997 |      0.001 |                    1 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |        |            |                      |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=39517)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=39517)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=39517)[0m Configuration completed!
[2m[36m(func pid=39517)[0m New optimizer parameters:
[2m[36m(func pid=39517)[0m SGD (
[2m[36m(func pid=39517)[0m Parameter Group 0
[2m[36m(func pid=39517)[0m     dampening: 0
[2m[36m(func pid=39517)[0m     differentiable: False
[2m[36m(func pid=39517)[0m     foreach: None
[2m[36m(func pid=39517)[0m     lr: 0.1
[2m[36m(func pid=39517)[0m     maximize: False
[2m[36m(func pid=39517)[0m     momentum: 0.99
[2m[36m(func pid=39517)[0m     nesterov: False
[2m[36m(func pid=39517)[0m     weight_decay: 0
[2m[36m(func pid=39517)[0m )
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 2.9765 | Steps: 2 | Val loss: 2.3263 | Batch size: 32 | lr: 0.001 | Duration: 2.76s
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 3.0745 | Steps: 2 | Val loss: 2.3275 | Batch size: 32 | lr: 0.0001 | Duration: 3.04s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 2.7267 | Steps: 2 | Val loss: 3.4858 | Batch size: 32 | lr: 0.01 | Duration: 3.10s
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 3.2557 | Steps: 2 | Val loss: 410.3123 | Batch size: 32 | lr: 0.1 | Duration: 4.55s
== Status ==
Current time: 2024-01-07 02:25:00 (running for 00:01:01.53)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  3.125 |      0.023 |                    1 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  3.04  |      0.021 |                    1 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  2.997 |      0.001 |                    1 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |        |            |                      |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38679)[0m top1: 0.11054104477611941
[2m[36m(func pid=38679)[0m top5: 0.5051305970149254
[2m[36m(func pid=38679)[0m f1_micro: 0.11054104477611941
[2m[36m(func pid=38679)[0m f1_macro: 0.06761536980743317
[2m[36m(func pid=38679)[0m f1_weighted: 0.08551361484180452
[2m[36m(func pid=38679)[0m f1_per_class: [0.0, 0.0, 0.025, 0.216, 0.0, 0.0, 0.0, 0.435, 0.0, 0.0]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=38305)[0m top1: 0.14319029850746268
[2m[36m(func pid=38305)[0m top5: 0.5200559701492538
[2m[36m(func pid=38305)[0m f1_micro: 0.14319029850746268
[2m[36m(func pid=38305)[0m f1_macro: 0.042626965237671594
[2m[36m(func pid=38305)[0m f1_weighted: 0.08101360976626176
[2m[36m(func pid=38305)[0m f1_per_class: [0.0, 0.0, 0.0, 0.255, 0.0, 0.0, 0.0, 0.171, 0.0, 0.0]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39098)[0m top1: 0.006996268656716418
[2m[36m(func pid=39098)[0m top5: 0.519589552238806
[2m[36m(func pid=39098)[0m f1_micro: 0.006996268656716418
[2m[36m(func pid=39098)[0m f1_macro: 0.0022800033371976752
[2m[36m(func pid=39098)[0m f1_weighted: 0.0019188875017765337
[2m[36m(func pid=39098)[0m f1_per_class: [0.0, 0.011, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=39517)[0m top1: 0.006063432835820896
[2m[36m(func pid=39517)[0m top5: 0.5083955223880597
[2m[36m(func pid=39517)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=39517)[0m f1_macro: 0.001205377839592026
[2m[36m(func pid=39517)[0m f1_weighted: 7.308727572153144e-05
[2m[36m(func pid=39517)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 2.7167 | Steps: 2 | Val loss: 2.3097 | Batch size: 32 | lr: 0.001 | Duration: 2.65s
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 3.0378 | Steps: 2 | Val loss: 2.3170 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 2.5805 | Steps: 2 | Val loss: 5.1766 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 5.5687 | Steps: 2 | Val loss: 360483.3125 | Batch size: 32 | lr: 0.1 | Duration: 2.67s
== Status ==
Current time: 2024-01-07 02:25:05 (running for 00:01:06.54)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  3.074 |      0.043 |                    2 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  2.717 |      0.014 |                    3 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  2.727 |      0.002 |                    2 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  3.256 |      0.001 |                    1 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38679)[0m top1: 0.03591417910447761
[2m[36m(func pid=38679)[0m top5: 0.5970149253731343
[2m[36m(func pid=38679)[0m f1_micro: 0.03591417910447761
[2m[36m(func pid=38679)[0m f1_macro: 0.014249129043076719
[2m[36m(func pid=38679)[0m f1_weighted: 0.035684896772335405
[2m[36m(func pid=38679)[0m f1_per_class: [0.0, 0.0, 0.015, 0.128, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=38305)[0m top1: 0.1875
[2m[36m(func pid=38305)[0m top5: 0.5573694029850746
[2m[36m(func pid=38305)[0m f1_micro: 0.1875
[2m[36m(func pid=38305)[0m f1_macro: 0.04986766021174366
[2m[36m(func pid=38305)[0m f1_weighted: 0.09993360745697433
[2m[36m(func pid=38305)[0m f1_per_class: [0.0, 0.0, 0.0, 0.322, 0.0, 0.0, 0.0, 0.177, 0.0, 0.0]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39098)[0m top1: 0.08162313432835822
[2m[36m(func pid=39098)[0m top5: 0.5410447761194029
[2m[36m(func pid=39098)[0m f1_micro: 0.08162313432835822
[2m[36m(func pid=39098)[0m f1_macro: 0.04811677011303069
[2m[36m(func pid=39098)[0m f1_weighted: 0.07723605981665702
[2m[36m(func pid=39098)[0m f1_per_class: [0.018, 0.446, 0.017, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=39517)[0m top1: 0.006063432835820896
[2m[36m(func pid=39517)[0m top5: 0.5093283582089553
[2m[36m(func pid=39517)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=39517)[0m f1_macro: 0.001205377839592026
[2m[36m(func pid=39517)[0m f1_weighted: 7.308727572153144e-05
[2m[36m(func pid=39517)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 2.6192 | Steps: 2 | Val loss: 2.3017 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 3.0236 | Steps: 2 | Val loss: 2.3155 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 2.3275 | Steps: 2 | Val loss: 7.1451 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 5.8975 | Steps: 2 | Val loss: 643194.3125 | Batch size: 32 | lr: 0.1 | Duration: 2.66s
== Status ==
Current time: 2024-01-07 02:25:10 (running for 00:01:11.54)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  3.038 |      0.05  |                    3 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  2.619 |      0.005 |                    4 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  2.581 |      0.048 |                    3 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  5.569 |      0.001 |                    2 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38679)[0m top1: 0.011194029850746268
[2m[36m(func pid=38679)[0m top5: 0.6128731343283582
[2m[36m(func pid=38679)[0m f1_micro: 0.01119402985074627
[2m[36m(func pid=38679)[0m f1_macro: 0.004574383452665076
[2m[36m(func pid=38679)[0m f1_weighted: 0.009372513922036597
[2m[36m(func pid=38679)[0m f1_per_class: [0.0, 0.0, 0.012, 0.033, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=38305)[0m top1: 0.19869402985074627
[2m[36m(func pid=38305)[0m top5: 0.5727611940298507
[2m[36m(func pid=38305)[0m f1_micro: 0.19869402985074627
[2m[36m(func pid=38305)[0m f1_macro: 0.0438887682994477
[2m[36m(func pid=38305)[0m f1_weighted: 0.10283440981907624
[2m[36m(func pid=38305)[0m f1_per_class: [0.0, 0.0, 0.0, 0.35, 0.0, 0.0, 0.0, 0.089, 0.0, 0.0]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39098)[0m top1: 0.13759328358208955
[2m[36m(func pid=39098)[0m top5: 0.6501865671641791
[2m[36m(func pid=39098)[0m f1_micro: 0.13759328358208955
[2m[36m(func pid=39098)[0m f1_macro: 0.045679021833498465
[2m[36m(func pid=39098)[0m f1_weighted: 0.07339164388623469
[2m[36m(func pid=39098)[0m f1_per_class: [0.007, 0.425, 0.025, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=39517)[0m top1: 0.006063432835820896
[2m[36m(func pid=39517)[0m top5: 0.5093283582089553
[2m[36m(func pid=39517)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=39517)[0m f1_macro: 0.001205377839592026
[2m[36m(func pid=39517)[0m f1_weighted: 7.308727572153144e-05
[2m[36m(func pid=39517)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 2.5251 | Steps: 2 | Val loss: 2.2947 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 2.9339 | Steps: 2 | Val loss: 2.3159 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 2.1099 | Steps: 2 | Val loss: 14.6559 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 3.1675 | Steps: 2 | Val loss: 95797.4453 | Batch size: 32 | lr: 0.1 | Duration: 2.69s
[2m[36m(func pid=38679)[0m top1: 0.015391791044776119
[2m[36m(func pid=38679)[0m top5: 0.617070895522388
[2m[36m(func pid=38679)[0m f1_micro: 0.015391791044776119
[2m[36m(func pid=38679)[0m f1_macro: 0.013039278891663264
[2m[36m(func pid=38679)[0m f1_weighted: 0.01716425417934853
[2m[36m(func pid=38679)[0m f1_per_class: [0.034, 0.064, 0.013, 0.019, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=38679)[0m 
== Status ==
Current time: 2024-01-07 02:25:15 (running for 00:01:16.73)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  3.024 |      0.044 |                    4 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  2.525 |      0.013 |                    5 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  2.327 |      0.046 |                    4 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  5.897 |      0.001 |                    3 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.21315298507462688
[2m[36m(func pid=38305)[0m top5: 0.5797574626865671
[2m[36m(func pid=38305)[0m f1_micro: 0.2131529850746269
[2m[36m(func pid=38305)[0m f1_macro: 0.06955015602836126
[2m[36m(func pid=38305)[0m f1_weighted: 0.10751071498842703
[2m[36m(func pid=38305)[0m f1_per_class: [0.0, 0.0, 0.276, 0.369, 0.0, 0.0, 0.0, 0.051, 0.0, 0.0]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39098)[0m top1: 0.04897388059701493
[2m[36m(func pid=39098)[0m top5: 0.5265858208955224
[2m[36m(func pid=39098)[0m f1_micro: 0.048973880597014935
[2m[36m(func pid=39098)[0m f1_macro: 0.05790334913564216
[2m[36m(func pid=39098)[0m f1_weighted: 0.06258203205925725
[2m[36m(func pid=39098)[0m f1_per_class: [0.0, 0.274, 0.015, 0.045, 0.211, 0.0, 0.0, 0.0, 0.035, 0.0]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=39517)[0m top1: 0.2789179104477612
[2m[36m(func pid=39517)[0m top5: 0.7821828358208955
[2m[36m(func pid=39517)[0m f1_micro: 0.2789179104477612
[2m[36m(func pid=39517)[0m f1_macro: 0.04361779722830051
[2m[36m(func pid=39517)[0m f1_weighted: 0.12165784861251727
[2m[36m(func pid=39517)[0m f1_per_class: [0.0, 0.0, 0.0, 0.436, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 2.5222 | Steps: 2 | Val loss: 2.2823 | Batch size: 32 | lr: 0.001 | Duration: 2.70s
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 2.8936 | Steps: 2 | Val loss: 2.3189 | Batch size: 32 | lr: 0.0001 | Duration: 2.71s
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 2.8396 | Steps: 2 | Val loss: 154541.8750 | Batch size: 32 | lr: 0.1 | Duration: 2.68s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 2.0126 | Steps: 2 | Val loss: 18.9469 | Batch size: 32 | lr: 0.01 | Duration: 2.77s
[2m[36m(func pid=38679)[0m top1: 0.09514925373134328
[2m[36m(func pid=38679)[0m top5: 0.6623134328358209
[2m[36m(func pid=38679)[0m f1_micro: 0.09514925373134328
[2m[36m(func pid=38679)[0m f1_macro: 0.07274905452486169
[2m[36m(func pid=38679)[0m f1_weighted: 0.08202172856803604
[2m[36m(func pid=38679)[0m f1_per_class: [0.039, 0.433, 0.019, 0.016, 0.143, 0.0, 0.0, 0.0, 0.0, 0.077]
[2m[36m(func pid=38679)[0m 
== Status ==
Current time: 2024-01-07 02:25:21 (running for 00:01:22.75)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  2.894 |      0.063 |                    6 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  2.522 |      0.073 |                    6 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  2.11  |      0.058 |                    5 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  3.167 |      0.044 |                    4 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.22154850746268656
[2m[36m(func pid=38305)[0m top5: 0.5792910447761194
[2m[36m(func pid=38305)[0m f1_micro: 0.22154850746268656
[2m[36m(func pid=38305)[0m f1_macro: 0.06292326012403215
[2m[36m(func pid=38305)[0m f1_weighted: 0.1094929744619546
[2m[36m(func pid=38305)[0m f1_per_class: [0.0, 0.0, 0.198, 0.377, 0.0, 0.0, 0.0, 0.055, 0.0, 0.0]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39098)[0m top1: 0.05223880597014925
[2m[36m(func pid=39098)[0m top5: 0.5219216417910447
[2m[36m(func pid=39098)[0m f1_micro: 0.05223880597014925
[2m[36m(func pid=39098)[0m f1_macro: 0.06876732221417932
[2m[36m(func pid=39098)[0m f1_weighted: 0.06583660574749375
[2m[36m(func pid=39098)[0m f1_per_class: [0.038, 0.077, 0.016, 0.167, 0.261, 0.008, 0.0, 0.0, 0.039, 0.082]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=39517)[0m top1: 0.006063432835820896
[2m[36m(func pid=39517)[0m top5: 0.5093283582089553
[2m[36m(func pid=39517)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=39517)[0m f1_macro: 0.001205377839592026
[2m[36m(func pid=39517)[0m f1_weighted: 7.308727572153144e-05
[2m[36m(func pid=39517)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 2.4081 | Steps: 2 | Val loss: 2.2581 | Batch size: 32 | lr: 0.001 | Duration: 2.67s
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 2.8578 | Steps: 2 | Val loss: 2.3226 | Batch size: 32 | lr: 0.0001 | Duration: 2.72s
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 2.9601 | Steps: 2 | Val loss: 204752.3281 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 2.0286 | Steps: 2 | Val loss: 23.4418 | Batch size: 32 | lr: 0.01 | Duration: 3.03s
[2m[36m(func pid=38679)[0m top1: 0.1394589552238806
[2m[36m(func pid=38679)[0m top5: 0.7551305970149254
[2m[36m(func pid=38679)[0m f1_micro: 0.1394589552238806
[2m[36m(func pid=38679)[0m f1_macro: 0.1055599025359526
[2m[36m(func pid=38679)[0m f1_weighted: 0.12006948532658183
[2m[36m(func pid=38679)[0m f1_per_class: [0.057, 0.439, 0.081, 0.0, 0.098, 0.199, 0.057, 0.0, 0.048, 0.077]
[2m[36m(func pid=38679)[0m 
== Status ==
Current time: 2024-01-07 02:25:27 (running for 00:01:27.87)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  2.858 |      0.049 |                    7 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  2.408 |      0.106 |                    7 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  2.013 |      0.069 |                    6 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  2.84  |      0.001 |                    5 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.2150186567164179
[2m[36m(func pid=38305)[0m top5: 0.5718283582089553
[2m[36m(func pid=38305)[0m f1_micro: 0.2150186567164179
[2m[36m(func pid=38305)[0m f1_macro: 0.049077084111355876
[2m[36m(func pid=38305)[0m f1_weighted: 0.10811087685301576
[2m[36m(func pid=38305)[0m f1_per_class: [0.0, 0.0, 0.076, 0.378, 0.0, 0.0, 0.0, 0.036, 0.0, 0.0]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39517)[0m top1: 0.006063432835820896
[2m[36m(func pid=39517)[0m top5: 0.5093283582089553
[2m[36m(func pid=39517)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=39517)[0m f1_macro: 0.001205377839592026
[2m[36m(func pid=39517)[0m f1_weighted: 7.308727572153144e-05
[2m[36m(func pid=39517)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=39098)[0m top1: 0.06436567164179105
[2m[36m(func pid=39098)[0m top5: 0.5382462686567164
[2m[36m(func pid=39098)[0m f1_micro: 0.06436567164179105
[2m[36m(func pid=39098)[0m f1_macro: 0.07940286407609377
[2m[36m(func pid=39098)[0m f1_weighted: 0.08765507462914092
[2m[36m(func pid=39098)[0m f1_per_class: [0.037, 0.301, 0.017, 0.098, 0.235, 0.04, 0.0, 0.0, 0.034, 0.033]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 2.3217 | Steps: 2 | Val loss: 2.2298 | Batch size: 32 | lr: 0.001 | Duration: 2.67s
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 2.7890 | Steps: 2 | Val loss: 2.3239 | Batch size: 32 | lr: 0.0001 | Duration: 2.77s
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 2.3462 | Steps: 2 | Val loss: 179393.1875 | Batch size: 32 | lr: 0.1 | Duration: 2.67s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 1.5974 | Steps: 2 | Val loss: 19.4620 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=38679)[0m top1: 0.17630597014925373
[2m[36m(func pid=38679)[0m top5: 0.7728544776119403
[2m[36m(func pid=38679)[0m f1_micro: 0.17630597014925373
[2m[36m(func pid=38679)[0m f1_macro: 0.13877984831198434
[2m[36m(func pid=38679)[0m f1_weighted: 0.17844748148011438
[2m[36m(func pid=38679)[0m f1_per_class: [0.077, 0.428, 0.138, 0.0, 0.089, 0.286, 0.219, 0.016, 0.06, 0.074]
[2m[36m(func pid=38679)[0m 
== Status ==
Current time: 2024-01-07 02:25:32 (running for 00:01:32.98)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  2.789 |      0.05  |                    8 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  2.322 |      0.139 |                    8 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  2.029 |      0.079 |                    7 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  2.96  |      0.001 |                    6 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.1865671641791045
[2m[36m(func pid=38305)[0m top5: 0.5629664179104478
[2m[36m(func pid=38305)[0m f1_micro: 0.1865671641791045
[2m[36m(func pid=38305)[0m f1_macro: 0.05022594496439957
[2m[36m(func pid=38305)[0m f1_weighted: 0.10512403614543148
[2m[36m(func pid=38305)[0m f1_per_class: [0.043, 0.0, 0.04, 0.361, 0.0, 0.0, 0.0, 0.058, 0.0, 0.0]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39517)[0m top1: 0.006063432835820896
[2m[36m(func pid=39517)[0m top5: 0.5093283582089553
[2m[36m(func pid=39517)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=39517)[0m f1_macro: 0.001205377839592026
[2m[36m(func pid=39517)[0m f1_weighted: 7.308727572153144e-05
[2m[36m(func pid=39517)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=39098)[0m top1: 0.07229477611940298
[2m[36m(func pid=39098)[0m top5: 0.6105410447761194
[2m[36m(func pid=39098)[0m f1_micro: 0.07229477611940298
[2m[36m(func pid=39098)[0m f1_macro: 0.0745471601576391
[2m[36m(func pid=39098)[0m f1_weighted: 0.07619771038165638
[2m[36m(func pid=39098)[0m f1_per_class: [0.033, 0.371, 0.022, 0.003, 0.229, 0.03, 0.015, 0.0, 0.019, 0.023]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 2.2434 | Steps: 2 | Val loss: 2.1908 | Batch size: 32 | lr: 0.001 | Duration: 2.62s
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 2.6947 | Steps: 2 | Val loss: 2.3209 | Batch size: 32 | lr: 0.0001 | Duration: 2.79s
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 2.8168 | Steps: 2 | Val loss: 88267.9531 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=38679)[0m top1: 0.24207089552238806
[2m[36m(func pid=38679)[0m top5: 0.7751865671641791
[2m[36m(func pid=38679)[0m f1_micro: 0.24207089552238806
[2m[36m(func pid=38679)[0m f1_macro: 0.1861003604230386
[2m[36m(func pid=38679)[0m f1_weighted: 0.23845400367689765
[2m[36m(func pid=38679)[0m f1_per_class: [0.098, 0.448, 0.211, 0.0, 0.102, 0.249, 0.389, 0.157, 0.058, 0.148]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 2.5515 | Steps: 2 | Val loss: 13.4773 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=38305)[0m top1: 0.1525186567164179
[2m[36m(func pid=38305)[0m top5: 0.5680970149253731
[2m[36m(func pid=38305)[0m f1_micro: 0.1525186567164179
[2m[36m(func pid=38305)[0m f1_macro: 0.04657805083885208
[2m[36m(func pid=38305)[0m f1_weighted: 0.10054773435116059
[2m[36m(func pid=38305)[0m f1_per_class: [0.0, 0.015, 0.027, 0.332, 0.0, 0.0, 0.0, 0.092, 0.0, 0.0]
[2m[36m(func pid=38305)[0m 
== Status ==
Current time: 2024-01-07 02:25:37 (running for 00:01:38.20)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  2.695 |      0.047 |                    9 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  2.243 |      0.186 |                    9 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  1.597 |      0.075 |                    8 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  2.346 |      0.001 |                    7 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=39517)[0m top1: 0.006063432835820896
[2m[36m(func pid=39517)[0m top5: 0.5093283582089553
[2m[36m(func pid=39517)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=39517)[0m f1_macro: 0.0012070566388115134
[2m[36m(func pid=39517)[0m f1_weighted: 7.318906858465332e-05
[2m[36m(func pid=39517)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=39098)[0m top1: 0.12313432835820895
[2m[36m(func pid=39098)[0m top5: 0.7430037313432836
[2m[36m(func pid=39098)[0m f1_micro: 0.12313432835820895
[2m[36m(func pid=39098)[0m f1_macro: 0.08203292470516027
[2m[36m(func pid=39098)[0m f1_weighted: 0.12761611948441873
[2m[36m(func pid=39098)[0m f1_per_class: [0.02, 0.387, 0.032, 0.0, 0.083, 0.062, 0.17, 0.031, 0.0, 0.035]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 2.1357 | Steps: 2 | Val loss: 2.1404 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 2.2502 | Steps: 2 | Val loss: 52313.4961 | Batch size: 32 | lr: 0.1 | Duration: 2.63s
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 2.5893 | Steps: 2 | Val loss: 2.3174 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=38679)[0m top1: 0.283115671641791
[2m[36m(func pid=38679)[0m top5: 0.8111007462686567
[2m[36m(func pid=38679)[0m f1_micro: 0.283115671641791
[2m[36m(func pid=38679)[0m f1_macro: 0.2089421272686328
[2m[36m(func pid=38679)[0m f1_weighted: 0.26255312710734646
[2m[36m(func pid=38679)[0m f1_per_class: [0.112, 0.421, 0.327, 0.0, 0.113, 0.211, 0.487, 0.203, 0.066, 0.148]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 1.5285 | Steps: 2 | Val loss: 8.5322 | Batch size: 32 | lr: 0.01 | Duration: 3.06s
== Status ==
Current time: 2024-01-07 02:25:42 (running for 00:01:43.28)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  2.695 |      0.047 |                    9 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  2.136 |      0.209 |                   10 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  2.551 |      0.082 |                    9 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  2.25  |      0.001 |                    9 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=39517)[0m top1: 0.006063432835820896
[2m[36m(func pid=39517)[0m top5: 0.507929104477612
[2m[36m(func pid=39517)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=39517)[0m f1_macro: 0.001212686567164179
[2m[36m(func pid=39517)[0m f1_weighted: 7.353043550902206e-05
[2m[36m(func pid=39517)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38305)[0m top1: 0.11613805970149253
[2m[36m(func pid=38305)[0m top5: 0.5764925373134329
[2m[36m(func pid=38305)[0m f1_micro: 0.11613805970149253
[2m[36m(func pid=38305)[0m f1_macro: 0.05224381159483602
[2m[36m(func pid=38305)[0m f1_weighted: 0.09211961730528588
[2m[36m(func pid=38305)[0m f1_per_class: [0.0, 0.0, 0.023, 0.285, 0.0, 0.0, 0.0, 0.214, 0.0, 0.0]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 2.0744 | Steps: 2 | Val loss: 2.0739 | Batch size: 32 | lr: 0.001 | Duration: 2.72s
[2m[36m(func pid=39098)[0m top1: 0.1166044776119403
[2m[36m(func pid=39098)[0m top5: 0.7201492537313433
[2m[36m(func pid=39098)[0m f1_micro: 0.1166044776119403
[2m[36m(func pid=39098)[0m f1_macro: 0.09688061634296333
[2m[36m(func pid=39098)[0m f1_weighted: 0.0844195986776623
[2m[36m(func pid=39098)[0m f1_per_class: [0.044, 0.393, 0.054, 0.0, 0.25, 0.0, 0.009, 0.182, 0.0, 0.036]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 2.6799 | Steps: 2 | Val loss: 21743.2539 | Batch size: 32 | lr: 0.1 | Duration: 2.71s
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 2.5801 | Steps: 2 | Val loss: 2.3128 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=38679)[0m top1: 0.314365671641791
[2m[36m(func pid=38679)[0m top5: 0.8479477611940298
[2m[36m(func pid=38679)[0m f1_micro: 0.314365671641791
[2m[36m(func pid=38679)[0m f1_macro: 0.21236569679846498
[2m[36m(func pid=38679)[0m f1_weighted: 0.2687087766124009
[2m[36m(func pid=38679)[0m f1_per_class: [0.145, 0.415, 0.421, 0.0, 0.104, 0.128, 0.548, 0.153, 0.076, 0.133]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 1.2075 | Steps: 2 | Val loss: 15.1690 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=39517)[0m top1: 0.008861940298507462
[2m[36m(func pid=39517)[0m top5: 0.5088619402985075
[2m[36m(func pid=39517)[0m f1_micro: 0.008861940298507462
[2m[36m(func pid=39517)[0m f1_macro: 0.01378141991462547
[2m[36m(func pid=39517)[0m f1_weighted: 0.005150325018476475
[2m[36m(func pid=39517)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.111, 0.0, 0.014, 0.0, 0.0, 0.0]
[2m[36m(func pid=39517)[0m 
== Status ==
Current time: 2024-01-07 02:25:47 (running for 00:01:48.32)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  2.589 |      0.052 |                   10 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  2.074 |      0.212 |                   11 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  1.529 |      0.097 |                   10 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  2.68  |      0.014 |                   10 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.08861940298507463
[2m[36m(func pid=38305)[0m top5: 0.5764925373134329
[2m[36m(func pid=38305)[0m f1_micro: 0.08861940298507463
[2m[36m(func pid=38305)[0m f1_macro: 0.05493343985654309
[2m[36m(func pid=38305)[0m f1_weighted: 0.08392300253065935
[2m[36m(func pid=38305)[0m f1_per_class: [0.0, 0.005, 0.019, 0.238, 0.0, 0.0, 0.0, 0.288, 0.0, 0.0]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 2.1307 | Steps: 2 | Val loss: 1.9994 | Batch size: 32 | lr: 0.001 | Duration: 2.76s
[2m[36m(func pid=39098)[0m top1: 0.055970149253731345
[2m[36m(func pid=39098)[0m top5: 0.507929104477612
[2m[36m(func pid=39098)[0m f1_micro: 0.055970149253731345
[2m[36m(func pid=39098)[0m f1_macro: 0.0584004337870909
[2m[36m(func pid=39098)[0m f1_weighted: 0.06794297714184003
[2m[36m(func pid=39098)[0m f1_per_class: [0.007, 0.267, 0.023, 0.066, 0.067, 0.008, 0.0, 0.0, 0.0, 0.145]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 3.5896 | Steps: 2 | Val loss: 2036.6428 | Batch size: 32 | lr: 0.1 | Duration: 2.74s
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 2.5474 | Steps: 2 | Val loss: 2.3090 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=38679)[0m top1: 0.34375
[2m[36m(func pid=38679)[0m top5: 0.867070895522388
[2m[36m(func pid=38679)[0m f1_micro: 0.34375
[2m[36m(func pid=38679)[0m f1_macro: 0.23117801335302612
[2m[36m(func pid=38679)[0m f1_weighted: 0.28357857644188933
[2m[36m(func pid=38679)[0m f1_per_class: [0.183, 0.413, 0.417, 0.0, 0.096, 0.133, 0.576, 0.28, 0.0, 0.214]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 1.5007 | Steps: 2 | Val loss: 24.4238 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
== Status ==
Current time: 2024-01-07 02:25:52 (running for 00:01:53.36)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  2.58  |      0.055 |                   11 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  2.131 |      0.231 |                   12 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  1.208 |      0.058 |                   11 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  3.59  |      0.018 |                   11 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=39517)[0m top1: 0.01632462686567164
[2m[36m(func pid=39517)[0m top5: 0.5153917910447762
[2m[36m(func pid=39517)[0m f1_micro: 0.01632462686567164
[2m[36m(func pid=39517)[0m f1_macro: 0.01796542907152133
[2m[36m(func pid=39517)[0m f1_weighted: 0.018405404833154535
[2m[36m(func pid=39517)[0m f1_per_class: [0.0, 0.0, 0.016, 0.0, 0.1, 0.007, 0.056, 0.0, 0.0, 0.0]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38305)[0m top1: 0.07229477611940298
[2m[36m(func pid=38305)[0m top5: 0.5886194029850746
[2m[36m(func pid=38305)[0m f1_micro: 0.07229477611940298
[2m[36m(func pid=38305)[0m f1_macro: 0.05684978177248168
[2m[36m(func pid=38305)[0m f1_weighted: 0.08168734122906744
[2m[36m(func pid=38305)[0m f1_per_class: [0.0, 0.057, 0.017, 0.195, 0.0, 0.0, 0.0, 0.299, 0.0, 0.0]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 1.8628 | Steps: 2 | Val loss: 1.9344 | Batch size: 32 | lr: 0.001 | Duration: 2.66s
[2m[36m(func pid=39098)[0m top1: 0.04477611940298507
[2m[36m(func pid=39098)[0m top5: 0.435634328358209
[2m[36m(func pid=39098)[0m f1_micro: 0.04477611940298508
[2m[36m(func pid=39098)[0m f1_macro: 0.047149941137453535
[2m[36m(func pid=39098)[0m f1_weighted: 0.06003107181901933
[2m[36m(func pid=39098)[0m f1_per_class: [0.015, 0.141, 0.017, 0.11, 0.0, 0.024, 0.0, 0.0, 0.0, 0.164]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 1.9107 | Steps: 2 | Val loss: 2900.1162 | Batch size: 32 | lr: 0.1 | Duration: 2.64s
[2m[36m(func pid=38679)[0m top1: 0.324160447761194
[2m[36m(func pid=38679)[0m top5: 0.8805970149253731
[2m[36m(func pid=38679)[0m f1_micro: 0.324160447761194
[2m[36m(func pid=38679)[0m f1_macro: 0.24691136162840918
[2m[36m(func pid=38679)[0m f1_weighted: 0.26178353339312743
[2m[36m(func pid=38679)[0m f1_per_class: [0.291, 0.419, 0.423, 0.0, 0.093, 0.123, 0.485, 0.312, 0.0, 0.323]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 2.5190 | Steps: 2 | Val loss: 2.3015 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 1.4981 | Steps: 2 | Val loss: 26.3916 | Batch size: 32 | lr: 0.01 | Duration: 2.76s
[2m[36m(func pid=39517)[0m top1: 0.006996268656716418
[2m[36m(func pid=39517)[0m top5: 0.5172574626865671
[2m[36m(func pid=39517)[0m f1_micro: 0.006996268656716418
[2m[36m(func pid=39517)[0m f1_macro: 0.0026073180720703124
[2m[36m(func pid=39517)[0m f1_weighted: 0.0019166711363670138
[2m[36m(func pid=39517)[0m f1_per_class: [0.0, 0.0, 0.015, 0.0, 0.0, 0.008, 0.003, 0.0, 0.0, 0.0]
[2m[36m(func pid=39517)[0m 
== Status ==
Current time: 2024-01-07 02:25:58 (running for 00:01:59.44)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  2.519 |      0.055 |                   13 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  1.863 |      0.247 |                   13 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  1.501 |      0.047 |                   12 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.911 |      0.003 |                   12 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.06576492537313433
[2m[36m(func pid=38305)[0m top5: 0.5993470149253731
[2m[36m(func pid=38305)[0m f1_micro: 0.06576492537313433
[2m[36m(func pid=38305)[0m f1_macro: 0.05494998507076691
[2m[36m(func pid=38305)[0m f1_weighted: 0.07884900536575877
[2m[36m(func pid=38305)[0m f1_per_class: [0.0, 0.108, 0.017, 0.161, 0.0, 0.0, 0.0, 0.264, 0.0, 0.0]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 1.8190 | Steps: 2 | Val loss: 1.8934 | Batch size: 32 | lr: 0.001 | Duration: 2.78s
[2m[36m(func pid=39098)[0m top1: 0.03404850746268657
[2m[36m(func pid=39098)[0m top5: 0.45988805970149255
[2m[36m(func pid=39098)[0m f1_micro: 0.03404850746268657
[2m[36m(func pid=39098)[0m f1_macro: 0.027082802217422354
[2m[36m(func pid=39098)[0m f1_weighted: 0.03427451130053602
[2m[36m(func pid=39098)[0m f1_per_class: [0.025, 0.172, 0.031, 0.013, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 1.9009 | Steps: 2 | Val loss: 4386.1108 | Batch size: 32 | lr: 0.1 | Duration: 2.71s
[2m[36m(func pid=38679)[0m top1: 0.2933768656716418
[2m[36m(func pid=38679)[0m top5: 0.8941231343283582
[2m[36m(func pid=38679)[0m f1_micro: 0.2933768656716418
[2m[36m(func pid=38679)[0m f1_macro: 0.20698533484974183
[2m[36m(func pid=38679)[0m f1_weighted: 0.22580571270103852
[2m[36m(func pid=38679)[0m f1_per_class: [0.074, 0.415, 0.379, 0.0, 0.074, 0.14, 0.371, 0.354, 0.0, 0.263]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 2.6373 | Steps: 2 | Val loss: 2.2983 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=39517)[0m top1: 0.0065298507462686565
[2m[36m(func pid=39517)[0m top5: 0.5237873134328358
[2m[36m(func pid=39517)[0m f1_micro: 0.0065298507462686565
[2m[36m(func pid=39517)[0m f1_macro: 0.0016256829313502797
[2m[36m(func pid=39517)[0m f1_weighted: 0.0010053349626667556
[2m[36m(func pid=39517)[0m f1_per_class: [0.0, 0.0, 0.013, 0.0, 0.0, 0.0, 0.003, 0.0, 0.0, 0.0]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 1.3057 | Steps: 2 | Val loss: 30.3982 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 1.7552 | Steps: 2 | Val loss: 1.8828 | Batch size: 32 | lr: 0.001 | Duration: 2.58s
== Status ==
Current time: 2024-01-07 02:26:03 (running for 00:02:04.64)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  2.637 |      0.051 |                   14 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  1.819 |      0.207 |                   14 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  1.498 |      0.027 |                   13 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.901 |      0.002 |                   13 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.06623134328358209
[2m[36m(func pid=38305)[0m top5: 0.6072761194029851
[2m[36m(func pid=38305)[0m f1_micro: 0.06623134328358209
[2m[36m(func pid=38305)[0m f1_macro: 0.05073082430268585
[2m[36m(func pid=38305)[0m f1_weighted: 0.07946519324684814
[2m[36m(func pid=38305)[0m f1_per_class: [0.0, 0.178, 0.017, 0.139, 0.0, 0.0, 0.0, 0.174, 0.0, 0.0]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39098)[0m top1: 0.03171641791044776
[2m[36m(func pid=39098)[0m top5: 0.40625
[2m[36m(func pid=39098)[0m f1_micro: 0.03171641791044776
[2m[36m(func pid=39098)[0m f1_macro: 0.025780858637390214
[2m[36m(func pid=39098)[0m f1_weighted: 0.031922164535585926
[2m[36m(func pid=39098)[0m f1_per_class: [0.0, 0.155, 0.03, 0.003, 0.0, 0.032, 0.0, 0.0, 0.0, 0.037]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 1.8872 | Steps: 2 | Val loss: 5838.9604 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
[2m[36m(func pid=38679)[0m top1: 0.2658582089552239
[2m[36m(func pid=38679)[0m top5: 0.8978544776119403
[2m[36m(func pid=38679)[0m f1_micro: 0.2658582089552239
[2m[36m(func pid=38679)[0m f1_macro: 0.16679740785109903
[2m[36m(func pid=38679)[0m f1_weighted: 0.18175454573864783
[2m[36m(func pid=38679)[0m f1_per_class: [0.0, 0.422, 0.373, 0.0, 0.081, 0.064, 0.258, 0.361, 0.0, 0.109]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 2.6650 | Steps: 2 | Val loss: 2.2987 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=39517)[0m top1: 0.007462686567164179
[2m[36m(func pid=39517)[0m top5: 0.523320895522388
[2m[36m(func pid=39517)[0m f1_micro: 0.007462686567164179
[2m[36m(func pid=39517)[0m f1_macro: 0.009572283747381023
[2m[36m(func pid=39517)[0m f1_weighted: 0.001590741946508106
[2m[36m(func pid=39517)[0m f1_per_class: [0.0, 0.0, 0.013, 0.0, 0.08, 0.0, 0.003, 0.0, 0.0, 0.0]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 1.4068 | Steps: 2 | Val loss: 42.9093 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 1.5653 | Steps: 2 | Val loss: 1.8927 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
== Status ==
Current time: 2024-01-07 02:26:09 (running for 00:02:09.91)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  2.665 |      0.047 |                   15 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  1.755 |      0.167 |                   15 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  1.306 |      0.026 |                   14 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.887 |      0.01  |                   14 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.0708955223880597
[2m[36m(func pid=38305)[0m top5: 0.6189365671641791
[2m[36m(func pid=38305)[0m f1_micro: 0.0708955223880597
[2m[36m(func pid=38305)[0m f1_macro: 0.04685468100040866
[2m[36m(func pid=38305)[0m f1_weighted: 0.0780528580649648
[2m[36m(func pid=38305)[0m f1_per_class: [0.0, 0.245, 0.018, 0.106, 0.0, 0.008, 0.0, 0.092, 0.0, 0.0]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 1.8959 | Steps: 2 | Val loss: 5087.8438 | Batch size: 32 | lr: 0.1 | Duration: 2.67s
[2m[36m(func pid=39098)[0m top1: 0.02751865671641791
[2m[36m(func pid=39098)[0m top5: 0.373134328358209
[2m[36m(func pid=39098)[0m f1_micro: 0.02751865671641791
[2m[36m(func pid=39098)[0m f1_macro: 0.04959802289826958
[2m[36m(func pid=39098)[0m f1_weighted: 0.019768421680853954
[2m[36m(func pid=39098)[0m f1_per_class: [0.0, 0.061, 0.027, 0.0, 0.319, 0.056, 0.0, 0.0, 0.0, 0.034]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=38679)[0m top1: 0.23647388059701493
[2m[36m(func pid=38679)[0m top5: 0.8861940298507462
[2m[36m(func pid=38679)[0m f1_micro: 0.23647388059701493
[2m[36m(func pid=38679)[0m f1_macro: 0.1490215574886866
[2m[36m(func pid=38679)[0m f1_weighted: 0.14024718467678543
[2m[36m(func pid=38679)[0m f1_per_class: [0.0, 0.423, 0.386, 0.019, 0.078, 0.008, 0.117, 0.39, 0.0, 0.069]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 2.4350 | Steps: 2 | Val loss: 2.2968 | Batch size: 32 | lr: 0.0001 | Duration: 2.78s
[2m[36m(func pid=39517)[0m top1: 0.007462686567164179
[2m[36m(func pid=39517)[0m top5: 0.5289179104477612
[2m[36m(func pid=39517)[0m f1_micro: 0.007462686567164179
[2m[36m(func pid=39517)[0m f1_macro: 0.008993843237131073
[2m[36m(func pid=39517)[0m f1_weighted: 0.001548760992901659
[2m[36m(func pid=39517)[0m f1_per_class: [0.0, 0.0, 0.013, 0.0, 0.074, 0.0, 0.003, 0.0, 0.0, 0.0]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 1.5648 | Steps: 2 | Val loss: 1.9001 | Batch size: 32 | lr: 0.001 | Duration: 2.58s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 2.1798 | Steps: 2 | Val loss: 26.6720 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
== Status ==
Current time: 2024-01-07 02:26:14 (running for 00:02:14.98)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  2.435 |      0.055 |                   16 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  1.565 |      0.149 |                   16 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  1.407 |      0.05  |                   15 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.896 |      0.009 |                   15 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.0853544776119403
[2m[36m(func pid=38305)[0m top5: 0.6380597014925373
[2m[36m(func pid=38305)[0m f1_micro: 0.0853544776119403
[2m[36m(func pid=38305)[0m f1_macro: 0.0547288647398233
[2m[36m(func pid=38305)[0m f1_weighted: 0.08397818159228891
[2m[36m(func pid=38305)[0m f1_per_class: [0.029, 0.311, 0.021, 0.069, 0.0, 0.053, 0.003, 0.061, 0.0, 0.0]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 4.6419 | Steps: 2 | Val loss: 12398.7578 | Batch size: 32 | lr: 0.1 | Duration: 2.67s
[2m[36m(func pid=38679)[0m top1: 0.23227611940298507
[2m[36m(func pid=38679)[0m top5: 0.8824626865671642
[2m[36m(func pid=38679)[0m f1_micro: 0.23227611940298507
[2m[36m(func pid=38679)[0m f1_macro: 0.1482679361273106
[2m[36m(func pid=38679)[0m f1_weighted: 0.1415311404913584
[2m[36m(func pid=38679)[0m f1_per_class: [0.0, 0.44, 0.361, 0.102, 0.074, 0.0, 0.036, 0.395, 0.0, 0.075]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=39098)[0m top1: 0.07416044776119403
[2m[36m(func pid=39098)[0m top5: 0.3885261194029851
[2m[36m(func pid=39098)[0m f1_micro: 0.07416044776119403
[2m[36m(func pid=39098)[0m f1_macro: 0.062172401550205536
[2m[36m(func pid=39098)[0m f1_weighted: 0.04854150043540598
[2m[36m(func pid=39098)[0m f1_per_class: [0.0, 0.267, 0.085, 0.0, 0.237, 0.0, 0.0, 0.0, 0.0, 0.034]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 2.4303 | Steps: 2 | Val loss: 2.2968 | Batch size: 32 | lr: 0.0001 | Duration: 2.75s
[2m[36m(func pid=39517)[0m top1: 0.006063432835820896
[2m[36m(func pid=39517)[0m top5: 0.5088619402985075
[2m[36m(func pid=39517)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=39517)[0m f1_macro: 0.001222378937470616
[2m[36m(func pid=39517)[0m f1_weighted: 7.41181258727519e-05
[2m[36m(func pid=39517)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 1.4292 | Steps: 2 | Val loss: 1.8661 | Batch size: 32 | lr: 0.001 | Duration: 2.61s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 1.9933 | Steps: 2 | Val loss: 113.0898 | Batch size: 32 | lr: 0.01 | Duration: 2.73s
== Status ==
Current time: 2024-01-07 02:26:19 (running for 00:02:20.17)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  2.43  |      0.082 |                   17 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  1.565 |      0.148 |                   17 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  2.18  |      0.062 |                   16 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  4.642 |      0.001 |                   16 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.11194029850746269
[2m[36m(func pid=38305)[0m top5: 0.667910447761194
[2m[36m(func pid=38305)[0m f1_micro: 0.11194029850746269
[2m[36m(func pid=38305)[0m f1_macro: 0.08244875906683921
[2m[36m(func pid=38305)[0m f1_weighted: 0.11748394170931602
[2m[36m(func pid=38305)[0m f1_per_class: [0.021, 0.354, 0.03, 0.04, 0.0, 0.219, 0.045, 0.099, 0.016, 0.0]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 1.7206 | Steps: 2 | Val loss: 13057.0137 | Batch size: 32 | lr: 0.1 | Duration: 2.73s
[2m[36m(func pid=38679)[0m top1: 0.259794776119403
[2m[36m(func pid=38679)[0m top5: 0.8824626865671642
[2m[36m(func pid=38679)[0m f1_micro: 0.259794776119403
[2m[36m(func pid=38679)[0m f1_macro: 0.16726743683178918
[2m[36m(func pid=38679)[0m f1_weighted: 0.18256297942406824
[2m[36m(func pid=38679)[0m f1_per_class: [0.0, 0.463, 0.361, 0.205, 0.063, 0.055, 0.045, 0.384, 0.0, 0.097]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=39098)[0m top1: 0.010261194029850746
[2m[36m(func pid=39098)[0m top5: 0.25886194029850745
[2m[36m(func pid=39098)[0m f1_micro: 0.010261194029850746
[2m[36m(func pid=39098)[0m f1_macro: 0.018190348967668496
[2m[36m(func pid=39098)[0m f1_weighted: 0.004003040658766024
[2m[36m(func pid=39098)[0m f1_per_class: [0.0, 0.011, 0.018, 0.0, 0.133, 0.008, 0.0, 0.0, 0.0, 0.012]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 2.4548 | Steps: 2 | Val loss: 2.2999 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=39517)[0m top1: 0.006063432835820896
[2m[36m(func pid=39517)[0m top5: 0.507929104477612
[2m[36m(func pid=39517)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=39517)[0m f1_macro: 0.0012070566388115134
[2m[36m(func pid=39517)[0m f1_weighted: 7.318906858465332e-05
[2m[36m(func pid=39517)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 1.5454 | Steps: 2 | Val loss: 1.8155 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 1.5742 | Steps: 2 | Val loss: 177.5011 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
== Status ==
Current time: 2024-01-07 02:26:24 (running for 00:02:25.60)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  2.455 |      0.099 |                   18 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  1.429 |      0.167 |                   18 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  1.993 |      0.018 |                   17 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.721 |      0.001 |                   17 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.12360074626865672
[2m[36m(func pid=38305)[0m top5: 0.7215485074626866
[2m[36m(func pid=38305)[0m f1_micro: 0.12360074626865672
[2m[36m(func pid=38305)[0m f1_macro: 0.09899345286633351
[2m[36m(func pid=38305)[0m f1_weighted: 0.14347426720320136
[2m[36m(func pid=38305)[0m f1_per_class: [0.026, 0.377, 0.039, 0.019, 0.0, 0.257, 0.116, 0.138, 0.019, 0.0]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 8.1373 | Steps: 2 | Val loss: 4469.3691 | Batch size: 32 | lr: 0.1 | Duration: 2.71s
[2m[36m(func pid=38679)[0m top1: 0.2971082089552239
[2m[36m(func pid=38679)[0m top5: 0.8922574626865671
[2m[36m(func pid=38679)[0m f1_micro: 0.2971082089552239
[2m[36m(func pid=38679)[0m f1_macro: 0.20863558253675643
[2m[36m(func pid=38679)[0m f1_weighted: 0.23707362229594361
[2m[36m(func pid=38679)[0m f1_per_class: [0.083, 0.493, 0.333, 0.29, 0.076, 0.196, 0.074, 0.352, 0.0, 0.189]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=39098)[0m top1: 0.010727611940298507
[2m[36m(func pid=39098)[0m top5: 0.2332089552238806
[2m[36m(func pid=39098)[0m f1_micro: 0.010727611940298507
[2m[36m(func pid=39098)[0m f1_macro: 0.014842419624966411
[2m[36m(func pid=39098)[0m f1_weighted: 0.005618992110058145
[2m[36m(func pid=39098)[0m f1_per_class: [0.0, 0.011, 0.015, 0.0, 0.095, 0.0, 0.009, 0.0, 0.0, 0.018]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 2.4609 | Steps: 2 | Val loss: 2.3050 | Batch size: 32 | lr: 0.0001 | Duration: 2.78s
[2m[36m(func pid=39517)[0m top1: 0.006063432835820896
[2m[36m(func pid=39517)[0m top5: 0.5107276119402985
[2m[36m(func pid=39517)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=39517)[0m f1_macro: 0.001207617278216442
[2m[36m(func pid=39517)[0m f1_weighted: 7.322306257842233e-05
[2m[36m(func pid=39517)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 1.3771 | Steps: 2 | Val loss: 1.8055 | Batch size: 32 | lr: 0.001 | Duration: 2.74s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 1.8360 | Steps: 2 | Val loss: 149.1488 | Batch size: 32 | lr: 0.01 | Duration: 2.64s
== Status ==
Current time: 2024-01-07 02:26:30 (running for 00:02:30.86)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  2.461 |      0.1   |                   19 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  1.545 |      0.209 |                   19 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  1.574 |      0.015 |                   18 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  8.137 |      0.001 |                   18 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.125
[2m[36m(func pid=38305)[0m top5: 0.7523320895522388
[2m[36m(func pid=38305)[0m f1_micro: 0.125
[2m[36m(func pid=38305)[0m f1_macro: 0.09985244569212286
[2m[36m(func pid=38305)[0m f1_weighted: 0.15102324281062054
[2m[36m(func pid=38305)[0m f1_per_class: [0.027, 0.386, 0.055, 0.003, 0.0, 0.23, 0.168, 0.089, 0.041, 0.0]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 2.0541 | Steps: 2 | Val loss: 2282.1914 | Batch size: 32 | lr: 0.1 | Duration: 2.73s
[2m[36m(func pid=38679)[0m top1: 0.34654850746268656
[2m[36m(func pid=38679)[0m top5: 0.894589552238806
[2m[36m(func pid=38679)[0m f1_micro: 0.34654850746268656
[2m[36m(func pid=38679)[0m f1_macro: 0.2586934267345188
[2m[36m(func pid=38679)[0m f1_weighted: 0.3152086412495813
[2m[36m(func pid=38679)[0m f1_per_class: [0.095, 0.5, 0.253, 0.366, 0.074, 0.321, 0.19, 0.407, 0.076, 0.304]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=39098)[0m top1: 0.01958955223880597
[2m[36m(func pid=39098)[0m top5: 0.22994402985074627
[2m[36m(func pid=39098)[0m f1_micro: 0.01958955223880597
[2m[36m(func pid=39098)[0m f1_macro: 0.02668893904377235
[2m[36m(func pid=39098)[0m f1_weighted: 0.021942517476520214
[2m[36m(func pid=39098)[0m f1_per_class: [0.0, 0.068, 0.016, 0.007, 0.095, 0.016, 0.015, 0.0, 0.026, 0.024]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=39517)[0m top1: 0.008395522388059701
[2m[36m(func pid=39517)[0m top5: 0.511660447761194
[2m[36m(func pid=39517)[0m f1_micro: 0.008395522388059701
[2m[36m(func pid=39517)[0m f1_macro: 0.0034478400991064966
[2m[36m(func pid=39517)[0m f1_weighted: 0.00470072455901063
[2m[36m(func pid=39517)[0m f1_per_class: [0.0, 0.016, 0.012, 0.0, 0.0, 0.0, 0.006, 0.0, 0.0, 0.0]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 2.4317 | Steps: 2 | Val loss: 2.3076 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 1.1935 | Steps: 2 | Val loss: 1.8273 | Batch size: 32 | lr: 0.001 | Duration: 2.64s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 2.3321 | Steps: 2 | Val loss: 107.2833 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 02:26:35 (running for 00:02:36.22)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  2.432 |      0.11  |                   20 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  1.377 |      0.259 |                   20 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  1.836 |      0.027 |                   19 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  2.054 |      0.003 |                   19 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.11893656716417911
[2m[36m(func pid=38305)[0m top5: 0.7714552238805971
[2m[36m(func pid=38305)[0m f1_micro: 0.11893656716417911
[2m[36m(func pid=38305)[0m f1_macro: 0.10960190822527474
[2m[36m(func pid=38305)[0m f1_weighted: 0.15462606086057626
[2m[36m(func pid=38305)[0m f1_per_class: [0.027, 0.342, 0.072, 0.003, 0.1, 0.191, 0.213, 0.116, 0.032, 0.0]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 15.1754 | Steps: 2 | Val loss: 792.3360 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
[2m[36m(func pid=38679)[0m top1: 0.3568097014925373
[2m[36m(func pid=38679)[0m top5: 0.8927238805970149
[2m[36m(func pid=38679)[0m f1_micro: 0.3568097014925374
[2m[36m(func pid=38679)[0m f1_macro: 0.27373493622257505
[2m[36m(func pid=38679)[0m f1_weighted: 0.3328716617419072
[2m[36m(func pid=38679)[0m f1_per_class: [0.214, 0.513, 0.229, 0.412, 0.086, 0.321, 0.194, 0.409, 0.05, 0.309]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=39098)[0m top1: 0.024720149253731342
[2m[36m(func pid=39098)[0m top5: 0.25326492537313433
[2m[36m(func pid=39098)[0m f1_micro: 0.024720149253731342
[2m[36m(func pid=39098)[0m f1_macro: 0.02166371357189985
[2m[36m(func pid=39098)[0m f1_weighted: 0.02894834624601889
[2m[36m(func pid=39098)[0m f1_per_class: [0.007, 0.133, 0.016, 0.003, 0.0, 0.016, 0.009, 0.0, 0.0, 0.032]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=39517)[0m top1: 0.012126865671641791
[2m[36m(func pid=39517)[0m top5: 0.5135261194029851
[2m[36m(func pid=39517)[0m f1_micro: 0.012126865671641791
[2m[36m(func pid=39517)[0m f1_macro: 0.009523744466697043
[2m[36m(func pid=39517)[0m f1_weighted: 0.011062548494513618
[2m[36m(func pid=39517)[0m f1_per_class: [0.0, 0.057, 0.013, 0.0, 0.0, 0.0, 0.003, 0.0, 0.0, 0.022]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 2.3968 | Steps: 2 | Val loss: 2.3095 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 1.1774 | Steps: 2 | Val loss: 1.8956 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 1.1144 | Steps: 2 | Val loss: 68.0147 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 1.8810 | Steps: 2 | Val loss: 466.7181 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
== Status ==
Current time: 2024-01-07 02:26:40 (running for 00:02:41.50)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  2.397 |      0.128 |                   21 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  1.194 |      0.274 |                   21 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  2.332 |      0.022 |                   20 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      | 15.175 |      0.01  |                   20 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.12313432835820895
[2m[36m(func pid=38305)[0m top5: 0.7784514925373134
[2m[36m(func pid=38305)[0m f1_micro: 0.12313432835820895
[2m[36m(func pid=38305)[0m f1_macro: 0.12815595318959686
[2m[36m(func pid=38305)[0m f1_weighted: 0.1606409083100924
[2m[36m(func pid=38305)[0m f1_per_class: [0.032, 0.321, 0.091, 0.003, 0.25, 0.122, 0.256, 0.17, 0.035, 0.0]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=38679)[0m top1: 0.34701492537313433
[2m[36m(func pid=38679)[0m top5: 0.8838619402985075
[2m[36m(func pid=38679)[0m f1_micro: 0.34701492537313433
[2m[36m(func pid=38679)[0m f1_macro: 0.27811507683662673
[2m[36m(func pid=38679)[0m f1_weighted: 0.3254352467107483
[2m[36m(func pid=38679)[0m f1_per_class: [0.217, 0.523, 0.245, 0.436, 0.092, 0.332, 0.127, 0.392, 0.175, 0.242]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=39098)[0m top1: 0.043843283582089554
[2m[36m(func pid=39098)[0m top5: 0.2994402985074627
[2m[36m(func pid=39098)[0m f1_micro: 0.043843283582089554
[2m[36m(func pid=39098)[0m f1_macro: 0.05774830060346142
[2m[36m(func pid=39098)[0m f1_weighted: 0.054014457557366904
[2m[36m(func pid=39098)[0m f1_per_class: [0.013, 0.248, 0.018, 0.0, 0.211, 0.04, 0.015, 0.0, 0.0, 0.033]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=39517)[0m top1: 0.020522388059701493
[2m[36m(func pid=39517)[0m top5: 0.5424440298507462
[2m[36m(func pid=39517)[0m f1_micro: 0.020522388059701493
[2m[36m(func pid=39517)[0m f1_macro: 0.02291677434936117
[2m[36m(func pid=39517)[0m f1_weighted: 0.02512354933920488
[2m[36m(func pid=39517)[0m f1_per_class: [0.0, 0.113, 0.015, 0.01, 0.062, 0.008, 0.003, 0.007, 0.0, 0.011]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 2.2838 | Steps: 2 | Val loss: 2.3075 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 1.2438 | Steps: 2 | Val loss: 2.0067 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 1.1352 | Steps: 2 | Val loss: 37.7967 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 2.0145 | Steps: 2 | Val loss: 184.1252 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 02:26:46 (running for 00:02:46.82)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  2.284 |      0.121 |                   22 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  1.177 |      0.278 |                   22 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  1.114 |      0.058 |                   21 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.881 |      0.023 |                   21 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.12360074626865672
[2m[36m(func pid=38305)[0m top5: 0.7565298507462687
[2m[36m(func pid=38305)[0m f1_micro: 0.12360074626865672
[2m[36m(func pid=38305)[0m f1_macro: 0.12058155798239298
[2m[36m(func pid=38305)[0m f1_weighted: 0.1604538350454317
[2m[36m(func pid=38305)[0m f1_per_class: [0.036, 0.303, 0.114, 0.0, 0.188, 0.115, 0.28, 0.129, 0.042, 0.0]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=38679)[0m top1: 0.32369402985074625
[2m[36m(func pid=38679)[0m top5: 0.8782649253731343
[2m[36m(func pid=38679)[0m f1_micro: 0.32369402985074625
[2m[36m(func pid=38679)[0m f1_macro: 0.266680545819582
[2m[36m(func pid=38679)[0m f1_weighted: 0.3170527977556698
[2m[36m(func pid=38679)[0m f1_per_class: [0.165, 0.519, 0.27, 0.415, 0.094, 0.317, 0.133, 0.397, 0.146, 0.209]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=39098)[0m top1: 0.05503731343283582
[2m[36m(func pid=39098)[0m top5: 0.41744402985074625
[2m[36m(func pid=39098)[0m f1_micro: 0.05503731343283582
[2m[36m(func pid=39098)[0m f1_macro: 0.06076938874408677
[2m[36m(func pid=39098)[0m f1_weighted: 0.0631568124866617
[2m[36m(func pid=39098)[0m f1_per_class: [0.014, 0.288, 0.021, 0.0, 0.167, 0.016, 0.024, 0.041, 0.0, 0.036]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=39517)[0m top1: 0.021455223880597014
[2m[36m(func pid=39517)[0m top5: 0.49113805970149255
[2m[36m(func pid=39517)[0m f1_micro: 0.021455223880597014
[2m[36m(func pid=39517)[0m f1_macro: 0.0187741785753676
[2m[36m(func pid=39517)[0m f1_weighted: 0.0236920603137438
[2m[36m(func pid=39517)[0m f1_per_class: [0.0, 0.091, 0.02, 0.016, 0.0, 0.021, 0.0, 0.011, 0.0, 0.029]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 2.3519 | Steps: 2 | Val loss: 2.3094 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 1.0931 | Steps: 2 | Val loss: 2.1930 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 1.0483 | Steps: 2 | Val loss: 32.4556 | Batch size: 32 | lr: 0.01 | Duration: 2.75s
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 12.9621 | Steps: 2 | Val loss: 113.1555 | Batch size: 32 | lr: 0.1 | Duration: 2.69s
== Status ==
Current time: 2024-01-07 02:26:51 (running for 00:02:52.07)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  2.352 |      0.116 |                   23 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  1.244 |      0.267 |                   23 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  1.135 |      0.061 |                   22 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  2.015 |      0.019 |                   22 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.12033582089552239
[2m[36m(func pid=38305)[0m top5: 0.7280783582089553
[2m[36m(func pid=38305)[0m f1_micro: 0.12033582089552239
[2m[36m(func pid=38305)[0m f1_macro: 0.11632033313311123
[2m[36m(func pid=38305)[0m f1_weighted: 0.15496142429510856
[2m[36m(func pid=38305)[0m f1_per_class: [0.04, 0.288, 0.137, 0.0, 0.165, 0.1, 0.279, 0.117, 0.038, 0.0]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=38679)[0m top1: 0.2947761194029851
[2m[36m(func pid=38679)[0m top5: 0.8759328358208955
[2m[36m(func pid=38679)[0m f1_micro: 0.2947761194029851
[2m[36m(func pid=38679)[0m f1_macro: 0.25601326651055634
[2m[36m(func pid=38679)[0m f1_weighted: 0.3112465096899945
[2m[36m(func pid=38679)[0m f1_per_class: [0.13, 0.51, 0.293, 0.356, 0.092, 0.267, 0.189, 0.453, 0.135, 0.135]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=39517)[0m top1: 0.08675373134328358
[2m[36m(func pid=39517)[0m top5: 0.5461753731343284
[2m[36m(func pid=39517)[0m f1_micro: 0.08675373134328358
[2m[36m(func pid=39517)[0m f1_macro: 0.050906966184128336
[2m[36m(func pid=39517)[0m f1_weighted: 0.05900400442438459
[2m[36m(func pid=39517)[0m f1_per_class: [0.0, 0.232, 0.118, 0.036, 0.0, 0.022, 0.0, 0.102, 0.0, 0.0]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=39098)[0m top1: 0.04757462686567164
[2m[36m(func pid=39098)[0m top5: 0.5111940298507462
[2m[36m(func pid=39098)[0m f1_micro: 0.04757462686567164
[2m[36m(func pid=39098)[0m f1_macro: 0.04522655488854411
[2m[36m(func pid=39098)[0m f1_weighted: 0.03937812138480895
[2m[36m(func pid=39098)[0m f1_per_class: [0.0, 0.06, 0.026, 0.0, 0.139, 0.0, 0.069, 0.118, 0.0, 0.041]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 2.2543 | Steps: 2 | Val loss: 2.2920 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.9470 | Steps: 2 | Val loss: 2.2354 | Batch size: 32 | lr: 0.001 | Duration: 2.78s
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 3.9011 | Steps: 2 | Val loss: 197.3894 | Batch size: 32 | lr: 0.1 | Duration: 2.66s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 3.0071 | Steps: 2 | Val loss: 50.1650 | Batch size: 32 | lr: 0.01 | Duration: 3.05s
== Status ==
Current time: 2024-01-07 02:26:56 (running for 00:02:57.26)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  2.254 |      0.115 |                   24 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  1.093 |      0.256 |                   24 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  1.048 |      0.045 |                   23 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      | 12.962 |      0.051 |                   23 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.12919776119402984
[2m[36m(func pid=38305)[0m top5: 0.7276119402985075
[2m[36m(func pid=38305)[0m f1_micro: 0.12919776119402984
[2m[36m(func pid=38305)[0m f1_macro: 0.11546400057147344
[2m[36m(func pid=38305)[0m f1_weighted: 0.16096938974261507
[2m[36m(func pid=38305)[0m f1_per_class: [0.044, 0.26, 0.171, 0.0, 0.136, 0.113, 0.319, 0.06, 0.052, 0.0]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=38679)[0m top1: 0.29757462686567165
[2m[36m(func pid=38679)[0m top5: 0.8847947761194029
[2m[36m(func pid=38679)[0m f1_micro: 0.29757462686567165
[2m[36m(func pid=38679)[0m f1_macro: 0.2630628960248321
[2m[36m(func pid=38679)[0m f1_weighted: 0.3230699428240327
[2m[36m(func pid=38679)[0m f1_per_class: [0.123, 0.502, 0.328, 0.327, 0.116, 0.262, 0.266, 0.425, 0.133, 0.147]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=39517)[0m top1: 0.13059701492537312
[2m[36m(func pid=39517)[0m top5: 0.6124067164179104
[2m[36m(func pid=39517)[0m f1_micro: 0.13059701492537312
[2m[36m(func pid=39517)[0m f1_macro: 0.06450376305292745
[2m[36m(func pid=39517)[0m f1_weighted: 0.07394699172693044
[2m[36m(func pid=39517)[0m f1_per_class: [0.0, 0.293, 0.0, 0.041, 0.105, 0.008, 0.0, 0.154, 0.043, 0.0]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=39098)[0m top1: 0.05317164179104478
[2m[36m(func pid=39098)[0m top5: 0.4300373134328358
[2m[36m(func pid=39098)[0m f1_micro: 0.05317164179104478
[2m[36m(func pid=39098)[0m f1_macro: 0.05202653239666573
[2m[36m(func pid=39098)[0m f1_weighted: 0.044563222214850436
[2m[36m(func pid=39098)[0m f1_per_class: [0.008, 0.02, 0.029, 0.003, 0.171, 0.0, 0.097, 0.161, 0.0, 0.031]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 2.3433 | Steps: 2 | Val loss: 2.2870 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.9453 | Steps: 2 | Val loss: 2.2636 | Batch size: 32 | lr: 0.001 | Duration: 2.73s
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 5.8245 | Steps: 2 | Val loss: 432.8643 | Batch size: 32 | lr: 0.1 | Duration: 2.78s
== Status ==
Current time: 2024-01-07 02:27:01 (running for 00:03:02.51)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  2.254 |      0.115 |                   24 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.945 |      0.26  |                   26 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  3.007 |      0.052 |                   24 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  3.901 |      0.065 |                   24 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38679)[0m top1: 0.3003731343283582
[2m[36m(func pid=38679)[0m top5: 0.8889925373134329
[2m[36m(func pid=38679)[0m f1_micro: 0.3003731343283582
[2m[36m(func pid=38679)[0m f1_macro: 0.2595015314857238
[2m[36m(func pid=38679)[0m f1_weighted: 0.3199565534803951
[2m[36m(func pid=38679)[0m f1_per_class: [0.129, 0.512, 0.333, 0.256, 0.115, 0.192, 0.34, 0.445, 0.127, 0.146]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.9288 | Steps: 2 | Val loss: 79.2938 | Batch size: 32 | lr: 0.01 | Duration: 2.73s
[2m[36m(func pid=38305)[0m top1: 0.13386194029850745
[2m[36m(func pid=38305)[0m top5: 0.7280783582089553
[2m[36m(func pid=38305)[0m f1_micro: 0.13386194029850745
[2m[36m(func pid=38305)[0m f1_macro: 0.11485256037306424
[2m[36m(func pid=38305)[0m f1_weighted: 0.16149668201505477
[2m[36m(func pid=38305)[0m f1_per_class: [0.043, 0.234, 0.193, 0.0, 0.168, 0.087, 0.352, 0.03, 0.041, 0.0]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39517)[0m top1: 0.07416044776119403
[2m[36m(func pid=39517)[0m top5: 0.5830223880597015
[2m[36m(func pid=39517)[0m f1_micro: 0.07416044776119403
[2m[36m(func pid=39517)[0m f1_macro: 0.04242025756686309
[2m[36m(func pid=39517)[0m f1_weighted: 0.035906488552652514
[2m[36m(func pid=39517)[0m f1_per_class: [0.0, 0.052, 0.04, 0.055, 0.095, 0.0, 0.003, 0.163, 0.0, 0.015]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=39098)[0m top1: 0.055970149253731345
[2m[36m(func pid=39098)[0m top5: 0.43843283582089554
[2m[36m(func pid=39098)[0m f1_micro: 0.055970149253731345
[2m[36m(func pid=39098)[0m f1_macro: 0.056363127045637465
[2m[36m(func pid=39098)[0m f1_weighted: 0.04203355410835349
[2m[36m(func pid=39098)[0m f1_per_class: [0.055, 0.02, 0.0, 0.003, 0.222, 0.008, 0.087, 0.128, 0.0, 0.039]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 1.2184 | Steps: 2 | Val loss: 2.2291 | Batch size: 32 | lr: 0.001 | Duration: 2.68s
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 2.1625 | Steps: 2 | Val loss: 2.2685 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 1.9870 | Steps: 2 | Val loss: 1042.1917 | Batch size: 32 | lr: 0.1 | Duration: 2.66s
[2m[36m(func pid=38679)[0m top1: 0.31343283582089554
[2m[36m(func pid=38679)[0m top5: 0.8903917910447762
[2m[36m(func pid=38679)[0m f1_micro: 0.31343283582089554
[2m[36m(func pid=38679)[0m f1_macro: 0.2578891928605332
[2m[36m(func pid=38679)[0m f1_weighted: 0.3136455166159451
[2m[36m(func pid=38679)[0m f1_per_class: [0.149, 0.535, 0.31, 0.202, 0.099, 0.184, 0.36, 0.436, 0.12, 0.184]
[2m[36m(func pid=38679)[0m 
== Status ==
Current time: 2024-01-07 02:27:06 (running for 00:03:07.79)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  2.163 |      0.128 |                   26 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  1.218 |      0.258 |                   27 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.929 |      0.056 |                   25 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  5.825 |      0.042 |                   25 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.15298507462686567
[2m[36m(func pid=38305)[0m top5: 0.7364738805970149
[2m[36m(func pid=38305)[0m f1_micro: 0.15298507462686567
[2m[36m(func pid=38305)[0m f1_macro: 0.1279096387574768
[2m[36m(func pid=38305)[0m f1_weighted: 0.1749429592369358
[2m[36m(func pid=38305)[0m f1_per_class: [0.054, 0.199, 0.242, 0.0, 0.18, 0.128, 0.399, 0.03, 0.048, 0.0]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 1.4222 | Steps: 2 | Val loss: 78.5156 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=39517)[0m top1: 0.06809701492537314
[2m[36m(func pid=39517)[0m top5: 0.5629664179104478
[2m[36m(func pid=39517)[0m f1_micro: 0.06809701492537314
[2m[36m(func pid=39517)[0m f1_macro: 0.03990142180617638
[2m[36m(func pid=39517)[0m f1_weighted: 0.025456121558880905
[2m[36m(func pid=39517)[0m f1_per_class: [0.0, 0.0, 0.033, 0.041, 0.105, 0.008, 0.003, 0.175, 0.034, 0.0]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 1.0875 | Steps: 2 | Val loss: 2.3129 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=39098)[0m top1: 0.05970149253731343
[2m[36m(func pid=39098)[0m top5: 0.43050373134328357
[2m[36m(func pid=39098)[0m f1_micro: 0.05970149253731343
[2m[36m(func pid=39098)[0m f1_macro: 0.06511461175029601
[2m[36m(func pid=39098)[0m f1_weighted: 0.053501324157199666
[2m[36m(func pid=39098)[0m f1_per_class: [0.056, 0.087, 0.0, 0.007, 0.15, 0.099, 0.05, 0.108, 0.039, 0.055]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 2.1667 | Steps: 2 | Val loss: 2.2510 | Batch size: 32 | lr: 0.0001 | Duration: 2.81s
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 2.0142 | Steps: 2 | Val loss: 1458.7927 | Batch size: 32 | lr: 0.1 | Duration: 2.70s
[2m[36m(func pid=38679)[0m top1: 0.3292910447761194
[2m[36m(func pid=38679)[0m top5: 0.8931902985074627
[2m[36m(func pid=38679)[0m f1_micro: 0.3292910447761194
[2m[36m(func pid=38679)[0m f1_macro: 0.2636343518499918
[2m[36m(func pid=38679)[0m f1_weighted: 0.3122229605071724
[2m[36m(func pid=38679)[0m f1_per_class: [0.166, 0.509, 0.22, 0.123, 0.089, 0.233, 0.412, 0.474, 0.156, 0.255]
[2m[36m(func pid=38679)[0m 
== Status ==
Current time: 2024-01-07 02:27:12 (running for 00:03:13.13)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  2.167 |      0.143 |                   27 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  1.087 |      0.264 |                   28 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  1.422 |      0.065 |                   26 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.987 |      0.04  |                   26 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.18330223880597016
[2m[36m(func pid=38305)[0m top5: 0.7416044776119403
[2m[36m(func pid=38305)[0m f1_micro: 0.18330223880597016
[2m[36m(func pid=38305)[0m f1_macro: 0.14257955126913863
[2m[36m(func pid=38305)[0m f1_weighted: 0.19714939998880035
[2m[36m(func pid=38305)[0m f1_per_class: [0.059, 0.211, 0.282, 0.0, 0.169, 0.134, 0.457, 0.061, 0.053, 0.0]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 1.0150 | Steps: 2 | Val loss: 44.2794 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=39517)[0m top1: 0.06996268656716417
[2m[36m(func pid=39517)[0m top5: 0.5690298507462687
[2m[36m(func pid=39517)[0m f1_micro: 0.06996268656716417
[2m[36m(func pid=39517)[0m f1_macro: 0.045096913792837874
[2m[36m(func pid=39517)[0m f1_weighted: 0.027302875609172623
[2m[36m(func pid=39517)[0m f1_per_class: [0.018, 0.0, 0.032, 0.042, 0.105, 0.008, 0.003, 0.178, 0.065, 0.0]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.8697 | Steps: 2 | Val loss: 2.5270 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=39098)[0m top1: 0.08861940298507463
[2m[36m(func pid=39098)[0m top5: 0.3983208955223881
[2m[36m(func pid=39098)[0m f1_micro: 0.08861940298507463
[2m[36m(func pid=39098)[0m f1_macro: 0.1036288003297811
[2m[36m(func pid=39098)[0m f1_weighted: 0.08036805716354226
[2m[36m(func pid=39098)[0m f1_per_class: [0.058, 0.128, 0.264, 0.032, 0.0, 0.162, 0.053, 0.138, 0.084, 0.116]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 2.1339 | Steps: 2 | Val loss: 2.2346 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 2.3993 | Steps: 2 | Val loss: 1718.0292 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=38679)[0m top1: 0.32276119402985076
[2m[36m(func pid=38679)[0m top5: 0.8913246268656716
[2m[36m(func pid=38679)[0m f1_micro: 0.32276119402985076
[2m[36m(func pid=38679)[0m f1_macro: 0.2595572621107847
[2m[36m(func pid=38679)[0m f1_weighted: 0.30440637081771293
[2m[36m(func pid=38679)[0m f1_per_class: [0.138, 0.509, 0.168, 0.096, 0.101, 0.275, 0.397, 0.481, 0.135, 0.296]
[2m[36m(func pid=38679)[0m 
== Status ==
Current time: 2024-01-07 02:27:17 (running for 00:03:18.27)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  2.134 |      0.156 |                   28 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.87  |      0.26  |                   29 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  1.015 |      0.104 |                   27 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  2.014 |      0.045 |                   27 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.20242537313432835
[2m[36m(func pid=38305)[0m top5: 0.7551305970149254
[2m[36m(func pid=38305)[0m f1_micro: 0.20242537313432832
[2m[36m(func pid=38305)[0m f1_macro: 0.15596710031542724
[2m[36m(func pid=38305)[0m f1_weighted: 0.21222803207324833
[2m[36m(func pid=38305)[0m f1_per_class: [0.067, 0.231, 0.319, 0.0, 0.167, 0.167, 0.479, 0.076, 0.054, 0.0]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.8124 | Steps: 2 | Val loss: 38.3840 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=39517)[0m top1: 0.06576492537313433
[2m[36m(func pid=39517)[0m top5: 0.5685634328358209
[2m[36m(func pid=39517)[0m f1_micro: 0.06576492537313433
[2m[36m(func pid=39517)[0m f1_macro: 0.04171854194498148
[2m[36m(func pid=39517)[0m f1_weighted: 0.02229343602676497
[2m[36m(func pid=39517)[0m f1_per_class: [0.018, 0.0, 0.033, 0.023, 0.095, 0.008, 0.006, 0.17, 0.065, 0.0]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 1.1959 | Steps: 2 | Val loss: 2.9029 | Batch size: 32 | lr: 0.001 | Duration: 2.78s
[2m[36m(func pid=39098)[0m top1: 0.09421641791044776
[2m[36m(func pid=39098)[0m top5: 0.44449626865671643
[2m[36m(func pid=39098)[0m f1_micro: 0.09421641791044776
[2m[36m(func pid=39098)[0m f1_macro: 0.08419071094059305
[2m[36m(func pid=39098)[0m f1_weighted: 0.09740177854821937
[2m[36m(func pid=39098)[0m f1_per_class: [0.0, 0.169, 0.039, 0.062, 0.0, 0.106, 0.085, 0.149, 0.088, 0.143]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 2.0704 | Steps: 2 | Val loss: 2.2183 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 1.9185 | Steps: 2 | Val loss: 1819.6146 | Batch size: 32 | lr: 0.1 | Duration: 2.65s
[2m[36m(func pid=38679)[0m top1: 0.2868470149253731
[2m[36m(func pid=38679)[0m top5: 0.8857276119402985
[2m[36m(func pid=38679)[0m f1_micro: 0.2868470149253731
[2m[36m(func pid=38679)[0m f1_macro: 0.2342283308637576
[2m[36m(func pid=38679)[0m f1_weighted: 0.2683905086205746
[2m[36m(func pid=38679)[0m f1_per_class: [0.117, 0.499, 0.126, 0.07, 0.105, 0.28, 0.314, 0.458, 0.112, 0.26]
[2m[36m(func pid=38679)[0m 
== Status ==
Current time: 2024-01-07 02:27:22 (running for 00:03:23.56)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  2.07  |      0.158 |                   29 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  1.196 |      0.234 |                   30 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.812 |      0.084 |                   28 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  2.399 |      0.042 |                   28 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.2103544776119403
[2m[36m(func pid=38305)[0m top5: 0.7658582089552238
[2m[36m(func pid=38305)[0m f1_micro: 0.2103544776119403
[2m[36m(func pid=38305)[0m f1_macro: 0.15815230955786772
[2m[36m(func pid=38305)[0m f1_weighted: 0.2141645863666758
[2m[36m(func pid=38305)[0m f1_per_class: [0.071, 0.235, 0.355, 0.0, 0.167, 0.173, 0.486, 0.047, 0.048, 0.0]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.7973 | Steps: 2 | Val loss: 34.4859 | Batch size: 32 | lr: 0.01 | Duration: 2.77s
[2m[36m(func pid=39517)[0m top1: 0.06296641791044776
[2m[36m(func pid=39517)[0m top5: 0.5652985074626866
[2m[36m(func pid=39517)[0m f1_micro: 0.06296641791044776
[2m[36m(func pid=39517)[0m f1_macro: 0.035864862102134944
[2m[36m(func pid=39517)[0m f1_weighted: 0.019555528548067237
[2m[36m(func pid=39517)[0m f1_per_class: [0.017, 0.0, 0.034, 0.013, 0.061, 0.0, 0.011, 0.168, 0.055, 0.0]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.6921 | Steps: 2 | Val loss: 3.4048 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 2.1075 | Steps: 2 | Val loss: 2.2069 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=39098)[0m top1: 0.11007462686567164
[2m[36m(func pid=39098)[0m top5: 0.5872201492537313
[2m[36m(func pid=39098)[0m f1_micro: 0.11007462686567164
[2m[36m(func pid=39098)[0m f1_macro: 0.09410262319128984
[2m[36m(func pid=39098)[0m f1_weighted: 0.13174260254148207
[2m[36m(func pid=39098)[0m f1_per_class: [0.0, 0.247, 0.031, 0.138, 0.029, 0.024, 0.115, 0.167, 0.083, 0.109]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 1.8709 | Steps: 2 | Val loss: 1833.8749 | Batch size: 32 | lr: 0.1 | Duration: 2.71s
[2m[36m(func pid=38679)[0m top1: 0.23787313432835822
[2m[36m(func pid=38679)[0m top5: 0.8801305970149254
[2m[36m(func pid=38679)[0m f1_micro: 0.23787313432835822
[2m[36m(func pid=38679)[0m f1_macro: 0.20386961694217015
[2m[36m(func pid=38679)[0m f1_weighted: 0.22386518217254772
[2m[36m(func pid=38679)[0m f1_per_class: [0.058, 0.525, 0.098, 0.093, 0.113, 0.22, 0.17, 0.373, 0.137, 0.252]
[2m[36m(func pid=38679)[0m 
== Status ==
Current time: 2024-01-07 02:27:27 (running for 00:03:28.62)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  2.108 |      0.156 |                   30 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.692 |      0.204 |                   31 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.797 |      0.094 |                   29 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.919 |      0.036 |                   29 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.22108208955223882
[2m[36m(func pid=38305)[0m top5: 0.7793843283582089
[2m[36m(func pid=38305)[0m f1_micro: 0.22108208955223882
[2m[36m(func pid=38305)[0m f1_macro: 0.1558927847827388
[2m[36m(func pid=38305)[0m f1_weighted: 0.21797003263627718
[2m[36m(func pid=38305)[0m f1_per_class: [0.076, 0.244, 0.355, 0.0, 0.149, 0.128, 0.51, 0.047, 0.049, 0.0]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 2.0314 | Steps: 2 | Val loss: 35.1756 | Batch size: 32 | lr: 0.01 | Duration: 2.73s
[2m[36m(func pid=39517)[0m top1: 0.06343283582089553
[2m[36m(func pid=39517)[0m top5: 0.5634328358208955
[2m[36m(func pid=39517)[0m f1_micro: 0.06343283582089553
[2m[36m(func pid=39517)[0m f1_macro: 0.03381305025664012
[2m[36m(func pid=39517)[0m f1_weighted: 0.022087081302003164
[2m[36m(func pid=39517)[0m f1_per_class: [0.0, 0.0, 0.035, 0.013, 0.048, 0.007, 0.019, 0.165, 0.05, 0.0]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.6511 | Steps: 2 | Val loss: 3.7148 | Batch size: 32 | lr: 0.001 | Duration: 2.65s
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 2.0567 | Steps: 2 | Val loss: 2.1922 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=39098)[0m top1: 0.0960820895522388
[2m[36m(func pid=39098)[0m top5: 0.5363805970149254
[2m[36m(func pid=39098)[0m f1_micro: 0.0960820895522388
[2m[36m(func pid=39098)[0m f1_macro: 0.07403232357366683
[2m[36m(func pid=39098)[0m f1_weighted: 0.11623534847261262
[2m[36m(func pid=39098)[0m f1_per_class: [0.0, 0.298, 0.03, 0.177, 0.0, 0.0, 0.025, 0.093, 0.059, 0.058]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 1.6960 | Steps: 2 | Val loss: 1730.2310 | Batch size: 32 | lr: 0.1 | Duration: 2.69s
[2m[36m(func pid=38679)[0m top1: 0.23414179104477612
[2m[36m(func pid=38679)[0m top5: 0.8680037313432836
[2m[36m(func pid=38679)[0m f1_micro: 0.23414179104477612
[2m[36m(func pid=38679)[0m f1_macro: 0.21771930364949038
[2m[36m(func pid=38679)[0m f1_weighted: 0.2381677253140328
[2m[36m(func pid=38679)[0m f1_per_class: [0.054, 0.505, 0.103, 0.12, 0.099, 0.296, 0.177, 0.355, 0.127, 0.341]
[2m[36m(func pid=38679)[0m 
== Status ==
Current time: 2024-01-07 02:27:33 (running for 00:03:33.96)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  2.057 |      0.17  |                   31 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.651 |      0.218 |                   32 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  2.031 |      0.074 |                   30 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.871 |      0.034 |                   30 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.23041044776119404
[2m[36m(func pid=38305)[0m top5: 0.7882462686567164
[2m[36m(func pid=38305)[0m f1_micro: 0.23041044776119404
[2m[36m(func pid=38305)[0m f1_macro: 0.17011110468260432
[2m[36m(func pid=38305)[0m f1_weighted: 0.2243513136813397
[2m[36m(func pid=38305)[0m f1_per_class: [0.08, 0.248, 0.373, 0.0, 0.142, 0.136, 0.519, 0.061, 0.066, 0.077]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39517)[0m top1: 0.06529850746268656
[2m[36m(func pid=39517)[0m top5: 0.566231343283582
[2m[36m(func pid=39517)[0m f1_micro: 0.06529850746268656
[2m[36m(func pid=39517)[0m f1_macro: 0.033081694663797026
[2m[36m(func pid=39517)[0m f1_weighted: 0.021925042569508377
[2m[36m(func pid=39517)[0m f1_per_class: [0.0, 0.0, 0.036, 0.016, 0.044, 0.014, 0.014, 0.169, 0.037, 0.0]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 1.2597 | Steps: 2 | Val loss: 26.5312 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.9271 | Steps: 2 | Val loss: 3.6329 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=39098)[0m top1: 0.13805970149253732
[2m[36m(func pid=39098)[0m top5: 0.6711753731343284
[2m[36m(func pid=39098)[0m f1_micro: 0.13805970149253732
[2m[36m(func pid=39098)[0m f1_macro: 0.10865085752040522
[2m[36m(func pid=39098)[0m f1_weighted: 0.16386297306159944
[2m[36m(func pid=39098)[0m f1_per_class: [0.0, 0.342, 0.028, 0.166, 0.0, 0.048, 0.136, 0.128, 0.107, 0.132]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 2.0064 | Steps: 2 | Val loss: 2.1737 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 2.4646 | Steps: 2 | Val loss: 1397.1047 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=38679)[0m top1: 0.23460820895522388
[2m[36m(func pid=38679)[0m top5: 0.8661380597014925
[2m[36m(func pid=38679)[0m f1_micro: 0.23460820895522388
[2m[36m(func pid=38679)[0m f1_macro: 0.2166498608471211
[2m[36m(func pid=38679)[0m f1_weighted: 0.24449015452377876
[2m[36m(func pid=38679)[0m f1_per_class: [0.055, 0.508, 0.115, 0.153, 0.092, 0.245, 0.188, 0.347, 0.118, 0.347]
[2m[36m(func pid=38679)[0m 
== Status ==
Current time: 2024-01-07 02:27:38 (running for 00:03:39.20)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  2.006 |      0.184 |                   32 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.927 |      0.217 |                   33 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  1.26  |      0.109 |                   31 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.696 |      0.033 |                   31 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.24300373134328357
[2m[36m(func pid=38305)[0m top5: 0.7947761194029851
[2m[36m(func pid=38305)[0m f1_micro: 0.24300373134328357
[2m[36m(func pid=38305)[0m f1_macro: 0.18360201712378837
[2m[36m(func pid=38305)[0m f1_weighted: 0.2330342470089712
[2m[36m(func pid=38305)[0m f1_per_class: [0.089, 0.252, 0.386, 0.0, 0.123, 0.109, 0.54, 0.131, 0.057, 0.148]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39517)[0m top1: 0.06389925373134328
[2m[36m(func pid=39517)[0m top5: 0.5722947761194029
[2m[36m(func pid=39517)[0m f1_micro: 0.06389925373134328
[2m[36m(func pid=39517)[0m f1_macro: 0.035576535799277845
[2m[36m(func pid=39517)[0m f1_weighted: 0.01935631526065455
[2m[36m(func pid=39517)[0m f1_per_class: [0.014, 0.011, 0.041, 0.007, 0.065, 0.013, 0.009, 0.161, 0.036, 0.0]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 4.2660 | Steps: 2 | Val loss: 20.5477 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.8779 | Steps: 2 | Val loss: 3.1167 | Batch size: 32 | lr: 0.001 | Duration: 2.73s
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 1.9948 | Steps: 2 | Val loss: 2.1589 | Batch size: 32 | lr: 0.0001 | Duration: 2.79s
[2m[36m(func pid=39098)[0m top1: 0.11333955223880597
[2m[36m(func pid=39098)[0m top5: 0.6259328358208955
[2m[36m(func pid=39098)[0m f1_micro: 0.11333955223880597
[2m[36m(func pid=39098)[0m f1_macro: 0.08497177834692848
[2m[36m(func pid=39098)[0m f1_weighted: 0.11782018286627034
[2m[36m(func pid=39098)[0m f1_per_class: [0.02, 0.331, 0.025, 0.125, 0.0, 0.0, 0.055, 0.073, 0.107, 0.113]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 1.7524 | Steps: 2 | Val loss: 887.8043 | Batch size: 32 | lr: 0.1 | Duration: 2.72s
[2m[36m(func pid=38679)[0m top1: 0.27798507462686567
[2m[36m(func pid=38679)[0m top5: 0.8754664179104478
[2m[36m(func pid=38679)[0m f1_micro: 0.27798507462686567
[2m[36m(func pid=38679)[0m f1_macro: 0.25437472198390043
[2m[36m(func pid=38679)[0m f1_weighted: 0.29148660114509334
[2m[36m(func pid=38679)[0m f1_per_class: [0.096, 0.537, 0.189, 0.237, 0.085, 0.251, 0.234, 0.381, 0.13, 0.405]
[2m[36m(func pid=38679)[0m 
== Status ==
Current time: 2024-01-07 02:27:43 (running for 00:03:44.45)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  2.006 |      0.184 |                   32 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.878 |      0.254 |                   34 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  4.266 |      0.085 |                   32 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.752 |      0.042 |                   33 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.2537313432835821
[2m[36m(func pid=38305)[0m top5: 0.8041044776119403
[2m[36m(func pid=38305)[0m f1_micro: 0.2537313432835821
[2m[36m(func pid=38305)[0m f1_macro: 0.20646621632026138
[2m[36m(func pid=38305)[0m f1_weighted: 0.24156739695310875
[2m[36m(func pid=38305)[0m f1_per_class: [0.102, 0.263, 0.423, 0.0, 0.119, 0.082, 0.553, 0.194, 0.061, 0.267]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39517)[0m top1: 0.061567164179104475
[2m[36m(func pid=39517)[0m top5: 0.5928171641791045
[2m[36m(func pid=39517)[0m f1_micro: 0.061567164179104475
[2m[36m(func pid=39517)[0m f1_macro: 0.04212166488125321
[2m[36m(func pid=39517)[0m f1_weighted: 0.022596926923153567
[2m[36m(func pid=39517)[0m f1_per_class: [0.022, 0.021, 0.048, 0.01, 0.074, 0.014, 0.012, 0.141, 0.037, 0.043]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 1.2913 | Steps: 2 | Val loss: 12.9635 | Batch size: 32 | lr: 0.01 | Duration: 2.65s
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.8432 | Steps: 2 | Val loss: 2.8057 | Batch size: 32 | lr: 0.001 | Duration: 2.73s
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 1.9227 | Steps: 2 | Val loss: 663.4730 | Batch size: 32 | lr: 0.1 | Duration: 2.76s
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 1.9292 | Steps: 2 | Val loss: 2.1490 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=39098)[0m top1: 0.12033582089552239
[2m[36m(func pid=39098)[0m top5: 0.6422574626865671
[2m[36m(func pid=39098)[0m f1_micro: 0.12033582089552239
[2m[36m(func pid=39098)[0m f1_macro: 0.0770804595961006
[2m[36m(func pid=39098)[0m f1_weighted: 0.09440301534029977
[2m[36m(func pid=39098)[0m f1_per_class: [0.035, 0.324, 0.037, 0.068, 0.0, 0.0, 0.035, 0.062, 0.102, 0.107]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=38679)[0m top1: 0.3353544776119403
[2m[36m(func pid=38679)[0m top5: 0.8689365671641791
[2m[36m(func pid=38679)[0m f1_micro: 0.3353544776119403
[2m[36m(func pid=38679)[0m f1_macro: 0.30641443532579515
[2m[36m(func pid=38679)[0m f1_weighted: 0.35840765998529367
[2m[36m(func pid=38679)[0m f1_per_class: [0.148, 0.549, 0.361, 0.327, 0.071, 0.29, 0.324, 0.492, 0.126, 0.375]
[2m[36m(func pid=38679)[0m 
== Status ==
Current time: 2024-01-07 02:27:48 (running for 00:03:49.53)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  1.995 |      0.206 |                   33 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.843 |      0.306 |                   35 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  1.291 |      0.077 |                   33 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.923 |      0.045 |                   34 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=39517)[0m top1: 0.07416044776119403
[2m[36m(func pid=39517)[0m top5: 0.6291977611940298
[2m[36m(func pid=39517)[0m f1_micro: 0.07416044776119403
[2m[36m(func pid=39517)[0m f1_macro: 0.04472875858648197
[2m[36m(func pid=39517)[0m f1_weighted: 0.03682148416183975
[2m[36m(func pid=39517)[0m f1_per_class: [0.029, 0.06, 0.055, 0.013, 0.0, 0.014, 0.03, 0.168, 0.041, 0.038]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38305)[0m top1: 0.25886194029850745
[2m[36m(func pid=38305)[0m top5: 0.8078358208955224
[2m[36m(func pid=38305)[0m f1_micro: 0.25886194029850745
[2m[36m(func pid=38305)[0m f1_macro: 0.20968563972757365
[2m[36m(func pid=38305)[0m f1_weighted: 0.2433961477277211
[2m[36m(func pid=38305)[0m f1_per_class: [0.109, 0.264, 0.44, 0.0, 0.114, 0.068, 0.559, 0.221, 0.055, 0.267]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 1.0070 | Steps: 2 | Val loss: 6.7635 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.5452 | Steps: 2 | Val loss: 2.8126 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 73.8094 | Steps: 2 | Val loss: 792.3096 | Batch size: 32 | lr: 0.1 | Duration: 2.72s
[2m[36m(func pid=39098)[0m top1: 0.1767723880597015
[2m[36m(func pid=39098)[0m top5: 0.7541977611940298
[2m[36m(func pid=39098)[0m f1_micro: 0.1767723880597015
[2m[36m(func pid=39098)[0m f1_macro: 0.1240694372652766
[2m[36m(func pid=39098)[0m f1_weighted: 0.14141114516802464
[2m[36m(func pid=39098)[0m f1_per_class: [0.028, 0.351, 0.104, 0.042, 0.091, 0.127, 0.131, 0.169, 0.088, 0.11]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 2.0085 | Steps: 2 | Val loss: 2.1429 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=38679)[0m top1: 0.35447761194029853
[2m[36m(func pid=38679)[0m top5: 0.8600746268656716
[2m[36m(func pid=38679)[0m f1_micro: 0.35447761194029853
[2m[36m(func pid=38679)[0m f1_macro: 0.33627962962562663
[2m[36m(func pid=38679)[0m f1_weighted: 0.38775968278517553
[2m[36m(func pid=38679)[0m f1_per_class: [0.162, 0.561, 0.486, 0.365, 0.048, 0.262, 0.375, 0.543, 0.144, 0.417]
[2m[36m(func pid=38679)[0m 
== Status ==
Current time: 2024-01-07 02:27:53 (running for 00:03:54.67)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  1.929 |      0.21  |                   34 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.545 |      0.336 |                   36 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  1.007 |      0.124 |                   34 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      | 73.809 |      0.05  |                   35 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=39517)[0m top1: 0.07695895522388059
[2m[36m(func pid=39517)[0m top5: 0.6324626865671642
[2m[36m(func pid=39517)[0m f1_micro: 0.07695895522388059
[2m[36m(func pid=39517)[0m f1_macro: 0.04953092694269918
[2m[36m(func pid=39517)[0m f1_weighted: 0.047508887602883805
[2m[36m(func pid=39517)[0m f1_per_class: [0.023, 0.041, 0.052, 0.05, 0.045, 0.007, 0.047, 0.165, 0.021, 0.044]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38305)[0m top1: 0.26072761194029853
[2m[36m(func pid=38305)[0m top5: 0.8166977611940298
[2m[36m(func pid=38305)[0m f1_micro: 0.26072761194029853
[2m[36m(func pid=38305)[0m f1_macro: 0.20544538400500906
[2m[36m(func pid=38305)[0m f1_weighted: 0.24248179090944172
[2m[36m(func pid=38305)[0m f1_per_class: [0.112, 0.258, 0.423, 0.0, 0.105, 0.054, 0.564, 0.222, 0.074, 0.242]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.9053 | Steps: 2 | Val loss: 6.1527 | Batch size: 32 | lr: 0.01 | Duration: 2.75s
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.5205 | Steps: 2 | Val loss: 2.5296 | Batch size: 32 | lr: 0.001 | Duration: 2.62s
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 1.7307 | Steps: 2 | Val loss: 606.2582 | Batch size: 32 | lr: 0.1 | Duration: 2.74s
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 1.8968 | Steps: 2 | Val loss: 2.1331 | Batch size: 32 | lr: 0.0001 | Duration: 2.75s
[2m[36m(func pid=39098)[0m top1: 0.23880597014925373
[2m[36m(func pid=39098)[0m top5: 0.8115671641791045
[2m[36m(func pid=39098)[0m f1_micro: 0.23880597014925373
[2m[36m(func pid=39098)[0m f1_macro: 0.1460918711183205
[2m[36m(func pid=39098)[0m f1_weighted: 0.18863078912965836
[2m[36m(func pid=39098)[0m f1_per_class: [0.034, 0.395, 0.0, 0.035, 0.077, 0.104, 0.255, 0.26, 0.134, 0.165]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=38679)[0m top1: 0.3810634328358209
[2m[36m(func pid=38679)[0m top5: 0.8931902985074627
[2m[36m(func pid=38679)[0m f1_micro: 0.3810634328358209
[2m[36m(func pid=38679)[0m f1_macro: 0.3492141211653109
[2m[36m(func pid=38679)[0m f1_weighted: 0.40359378074425195
[2m[36m(func pid=38679)[0m f1_per_class: [0.197, 0.552, 0.48, 0.38, 0.067, 0.272, 0.418, 0.509, 0.141, 0.476]
[2m[36m(func pid=38679)[0m 
== Status ==
Current time: 2024-01-07 02:27:58 (running for 00:03:59.67)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  2.009 |      0.205 |                   35 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.521 |      0.349 |                   37 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.905 |      0.146 |                   35 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.731 |      0.051 |                   36 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=39517)[0m top1: 0.08208955223880597
[2m[36m(func pid=39517)[0m top5: 0.6380597014925373
[2m[36m(func pid=39517)[0m f1_micro: 0.08208955223880597
[2m[36m(func pid=39517)[0m f1_macro: 0.05102020723318741
[2m[36m(func pid=39517)[0m f1_weighted: 0.05262532087969274
[2m[36m(func pid=39517)[0m f1_per_class: [0.024, 0.056, 0.056, 0.079, 0.033, 0.026, 0.022, 0.17, 0.0, 0.043]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38305)[0m top1: 0.26119402985074625
[2m[36m(func pid=38305)[0m top5: 0.8297574626865671
[2m[36m(func pid=38305)[0m f1_micro: 0.26119402985074625
[2m[36m(func pid=38305)[0m f1_macro: 0.20451618272007285
[2m[36m(func pid=38305)[0m f1_weighted: 0.24170333050685883
[2m[36m(func pid=38305)[0m f1_per_class: [0.119, 0.27, 0.407, 0.0, 0.098, 0.039, 0.56, 0.213, 0.088, 0.25]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 1.1098 | Steps: 2 | Val loss: 6.7207 | Batch size: 32 | lr: 0.01 | Duration: 2.77s
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.7231 | Steps: 2 | Val loss: 2.6074 | Batch size: 32 | lr: 0.001 | Duration: 2.64s
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 2.2685 | Steps: 2 | Val loss: 513.5874 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 1.8561 | Steps: 2 | Val loss: 2.1167 | Batch size: 32 | lr: 0.0001 | Duration: 3.04s
[2m[36m(func pid=39098)[0m top1: 0.22761194029850745
[2m[36m(func pid=39098)[0m top5: 0.8339552238805971
[2m[36m(func pid=39098)[0m f1_micro: 0.22761194029850745
[2m[36m(func pid=39098)[0m f1_macro: 0.1266529205455426
[2m[36m(func pid=39098)[0m f1_weighted: 0.1583319150754984
[2m[36m(func pid=39098)[0m f1_per_class: [0.015, 0.406, 0.0, 0.022, 0.095, 0.032, 0.197, 0.221, 0.136, 0.142]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=38679)[0m top1: 0.3787313432835821
[2m[36m(func pid=38679)[0m top5: 0.8941231343283582
[2m[36m(func pid=38679)[0m f1_micro: 0.3787313432835821
[2m[36m(func pid=38679)[0m f1_macro: 0.31617584933201287
[2m[36m(func pid=38679)[0m f1_weighted: 0.3925637537605871
[2m[36m(func pid=38679)[0m f1_per_class: [0.201, 0.556, 0.222, 0.399, 0.099, 0.204, 0.401, 0.442, 0.161, 0.476]
[2m[36m(func pid=38679)[0m 
== Status ==
Current time: 2024-01-07 02:28:03 (running for 00:04:04.78)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  1.897 |      0.205 |                   36 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.723 |      0.316 |                   38 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  1.11  |      0.127 |                   36 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  2.269 |      0.05  |                   37 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=39517)[0m top1: 0.08208955223880597
[2m[36m(func pid=39517)[0m top5: 0.6399253731343284
[2m[36m(func pid=39517)[0m f1_micro: 0.08208955223880597
[2m[36m(func pid=39517)[0m f1_macro: 0.05008535168347985
[2m[36m(func pid=39517)[0m f1_weighted: 0.04988439812697787
[2m[36m(func pid=39517)[0m f1_per_class: [0.024, 0.041, 0.06, 0.095, 0.028, 0.018, 0.009, 0.169, 0.0, 0.056]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38305)[0m top1: 0.26865671641791045
[2m[36m(func pid=38305)[0m top5: 0.8451492537313433
[2m[36m(func pid=38305)[0m f1_micro: 0.26865671641791045
[2m[36m(func pid=38305)[0m f1_macro: 0.212959789347056
[2m[36m(func pid=38305)[0m f1_weighted: 0.2543837033030702
[2m[36m(func pid=38305)[0m f1_per_class: [0.114, 0.323, 0.379, 0.0, 0.09, 0.039, 0.559, 0.289, 0.086, 0.25]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.6057 | Steps: 2 | Val loss: 2.7502 | Batch size: 32 | lr: 0.001 | Duration: 2.73s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 1.1731 | Steps: 2 | Val loss: 7.8561 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 2.0486 | Steps: 2 | Val loss: 377.8991 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 1.8028 | Steps: 2 | Val loss: 2.0962 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
[2m[36m(func pid=38679)[0m top1: 0.36800373134328357
[2m[36m(func pid=38679)[0m top5: 0.8908582089552238
[2m[36m(func pid=38679)[0m f1_micro: 0.3680037313432836
[2m[36m(func pid=38679)[0m f1_macro: 0.2842831536537889
[2m[36m(func pid=38679)[0m f1_weighted: 0.38374497344706776
[2m[36m(func pid=38679)[0m f1_per_class: [0.175, 0.551, 0.0, 0.394, 0.098, 0.21, 0.387, 0.426, 0.171, 0.431]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=39098)[0m top1: 0.2019589552238806
[2m[36m(func pid=39098)[0m top5: 0.840018656716418
[2m[36m(func pid=39098)[0m f1_micro: 0.2019589552238806
[2m[36m(func pid=39098)[0m f1_macro: 0.0987089609277467
[2m[36m(func pid=39098)[0m f1_weighted: 0.13743247147889456
[2m[36m(func pid=39098)[0m f1_per_class: [0.014, 0.424, 0.0, 0.019, 0.071, 0.0, 0.15, 0.206, 0.024, 0.079]
[2m[36m(func pid=39098)[0m 
== Status ==
Current time: 2024-01-07 02:28:09 (running for 00:04:09.90)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  1.856 |      0.213 |                   37 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.606 |      0.284 |                   39 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  1.173 |      0.099 |                   37 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  2.049 |      0.048 |                   38 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=39517)[0m top1: 0.08162313432835822
[2m[36m(func pid=39517)[0m top5: 0.6436567164179104
[2m[36m(func pid=39517)[0m f1_micro: 0.08162313432835822
[2m[36m(func pid=39517)[0m f1_macro: 0.04817944713806647
[2m[36m(func pid=39517)[0m f1_weighted: 0.044304860628174375
[2m[36m(func pid=39517)[0m f1_per_class: [0.032, 0.021, 0.066, 0.094, 0.038, 0.025, 0.0, 0.17, 0.0, 0.035]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38305)[0m top1: 0.27098880597014924
[2m[36m(func pid=38305)[0m top5: 0.8568097014925373
[2m[36m(func pid=38305)[0m f1_micro: 0.27098880597014924
[2m[36m(func pid=38305)[0m f1_macro: 0.2162646092746446
[2m[36m(func pid=38305)[0m f1_weighted: 0.25679857254256155
[2m[36m(func pid=38305)[0m f1_per_class: [0.128, 0.339, 0.349, 0.0, 0.084, 0.032, 0.55, 0.343, 0.082, 0.256]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.4890 | Steps: 2 | Val loss: 2.9368 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.9842 | Steps: 2 | Val loss: 9.5815 | Batch size: 32 | lr: 0.01 | Duration: 2.73s
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 1.8465 | Steps: 2 | Val loss: 298.9263 | Batch size: 32 | lr: 0.1 | Duration: 2.78s
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 1.8516 | Steps: 2 | Val loss: 2.0666 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=38679)[0m top1: 0.35447761194029853
[2m[36m(func pid=38679)[0m top5: 0.8875932835820896
[2m[36m(func pid=38679)[0m f1_micro: 0.35447761194029853
[2m[36m(func pid=38679)[0m f1_macro: 0.2777877593056547
[2m[36m(func pid=38679)[0m f1_weighted: 0.3714239441683826
[2m[36m(func pid=38679)[0m f1_per_class: [0.164, 0.54, 0.0, 0.369, 0.105, 0.231, 0.371, 0.41, 0.182, 0.406]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=39098)[0m top1: 0.1730410447761194
[2m[36m(func pid=39098)[0m top5: 0.8353544776119403
[2m[36m(func pid=39098)[0m f1_micro: 0.1730410447761194
[2m[36m(func pid=39098)[0m f1_macro: 0.09750341590861533
[2m[36m(func pid=39098)[0m f1_weighted: 0.12591825502412343
[2m[36m(func pid=39098)[0m f1_per_class: [0.037, 0.417, 0.0, 0.041, 0.046, 0.0, 0.08, 0.297, 0.0, 0.057]
[2m[36m(func pid=39098)[0m 
== Status ==
Current time: 2024-01-07 02:28:14 (running for 00:04:15.04)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  1.803 |      0.216 |                   38 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.489 |      0.278 |                   40 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.984 |      0.098 |                   38 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.847 |      0.052 |                   39 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=39517)[0m top1: 0.08115671641791045
[2m[36m(func pid=39517)[0m top5: 0.6637126865671642
[2m[36m(func pid=39517)[0m f1_micro: 0.08115671641791045
[2m[36m(func pid=39517)[0m f1_macro: 0.05217354317352184
[2m[36m(func pid=39517)[0m f1_weighted: 0.038935533122015274
[2m[36m(func pid=39517)[0m f1_per_class: [0.035, 0.021, 0.072, 0.07, 0.048, 0.025, 0.0, 0.177, 0.017, 0.057]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38305)[0m top1: 0.2887126865671642
[2m[36m(func pid=38305)[0m top5: 0.8708022388059702
[2m[36m(func pid=38305)[0m f1_micro: 0.2887126865671642
[2m[36m(func pid=38305)[0m f1_macro: 0.2406614846281776
[2m[36m(func pid=38305)[0m f1_weighted: 0.26989071996682995
[2m[36m(func pid=38305)[0m f1_per_class: [0.145, 0.381, 0.338, 0.0, 0.081, 0.016, 0.555, 0.413, 0.098, 0.381]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 1.0354 | Steps: 2 | Val loss: 3.1609 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.6877 | Steps: 2 | Val loss: 10.4011 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 2.2558 | Steps: 2 | Val loss: 232.0102 | Batch size: 32 | lr: 0.1 | Duration: 2.54s
[2m[36m(func pid=38679)[0m top1: 0.35261194029850745
[2m[36m(func pid=38679)[0m top5: 0.8717350746268657
[2m[36m(func pid=38679)[0m f1_micro: 0.35261194029850745
[2m[36m(func pid=38679)[0m f1_macro: 0.3127652034579077
[2m[36m(func pid=38679)[0m f1_weighted: 0.3796847813036833
[2m[36m(func pid=38679)[0m f1_per_class: [0.139, 0.536, 0.25, 0.31, 0.104, 0.309, 0.411, 0.464, 0.188, 0.417]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 1.7198 | Steps: 2 | Val loss: 2.0366 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=39098)[0m top1: 0.14132462686567165
[2m[36m(func pid=39098)[0m top5: 0.8348880597014925
[2m[36m(func pid=39098)[0m f1_micro: 0.14132462686567165
[2m[36m(func pid=39098)[0m f1_macro: 0.09552545651375222
[2m[36m(func pid=39098)[0m f1_weighted: 0.11608515598125146
[2m[36m(func pid=39098)[0m f1_per_class: [0.038, 0.322, 0.0, 0.094, 0.07, 0.0, 0.045, 0.332, 0.0, 0.055]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=39517)[0m top1: 0.09654850746268656
[2m[36m(func pid=39517)[0m top5: 0.6833022388059702
[2m[36m(func pid=39517)[0m f1_micro: 0.09654850746268658
[2m[36m(func pid=39517)[0m f1_macro: 0.06753271360069904
[2m[36m(func pid=39517)[0m f1_weighted: 0.06642180063173495
[2m[36m(func pid=39517)[0m f1_per_class: [0.041, 0.124, 0.076, 0.065, 0.033, 0.038, 0.029, 0.192, 0.025, 0.053]
[2m[36m(func pid=39517)[0m 
== Status ==
Current time: 2024-01-07 02:28:20 (running for 00:04:21.36)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  1.72  |      0.245 |                   40 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  1.035 |      0.313 |                   41 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.688 |      0.096 |                   39 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  2.256 |      0.068 |                   40 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.29524253731343286
[2m[36m(func pid=38305)[0m top5: 0.8857276119402985
[2m[36m(func pid=38305)[0m f1_micro: 0.29524253731343286
[2m[36m(func pid=38305)[0m f1_macro: 0.24460720519802429
[2m[36m(func pid=38305)[0m f1_weighted: 0.2734030749158208
[2m[36m(func pid=38305)[0m f1_per_class: [0.175, 0.375, 0.314, 0.0, 0.078, 0.04, 0.553, 0.449, 0.099, 0.364]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.4122 | Steps: 2 | Val loss: 3.2570 | Batch size: 32 | lr: 0.001 | Duration: 2.76s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.8037 | Steps: 2 | Val loss: 11.4430 | Batch size: 32 | lr: 0.01 | Duration: 2.70s
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 1.7030 | Steps: 2 | Val loss: 179.9321 | Batch size: 32 | lr: 0.1 | Duration: 2.66s
[2m[36m(func pid=38679)[0m top1: 0.35447761194029853
[2m[36m(func pid=38679)[0m top5: 0.8521455223880597
[2m[36m(func pid=38679)[0m f1_micro: 0.35447761194029853
[2m[36m(func pid=38679)[0m f1_macro: 0.31854649273103847
[2m[36m(func pid=38679)[0m f1_weighted: 0.3916988860079333
[2m[36m(func pid=38679)[0m f1_per_class: [0.14, 0.501, 0.324, 0.306, 0.084, 0.367, 0.445, 0.519, 0.189, 0.309]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 1.7414 | Steps: 2 | Val loss: 2.0150 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=39098)[0m top1: 0.12220149253731344
[2m[36m(func pid=39098)[0m top5: 0.8297574626865671
[2m[36m(func pid=39098)[0m f1_micro: 0.12220149253731344
[2m[36m(func pid=39098)[0m f1_macro: 0.0903954553902889
[2m[36m(func pid=39098)[0m f1_weighted: 0.10286995486308005
[2m[36m(func pid=39098)[0m f1_per_class: [0.054, 0.213, 0.0, 0.114, 0.057, 0.008, 0.033, 0.368, 0.0, 0.057]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=39517)[0m top1: 0.13619402985074627
[2m[36m(func pid=39517)[0m top5: 0.7467350746268657
[2m[36m(func pid=39517)[0m f1_micro: 0.13619402985074627
[2m[36m(func pid=39517)[0m f1_macro: 0.10223673970931979
[2m[36m(func pid=39517)[0m f1_weighted: 0.1215828672751557
[2m[36m(func pid=39517)[0m f1_per_class: [0.059, 0.267, 0.082, 0.068, 0.082, 0.085, 0.104, 0.224, 0.0, 0.051]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.5661 | Steps: 2 | Val loss: 3.3883 | Batch size: 32 | lr: 0.001 | Duration: 2.69s
== Status ==
Current time: 2024-01-07 02:28:25 (running for 00:04:26.66)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  1.741 |      0.262 |                   41 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.412 |      0.319 |                   42 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.804 |      0.09  |                   40 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.703 |      0.102 |                   41 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.3031716417910448
[2m[36m(func pid=38305)[0m top5: 0.8936567164179104
[2m[36m(func pid=38305)[0m f1_micro: 0.3031716417910448
[2m[36m(func pid=38305)[0m f1_macro: 0.2615087355699468
[2m[36m(func pid=38305)[0m f1_weighted: 0.27842676861104176
[2m[36m(func pid=38305)[0m f1_per_class: [0.208, 0.39, 0.306, 0.0, 0.073, 0.055, 0.545, 0.469, 0.104, 0.465]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.7698 | Steps: 2 | Val loss: 12.0260 | Batch size: 32 | lr: 0.01 | Duration: 2.73s
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 21.2978 | Steps: 2 | Val loss: 126.7551 | Batch size: 32 | lr: 0.1 | Duration: 2.67s
[2m[36m(func pid=38679)[0m top1: 0.314365671641791
[2m[36m(func pid=38679)[0m top5: 0.8698694029850746
[2m[36m(func pid=38679)[0m f1_micro: 0.314365671641791
[2m[36m(func pid=38679)[0m f1_macro: 0.268984309025633
[2m[36m(func pid=38679)[0m f1_weighted: 0.32489151861169746
[2m[36m(func pid=38679)[0m f1_per_class: [0.18, 0.481, 0.264, 0.322, 0.093, 0.203, 0.314, 0.338, 0.194, 0.3]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 1.6730 | Steps: 2 | Val loss: 1.9897 | Batch size: 32 | lr: 0.0001 | Duration: 2.76s
[2m[36m(func pid=39098)[0m top1: 0.13246268656716417
[2m[36m(func pid=39098)[0m top5: 0.824160447761194
[2m[36m(func pid=39098)[0m f1_micro: 0.13246268656716417
[2m[36m(func pid=39098)[0m f1_macro: 0.10584346713298294
[2m[36m(func pid=39098)[0m f1_weighted: 0.11818521479866999
[2m[36m(func pid=39098)[0m f1_per_class: [0.087, 0.221, 0.0, 0.105, 0.06, 0.051, 0.065, 0.379, 0.027, 0.064]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=39517)[0m top1: 0.15578358208955223
[2m[36m(func pid=39517)[0m top5: 0.7709888059701493
[2m[36m(func pid=39517)[0m f1_micro: 0.15578358208955223
[2m[36m(func pid=39517)[0m f1_macro: 0.1137879296851777
[2m[36m(func pid=39517)[0m f1_weighted: 0.14820168900489544
[2m[36m(func pid=39517)[0m f1_per_class: [0.043, 0.242, 0.085, 0.09, 0.076, 0.112, 0.171, 0.263, 0.0, 0.057]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.7398 | Steps: 2 | Val loss: 3.7471 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
== Status ==
Current time: 2024-01-07 02:28:30 (running for 00:04:31.71)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  1.673 |      0.266 |                   42 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.566 |      0.269 |                   43 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.77  |      0.106 |                   41 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      | 21.298 |      0.114 |                   42 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.3031716417910448
[2m[36m(func pid=38305)[0m top5: 0.9001865671641791
[2m[36m(func pid=38305)[0m f1_micro: 0.3031716417910448
[2m[36m(func pid=38305)[0m f1_macro: 0.26567451102087214
[2m[36m(func pid=38305)[0m f1_weighted: 0.2780631652904033
[2m[36m(func pid=38305)[0m f1_per_class: [0.248, 0.38, 0.319, 0.0, 0.069, 0.069, 0.536, 0.496, 0.115, 0.426]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 1.0703 | Steps: 2 | Val loss: 11.9591 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 1.7381 | Steps: 2 | Val loss: 62.2462 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
[2m[36m(func pid=38679)[0m top1: 0.28824626865671643
[2m[36m(func pid=38679)[0m top5: 0.8726679104477612
[2m[36m(func pid=38679)[0m f1_micro: 0.28824626865671643
[2m[36m(func pid=38679)[0m f1_macro: 0.24845592693694057
[2m[36m(func pid=38679)[0m f1_weighted: 0.2816490044614629
[2m[36m(func pid=38679)[0m f1_per_class: [0.227, 0.476, 0.231, 0.288, 0.103, 0.171, 0.224, 0.289, 0.19, 0.286]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 1.7176 | Steps: 2 | Val loss: 1.9803 | Batch size: 32 | lr: 0.0001 | Duration: 3.12s
[2m[36m(func pid=39098)[0m top1: 0.18516791044776118
[2m[36m(func pid=39098)[0m top5: 0.8325559701492538
[2m[36m(func pid=39098)[0m f1_micro: 0.18516791044776118
[2m[36m(func pid=39098)[0m f1_macro: 0.16613928685172497
[2m[36m(func pid=39098)[0m f1_weighted: 0.17106758616974246
[2m[36m(func pid=39098)[0m f1_per_class: [0.107, 0.264, 0.0, 0.066, 0.103, 0.369, 0.112, 0.382, 0.18, 0.08]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=39517)[0m top1: 0.16277985074626866
[2m[36m(func pid=39517)[0m top5: 0.7770522388059702
[2m[36m(func pid=39517)[0m f1_micro: 0.16277985074626866
[2m[36m(func pid=39517)[0m f1_macro: 0.11955780436485948
[2m[36m(func pid=39517)[0m f1_weighted: 0.17407006084095777
[2m[36m(func pid=39517)[0m f1_per_class: [0.055, 0.124, 0.111, 0.184, 0.067, 0.16, 0.225, 0.228, 0.0, 0.042]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.3987 | Steps: 2 | Val loss: 3.4347 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
== Status ==
Current time: 2024-01-07 02:28:36 (running for 00:04:37.27)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  1.718 |      0.265 |                   43 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.74  |      0.248 |                   44 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  1.07  |      0.166 |                   42 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.738 |      0.12  |                   43 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.2943097014925373
[2m[36m(func pid=38305)[0m top5: 0.90625
[2m[36m(func pid=38305)[0m f1_micro: 0.2943097014925373
[2m[36m(func pid=38305)[0m f1_macro: 0.2654382868634646
[2m[36m(func pid=38305)[0m f1_weighted: 0.2732092863101507
[2m[36m(func pid=38305)[0m f1_per_class: [0.279, 0.368, 0.306, 0.0, 0.065, 0.103, 0.513, 0.498, 0.108, 0.415]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.8922 | Steps: 2 | Val loss: 10.6391 | Batch size: 32 | lr: 0.01 | Duration: 2.73s
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 2.3226 | Steps: 2 | Val loss: 29.0206 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=38679)[0m top1: 0.2947761194029851
[2m[36m(func pid=38679)[0m top5: 0.8661380597014925
[2m[36m(func pid=38679)[0m f1_micro: 0.2947761194029851
[2m[36m(func pid=38679)[0m f1_macro: 0.2524601880821395
[2m[36m(func pid=38679)[0m f1_weighted: 0.2918079098955285
[2m[36m(func pid=38679)[0m f1_per_class: [0.215, 0.479, 0.241, 0.292, 0.112, 0.221, 0.229, 0.334, 0.172, 0.229]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 1.8215 | Steps: 2 | Val loss: 1.9633 | Batch size: 32 | lr: 0.0001 | Duration: 2.76s
[2m[36m(func pid=39098)[0m top1: 0.20848880597014927
[2m[36m(func pid=39098)[0m top5: 0.8302238805970149
[2m[36m(func pid=39098)[0m f1_micro: 0.20848880597014927
[2m[36m(func pid=39098)[0m f1_macro: 0.18441520743366832
[2m[36m(func pid=39098)[0m f1_weighted: 0.1813973590084101
[2m[36m(func pid=39098)[0m f1_per_class: [0.113, 0.377, 0.0, 0.023, 0.164, 0.334, 0.12, 0.451, 0.16, 0.103]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=39517)[0m top1: 0.177705223880597
[2m[36m(func pid=39517)[0m top5: 0.7700559701492538
[2m[36m(func pid=39517)[0m f1_micro: 0.177705223880597
[2m[36m(func pid=39517)[0m f1_macro: 0.1283001647723504
[2m[36m(func pid=39517)[0m f1_weighted: 0.2040859188019386
[2m[36m(func pid=39517)[0m f1_per_class: [0.041, 0.09, 0.169, 0.199, 0.029, 0.186, 0.332, 0.146, 0.053, 0.036]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.6147 | Steps: 2 | Val loss: 3.4515 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
== Status ==
Current time: 2024-01-07 02:28:41 (running for 00:04:42.56)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  1.822 |      0.265 |                   44 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.399 |      0.252 |                   45 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.892 |      0.184 |                   43 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  2.323 |      0.128 |                   44 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.2835820895522388
[2m[36m(func pid=38305)[0m top5: 0.9081156716417911
[2m[36m(func pid=38305)[0m f1_micro: 0.2835820895522388
[2m[36m(func pid=38305)[0m f1_macro: 0.26460053702857117
[2m[36m(func pid=38305)[0m f1_weighted: 0.26725549125056736
[2m[36m(func pid=38305)[0m f1_per_class: [0.29, 0.358, 0.319, 0.0, 0.058, 0.122, 0.486, 0.517, 0.122, 0.373]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 1.9641 | Steps: 2 | Val loss: 14.9156 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 1.1050 | Steps: 2 | Val loss: 10.2696 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=38679)[0m top1: 0.2943097014925373
[2m[36m(func pid=38679)[0m top5: 0.8661380597014925
[2m[36m(func pid=38679)[0m f1_micro: 0.2943097014925373
[2m[36m(func pid=38679)[0m f1_macro: 0.24612449806451533
[2m[36m(func pid=38679)[0m f1_weighted: 0.2862328570918628
[2m[36m(func pid=38679)[0m f1_per_class: [0.262, 0.495, 0.225, 0.27, 0.129, 0.177, 0.241, 0.332, 0.137, 0.193]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=39517)[0m top1: 0.2537313432835821
[2m[36m(func pid=39517)[0m top5: 0.8092350746268657
[2m[36m(func pid=39517)[0m f1_micro: 0.2537313432835821
[2m[36m(func pid=39517)[0m f1_macro: 0.15776923435142245
[2m[36m(func pid=39517)[0m f1_weighted: 0.26444912577682345
[2m[36m(func pid=39517)[0m f1_per_class: [0.063, 0.208, 0.229, 0.167, 0.026, 0.333, 0.465, 0.032, 0.0, 0.055]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 1.6097 | Steps: 2 | Val loss: 1.9563 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=39098)[0m top1: 0.18563432835820895
[2m[36m(func pid=39098)[0m top5: 0.8120335820895522
[2m[36m(func pid=39098)[0m f1_micro: 0.18563432835820895
[2m[36m(func pid=39098)[0m f1_macro: 0.1655299119470681
[2m[36m(func pid=39098)[0m f1_weighted: 0.17247618515022317
[2m[36m(func pid=39098)[0m f1_per_class: [0.121, 0.382, 0.0, 0.016, 0.119, 0.265, 0.13, 0.435, 0.115, 0.072]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.8652 | Steps: 2 | Val loss: 4.0040 | Batch size: 32 | lr: 0.001 | Duration: 2.74s
== Status ==
Current time: 2024-01-07 02:28:46 (running for 00:04:47.79)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  1.61  |      0.256 |                   45 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.615 |      0.246 |                   46 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  1.105 |      0.166 |                   44 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.964 |      0.158 |                   45 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.27098880597014924
[2m[36m(func pid=38305)[0m top5: 0.9081156716417911
[2m[36m(func pid=38305)[0m f1_micro: 0.27098880597014924
[2m[36m(func pid=38305)[0m f1_macro: 0.25579544662835896
[2m[36m(func pid=38305)[0m f1_weighted: 0.26004985791478374
[2m[36m(func pid=38305)[0m f1_per_class: [0.3, 0.353, 0.319, 0.007, 0.056, 0.154, 0.452, 0.507, 0.115, 0.295]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 1.9027 | Steps: 2 | Val loss: 7.9052 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.9359 | Steps: 2 | Val loss: 10.4507 | Batch size: 32 | lr: 0.01 | Duration: 2.73s
[2m[36m(func pid=38679)[0m top1: 0.2980410447761194
[2m[36m(func pid=38679)[0m top5: 0.8698694029850746
[2m[36m(func pid=38679)[0m f1_micro: 0.2980410447761194
[2m[36m(func pid=38679)[0m f1_macro: 0.26762934290917256
[2m[36m(func pid=38679)[0m f1_weighted: 0.27011687853315747
[2m[36m(func pid=38679)[0m f1_per_class: [0.325, 0.495, 0.338, 0.223, 0.169, 0.156, 0.237, 0.287, 0.128, 0.319]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=39517)[0m top1: 0.19869402985074627
[2m[36m(func pid=39517)[0m top5: 0.7975746268656716
[2m[36m(func pid=39517)[0m f1_micro: 0.19869402985074627
[2m[36m(func pid=39517)[0m f1_macro: 0.14396660128083255
[2m[36m(func pid=39517)[0m f1_weighted: 0.18005062286694637
[2m[36m(func pid=39517)[0m f1_per_class: [0.073, 0.24, 0.37, 0.209, 0.026, 0.309, 0.134, 0.0, 0.018, 0.061]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 1.7951 | Steps: 2 | Val loss: 1.9533 | Batch size: 32 | lr: 0.0001 | Duration: 2.74s
[2m[36m(func pid=39098)[0m top1: 0.16557835820895522
[2m[36m(func pid=39098)[0m top5: 0.8115671641791045
[2m[36m(func pid=39098)[0m f1_micro: 0.16557835820895522
[2m[36m(func pid=39098)[0m f1_macro: 0.15302943478396996
[2m[36m(func pid=39098)[0m f1_weighted: 0.1689148626405384
[2m[36m(func pid=39098)[0m f1_per_class: [0.125, 0.287, 0.0, 0.02, 0.155, 0.125, 0.224, 0.432, 0.103, 0.06]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.5679 | Steps: 2 | Val loss: 3.8132 | Batch size: 32 | lr: 0.001 | Duration: 2.71s
== Status ==
Current time: 2024-01-07 02:28:52 (running for 00:04:52.94)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  1.795 |      0.234 |                   46 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.865 |      0.268 |                   47 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.936 |      0.153 |                   45 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.903 |      0.144 |                   46 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.24813432835820895
[2m[36m(func pid=38305)[0m top5: 0.9095149253731343
[2m[36m(func pid=38305)[0m f1_micro: 0.24813432835820895
[2m[36m(func pid=38305)[0m f1_macro: 0.23388899795385623
[2m[36m(func pid=38305)[0m f1_weighted: 0.23780581190119174
[2m[36m(func pid=38305)[0m f1_per_class: [0.286, 0.344, 0.314, 0.026, 0.054, 0.11, 0.39, 0.48, 0.132, 0.203]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.7221 | Steps: 2 | Val loss: 9.7878 | Batch size: 32 | lr: 0.01 | Duration: 2.77s
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 1.9173 | Steps: 2 | Val loss: 4.8994 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
[2m[36m(func pid=38679)[0m top1: 0.31576492537313433
[2m[36m(func pid=38679)[0m top5: 0.8684701492537313
[2m[36m(func pid=38679)[0m f1_micro: 0.31576492537313433
[2m[36m(func pid=38679)[0m f1_macro: 0.2669885285456305
[2m[36m(func pid=38679)[0m f1_weighted: 0.28441172485688526
[2m[36m(func pid=38679)[0m f1_per_class: [0.301, 0.504, 0.367, 0.184, 0.113, 0.131, 0.324, 0.324, 0.086, 0.337]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=39098)[0m top1: 0.18330223880597016
[2m[36m(func pid=39098)[0m top5: 0.8157649253731343
[2m[36m(func pid=39098)[0m f1_micro: 0.18330223880597016
[2m[36m(func pid=39098)[0m f1_macro: 0.15734690084055783
[2m[36m(func pid=39098)[0m f1_weighted: 0.18877017306698343
[2m[36m(func pid=39098)[0m f1_per_class: [0.137, 0.235, 0.0, 0.041, 0.142, 0.129, 0.302, 0.412, 0.108, 0.067]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=39517)[0m top1: 0.1935634328358209
[2m[36m(func pid=39517)[0m top5: 0.8013059701492538
[2m[36m(func pid=39517)[0m f1_micro: 0.1935634328358209
[2m[36m(func pid=39517)[0m f1_macro: 0.14230688820891696
[2m[36m(func pid=39517)[0m f1_weighted: 0.1691839337648661
[2m[36m(func pid=39517)[0m f1_per_class: [0.068, 0.207, 0.4, 0.229, 0.034, 0.297, 0.1, 0.0, 0.042, 0.046]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 1.5895 | Steps: 2 | Val loss: 1.9540 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.5661 | Steps: 2 | Val loss: 3.6670 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=38305)[0m top1: 0.24253731343283583
[2m[36m(func pid=38305)[0m top5: 0.9132462686567164
[2m[36m(func pid=38305)[0m f1_micro: 0.24253731343283583
[2m[36m(func pid=38305)[0m f1_macro: 0.22805177765349546
[2m[36m(func pid=38305)[0m f1_weighted: 0.23630201350091776
[2m[36m(func pid=38305)[0m f1_per_class: [0.294, 0.344, 0.297, 0.075, 0.054, 0.082, 0.35, 0.473, 0.143, 0.168]
[2m[36m(func pid=38305)[0m 
== Status ==
Current time: 2024-01-07 02:28:57 (running for 00:04:58.37)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  1.59  |      0.228 |                   47 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.568 |      0.267 |                   48 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.722 |      0.157 |                   46 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.917 |      0.142 |                   47 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 2.4096 | Steps: 2 | Val loss: 4.3955 | Batch size: 32 | lr: 0.1 | Duration: 2.76s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.6439 | Steps: 2 | Val loss: 9.1719 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=38679)[0m top1: 0.3358208955223881
[2m[36m(func pid=38679)[0m top5: 0.8694029850746269
[2m[36m(func pid=38679)[0m f1_micro: 0.3358208955223881
[2m[36m(func pid=38679)[0m f1_macro: 0.26998261646251176
[2m[36m(func pid=38679)[0m f1_weighted: 0.30553669479057255
[2m[36m(func pid=38679)[0m f1_per_class: [0.28, 0.507, 0.348, 0.16, 0.114, 0.141, 0.404, 0.383, 0.086, 0.275]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=39517)[0m top1: 0.20475746268656717
[2m[36m(func pid=39517)[0m top5: 0.777518656716418
[2m[36m(func pid=39517)[0m f1_micro: 0.20475746268656717
[2m[36m(func pid=39517)[0m f1_macro: 0.1256382554667695
[2m[36m(func pid=39517)[0m f1_weighted: 0.19360931783381247
[2m[36m(func pid=39517)[0m f1_per_class: [0.063, 0.127, 0.151, 0.214, 0.042, 0.3, 0.243, 0.0, 0.059, 0.057]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=39098)[0m top1: 0.18983208955223882
[2m[36m(func pid=39098)[0m top5: 0.8274253731343284
[2m[36m(func pid=39098)[0m f1_micro: 0.18983208955223882
[2m[36m(func pid=39098)[0m f1_macro: 0.16260837271200482
[2m[36m(func pid=39098)[0m f1_weighted: 0.1834449895511423
[2m[36m(func pid=39098)[0m f1_per_class: [0.152, 0.23, 0.0, 0.07, 0.173, 0.168, 0.252, 0.339, 0.156, 0.088]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 1.5713 | Steps: 2 | Val loss: 1.9549 | Batch size: 32 | lr: 0.0001 | Duration: 2.76s
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.5251 | Steps: 2 | Val loss: 3.4348 | Batch size: 32 | lr: 0.001 | Duration: 2.76s
== Status ==
Current time: 2024-01-07 02:29:02 (running for 00:05:03.55)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  1.571 |      0.229 |                   48 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.566 |      0.27  |                   49 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.644 |      0.163 |                   47 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  2.41  |      0.126 |                   48 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.24067164179104478
[2m[36m(func pid=38305)[0m top5: 0.9169776119402985
[2m[36m(func pid=38305)[0m f1_micro: 0.24067164179104478
[2m[36m(func pid=38305)[0m f1_macro: 0.22850035357904094
[2m[36m(func pid=38305)[0m f1_weighted: 0.24141583476638234
[2m[36m(func pid=38305)[0m f1_per_class: [0.275, 0.338, 0.278, 0.114, 0.054, 0.123, 0.32, 0.473, 0.16, 0.15]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 1.9285 | Steps: 2 | Val loss: 4.6470 | Batch size: 32 | lr: 0.1 | Duration: 2.75s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.9899 | Steps: 2 | Val loss: 9.4230 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=38679)[0m top1: 0.363339552238806
[2m[36m(func pid=38679)[0m top5: 0.8563432835820896
[2m[36m(func pid=38679)[0m f1_micro: 0.363339552238806
[2m[36m(func pid=38679)[0m f1_macro: 0.279863519576344
[2m[36m(func pid=38679)[0m f1_weighted: 0.35452910343479305
[2m[36m(func pid=38679)[0m f1_per_class: [0.258, 0.529, 0.235, 0.199, 0.109, 0.212, 0.48, 0.477, 0.106, 0.194]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=39517)[0m top1: 0.27845149253731344
[2m[36m(func pid=39517)[0m top5: 0.7453358208955224
[2m[36m(func pid=39517)[0m f1_micro: 0.27845149253731344
[2m[36m(func pid=39517)[0m f1_macro: 0.131945424712487
[2m[36m(func pid=39517)[0m f1_weighted: 0.24824156366481195
[2m[36m(func pid=39517)[0m f1_per_class: [0.066, 0.077, 0.101, 0.121, 0.045, 0.239, 0.569, 0.0, 0.043, 0.058]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 1.6514 | Steps: 2 | Val loss: 1.9602 | Batch size: 32 | lr: 0.0001 | Duration: 2.75s
[2m[36m(func pid=39098)[0m top1: 0.1865671641791045
[2m[36m(func pid=39098)[0m top5: 0.8278917910447762
[2m[36m(func pid=39098)[0m f1_micro: 0.1865671641791045
[2m[36m(func pid=39098)[0m f1_macro: 0.16324237016368576
[2m[36m(func pid=39098)[0m f1_weighted: 0.1831290707560817
[2m[36m(func pid=39098)[0m f1_per_class: [0.153, 0.216, 0.0, 0.123, 0.196, 0.2, 0.202, 0.313, 0.149, 0.08]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.3736 | Steps: 2 | Val loss: 3.5998 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 2.0216 | Steps: 2 | Val loss: 5.5215 | Batch size: 32 | lr: 0.1 | Duration: 2.65s
== Status ==
Current time: 2024-01-07 02:29:07 (running for 00:05:08.75)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  1.651 |      0.231 |                   49 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.525 |      0.28  |                   50 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.99  |      0.163 |                   48 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.928 |      0.132 |                   49 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.24347014925373134
[2m[36m(func pid=38305)[0m top5: 0.917910447761194
[2m[36m(func pid=38305)[0m f1_micro: 0.24347014925373134
[2m[36m(func pid=38305)[0m f1_macro: 0.2309784301170633
[2m[36m(func pid=38305)[0m f1_weighted: 0.2497129821661303
[2m[36m(func pid=38305)[0m f1_per_class: [0.261, 0.348, 0.265, 0.16, 0.055, 0.146, 0.289, 0.481, 0.161, 0.143]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 1.3176 | Steps: 2 | Val loss: 9.7331 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=38679)[0m top1: 0.3582089552238806
[2m[36m(func pid=38679)[0m top5: 0.8390858208955224
[2m[36m(func pid=38679)[0m f1_micro: 0.35820895522388063
[2m[36m(func pid=38679)[0m f1_macro: 0.2881762584117264
[2m[36m(func pid=38679)[0m f1_weighted: 0.3774614126865882
[2m[36m(func pid=38679)[0m f1_per_class: [0.233, 0.497, 0.185, 0.215, 0.079, 0.362, 0.499, 0.5, 0.126, 0.185]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=39517)[0m top1: 0.25886194029850745
[2m[36m(func pid=39517)[0m top5: 0.7453358208955224
[2m[36m(func pid=39517)[0m f1_micro: 0.25886194029850745
[2m[36m(func pid=39517)[0m f1_macro: 0.11163063545061162
[2m[36m(func pid=39517)[0m f1_weighted: 0.21215516335801773
[2m[36m(func pid=39517)[0m f1_per_class: [0.041, 0.111, 0.149, 0.08, 0.029, 0.08, 0.529, 0.0, 0.041, 0.055]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 1.5111 | Steps: 2 | Val loss: 1.9455 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=39098)[0m top1: 0.1814365671641791
[2m[36m(func pid=39098)[0m top5: 0.8190298507462687
[2m[36m(func pid=39098)[0m f1_micro: 0.1814365671641791
[2m[36m(func pid=39098)[0m f1_macro: 0.16577362593817108
[2m[36m(func pid=39098)[0m f1_weighted: 0.17889600229411584
[2m[36m(func pid=39098)[0m f1_per_class: [0.15, 0.207, 0.0, 0.093, 0.229, 0.257, 0.198, 0.328, 0.12, 0.074]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.5491 | Steps: 2 | Val loss: 4.0924 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 1.7269 | Steps: 2 | Val loss: 6.5587 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=38305)[0m top1: 0.2490671641791045
[2m[36m(func pid=38305)[0m top5: 0.9202425373134329
[2m[36m(func pid=38305)[0m f1_micro: 0.2490671641791045
[2m[36m(func pid=38305)[0m f1_macro: 0.2349103577681062
[2m[36m(func pid=38305)[0m f1_weighted: 0.2612035209411973
[2m[36m(func pid=38305)[0m f1_per_class: [0.244, 0.341, 0.25, 0.198, 0.054, 0.182, 0.286, 0.465, 0.16, 0.169]
== Status ==
Current time: 2024-01-07 02:29:13 (running for 00:05:14.16)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  1.511 |      0.235 |                   50 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.374 |      0.288 |                   51 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  1.318 |      0.166 |                   49 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  2.022 |      0.112 |                   50 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.9329 | Steps: 2 | Val loss: 10.7083 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=38679)[0m top1: 0.3218283582089552
[2m[36m(func pid=38679)[0m top5: 0.8129664179104478
[2m[36m(func pid=38679)[0m f1_micro: 0.3218283582089552
[2m[36m(func pid=38679)[0m f1_macro: 0.26964152640167727
[2m[36m(func pid=38679)[0m f1_weighted: 0.35220808889629074
[2m[36m(func pid=38679)[0m f1_per_class: [0.21, 0.407, 0.169, 0.207, 0.081, 0.375, 0.474, 0.488, 0.129, 0.157]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=39517)[0m top1: 0.26119402985074625
[2m[36m(func pid=39517)[0m top5: 0.7644589552238806
[2m[36m(func pid=39517)[0m f1_micro: 0.26119402985074625
[2m[36m(func pid=39517)[0m f1_macro: 0.1136562835301109
[2m[36m(func pid=39517)[0m f1_weighted: 0.20867887163482893
[2m[36m(func pid=39517)[0m f1_per_class: [0.068, 0.171, 0.14, 0.059, 0.071, 0.0, 0.53, 0.0, 0.038, 0.058]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 1.4862 | Steps: 2 | Val loss: 1.9296 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=39098)[0m top1: 0.19636194029850745
[2m[36m(func pid=39098)[0m top5: 0.8069029850746269
[2m[36m(func pid=39098)[0m f1_micro: 0.19636194029850748
[2m[36m(func pid=39098)[0m f1_macro: 0.1496855617182393
[2m[36m(func pid=39098)[0m f1_weighted: 0.20153841392417668
[2m[36m(func pid=39098)[0m f1_per_class: [0.101, 0.2, 0.0, 0.06, 0.0, 0.194, 0.326, 0.399, 0.158, 0.059]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.3563 | Steps: 2 | Val loss: 4.6349 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 2.5718 | Steps: 2 | Val loss: 8.0382 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
== Status ==
Current time: 2024-01-07 02:29:18 (running for 00:05:19.51)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  1.486 |      0.249 |                   51 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.549 |      0.27  |                   52 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.933 |      0.15  |                   50 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.727 |      0.114 |                   51 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.2644589552238806
[2m[36m(func pid=38305)[0m top5: 0.9216417910447762
[2m[36m(func pid=38305)[0m f1_micro: 0.2644589552238806
[2m[36m(func pid=38305)[0m f1_macro: 0.2493543399621192
[2m[36m(func pid=38305)[0m f1_weighted: 0.27816107769389525
[2m[36m(func pid=38305)[0m f1_per_class: [0.235, 0.352, 0.239, 0.259, 0.055, 0.218, 0.263, 0.463, 0.177, 0.231]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 1.2768 | Steps: 2 | Val loss: 12.6698 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=38679)[0m top1: 0.2887126865671642
[2m[36m(func pid=38679)[0m top5: 0.7840485074626866
[2m[36m(func pid=38679)[0m f1_micro: 0.2887126865671642
[2m[36m(func pid=38679)[0m f1_macro: 0.24612565932086922
[2m[36m(func pid=38679)[0m f1_weighted: 0.31546417508512686
[2m[36m(func pid=38679)[0m f1_per_class: [0.197, 0.247, 0.16, 0.186, 0.081, 0.314, 0.487, 0.49, 0.119, 0.18]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=39517)[0m top1: 0.2658582089552239
[2m[36m(func pid=39517)[0m top5: 0.777518656716418
[2m[36m(func pid=39517)[0m f1_micro: 0.2658582089552239
[2m[36m(func pid=39517)[0m f1_macro: 0.11389295857200477
[2m[36m(func pid=39517)[0m f1_weighted: 0.20472516448453365
[2m[36m(func pid=39517)[0m f1_per_class: [0.078, 0.136, 0.145, 0.047, 0.085, 0.0, 0.547, 0.0, 0.039, 0.061]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=39098)[0m top1: 0.240205223880597
[2m[36m(func pid=39098)[0m top5: 0.7938432835820896
[2m[36m(func pid=39098)[0m f1_micro: 0.240205223880597
[2m[36m(func pid=39098)[0m f1_macro: 0.16891407346629808
[2m[36m(func pid=39098)[0m f1_weighted: 0.26075898568514
[2m[36m(func pid=39098)[0m f1_per_class: [0.054, 0.193, 0.0, 0.058, 0.0, 0.151, 0.532, 0.504, 0.138, 0.059]
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 1.6671 | Steps: 2 | Val loss: 1.9071 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.3511 | Steps: 2 | Val loss: 5.0279 | Batch size: 32 | lr: 0.001 | Duration: 2.64s
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 2.2691 | Steps: 2 | Val loss: 8.0446 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
== Status ==
Current time: 2024-01-07 02:29:24 (running for 00:05:24.97)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  1.667 |      0.267 |                   52 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.356 |      0.246 |                   53 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  1.277 |      0.169 |                   51 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  2.572 |      0.114 |                   52 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.27845149253731344
[2m[36m(func pid=38305)[0m top5: 0.9202425373134329
[2m[36m(func pid=38305)[0m f1_micro: 0.27845149253731344
[2m[36m(func pid=38305)[0m f1_macro: 0.26674518022341964
[2m[36m(func pid=38305)[0m f1_weighted: 0.294665787797548
[2m[36m(func pid=38305)[0m f1_per_class: [0.254, 0.356, 0.247, 0.32, 0.053, 0.247, 0.248, 0.448, 0.158, 0.337]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=38679)[0m top1: 0.2644589552238806
[2m[36m(func pid=38679)[0m top5: 0.7574626865671642
[2m[36m(func pid=38679)[0m f1_micro: 0.2644589552238806
[2m[36m(func pid=38679)[0m f1_macro: 0.22708318722216844
[2m[36m(func pid=38679)[0m f1_weighted: 0.28004677619639523
[2m[36m(func pid=38679)[0m f1_per_class: [0.187, 0.155, 0.165, 0.16, 0.08, 0.261, 0.467, 0.494, 0.102, 0.199]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.8608 | Steps: 2 | Val loss: 12.9153 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=39517)[0m top1: 0.2644589552238806
[2m[36m(func pid=39517)[0m top5: 0.7658582089552238
[2m[36m(func pid=39517)[0m f1_micro: 0.2644589552238806
[2m[36m(func pid=39517)[0m f1_macro: 0.10973688240181971
[2m[36m(func pid=39517)[0m f1_weighted: 0.20076491096258767
[2m[36m(func pid=39517)[0m f1_per_class: [0.059, 0.075, 0.169, 0.065, 0.066, 0.015, 0.548, 0.0, 0.042, 0.059]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 1.3606 | Steps: 2 | Val loss: 1.8980 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.4719 | Steps: 2 | Val loss: 5.3078 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=39098)[0m top1: 0.21315298507462688
[2m[36m(func pid=39098)[0m top5: 0.7831156716417911
[2m[36m(func pid=39098)[0m f1_micro: 0.2131529850746269
[2m[36m(func pid=39098)[0m f1_macro: 0.18007066017901474
[2m[36m(func pid=39098)[0m f1_weighted: 0.23673435275990715
[2m[36m(func pid=39098)[0m f1_per_class: [0.032, 0.196, 0.0, 0.069, 0.222, 0.184, 0.429, 0.478, 0.126, 0.065]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 1.6855 | Steps: 2 | Val loss: 8.6661 | Batch size: 32 | lr: 0.1 | Duration: 2.59s
== Status ==
Current time: 2024-01-07 02:29:29 (running for 00:05:30.07)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  1.667 |      0.267 |                   52 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.472 |      0.223 |                   55 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.861 |      0.18  |                   52 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  2.269 |      0.11  |                   53 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38679)[0m top1: 0.24673507462686567
[2m[36m(func pid=38679)[0m top5: 0.7299440298507462
[2m[36m(func pid=38679)[0m f1_micro: 0.24673507462686567
[2m[36m(func pid=38679)[0m f1_macro: 0.2225787084993113
[2m[36m(func pid=38679)[0m f1_weighted: 0.2555881373792139
[2m[36m(func pid=38679)[0m f1_per_class: [0.173, 0.116, 0.224, 0.142, 0.081, 0.264, 0.426, 0.471, 0.105, 0.224]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=38305)[0m top1: 0.2873134328358209
[2m[36m(func pid=38305)[0m top5: 0.9197761194029851
[2m[36m(func pid=38305)[0m f1_micro: 0.2873134328358209
[2m[36m(func pid=38305)[0m f1_macro: 0.2690271706121402
[2m[36m(func pid=38305)[0m f1_weighted: 0.3032223248961579
[2m[36m(func pid=38305)[0m f1_per_class: [0.24, 0.361, 0.234, 0.369, 0.053, 0.23, 0.234, 0.442, 0.17, 0.357]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.6959 | Steps: 2 | Val loss: 12.0909 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=39517)[0m top1: 0.25046641791044777
[2m[36m(func pid=39517)[0m top5: 0.7686567164179104
[2m[36m(func pid=39517)[0m f1_micro: 0.25046641791044777
[2m[36m(func pid=39517)[0m f1_macro: 0.12858527629820862
[2m[36m(func pid=39517)[0m f1_weighted: 0.21765724990077784
[2m[36m(func pid=39517)[0m f1_per_class: [0.015, 0.114, 0.194, 0.056, 0.105, 0.138, 0.539, 0.03, 0.042, 0.053]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.3655 | Steps: 2 | Val loss: 4.5947 | Batch size: 32 | lr: 0.001 | Duration: 2.72s
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 1.6326 | Steps: 2 | Val loss: 1.9193 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=39098)[0m top1: 0.18097014925373134
[2m[36m(func pid=39098)[0m top5: 0.753731343283582
[2m[36m(func pid=39098)[0m f1_micro: 0.18097014925373134
[2m[36m(func pid=39098)[0m f1_macro: 0.15851024442711387
[2m[36m(func pid=39098)[0m f1_weighted: 0.187271352834328
[2m[36m(func pid=39098)[0m f1_per_class: [0.044, 0.207, 0.0, 0.08, 0.188, 0.122, 0.274, 0.453, 0.129, 0.09]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 1.7649 | Steps: 2 | Val loss: 9.3454 | Batch size: 32 | lr: 0.1 | Duration: 2.66s
[2m[36m(func pid=38679)[0m top1: 0.2593283582089552
[2m[36m(func pid=38679)[0m top5: 0.7490671641791045
[2m[36m(func pid=38679)[0m f1_micro: 0.2593283582089552
[2m[36m(func pid=38679)[0m f1_macro: 0.2414602558055769
[2m[36m(func pid=38679)[0m f1_weighted: 0.2744563636631133
[2m[36m(func pid=38679)[0m f1_per_class: [0.21, 0.139, 0.247, 0.19, 0.078, 0.313, 0.409, 0.472, 0.094, 0.263]
[2m[36m(func pid=38679)[0m 
== Status ==
Current time: 2024-01-07 02:29:34 (running for 00:05:35.57)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  1.633 |      0.257 |                   54 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.365 |      0.241 |                   56 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.696 |      0.159 |                   53 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.686 |      0.129 |                   54 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.28824626865671643
[2m[36m(func pid=38305)[0m top5: 0.909981343283582
[2m[36m(func pid=38305)[0m f1_micro: 0.28824626865671643
[2m[36m(func pid=38305)[0m f1_macro: 0.257365882307896
[2m[36m(func pid=38305)[0m f1_weighted: 0.29835168725114364
[2m[36m(func pid=38305)[0m f1_per_class: [0.222, 0.364, 0.196, 0.412, 0.055, 0.218, 0.187, 0.431, 0.155, 0.333]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.4907 | Steps: 2 | Val loss: 11.1712 | Batch size: 32 | lr: 0.01 | Duration: 2.73s
[2m[36m(func pid=39517)[0m top1: 0.11847014925373134
[2m[36m(func pid=39517)[0m top5: 0.7611940298507462
[2m[36m(func pid=39517)[0m f1_micro: 0.11847014925373134
[2m[36m(func pid=39517)[0m f1_macro: 0.10449769351085374
[2m[36m(func pid=39517)[0m f1_weighted: 0.09225867970923285
[2m[36m(func pid=39517)[0m f1_per_class: [0.0, 0.134, 0.205, 0.07, 0.138, 0.323, 0.012, 0.097, 0.023, 0.043]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.3035 | Steps: 2 | Val loss: 4.0937 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 1.4947 | Steps: 2 | Val loss: 1.9387 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=39098)[0m top1: 0.18003731343283583
[2m[36m(func pid=39098)[0m top5: 0.773320895522388
[2m[36m(func pid=39098)[0m f1_micro: 0.1800373134328358
[2m[36m(func pid=39098)[0m f1_macro: 0.1596350222634153
[2m[36m(func pid=39098)[0m f1_weighted: 0.1827960567249219
[2m[36m(func pid=39098)[0m f1_per_class: [0.045, 0.186, 0.069, 0.081, 0.126, 0.162, 0.262, 0.393, 0.149, 0.122]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 1.9517 | Steps: 2 | Val loss: 9.6751 | Batch size: 32 | lr: 0.1 | Duration: 2.78s
[2m[36m(func pid=38679)[0m top1: 0.28125
[2m[36m(func pid=38679)[0m top5: 0.7630597014925373
[2m[36m(func pid=38679)[0m f1_micro: 0.28125
[2m[36m(func pid=38679)[0m f1_macro: 0.25560290007748093
[2m[36m(func pid=38679)[0m f1_weighted: 0.30158736129871855
[2m[36m(func pid=38679)[0m f1_per_class: [0.235, 0.176, 0.29, 0.236, 0.064, 0.328, 0.43, 0.469, 0.089, 0.239]
[2m[36m(func pid=38679)[0m 
== Status ==
Current time: 2024-01-07 02:29:40 (running for 00:05:40.90)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  1.495 |      0.249 |                   55 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.303 |      0.256 |                   57 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.491 |      0.16  |                   54 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.765 |      0.104 |                   55 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.28638059701492535
[2m[36m(func pid=38305)[0m top5: 0.9011194029850746
[2m[36m(func pid=38305)[0m f1_micro: 0.28638059701492535
[2m[36m(func pid=38305)[0m f1_macro: 0.24912607306140946
[2m[36m(func pid=38305)[0m f1_weighted: 0.2848682796917669
[2m[36m(func pid=38305)[0m f1_per_class: [0.217, 0.37, 0.207, 0.44, 0.054, 0.24, 0.108, 0.419, 0.167, 0.27]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.3721 | Steps: 2 | Val loss: 10.5152 | Batch size: 32 | lr: 0.01 | Duration: 2.65s
[2m[36m(func pid=39517)[0m top1: 0.08675373134328358
[2m[36m(func pid=39517)[0m top5: 0.6436567164179104
[2m[36m(func pid=39517)[0m f1_micro: 0.08675373134328358
[2m[36m(func pid=39517)[0m f1_macro: 0.0771608848635709
[2m[36m(func pid=39517)[0m f1_weighted: 0.07623149002443154
[2m[36m(func pid=39517)[0m f1_per_class: [0.0, 0.076, 0.224, 0.11, 0.0, 0.227, 0.0, 0.067, 0.024, 0.043]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.2839 | Steps: 2 | Val loss: 3.3696 | Batch size: 32 | lr: 0.001 | Duration: 2.61s
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 1.3851 | Steps: 2 | Val loss: 1.9405 | Batch size: 32 | lr: 0.0001 | Duration: 2.74s
[2m[36m(func pid=39098)[0m top1: 0.20475746268656717
[2m[36m(func pid=39098)[0m top5: 0.800839552238806
[2m[36m(func pid=39098)[0m f1_micro: 0.20475746268656717
[2m[36m(func pid=39098)[0m f1_macro: 0.17816304103984804
[2m[36m(func pid=39098)[0m f1_weighted: 0.20918479492633893
[2m[36m(func pid=39098)[0m f1_per_class: [0.048, 0.243, 0.093, 0.098, 0.133, 0.141, 0.306, 0.395, 0.166, 0.158]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 1.6706 | Steps: 2 | Val loss: 10.4523 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=38679)[0m top1: 0.3185634328358209
[2m[36m(func pid=38679)[0m top5: 0.8120335820895522
[2m[36m(func pid=38679)[0m f1_micro: 0.3185634328358209
[2m[36m(func pid=38679)[0m f1_macro: 0.2825270960319257
[2m[36m(func pid=38679)[0m f1_weighted: 0.34509271608306685
[2m[36m(func pid=38679)[0m f1_per_class: [0.318, 0.268, 0.317, 0.309, 0.046, 0.349, 0.442, 0.453, 0.118, 0.206]
[2m[36m(func pid=38679)[0m 
== Status ==
Current time: 2024-01-07 02:29:45 (running for 00:05:45.94)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  1.385 |      0.233 |                   56 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.284 |      0.283 |                   58 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.372 |      0.178 |                   55 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.952 |      0.077 |                   56 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.28404850746268656
[2m[36m(func pid=38305)[0m top5: 0.8917910447761194
[2m[36m(func pid=38305)[0m f1_micro: 0.28404850746268656
[2m[36m(func pid=38305)[0m f1_macro: 0.23288093222599784
[2m[36m(func pid=38305)[0m f1_weighted: 0.2726056758004506
[2m[36m(func pid=38305)[0m f1_per_class: [0.212, 0.373, 0.209, 0.475, 0.057, 0.225, 0.048, 0.4, 0.141, 0.189]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.3946 | Steps: 2 | Val loss: 10.0042 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
[2m[36m(func pid=39517)[0m top1: 0.10307835820895522
[2m[36m(func pid=39517)[0m top5: 0.6119402985074627
[2m[36m(func pid=39517)[0m f1_micro: 0.10307835820895522
[2m[36m(func pid=39517)[0m f1_macro: 0.08703196436340487
[2m[36m(func pid=39517)[0m f1_weighted: 0.109123140563354
[2m[36m(func pid=39517)[0m f1_per_class: [0.0, 0.097, 0.226, 0.22, 0.0, 0.231, 0.0, 0.033, 0.024, 0.039]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.7089 | Steps: 2 | Val loss: 3.3401 | Batch size: 32 | lr: 0.001 | Duration: 2.62s
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 1.2857 | Steps: 2 | Val loss: 1.9452 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=39098)[0m top1: 0.2635261194029851
[2m[36m(func pid=39098)[0m top5: 0.8222947761194029
[2m[36m(func pid=39098)[0m f1_micro: 0.2635261194029851
[2m[36m(func pid=39098)[0m f1_macro: 0.2127254021721669
[2m[36m(func pid=39098)[0m f1_weighted: 0.27408656504143486
[2m[36m(func pid=39098)[0m f1_per_class: [0.051, 0.363, 0.083, 0.134, 0.153, 0.103, 0.424, 0.433, 0.186, 0.198]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 1.8584 | Steps: 2 | Val loss: 10.3705 | Batch size: 32 | lr: 0.1 | Duration: 2.71s
[2m[36m(func pid=38679)[0m top1: 0.31902985074626866
[2m[36m(func pid=38679)[0m top5: 0.8316231343283582
[2m[36m(func pid=38679)[0m f1_micro: 0.31902985074626866
[2m[36m(func pid=38679)[0m f1_macro: 0.30936977951410244
[2m[36m(func pid=38679)[0m f1_weighted: 0.34780004063377207
[2m[36m(func pid=38679)[0m f1_per_class: [0.442, 0.326, 0.444, 0.416, 0.054, 0.293, 0.329, 0.415, 0.163, 0.211]
[2m[36m(func pid=38679)[0m 
== Status ==
Current time: 2024-01-07 02:29:50 (running for 00:05:51.08)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  1.286 |      0.218 |                   57 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.709 |      0.309 |                   59 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.395 |      0.213 |                   56 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.671 |      0.087 |                   57 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.28078358208955223
[2m[36m(func pid=38305)[0m top5: 0.8861940298507462
[2m[36m(func pid=38305)[0m f1_micro: 0.28078358208955223
[2m[36m(func pid=38305)[0m f1_macro: 0.21769102559558223
[2m[36m(func pid=38305)[0m f1_weighted: 0.2620751141957604
[2m[36m(func pid=38305)[0m f1_per_class: [0.209, 0.364, 0.2, 0.485, 0.063, 0.203, 0.024, 0.402, 0.087, 0.14]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39517)[0m top1: 0.1310634328358209
[2m[36m(func pid=39517)[0m top5: 0.6263992537313433
[2m[36m(func pid=39517)[0m f1_micro: 0.1310634328358209
[2m[36m(func pid=39517)[0m f1_macro: 0.10771423119771555
[2m[36m(func pid=39517)[0m f1_weighted: 0.14278461930130812
[2m[36m(func pid=39517)[0m f1_per_class: [0.0, 0.099, 0.224, 0.337, 0.083, 0.228, 0.0, 0.044, 0.023, 0.039]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.4810 | Steps: 2 | Val loss: 10.0682 | Batch size: 32 | lr: 0.01 | Duration: 3.05s
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.3762 | Steps: 2 | Val loss: 3.7852 | Batch size: 32 | lr: 0.001 | Duration: 2.75s
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 1.3692 | Steps: 2 | Val loss: 1.9363 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 1.6738 | Steps: 2 | Val loss: 10.5822 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=39098)[0m top1: 0.31296641791044777
[2m[36m(func pid=39098)[0m top5: 0.8330223880597015
[2m[36m(func pid=39098)[0m f1_micro: 0.31296641791044777
[2m[36m(func pid=39098)[0m f1_macro: 0.2156157159971285
[2m[36m(func pid=39098)[0m f1_weighted: 0.31220093601216886
[2m[36m(func pid=39098)[0m f1_per_class: [0.05, 0.416, 0.079, 0.14, 0.0, 0.016, 0.539, 0.493, 0.201, 0.223]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=38679)[0m top1: 0.3111007462686567
[2m[36m(func pid=38679)[0m top5: 0.7761194029850746
[2m[36m(func pid=38679)[0m f1_micro: 0.3111007462686567
[2m[36m(func pid=38679)[0m f1_macro: 0.3016079616097707
[2m[36m(func pid=38679)[0m f1_weighted: 0.3322959867478517
[2m[36m(func pid=38679)[0m f1_per_class: [0.542, 0.361, 0.55, 0.471, 0.025, 0.248, 0.251, 0.222, 0.196, 0.15]
[2m[36m(func pid=38679)[0m 
== Status ==
Current time: 2024-01-07 02:29:55 (running for 00:05:56.24)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  1.369 |      0.214 |                   58 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.376 |      0.302 |                   60 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.481 |      0.216 |                   57 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.858 |      0.108 |                   58 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.2826492537313433
[2m[36m(func pid=38305)[0m top5: 0.8796641791044776
[2m[36m(func pid=38305)[0m f1_micro: 0.2826492537313433
[2m[36m(func pid=38305)[0m f1_macro: 0.21420467425183745
[2m[36m(func pid=38305)[0m f1_weighted: 0.2597539508175037
[2m[36m(func pid=38305)[0m f1_per_class: [0.188, 0.354, 0.208, 0.501, 0.066, 0.17, 0.018, 0.414, 0.095, 0.128]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39517)[0m top1: 0.15904850746268656
[2m[36m(func pid=39517)[0m top5: 0.65625
[2m[36m(func pid=39517)[0m f1_micro: 0.15904850746268656
[2m[36m(func pid=39517)[0m f1_macro: 0.11706546340192044
[2m[36m(func pid=39517)[0m f1_weighted: 0.16517312891231972
[2m[36m(func pid=39517)[0m f1_per_class: [0.0, 0.095, 0.229, 0.42, 0.081, 0.221, 0.0, 0.044, 0.038, 0.042]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.5679 | Steps: 2 | Val loss: 10.5353 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.4422 | Steps: 2 | Val loss: 3.1195 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 1.2750 | Steps: 2 | Val loss: 1.9239 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 2.9093 | Steps: 2 | Val loss: 9.2356 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
[2m[36m(func pid=39098)[0m top1: 0.29197761194029853
[2m[36m(func pid=39098)[0m top5: 0.8367537313432836
[2m[36m(func pid=39098)[0m f1_micro: 0.29197761194029853
[2m[36m(func pid=39098)[0m f1_macro: 0.20532123188778267
[2m[36m(func pid=39098)[0m f1_weighted: 0.2939277884666412
[2m[36m(func pid=39098)[0m f1_per_class: [0.042, 0.42, 0.073, 0.148, 0.0, 0.008, 0.479, 0.46, 0.179, 0.245]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=38679)[0m top1: 0.3516791044776119
[2m[36m(func pid=38679)[0m top5: 0.8414179104477612
[2m[36m(func pid=38679)[0m f1_micro: 0.3516791044776119
[2m[36m(func pid=38679)[0m f1_macro: 0.3247116425817611
[2m[36m(func pid=38679)[0m f1_weighted: 0.3729067357742608
[2m[36m(func pid=38679)[0m f1_per_class: [0.476, 0.352, 0.537, 0.453, 0.027, 0.31, 0.369, 0.316, 0.195, 0.212]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=38305)[0m top1: 0.2896455223880597
[2m[36m(func pid=38305)[0m top5: 0.8768656716417911
[2m[36m(func pid=38305)[0m f1_micro: 0.2896455223880597
[2m[36m(func pid=38305)[0m f1_macro: 0.21411536398596814
[2m[36m(func pid=38305)[0m f1_weighted: 0.26269506501683876
[2m[36m(func pid=38305)[0m f1_per_class: [0.182, 0.357, 0.227, 0.515, 0.069, 0.184, 0.012, 0.414, 0.051, 0.13]
== Status ==
Current time: 2024-01-07 02:30:00 (running for 00:06:01.75)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  1.275 |      0.214 |                   59 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.442 |      0.325 |                   61 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.568 |      0.205 |                   58 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.674 |      0.117 |                   59 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39517)[0m top1: 0.19496268656716417
[2m[36m(func pid=39517)[0m top5: 0.7826492537313433
[2m[36m(func pid=39517)[0m f1_micro: 0.19496268656716417
[2m[36m(func pid=39517)[0m f1_macro: 0.1373105096721458
[2m[36m(func pid=39517)[0m f1_weighted: 0.17290546722002437
[2m[36m(func pid=39517)[0m f1_per_class: [0.085, 0.091, 0.222, 0.429, 0.105, 0.173, 0.006, 0.196, 0.0, 0.066]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.2578 | Steps: 2 | Val loss: 2.8706 | Batch size: 32 | lr: 0.001 | Duration: 2.73s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.5214 | Steps: 2 | Val loss: 11.0403 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 1.9385 | Steps: 2 | Val loss: 7.1960 | Batch size: 32 | lr: 0.1 | Duration: 2.60s
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 1.3053 | Steps: 2 | Val loss: 1.8980 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=38679)[0m top1: 0.38572761194029853
[2m[36m(func pid=38679)[0m top5: 0.855410447761194
[2m[36m(func pid=38679)[0m f1_micro: 0.3857276119402986
[2m[36m(func pid=38679)[0m f1_macro: 0.3362289438420377
[2m[36m(func pid=38679)[0m f1_weighted: 0.41189754455563987
[2m[36m(func pid=38679)[0m f1_per_class: [0.45, 0.345, 0.489, 0.413, 0.062, 0.352, 0.518, 0.409, 0.125, 0.199]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=39098)[0m top1: 0.2630597014925373
[2m[36m(func pid=39098)[0m top5: 0.8362873134328358
[2m[36m(func pid=39098)[0m f1_micro: 0.2630597014925373
[2m[36m(func pid=39098)[0m f1_macro: 0.20009496373117241
[2m[36m(func pid=39098)[0m f1_weighted: 0.2703770254340306
[2m[36m(func pid=39098)[0m f1_per_class: [0.042, 0.408, 0.068, 0.166, 0.0, 0.061, 0.378, 0.409, 0.184, 0.286]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=39517)[0m top1: 0.18983208955223882
[2m[36m(func pid=39517)[0m top5: 0.7943097014925373
[2m[36m(func pid=39517)[0m f1_micro: 0.18983208955223882
[2m[36m(func pid=39517)[0m f1_macro: 0.1507014511402681
[2m[36m(func pid=39517)[0m f1_weighted: 0.18301587505903807
[2m[36m(func pid=39517)[0m f1_per_class: [0.075, 0.125, 0.333, 0.408, 0.09, 0.128, 0.051, 0.209, 0.021, 0.066]
[2m[36m(func pid=39517)[0m 
== Status ==
Current time: 2024-01-07 02:30:06 (running for 00:06:07.13)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  1.305 |      0.223 |                   60 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.258 |      0.336 |                   62 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.521 |      0.2   |                   59 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.939 |      0.151 |                   61 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.2994402985074627
[2m[36m(func pid=38305)[0m top5: 0.8833955223880597
[2m[36m(func pid=38305)[0m f1_micro: 0.2994402985074627
[2m[36m(func pid=38305)[0m f1_macro: 0.22295196658026883
[2m[36m(func pid=38305)[0m f1_weighted: 0.26857339615917153
[2m[36m(func pid=38305)[0m f1_per_class: [0.218, 0.362, 0.253, 0.526, 0.072, 0.203, 0.012, 0.392, 0.053, 0.139]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.4154 | Steps: 2 | Val loss: 2.6189 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.6688 | Steps: 2 | Val loss: 11.2123 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 1.6477 | Steps: 2 | Val loss: 6.9169 | Batch size: 32 | lr: 0.1 | Duration: 2.69s
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 1.2843 | Steps: 2 | Val loss: 1.8777 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=38679)[0m top1: 0.417910447761194
[2m[36m(func pid=38679)[0m top5: 0.8763992537313433
[2m[36m(func pid=38679)[0m f1_micro: 0.417910447761194
[2m[36m(func pid=38679)[0m f1_macro: 0.3591607230935555
[2m[36m(func pid=38679)[0m f1_weighted: 0.44058967083011197
[2m[36m(func pid=38679)[0m f1_per_class: [0.561, 0.357, 0.512, 0.454, 0.075, 0.332, 0.57, 0.38, 0.163, 0.188]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=39098)[0m top1: 0.25419776119402987
[2m[36m(func pid=39098)[0m top5: 0.8442164179104478
[2m[36m(func pid=39098)[0m f1_micro: 0.25419776119402987
[2m[36m(func pid=39098)[0m f1_macro: 0.21481282107612584
[2m[36m(func pid=39098)[0m f1_weighted: 0.27019491777366905
[2m[36m(func pid=39098)[0m f1_per_class: [0.046, 0.392, 0.066, 0.213, 0.108, 0.121, 0.324, 0.365, 0.178, 0.336]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=39517)[0m top1: 0.0914179104477612
[2m[36m(func pid=39517)[0m top5: 0.7905783582089553
[2m[36m(func pid=39517)[0m f1_micro: 0.0914179104477612
[2m[36m(func pid=39517)[0m f1_macro: 0.11304086832628353
[2m[36m(func pid=39517)[0m f1_weighted: 0.10588626202696877
[2m[36m(func pid=39517)[0m f1_per_class: [0.077, 0.116, 0.333, 0.128, 0.088, 0.082, 0.09, 0.132, 0.045, 0.038]
[2m[36m(func pid=39517)[0m 
== Status ==
Current time: 2024-01-07 02:30:11 (running for 00:06:12.37)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  1.284 |      0.233 |                   61 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.415 |      0.359 |                   63 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.669 |      0.215 |                   60 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.648 |      0.113 |                   62 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.30783582089552236
[2m[36m(func pid=38305)[0m top5: 0.8843283582089553
[2m[36m(func pid=38305)[0m f1_micro: 0.30783582089552236
[2m[36m(func pid=38305)[0m f1_macro: 0.2332234922188599
[2m[36m(func pid=38305)[0m f1_weighted: 0.27361369360899923
[2m[36m(func pid=38305)[0m f1_per_class: [0.23, 0.358, 0.259, 0.527, 0.073, 0.263, 0.006, 0.389, 0.053, 0.175]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.3971 | Steps: 2 | Val loss: 2.5034 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.7959 | Steps: 2 | Val loss: 10.9715 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 1.5589 | Steps: 2 | Val loss: 7.5749 | Batch size: 32 | lr: 0.1 | Duration: 2.62s
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 1.2530 | Steps: 2 | Val loss: 1.8586 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=38679)[0m top1: 0.4375
[2m[36m(func pid=38679)[0m top5: 0.8861940298507462
[2m[36m(func pid=38679)[0m f1_micro: 0.4375
[2m[36m(func pid=38679)[0m f1_macro: 0.3683317317580644
[2m[36m(func pid=38679)[0m f1_weighted: 0.4525307070484103
[2m[36m(func pid=38679)[0m f1_per_class: [0.568, 0.354, 0.667, 0.511, 0.075, 0.317, 0.592, 0.195, 0.202, 0.203]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=39098)[0m top1: 0.2691231343283582
[2m[36m(func pid=39098)[0m top5: 0.8521455223880597
[2m[36m(func pid=39098)[0m f1_micro: 0.2691231343283582
[2m[36m(func pid=39098)[0m f1_macro: 0.22603825131627125
[2m[36m(func pid=39098)[0m f1_weighted: 0.292687900482671
[2m[36m(func pid=39098)[0m f1_per_class: [0.048, 0.379, 0.067, 0.254, 0.098, 0.14, 0.356, 0.388, 0.175, 0.356]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=39517)[0m top1: 0.06763059701492537
[2m[36m(func pid=39517)[0m top5: 0.7803171641791045
[2m[36m(func pid=39517)[0m f1_micro: 0.06763059701492537
[2m[36m(func pid=39517)[0m f1_macro: 0.08359955512994169
[2m[36m(func pid=39517)[0m f1_weighted: 0.07879808425398356
[2m[36m(func pid=39517)[0m f1_per_class: [0.079, 0.092, 0.261, 0.044, 0.079, 0.085, 0.116, 0.028, 0.022, 0.03]
[2m[36m(func pid=39517)[0m 
== Status ==
Current time: 2024-01-07 02:30:16 (running for 00:06:17.70)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  1.253 |      0.245 |                   62 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.397 |      0.368 |                   64 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.796 |      0.226 |                   61 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.559 |      0.084 |                   63 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.3180970149253731
[2m[36m(func pid=38305)[0m top5: 0.882929104477612
[2m[36m(func pid=38305)[0m f1_micro: 0.3180970149253731
[2m[36m(func pid=38305)[0m f1_macro: 0.24482472040392755
[2m[36m(func pid=38305)[0m f1_weighted: 0.2805510542977128
[2m[36m(func pid=38305)[0m f1_per_class: [0.237, 0.375, 0.286, 0.531, 0.075, 0.273, 0.006, 0.405, 0.053, 0.206]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.2822 | Steps: 2 | Val loss: 2.7633 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 3.2836 | Steps: 2 | Val loss: 10.3250 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 1.9763 | Steps: 2 | Val loss: 8.6561 | Batch size: 32 | lr: 0.1 | Duration: 2.73s
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 1.2960 | Steps: 2 | Val loss: 1.8412 | Batch size: 32 | lr: 0.0001 | Duration: 2.78s
[2m[36m(func pid=38679)[0m top1: 0.3969216417910448
[2m[36m(func pid=38679)[0m top5: 0.8675373134328358
[2m[36m(func pid=38679)[0m f1_micro: 0.3969216417910448
[2m[36m(func pid=38679)[0m f1_macro: 0.3338282267787074
[2m[36m(func pid=38679)[0m f1_weighted: 0.4145475266928195
[2m[36m(func pid=38679)[0m f1_per_class: [0.479, 0.307, 0.611, 0.487, 0.13, 0.227, 0.571, 0.118, 0.172, 0.236]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=39098)[0m top1: 0.3162313432835821
[2m[36m(func pid=39098)[0m top5: 0.8558768656716418
[2m[36m(func pid=39098)[0m f1_micro: 0.3162313432835821
[2m[36m(func pid=39098)[0m f1_macro: 0.2486551475955964
[2m[36m(func pid=39098)[0m f1_weighted: 0.34558590626594976
[2m[36m(func pid=39098)[0m f1_per_class: [0.053, 0.357, 0.07, 0.261, 0.109, 0.13, 0.527, 0.477, 0.166, 0.336]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=39517)[0m top1: 0.045242537313432835
[2m[36m(func pid=39517)[0m top5: 0.7677238805970149
[2m[36m(func pid=39517)[0m f1_micro: 0.045242537313432835
[2m[36m(func pid=39517)[0m f1_macro: 0.04946884581864207
[2m[36m(func pid=39517)[0m f1_weighted: 0.043594181492074065
[2m[36m(func pid=39517)[0m f1_per_class: [0.076, 0.055, 0.108, 0.016, 0.085, 0.061, 0.065, 0.0, 0.0, 0.028]
[2m[36m(func pid=39517)[0m 
== Status ==
Current time: 2024-01-07 02:30:22 (running for 00:06:22.92)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  1.296 |      0.252 |                   63 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.282 |      0.334 |                   65 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  3.284 |      0.249 |                   62 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.976 |      0.049 |                   64 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.32369402985074625
[2m[36m(func pid=38305)[0m top5: 0.8875932835820896
[2m[36m(func pid=38305)[0m f1_micro: 0.32369402985074625
[2m[36m(func pid=38305)[0m f1_macro: 0.25191290258235444
[2m[36m(func pid=38305)[0m f1_weighted: 0.2860941602496034
[2m[36m(func pid=38305)[0m f1_per_class: [0.226, 0.378, 0.31, 0.533, 0.079, 0.297, 0.012, 0.401, 0.053, 0.23]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.3591 | Steps: 2 | Val loss: 3.4408 | Batch size: 32 | lr: 0.001 | Duration: 2.67s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 1.0833 | Steps: 2 | Val loss: 8.5493 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 1.5338 | Steps: 2 | Val loss: 9.0583 | Batch size: 32 | lr: 0.1 | Duration: 2.78s
[2m[36m(func pid=38679)[0m top1: 0.32509328358208955
[2m[36m(func pid=38679)[0m top5: 0.8222947761194029
[2m[36m(func pid=38679)[0m f1_micro: 0.32509328358208955
[2m[36m(func pid=38679)[0m f1_macro: 0.251116699315495
[2m[36m(func pid=38679)[0m f1_weighted: 0.3589991262655899
[2m[36m(func pid=38679)[0m f1_per_class: [0.262, 0.318, 0.267, 0.381, 0.126, 0.212, 0.525, 0.042, 0.113, 0.266]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 1.2134 | Steps: 2 | Val loss: 1.8438 | Batch size: 32 | lr: 0.0001 | Duration: 2.79s
[2m[36m(func pid=39098)[0m top1: 0.3260261194029851
[2m[36m(func pid=39098)[0m top5: 0.8582089552238806
[2m[36m(func pid=39098)[0m f1_micro: 0.3260261194029851
[2m[36m(func pid=39098)[0m f1_macro: 0.23991359934529113
[2m[36m(func pid=39098)[0m f1_weighted: 0.34727285478555525
[2m[36m(func pid=39098)[0m f1_per_class: [0.043, 0.386, 0.099, 0.239, 0.177, 0.089, 0.578, 0.349, 0.171, 0.268]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=39517)[0m top1: 0.06063432835820896
[2m[36m(func pid=39517)[0m top5: 0.7719216417910447
[2m[36m(func pid=39517)[0m f1_micro: 0.06063432835820896
[2m[36m(func pid=39517)[0m f1_macro: 0.06417011268500016
[2m[36m(func pid=39517)[0m f1_weighted: 0.06758778005383077
[2m[36m(func pid=39517)[0m f1_per_class: [0.072, 0.116, 0.065, 0.01, 0.093, 0.12, 0.085, 0.051, 0.0, 0.031]
[2m[36m(func pid=39517)[0m 
== Status ==
Current time: 2024-01-07 02:30:27 (running for 00:06:28.04)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  1.213 |      0.259 |                   64 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.359 |      0.251 |                   66 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  1.083 |      0.24  |                   63 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.534 |      0.064 |                   65 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.33255597014925375
[2m[36m(func pid=38305)[0m top5: 0.882929104477612
[2m[36m(func pid=38305)[0m f1_micro: 0.33255597014925375
[2m[36m(func pid=38305)[0m f1_macro: 0.2590934276728509
[2m[36m(func pid=38305)[0m f1_weighted: 0.29400537850105085
[2m[36m(func pid=38305)[0m f1_per_class: [0.232, 0.405, 0.319, 0.542, 0.083, 0.302, 0.009, 0.413, 0.053, 0.232]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.4091 | Steps: 2 | Val loss: 4.5329 | Batch size: 32 | lr: 0.001 | Duration: 2.64s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.4149 | Steps: 2 | Val loss: 7.8655 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 1.7185 | Steps: 2 | Val loss: 7.9705 | Batch size: 32 | lr: 0.1 | Duration: 2.63s
[2m[36m(func pid=38679)[0m top1: 0.28544776119402987
[2m[36m(func pid=38679)[0m top5: 0.8069029850746269
[2m[36m(func pid=38679)[0m f1_micro: 0.28544776119402987
[2m[36m(func pid=38679)[0m f1_macro: 0.2165846158037517
[2m[36m(func pid=38679)[0m f1_weighted: 0.3129054124138603
[2m[36m(func pid=38679)[0m f1_per_class: [0.136, 0.344, 0.0, 0.136, 0.12, 0.283, 0.556, 0.116, 0.091, 0.386]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 1.2151 | Steps: 2 | Val loss: 1.8482 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=39098)[0m top1: 0.3204291044776119
[2m[36m(func pid=39098)[0m top5: 0.851679104477612
[2m[36m(func pid=39098)[0m f1_micro: 0.3204291044776119
[2m[36m(func pid=39098)[0m f1_macro: 0.24540917740832763
[2m[36m(func pid=39098)[0m f1_weighted: 0.3375683030148058
[2m[36m(func pid=39098)[0m f1_per_class: [0.052, 0.446, 0.154, 0.179, 0.196, 0.11, 0.555, 0.369, 0.169, 0.225]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=39517)[0m top1: 0.11940298507462686
[2m[36m(func pid=39517)[0m top5: 0.7798507462686567
[2m[36m(func pid=39517)[0m f1_micro: 0.11940298507462686
[2m[36m(func pid=39517)[0m f1_macro: 0.13832401417354576
[2m[36m(func pid=39517)[0m f1_weighted: 0.09662162169264277
[2m[36m(func pid=39517)[0m f1_per_class: [0.078, 0.135, 0.41, 0.023, 0.109, 0.158, 0.082, 0.318, 0.026, 0.045]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.3998 | Steps: 2 | Val loss: 6.3640 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
== Status ==
Current time: 2024-01-07 02:30:32 (running for 00:06:33.31)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  1.215 |      0.256 |                   65 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.409 |      0.217 |                   67 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.415 |      0.245 |                   64 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.719 |      0.138 |                   66 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.3283582089552239
[2m[36m(func pid=38305)[0m top5: 0.8754664179104478
[2m[36m(func pid=38305)[0m f1_micro: 0.3283582089552239
[2m[36m(func pid=38305)[0m f1_macro: 0.2555073182960822
[2m[36m(func pid=38305)[0m f1_weighted: 0.29151142778960165
[2m[36m(func pid=38305)[0m f1_per_class: [0.217, 0.4, 0.328, 0.537, 0.08, 0.307, 0.009, 0.413, 0.053, 0.211]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 1.9486 | Steps: 2 | Val loss: 9.4673 | Batch size: 32 | lr: 0.1 | Duration: 2.61s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.2564 | Steps: 2 | Val loss: 7.8746 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=38679)[0m top1: 0.2439365671641791
[2m[36m(func pid=38679)[0m top5: 0.7709888059701493
[2m[36m(func pid=38679)[0m f1_micro: 0.2439365671641791
[2m[36m(func pid=38679)[0m f1_macro: 0.17808291082311717
[2m[36m(func pid=38679)[0m f1_weighted: 0.263167727285634
[2m[36m(func pid=38679)[0m f1_per_class: [0.09, 0.36, 0.0, 0.026, 0.104, 0.21, 0.532, 0.058, 0.041, 0.361]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 1.0828 | Steps: 2 | Val loss: 1.8409 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=39517)[0m top1: 0.11567164179104478
[2m[36m(func pid=39517)[0m top5: 0.7719216417910447
[2m[36m(func pid=39517)[0m f1_micro: 0.11567164179104478
[2m[36m(func pid=39517)[0m f1_macro: 0.12544599003461232
[2m[36m(func pid=39517)[0m f1_weighted: 0.07691906174581141
[2m[36m(func pid=39517)[0m f1_per_class: [0.074, 0.144, 0.333, 0.013, 0.099, 0.192, 0.015, 0.268, 0.044, 0.071]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=39098)[0m top1: 0.28638059701492535
[2m[36m(func pid=39098)[0m top5: 0.8540111940298507
[2m[36m(func pid=39098)[0m f1_micro: 0.28638059701492535
[2m[36m(func pid=39098)[0m f1_macro: 0.2384146202589664
[2m[36m(func pid=39098)[0m f1_weighted: 0.2960290392276163
[2m[36m(func pid=39098)[0m f1_per_class: [0.074, 0.437, 0.24, 0.115, 0.136, 0.154, 0.459, 0.386, 0.156, 0.226]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.3243 | Steps: 2 | Val loss: 6.7349 | Batch size: 32 | lr: 0.001 | Duration: 2.69s
== Status ==
Current time: 2024-01-07 02:30:38 (running for 00:06:38.90)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  1.083 |      0.262 |                   66 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.4   |      0.178 |                   68 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.256 |      0.238 |                   65 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.949 |      0.125 |                   67 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.33488805970149255
[2m[36m(func pid=38305)[0m top5: 0.8777985074626866
[2m[36m(func pid=38305)[0m f1_micro: 0.33488805970149255
[2m[36m(func pid=38305)[0m f1_macro: 0.2621512061856799
[2m[36m(func pid=38305)[0m f1_weighted: 0.2977575791560248
[2m[36m(func pid=38305)[0m f1_per_class: [0.219, 0.418, 0.349, 0.544, 0.082, 0.309, 0.009, 0.425, 0.053, 0.213]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 1.6199 | Steps: 2 | Val loss: 10.4669 | Batch size: 32 | lr: 0.1 | Duration: 2.74s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.3053 | Steps: 2 | Val loss: 8.2029 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
[2m[36m(func pid=38679)[0m top1: 0.22061567164179105
[2m[36m(func pid=38679)[0m top5: 0.7915111940298507
[2m[36m(func pid=38679)[0m f1_micro: 0.22061567164179105
[2m[36m(func pid=38679)[0m f1_macro: 0.14758342030577337
[2m[36m(func pid=38679)[0m f1_weighted: 0.23920693478250526
[2m[36m(func pid=38679)[0m f1_per_class: [0.08, 0.388, 0.0, 0.01, 0.066, 0.135, 0.493, 0.015, 0.038, 0.25]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=39517)[0m top1: 0.11380597014925373
[2m[36m(func pid=39517)[0m top5: 0.7467350746268657
[2m[36m(func pid=39517)[0m f1_micro: 0.11380597014925373
[2m[36m(func pid=39517)[0m f1_macro: 0.11399795703877329
[2m[36m(func pid=39517)[0m f1_weighted: 0.07501107983302033
[2m[36m(func pid=39517)[0m f1_per_class: [0.068, 0.106, 0.286, 0.048, 0.114, 0.193, 0.006, 0.258, 0.0, 0.061]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 1.1080 | Steps: 2 | Val loss: 1.8320 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=39098)[0m top1: 0.23740671641791045
[2m[36m(func pid=39098)[0m top5: 0.8502798507462687
[2m[36m(func pid=39098)[0m f1_micro: 0.23740671641791045
[2m[36m(func pid=39098)[0m f1_macro: 0.2119235732085135
[2m[36m(func pid=39098)[0m f1_weighted: 0.2352501448154014
[2m[36m(func pid=39098)[0m f1_per_class: [0.083, 0.429, 0.261, 0.071, 0.091, 0.208, 0.297, 0.313, 0.129, 0.237]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.3115 | Steps: 2 | Val loss: 7.9861 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
== Status ==
Current time: 2024-01-07 02:30:43 (running for 00:06:44.31)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  1.108 |      0.271 |                   67 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.324 |      0.148 |                   69 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.305 |      0.212 |                   66 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.62  |      0.114 |                   68 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.33908582089552236
[2m[36m(func pid=38305)[0m top5: 0.8810634328358209
[2m[36m(func pid=38305)[0m f1_micro: 0.33908582089552236
[2m[36m(func pid=38305)[0m f1_macro: 0.27123295223251276
[2m[36m(func pid=38305)[0m f1_weighted: 0.30374390147425573
[2m[36m(func pid=38305)[0m f1_per_class: [0.219, 0.422, 0.373, 0.541, 0.082, 0.315, 0.021, 0.448, 0.053, 0.238]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 1.7627 | Steps: 2 | Val loss: 11.3516 | Batch size: 32 | lr: 0.1 | Duration: 2.64s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.4254 | Steps: 2 | Val loss: 8.6465 | Batch size: 32 | lr: 0.01 | Duration: 2.74s
[2m[36m(func pid=38679)[0m top1: 0.1828358208955224
[2m[36m(func pid=38679)[0m top5: 0.7943097014925373
[2m[36m(func pid=38679)[0m f1_micro: 0.1828358208955224
[2m[36m(func pid=38679)[0m f1_macro: 0.1735007004396656
[2m[36m(func pid=38679)[0m f1_weighted: 0.20908063829038182
[2m[36m(func pid=38679)[0m f1_per_class: [0.067, 0.373, 0.455, 0.013, 0.067, 0.089, 0.412, 0.0, 0.021, 0.238]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=39517)[0m top1: 0.10587686567164178
[2m[36m(func pid=39517)[0m top5: 0.7360074626865671
[2m[36m(func pid=39517)[0m f1_micro: 0.10587686567164178
[2m[36m(func pid=39517)[0m f1_macro: 0.10449741521083174
[2m[36m(func pid=39517)[0m f1_weighted: 0.07662101566324167
[2m[36m(func pid=39517)[0m f1_per_class: [0.029, 0.086, 0.235, 0.057, 0.116, 0.175, 0.021, 0.284, 0.0, 0.042]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 1.1420 | Steps: 2 | Val loss: 1.8235 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=39098)[0m top1: 0.21548507462686567
[2m[36m(func pid=39098)[0m top5: 0.8470149253731343
[2m[36m(func pid=39098)[0m f1_micro: 0.21548507462686567
[2m[36m(func pid=39098)[0m f1_macro: 0.20234929460196108
[2m[36m(func pid=39098)[0m f1_weighted: 0.2058465980365861
[2m[36m(func pid=39098)[0m f1_per_class: [0.084, 0.407, 0.269, 0.054, 0.145, 0.204, 0.231, 0.307, 0.118, 0.203]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.4730 | Steps: 2 | Val loss: 9.3032 | Batch size: 32 | lr: 0.001 | Duration: 2.67s
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 1.6505 | Steps: 2 | Val loss: 12.0144 | Batch size: 32 | lr: 0.1 | Duration: 2.59s
== Status ==
Current time: 2024-01-07 02:30:48 (running for 00:06:49.62)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  1.142 |      0.274 |                   68 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.312 |      0.174 |                   70 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.425 |      0.202 |                   67 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.763 |      0.104 |                   69 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.3414179104477612
[2m[36m(func pid=38305)[0m top5: 0.8838619402985075
[2m[36m(func pid=38305)[0m f1_micro: 0.3414179104477612
[2m[36m(func pid=38305)[0m f1_macro: 0.2742407689120543
[2m[36m(func pid=38305)[0m f1_weighted: 0.310244962640279
[2m[36m(func pid=38305)[0m f1_per_class: [0.217, 0.421, 0.351, 0.538, 0.08, 0.317, 0.042, 0.467, 0.053, 0.256]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.2195 | Steps: 2 | Val loss: 8.9588 | Batch size: 32 | lr: 0.01 | Duration: 2.68s
[2m[36m(func pid=38679)[0m top1: 0.17817164179104478
[2m[36m(func pid=38679)[0m top5: 0.7751865671641791
[2m[36m(func pid=38679)[0m f1_micro: 0.17817164179104475
[2m[36m(func pid=38679)[0m f1_macro: 0.18944251514034952
[2m[36m(func pid=38679)[0m f1_weighted: 0.20994057359170465
[2m[36m(func pid=38679)[0m f1_per_class: [0.061, 0.38, 0.5, 0.01, 0.079, 0.135, 0.392, 0.016, 0.0, 0.323]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=39517)[0m top1: 0.09001865671641791
[2m[36m(func pid=39517)[0m top5: 0.7360074626865671
[2m[36m(func pid=39517)[0m f1_micro: 0.0900186567164179
[2m[36m(func pid=39517)[0m f1_macro: 0.10507662099353716
[2m[36m(func pid=39517)[0m f1_weighted: 0.06959888328296307
[2m[36m(func pid=39517)[0m f1_per_class: [0.041, 0.093, 0.244, 0.01, 0.118, 0.126, 0.044, 0.338, 0.0, 0.037]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 1.1115 | Steps: 2 | Val loss: 1.8227 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=39098)[0m top1: 0.22574626865671643
[2m[36m(func pid=39098)[0m top5: 0.847481343283582
[2m[36m(func pid=39098)[0m f1_micro: 0.22574626865671643
[2m[36m(func pid=39098)[0m f1_macro: 0.2186888108583369
[2m[36m(func pid=39098)[0m f1_weighted: 0.2255231984444566
[2m[36m(func pid=39098)[0m f1_per_class: [0.089, 0.344, 0.326, 0.054, 0.186, 0.236, 0.313, 0.341, 0.118, 0.179]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.2585 | Steps: 2 | Val loss: 9.8726 | Batch size: 32 | lr: 0.001 | Duration: 2.64s
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 1.5079 | Steps: 2 | Val loss: 12.7259 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
== Status ==
Current time: 2024-01-07 02:30:54 (running for 00:06:55.00)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  1.112 |      0.274 |                   69 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.473 |      0.189 |                   71 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.219 |      0.219 |                   68 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.651 |      0.105 |                   70 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.3414179104477612
[2m[36m(func pid=38305)[0m top5: 0.8857276119402985
[2m[36m(func pid=38305)[0m f1_micro: 0.3414179104477612
[2m[36m(func pid=38305)[0m f1_macro: 0.274145738755052
[2m[36m(func pid=38305)[0m f1_weighted: 0.3165484722634907
[2m[36m(func pid=38305)[0m f1_per_class: [0.204, 0.427, 0.333, 0.534, 0.082, 0.313, 0.065, 0.472, 0.053, 0.258]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=38679)[0m top1: 0.22061567164179105
[2m[36m(func pid=38679)[0m top5: 0.7532649253731343
[2m[36m(func pid=38679)[0m f1_micro: 0.22061567164179105
[2m[36m(func pid=38679)[0m f1_macro: 0.2530613709495298
[2m[36m(func pid=38679)[0m f1_weighted: 0.26353614474940695
[2m[36m(func pid=38679)[0m f1_per_class: [0.067, 0.356, 0.387, 0.02, 0.077, 0.301, 0.437, 0.36, 0.036, 0.489]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.9325 | Steps: 2 | Val loss: 10.5024 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=39517)[0m top1: 0.049906716417910446
[2m[36m(func pid=39517)[0m top5: 0.7607276119402985
[2m[36m(func pid=39517)[0m f1_micro: 0.04990671641791045
[2m[36m(func pid=39517)[0m f1_macro: 0.0762977901090505
[2m[36m(func pid=39517)[0m f1_weighted: 0.04890788547855148
[2m[36m(func pid=39517)[0m f1_per_class: [0.048, 0.17, 0.268, 0.0, 0.131, 0.029, 0.03, 0.057, 0.0, 0.028]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 1.1576 | Steps: 2 | Val loss: 1.8164 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=39098)[0m top1: 0.23694029850746268
[2m[36m(func pid=39098)[0m top5: 0.8386194029850746
[2m[36m(func pid=39098)[0m f1_micro: 0.23694029850746268
[2m[36m(func pid=39098)[0m f1_macro: 0.22482874965862149
[2m[36m(func pid=39098)[0m f1_weighted: 0.2454338141771496
[2m[36m(func pid=39098)[0m f1_per_class: [0.082, 0.258, 0.349, 0.07, 0.183, 0.235, 0.403, 0.407, 0.132, 0.129]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.2170 | Steps: 2 | Val loss: 12.3210 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 1.6631 | Steps: 2 | Val loss: 12.3218 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
== Status ==
Current time: 2024-01-07 02:30:59 (running for 00:07:00.20)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  1.158 |      0.287 |                   70 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.259 |      0.253 |                   72 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.933 |      0.225 |                   69 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.508 |      0.076 |                   71 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.35074626865671643
[2m[36m(func pid=38305)[0m top5: 0.8875932835820896
[2m[36m(func pid=38305)[0m f1_micro: 0.35074626865671643
[2m[36m(func pid=38305)[0m f1_macro: 0.2872157786897872
[2m[36m(func pid=38305)[0m f1_weighted: 0.3366235365849723
[2m[36m(func pid=38305)[0m f1_per_class: [0.21, 0.448, 0.353, 0.527, 0.076, 0.32, 0.12, 0.49, 0.053, 0.275]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=38679)[0m top1: 0.20615671641791045
[2m[36m(func pid=38679)[0m top5: 0.7332089552238806
[2m[36m(func pid=38679)[0m f1_micro: 0.20615671641791045
[2m[36m(func pid=38679)[0m f1_macro: 0.25401891260792864
[2m[36m(func pid=38679)[0m f1_weighted: 0.24310273171679703
[2m[36m(func pid=38679)[0m f1_per_class: [0.071, 0.322, 0.345, 0.023, 0.092, 0.326, 0.353, 0.451, 0.099, 0.458]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.2020 | Steps: 2 | Val loss: 14.1375 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=39517)[0m top1: 0.05783582089552239
[2m[36m(func pid=39517)[0m top5: 0.7747201492537313
[2m[36m(func pid=39517)[0m f1_micro: 0.05783582089552239
[2m[36m(func pid=39517)[0m f1_macro: 0.0790274059636991
[2m[36m(func pid=39517)[0m f1_weighted: 0.05941805475938776
[2m[36m(func pid=39517)[0m f1_per_class: [0.049, 0.202, 0.268, 0.0, 0.138, 0.023, 0.055, 0.025, 0.0, 0.029]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 1.0022 | Steps: 2 | Val loss: 1.7979 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=39098)[0m top1: 0.24253731343283583
[2m[36m(func pid=39098)[0m top5: 0.8194962686567164
[2m[36m(func pid=39098)[0m f1_micro: 0.24253731343283583
[2m[36m(func pid=39098)[0m f1_macro: 0.20447005433296406
[2m[36m(func pid=39098)[0m f1_weighted: 0.260279348534703
[2m[36m(func pid=39098)[0m f1_per_class: [0.057, 0.146, 0.214, 0.115, 0.174, 0.229, 0.481, 0.433, 0.104, 0.09]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.1709 | Steps: 2 | Val loss: 14.8995 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 1.7811 | Steps: 2 | Val loss: 11.2473 | Batch size: 32 | lr: 0.1 | Duration: 2.70s
== Status ==
Current time: 2024-01-07 02:31:04 (running for 00:07:05.52)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  1.002 |      0.299 |                   71 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.217 |      0.254 |                   73 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.202 |      0.204 |                   70 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.663 |      0.079 |                   72 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m top1: 0.3614738805970149
[2m[36m(func pid=38305)[0m top5: 0.8885261194029851
[2m[36m(func pid=38305)[0m f1_micro: 0.3614738805970149
[2m[36m(func pid=38305)[0m f1_macro: 0.29861209266699074
[2m[36m(func pid=38305)[0m f1_weighted: 0.3579615381391836
[2m[36m(func pid=38305)[0m f1_per_class: [0.203, 0.46, 0.375, 0.528, 0.078, 0.306, 0.185, 0.507, 0.053, 0.291]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=38679)[0m top1: 0.18889925373134328
[2m[36m(func pid=38679)[0m top5: 0.6940298507462687
[2m[36m(func pid=38679)[0m f1_micro: 0.18889925373134325
[2m[36m(func pid=38679)[0m f1_macro: 0.236115508179165
[2m[36m(func pid=38679)[0m f1_weighted: 0.2188248652566239
[2m[36m(func pid=38679)[0m f1_per_class: [0.074, 0.292, 0.3, 0.041, 0.098, 0.339, 0.272, 0.416, 0.141, 0.389]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.3444 | Steps: 2 | Val loss: 17.6364 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=39517)[0m top1: 0.11707089552238806
[2m[36m(func pid=39517)[0m top5: 0.7910447761194029
[2m[36m(func pid=39517)[0m f1_micro: 0.11707089552238806
[2m[36m(func pid=39517)[0m f1_macro: 0.12589165517331458
[2m[36m(func pid=39517)[0m f1_weighted: 0.10599085889427629
[2m[36m(func pid=39517)[0m f1_per_class: [0.081, 0.203, 0.259, 0.022, 0.148, 0.015, 0.125, 0.358, 0.0, 0.046]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 1.0259 | Steps: 2 | Val loss: 1.7989 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.2460 | Steps: 2 | Val loss: 14.9250 | Batch size: 32 | lr: 0.001 | Duration: 2.73s
[2m[36m(func pid=39098)[0m top1: 0.23087686567164178
[2m[36m(func pid=39098)[0m top5: 0.7975746268656716
[2m[36m(func pid=39098)[0m f1_micro: 0.23087686567164178
[2m[36m(func pid=39098)[0m f1_macro: 0.18221985668506563
[2m[36m(func pid=39098)[0m f1_weighted: 0.2514770450916552
[2m[36m(func pid=39098)[0m f1_per_class: [0.046, 0.081, 0.155, 0.167, 0.166, 0.179, 0.47, 0.423, 0.067, 0.069]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 1.5610 | Steps: 2 | Val loss: 10.5078 | Batch size: 32 | lr: 0.1 | Duration: 2.67s
== Status ==
Current time: 2024-01-07 02:31:09 (running for 00:07:10.77)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: 0.178
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  1.002 |      0.299 |                   71 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.246 |      0.178 |                   75 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.344 |      0.182 |                   71 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.781 |      0.126 |                   73 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38679)[0m top1: 0.15904850746268656
[2m[36m(func pid=38679)[0m top5: 0.6879664179104478
[2m[36m(func pid=38679)[0m f1_micro: 0.15904850746268656
[2m[36m(func pid=38679)[0m f1_macro: 0.17837341883676597
[2m[36m(func pid=38679)[0m f1_weighted: 0.17779216141634366
[2m[36m(func pid=38679)[0m f1_per_class: [0.074, 0.302, 0.125, 0.04, 0.073, 0.307, 0.181, 0.27, 0.114, 0.298]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=38305)[0m top1: 0.363339552238806
[2m[36m(func pid=38305)[0m top5: 0.8922574626865671
[2m[36m(func pid=38305)[0m f1_micro: 0.363339552238806
[2m[36m(func pid=38305)[0m f1_macro: 0.29948974977131937
[2m[36m(func pid=38305)[0m f1_weighted: 0.36502130930146914
[2m[36m(func pid=38305)[0m f1_per_class: [0.193, 0.473, 0.367, 0.518, 0.077, 0.299, 0.212, 0.518, 0.052, 0.286]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.8193 | Steps: 2 | Val loss: 19.1853 | Batch size: 32 | lr: 0.01 | Duration: 2.63s
[2m[36m(func pid=39517)[0m top1: 0.1553171641791045
[2m[36m(func pid=39517)[0m top5: 0.8031716417910447
[2m[36m(func pid=39517)[0m f1_micro: 0.1553171641791045
[2m[36m(func pid=39517)[0m f1_macro: 0.1391252119633293
[2m[36m(func pid=39517)[0m f1_weighted: 0.15052753184426085
[2m[36m(func pid=39517)[0m f1_per_class: [0.075, 0.168, 0.279, 0.116, 0.114, 0.056, 0.196, 0.343, 0.0, 0.045]
[2m[36m(func pid=39517)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.9759 | Steps: 2 | Val loss: 1.7963 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 75] | Train loss: 0.1445 | Steps: 2 | Val loss: 12.7990 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=39098)[0m top1: 0.23180970149253732
[2m[36m(func pid=39098)[0m top5: 0.7901119402985075
[2m[36m(func pid=39098)[0m f1_micro: 0.23180970149253732
[2m[36m(func pid=39098)[0m f1_macro: 0.1842956758178059
[2m[36m(func pid=39098)[0m f1_weighted: 0.25439250370306277
[2m[36m(func pid=39098)[0m f1_per_class: [0.034, 0.063, 0.135, 0.252, 0.152, 0.203, 0.393, 0.459, 0.088, 0.064]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=39517)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 1.6255 | Steps: 2 | Val loss: 9.7166 | Batch size: 32 | lr: 0.1 | Duration: 2.75s
== Status ==
Current time: 2024-01-07 02:31:15 (running for 00:07:16.04)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: 0.178
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING  | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  1.026 |      0.299 |                   72 |
| train_6ed81_00001 | RUNNING  | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.144 |      0.176 |                   76 |
| train_6ed81_00002 | RUNNING  | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.819 |      0.184 |                   72 |
| train_6ed81_00003 | RUNNING  | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.561 |      0.139 |                   74 |
| train_6ed81_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38679)[0m top1: 0.1501865671641791
[2m[36m(func pid=38679)[0m top5: 0.6875
[2m[36m(func pid=38679)[0m f1_micro: 0.1501865671641791
[2m[36m(func pid=38679)[0m f1_macro: 0.17552584383475006
[2m[36m(func pid=38679)[0m f1_weighted: 0.16174309721486352
[2m[36m(func pid=38679)[0m f1_per_class: [0.08, 0.307, 0.286, 0.068, 0.061, 0.289, 0.126, 0.135, 0.141, 0.262]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=38305)[0m top1: 0.37033582089552236
[2m[36m(func pid=38305)[0m top5: 0.894589552238806
[2m[36m(func pid=38305)[0m f1_micro: 0.37033582089552236
[2m[36m(func pid=38305)[0m f1_macro: 0.3034122790993676
[2m[36m(func pid=38305)[0m f1_weighted: 0.37204672358000396
[2m[36m(func pid=38305)[0m f1_per_class: [0.2, 0.473, 0.383, 0.523, 0.079, 0.309, 0.227, 0.517, 0.051, 0.272]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39517)[0m top1: 0.1669776119402985
[2m[36m(func pid=39517)[0m top5: 0.8185634328358209
[2m[36m(func pid=39517)[0m f1_micro: 0.1669776119402985
[2m[36m(func pid=39517)[0m f1_macro: 0.14835774184467104
[2m[36m(func pid=39517)[0m f1_weighted: 0.1641799621062748
[2m[36m(func pid=39517)[0m f1_per_class: [0.087, 0.165, 0.279, 0.215, 0.108, 0.125, 0.129, 0.304, 0.017, 0.054]
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 1.1566 | Steps: 2 | Val loss: 18.2677 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 76] | Train loss: 0.2823 | Steps: 2 | Val loss: 9.7410 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.9875 | Steps: 2 | Val loss: 1.7868 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=39098)[0m top1: 0.23694029850746268
[2m[36m(func pid=39098)[0m top5: 0.7943097014925373
[2m[36m(func pid=39098)[0m f1_micro: 0.23694029850746268
[2m[36m(func pid=39098)[0m f1_macro: 0.18392731353482725
[2m[36m(func pid=39098)[0m f1_weighted: 0.24830607065467866
[2m[36m(func pid=39098)[0m f1_per_class: [0.023, 0.078, 0.122, 0.325, 0.163, 0.245, 0.284, 0.434, 0.098, 0.068]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=38679)[0m top1: 0.16791044776119404
[2m[36m(func pid=38679)[0m top5: 0.7416044776119403
[2m[36m(func pid=38679)[0m f1_micro: 0.16791044776119404
[2m[36m(func pid=38679)[0m f1_macro: 0.19978344044487317
[2m[36m(func pid=38679)[0m f1_weighted: 0.1840843913472293
[2m[36m(func pid=38679)[0m f1_per_class: [0.086, 0.288, 0.312, 0.078, 0.076, 0.286, 0.194, 0.135, 0.172, 0.37]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=38305)[0m top1: 0.37453358208955223
[2m[36m(func pid=38305)[0m top5: 0.8964552238805971
[2m[36m(func pid=38305)[0m f1_micro: 0.3745335820895522
[2m[36m(func pid=38305)[0m f1_macro: 0.3108704796204387
[2m[36m(func pid=38305)[0m f1_weighted: 0.37972769293683345
[2m[36m(func pid=38305)[0m f1_per_class: [0.196, 0.486, 0.383, 0.516, 0.087, 0.326, 0.242, 0.514, 0.094, 0.265]
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.5295 | Steps: 2 | Val loss: 13.7810 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 77] | Train loss: 0.0727 | Steps: 2 | Val loss: 7.0444 | Batch size: 32 | lr: 0.001 | Duration: 2.75s
[2m[36m(func pid=39098)[0m top1: 0.2658582089552239
[2m[36m(func pid=39098)[0m top5: 0.824160447761194
[2m[36m(func pid=39098)[0m f1_micro: 0.2658582089552239
[2m[36m(func pid=39098)[0m f1_macro: 0.18881358241168808
[2m[36m(func pid=39098)[0m f1_weighted: 0.2587804534007302
[2m[36m(func pid=39098)[0m f1_per_class: [0.037, 0.075, 0.157, 0.412, 0.162, 0.239, 0.245, 0.398, 0.129, 0.033]
== Status ==
Current time: 2024-01-07 02:31:20 (running for 00:07:21.15)
Memory usage on this node: 22.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=1
Bracket: Iter 75.000: 0.17049999999999998
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (19 PENDING, 4 RUNNING, 1 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING    | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.976 |      0.303 |                   73 |
| train_6ed81_00001 | RUNNING    | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.282 |      0.2   |                   77 |
| train_6ed81_00002 | RUNNING    | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  1.157 |      0.184 |                   73 |
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING    |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=55782)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=55782)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=55782)[0m Configuration completed!
[2m[36m(func pid=55782)[0m New optimizer parameters:
[2m[36m(func pid=55782)[0m SGD (
[2m[36m(func pid=55782)[0m Parameter Group 0
[2m[36m(func pid=55782)[0m     dampening: 0
[2m[36m(func pid=55782)[0m     differentiable: False
[2m[36m(func pid=55782)[0m     foreach: None
[2m[36m(func pid=55782)[0m     lr: 0.0001
[2m[36m(func pid=55782)[0m     maximize: False
[2m[36m(func pid=55782)[0m     momentum: 0.9
[2m[36m(func pid=55782)[0m     nesterov: False
[2m[36m(func pid=55782)[0m     weight_decay: 0
[2m[36m(func pid=55782)[0m )
[2m[36m(func pid=55782)[0m 
== Status ==
Current time: 2024-01-07 02:31:25 (running for 00:07:26.23)
Memory usage on this node: 24.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=1
Bracket: Iter 75.000: 0.17049999999999998
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (19 PENDING, 4 RUNNING, 1 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING    | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.988 |      0.311 |                   74 |
| train_6ed81_00001 | RUNNING    | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.073 |      0.203 |                   78 |
| train_6ed81_00002 | RUNNING    | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.529 |      0.189 |                   74 |
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |        |            |                      |
| train_6ed81_00005 | PENDING    |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38679)[0m top1: 0.20569029850746268
[2m[36m(func pid=38679)[0m top5: 0.800839552238806
[2m[36m(func pid=38679)[0m f1_micro: 0.20569029850746268
[2m[36m(func pid=38679)[0m f1_macro: 0.20326230162918463
[2m[36m(func pid=38679)[0m f1_weighted: 0.235119237206667
[2m[36m(func pid=38679)[0m f1_per_class: [0.099, 0.285, 0.241, 0.159, 0.067, 0.294, 0.308, 0.032, 0.186, 0.361]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.8666 | Steps: 2 | Val loss: 10.9556 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.8961 | Steps: 2 | Val loss: 1.7781 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 78] | Train loss: 0.2260 | Steps: 2 | Val loss: 5.6680 | Batch size: 32 | lr: 0.001 | Duration: 2.68s
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 3.0955 | Steps: 2 | Val loss: 2.3724 | Batch size: 32 | lr: 0.0001 | Duration: 4.68s
[2m[36m(func pid=39098)[0m top1: 0.29244402985074625
[2m[36m(func pid=39098)[0m top5: 0.8404850746268657
[2m[36m(func pid=39098)[0m f1_micro: 0.29244402985074625
[2m[36m(func pid=39098)[0m f1_macro: 0.1983938394784855
[2m[36m(func pid=39098)[0m f1_weighted: 0.27435699155106325
[2m[36m(func pid=39098)[0m f1_per_class: [0.0, 0.128, 0.22, 0.451, 0.171, 0.174, 0.255, 0.391, 0.159, 0.037]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=38305)[0m top1: 0.3824626865671642
[2m[36m(func pid=38305)[0m top5: 0.9001865671641791
[2m[36m(func pid=38305)[0m f1_micro: 0.38246268656716415
[2m[36m(func pid=38305)[0m f1_macro: 0.3199210571664337
[2m[36m(func pid=38305)[0m f1_weighted: 0.3915593526623237
[2m[36m(func pid=38305)[0m f1_per_class: [0.195, 0.492, 0.391, 0.512, 0.094, 0.335, 0.273, 0.516, 0.132, 0.259]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=38679)[0m top1: 0.2887126865671642
[2m[36m(func pid=38679)[0m top5: 0.835820895522388
[2m[36m(func pid=38679)[0m f1_micro: 0.2887126865671642
[2m[36m(func pid=38679)[0m f1_macro: 0.23288693470636618
[2m[36m(func pid=38679)[0m f1_weighted: 0.32846040186357334
[2m[36m(func pid=38679)[0m f1_per_class: [0.12, 0.304, 0.213, 0.26, 0.071, 0.286, 0.525, 0.0, 0.183, 0.368]
[2m[36m(func pid=38679)[0m 
== Status ==
Current time: 2024-01-07 02:31:31 (running for 00:07:32.15)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=1
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (19 PENDING, 4 RUNNING, 1 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING    | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.896 |      0.32  |                   75 |
| train_6ed81_00001 | RUNNING    | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.226 |      0.233 |                   79 |
| train_6ed81_00002 | RUNNING    | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.867 |      0.198 |                   75 |
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  3.095 |      0.017 |                    1 |
| train_6ed81_00005 | PENDING    |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=55782)[0m top1: 0.06623134328358209
[2m[36m(func pid=55782)[0m top5: 0.3805970149253731
[2m[36m(func pid=55782)[0m f1_micro: 0.06623134328358209
[2m[36m(func pid=55782)[0m f1_macro: 0.0166239924134661
[2m[36m(func pid=55782)[0m f1_weighted: 0.020369967375073423
[2m[36m(func pid=55782)[0m f1_per_class: [0.0, 0.0, 0.0, 0.049, 0.0, 0.0, 0.0, 0.118, 0.0, 0.0]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 75] | Train loss: 0.8657 | Steps: 2 | Val loss: 1.7786 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 75] | Train loss: 0.6029 | Steps: 2 | Val loss: 9.0915 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 79] | Train loss: 0.5978 | Steps: 2 | Val loss: 5.5896 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 3.0695 | Steps: 2 | Val loss: 2.3268 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=38305)[0m top1: 0.37919776119402987
[2m[36m(func pid=38305)[0m top5: 0.8973880597014925
[2m[36m(func pid=38305)[0m f1_micro: 0.37919776119402987
[2m[36m(func pid=38305)[0m f1_macro: 0.31455811145737933
[2m[36m(func pid=38305)[0m f1_weighted: 0.389870754042105
[2m[36m(func pid=38305)[0m f1_per_class: [0.191, 0.503, 0.367, 0.5, 0.091, 0.34, 0.274, 0.501, 0.149, 0.229]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39098)[0m top1: 0.3064365671641791
[2m[36m(func pid=39098)[0m top5: 0.8549440298507462
[2m[36m(func pid=39098)[0m f1_micro: 0.3064365671641791
[2m[36m(func pid=39098)[0m f1_macro: 0.20712812870015665
[2m[36m(func pid=39098)[0m f1_weighted: 0.2890138884936565
[2m[36m(func pid=39098)[0m f1_per_class: [0.0, 0.156, 0.25, 0.463, 0.2, 0.128, 0.292, 0.393, 0.154, 0.034]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=38679)[0m top1: 0.28591417910447764
[2m[36m(func pid=38679)[0m top5: 0.840018656716418
[2m[36m(func pid=38679)[0m f1_micro: 0.28591417910447764
[2m[36m(func pid=38679)[0m f1_macro: 0.2160285192620818
[2m[36m(func pid=38679)[0m f1_weighted: 0.32445154048354635
[2m[36m(func pid=38679)[0m f1_per_class: [0.142, 0.289, 0.154, 0.279, 0.066, 0.235, 0.526, 0.0, 0.16, 0.31]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=55782)[0m top1: 0.14505597014925373
[2m[36m(func pid=55782)[0m top5: 0.5242537313432836
[2m[36m(func pid=55782)[0m f1_micro: 0.14505597014925373
[2m[36m(func pid=55782)[0m f1_macro: 0.04302617278000758
[2m[36m(func pid=55782)[0m f1_weighted: 0.08203888106325606
[2m[36m(func pid=55782)[0m f1_per_class: [0.0, 0.0, 0.0, 0.259, 0.0, 0.0, 0.0, 0.172, 0.0, 0.0]
[2m[36m(func pid=55782)[0m 
== Status ==
Current time: 2024-01-07 02:31:36 (running for 00:07:37.38)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=1
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (19 PENDING, 4 RUNNING, 1 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING    | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.866 |      0.315 |                   76 |
| train_6ed81_00001 | RUNNING    | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.598 |      0.216 |                   80 |
| train_6ed81_00002 | RUNNING    | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.603 |      0.207 |                   76 |
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  3.07  |      0.043 |                    2 |
| train_6ed81_00005 | PENDING    |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 76] | Train loss: 0.9248 | Steps: 2 | Val loss: 1.7875 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 76] | Train loss: 0.5461 | Steps: 2 | Val loss: 7.9832 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 80] | Train loss: 0.1355 | Steps: 2 | Val loss: 5.7345 | Batch size: 32 | lr: 0.001 | Duration: 2.66s
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 3.0347 | Steps: 2 | Val loss: 2.3149 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
[2m[36m(func pid=38305)[0m top1: 0.37593283582089554
[2m[36m(func pid=38305)[0m top5: 0.8955223880597015
[2m[36m(func pid=38305)[0m f1_micro: 0.37593283582089554
[2m[36m(func pid=38305)[0m f1_macro: 0.31461524233110777
[2m[36m(func pid=38305)[0m f1_weighted: 0.38779106487473103
[2m[36m(func pid=38305)[0m f1_per_class: [0.198, 0.512, 0.367, 0.489, 0.092, 0.328, 0.273, 0.509, 0.16, 0.217]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=38679)[0m top1: 0.23274253731343283
[2m[36m(func pid=38679)[0m top5: 0.8269589552238806
[2m[36m(func pid=38679)[0m f1_micro: 0.23274253731343286
[2m[36m(func pid=38679)[0m f1_macro: 0.16875438456369807
[2m[36m(func pid=38679)[0m f1_weighted: 0.2622418835641689
[2m[36m(func pid=38679)[0m f1_per_class: [0.158, 0.235, 0.124, 0.245, 0.056, 0.03, 0.465, 0.0, 0.124, 0.25]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=39098)[0m top1: 0.34281716417910446
[2m[36m(func pid=39098)[0m top5: 0.8652052238805971
[2m[36m(func pid=39098)[0m f1_micro: 0.34281716417910446
[2m[36m(func pid=39098)[0m f1_macro: 0.22911973137654998
[2m[36m(func pid=39098)[0m f1_weighted: 0.3434429629597067
[2m[36m(func pid=39098)[0m f1_per_class: [0.0, 0.203, 0.255, 0.462, 0.214, 0.105, 0.455, 0.407, 0.155, 0.036]
[2m[36m(func pid=39098)[0m 
== Status ==
Current time: 2024-01-07 02:31:41 (running for 00:07:42.60)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=1
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (19 PENDING, 4 RUNNING, 1 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING    | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.925 |      0.315 |                   77 |
| train_6ed81_00001 | RUNNING    | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.135 |      0.169 |                   81 |
| train_6ed81_00002 | RUNNING    | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.546 |      0.229 |                   77 |
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  3.035 |      0.049 |                    3 |
| train_6ed81_00005 | PENDING    |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=55782)[0m top1: 0.1884328358208955
[2m[36m(func pid=55782)[0m top5: 0.5652985074626866
[2m[36m(func pid=55782)[0m f1_micro: 0.1884328358208955
[2m[36m(func pid=55782)[0m f1_macro: 0.048994925371544804
[2m[36m(func pid=55782)[0m f1_weighted: 0.10043313282308088
[2m[36m(func pid=55782)[0m f1_per_class: [0.0, 0.0, 0.0, 0.326, 0.0, 0.0, 0.0, 0.164, 0.0, 0.0]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 77] | Train loss: 0.9697 | Steps: 2 | Val loss: 1.8312 | Batch size: 32 | lr: 0.0001 | Duration: 2.81s
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 81] | Train loss: 0.2341 | Steps: 2 | Val loss: 6.1033 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 77] | Train loss: 1.9871 | Steps: 2 | Val loss: 7.8438 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 3.0083 | Steps: 2 | Val loss: 2.3127 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=38305)[0m top1: 0.375
[2m[36m(func pid=38305)[0m top5: 0.8922574626865671
[2m[36m(func pid=38305)[0m f1_micro: 0.375
[2m[36m(func pid=38305)[0m f1_macro: 0.3152275466398332
[2m[36m(func pid=38305)[0m f1_weighted: 0.3937683304154668
[2m[36m(func pid=38305)[0m f1_per_class: [0.18, 0.528, 0.353, 0.49, 0.098, 0.32, 0.281, 0.542, 0.177, 0.184]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=38679)[0m top1: 0.20335820895522388
[2m[36m(func pid=38679)[0m top5: 0.8208955223880597
[2m[36m(func pid=38679)[0m f1_micro: 0.20335820895522388
[2m[36m(func pid=38679)[0m f1_macro: 0.16569341168432886
[2m[36m(func pid=38679)[0m f1_weighted: 0.233177307337618
[2m[36m(func pid=38679)[0m f1_per_class: [0.142, 0.196, 0.119, 0.199, 0.062, 0.161, 0.382, 0.0, 0.139, 0.257]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=39098)[0m top1: 0.36007462686567165
[2m[36m(func pid=39098)[0m top5: 0.8684701492537313
[2m[36m(func pid=39098)[0m f1_micro: 0.3600746268656716
[2m[36m(func pid=39098)[0m f1_macro: 0.20968010700410084
[2m[36m(func pid=39098)[0m f1_weighted: 0.3694985041849373
[2m[36m(func pid=39098)[0m f1_per_class: [0.0, 0.234, 0.0, 0.45, 0.225, 0.105, 0.551, 0.361, 0.138, 0.033]
[2m[36m(func pid=39098)[0m 
== Status ==
Current time: 2024-01-07 02:31:47 (running for 00:07:48.00)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=1
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (19 PENDING, 4 RUNNING, 1 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING    | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.97  |      0.315 |                   78 |
| train_6ed81_00001 | RUNNING    | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.234 |      0.166 |                   82 |
| train_6ed81_00002 | RUNNING    | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  1.987 |      0.21  |                   78 |
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  3.008 |      0.043 |                    4 |
| train_6ed81_00005 | PENDING    |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=55782)[0m top1: 0.1982276119402985
[2m[36m(func pid=55782)[0m top5: 0.5783582089552238
[2m[36m(func pid=55782)[0m f1_micro: 0.19822761194029853
[2m[36m(func pid=55782)[0m f1_macro: 0.04305492402673674
[2m[36m(func pid=55782)[0m f1_weighted: 0.10226553789284783
[2m[36m(func pid=55782)[0m f1_per_class: [0.0, 0.0, 0.0, 0.35, 0.0, 0.0, 0.0, 0.081, 0.0, 0.0]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 78] | Train loss: 0.7840 | Steps: 2 | Val loss: 1.8305 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 82] | Train loss: 0.1781 | Steps: 2 | Val loss: 7.6816 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 78] | Train loss: 0.3290 | Steps: 2 | Val loss: 7.7013 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 2.9807 | Steps: 2 | Val loss: 2.3158 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=38305)[0m top1: 0.37919776119402987
[2m[36m(func pid=38305)[0m top5: 0.8936567164179104
[2m[36m(func pid=38305)[0m f1_micro: 0.37919776119402987
[2m[36m(func pid=38305)[0m f1_macro: 0.3178257143099951
[2m[36m(func pid=38305)[0m f1_weighted: 0.40178345496322054
[2m[36m(func pid=38305)[0m f1_per_class: [0.177, 0.537, 0.333, 0.485, 0.084, 0.316, 0.305, 0.56, 0.186, 0.195]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=38679)[0m top1: 0.125
[2m[36m(func pid=38679)[0m top5: 0.7569962686567164
[2m[36m(func pid=38679)[0m f1_micro: 0.125
[2m[36m(func pid=38679)[0m f1_macro: 0.12104534450169728
[2m[36m(func pid=38679)[0m f1_weighted: 0.1349937669819817
[2m[36m(func pid=38679)[0m f1_per_class: [0.128, 0.182, 0.131, 0.174, 0.067, 0.094, 0.117, 0.0, 0.083, 0.234]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=39098)[0m top1: 0.3596082089552239
[2m[36m(func pid=39098)[0m top5: 0.871268656716418
[2m[36m(func pid=39098)[0m f1_micro: 0.35960820895522383
[2m[36m(func pid=39098)[0m f1_macro: 0.20049531436890194
[2m[36m(func pid=39098)[0m f1_weighted: 0.37340257698884544
[2m[36m(func pid=39098)[0m f1_per_class: [0.0, 0.304, 0.0, 0.44, 0.233, 0.122, 0.562, 0.182, 0.127, 0.036]
[2m[36m(func pid=39098)[0m 
== Status ==
Current time: 2024-01-07 02:31:52 (running for 00:07:53.19)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=1
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (19 PENDING, 4 RUNNING, 1 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING    | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.784 |      0.318 |                   79 |
| train_6ed81_00001 | RUNNING    | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.178 |      0.121 |                   83 |
| train_6ed81_00002 | RUNNING    | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.329 |      0.2   |                   79 |
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.981 |      0.053 |                    5 |
| train_6ed81_00005 | PENDING    |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=55782)[0m top1: 0.20662313432835822
[2m[36m(func pid=55782)[0m top5: 0.5802238805970149
[2m[36m(func pid=55782)[0m f1_micro: 0.20662313432835824
[2m[36m(func pid=55782)[0m f1_macro: 0.05284389866452686
[2m[36m(func pid=55782)[0m f1_weighted: 0.10419872292867352
[2m[36m(func pid=55782)[0m f1_per_class: [0.0, 0.0, 0.125, 0.362, 0.0, 0.0, 0.0, 0.041, 0.0, 0.0]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 79] | Train loss: 0.8482 | Steps: 2 | Val loss: 1.8321 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 83] | Train loss: 0.1760 | Steps: 2 | Val loss: 8.6259 | Batch size: 32 | lr: 0.001 | Duration: 2.72s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 79] | Train loss: 0.6196 | Steps: 2 | Val loss: 7.6379 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 2.9110 | Steps: 2 | Val loss: 2.3203 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=38305)[0m top1: 0.37966417910447764
[2m[36m(func pid=38305)[0m top5: 0.894589552238806
[2m[36m(func pid=38305)[0m f1_micro: 0.37966417910447764
[2m[36m(func pid=38305)[0m f1_macro: 0.3187477537957332
[2m[36m(func pid=38305)[0m f1_weighted: 0.40465980433022075
[2m[36m(func pid=38305)[0m f1_per_class: [0.17, 0.545, 0.321, 0.474, 0.081, 0.319, 0.318, 0.57, 0.18, 0.208]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=38679)[0m top1: 0.10914179104477612
[2m[36m(func pid=38679)[0m top5: 0.6870335820895522
[2m[36m(func pid=38679)[0m f1_micro: 0.10914179104477612
[2m[36m(func pid=38679)[0m f1_macro: 0.10198611837844977
[2m[36m(func pid=38679)[0m f1_weighted: 0.10555488612093747
[2m[36m(func pid=38679)[0m f1_per_class: [0.116, 0.243, 0.133, 0.167, 0.074, 0.031, 0.019, 0.0, 0.074, 0.162]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=39098)[0m top1: 0.3591417910447761
[2m[36m(func pid=39098)[0m top5: 0.8791977611940298
[2m[36m(func pid=39098)[0m f1_micro: 0.3591417910447761
[2m[36m(func pid=39098)[0m f1_macro: 0.20856679338590772
[2m[36m(func pid=39098)[0m f1_weighted: 0.38054518405361
[2m[36m(func pid=39098)[0m f1_per_class: [0.0, 0.341, 0.0, 0.418, 0.206, 0.149, 0.566, 0.231, 0.12, 0.054]
[2m[36m(func pid=39098)[0m 
== Status ==
Current time: 2024-01-07 02:31:57 (running for 00:07:58.50)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=1
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (19 PENDING, 4 RUNNING, 1 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING    | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.848 |      0.319 |                   80 |
| train_6ed81_00001 | RUNNING    | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.176 |      0.102 |                   84 |
| train_6ed81_00002 | RUNNING    | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.62  |      0.209 |                   80 |
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.911 |      0.065 |                    6 |
| train_6ed81_00005 | PENDING    |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=55782)[0m top1: 0.21175373134328357
[2m[36m(func pid=55782)[0m top5: 0.5802238805970149
[2m[36m(func pid=55782)[0m f1_micro: 0.21175373134328357
[2m[36m(func pid=55782)[0m f1_macro: 0.06466021768605383
[2m[36m(func pid=55782)[0m f1_weighted: 0.10621516533420633
[2m[36m(func pid=55782)[0m f1_per_class: [0.0, 0.0, 0.24, 0.367, 0.0, 0.0, 0.0, 0.039, 0.0, 0.0]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 84] | Train loss: 0.2239 | Steps: 2 | Val loss: 8.5280 | Batch size: 32 | lr: 0.001 | Duration: 2.72s
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 80] | Train loss: 0.8446 | Steps: 2 | Val loss: 1.8149 | Batch size: 32 | lr: 0.0001 | Duration: 3.01s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 80] | Train loss: 0.2951 | Steps: 2 | Val loss: 7.6993 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 2.8495 | Steps: 2 | Val loss: 2.3227 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=38679)[0m top1: 0.125
[2m[36m(func pid=38679)[0m top5: 0.6884328358208955
[2m[36m(func pid=38679)[0m f1_micro: 0.125
[2m[36m(func pid=38679)[0m f1_macro: 0.11106045520119465
[2m[36m(func pid=38679)[0m f1_weighted: 0.12253203293017087
[2m[36m(func pid=38679)[0m f1_per_class: [0.106, 0.288, 0.137, 0.199, 0.073, 0.032, 0.019, 0.0, 0.082, 0.175]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=38305)[0m top1: 0.3843283582089552
[2m[36m(func pid=38305)[0m top5: 0.8950559701492538
[2m[36m(func pid=38305)[0m f1_micro: 0.3843283582089552
[2m[36m(func pid=38305)[0m f1_macro: 0.3231859675253995
[2m[36m(func pid=38305)[0m f1_weighted: 0.4110621408829025
[2m[36m(func pid=38305)[0m f1_per_class: [0.174, 0.55, 0.316, 0.463, 0.087, 0.327, 0.347, 0.557, 0.155, 0.255]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39098)[0m top1: 0.3614738805970149
[2m[36m(func pid=39098)[0m top5: 0.8801305970149254
[2m[36m(func pid=39098)[0m f1_micro: 0.3614738805970149
[2m[36m(func pid=39098)[0m f1_macro: 0.2267691041959528
[2m[36m(func pid=39098)[0m f1_weighted: 0.38332378387520916
[2m[36m(func pid=39098)[0m f1_per_class: [0.0, 0.335, 0.0, 0.417, 0.184, 0.111, 0.543, 0.502, 0.117, 0.06]
[2m[36m(func pid=39098)[0m 
== Status ==
Current time: 2024-01-07 02:32:02 (running for 00:08:03.80)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=1
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (19 PENDING, 4 RUNNING, 1 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING    | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.845 |      0.323 |                   81 |
| train_6ed81_00001 | RUNNING    | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.224 |      0.111 |                   85 |
| train_6ed81_00002 | RUNNING    | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.295 |      0.227 |                   81 |
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.85  |      0.067 |                    7 |
| train_6ed81_00005 | PENDING    |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=55782)[0m top1: 0.21921641791044777
[2m[36m(func pid=55782)[0m top5: 0.570429104477612
[2m[36m(func pid=55782)[0m f1_micro: 0.21921641791044777
[2m[36m(func pid=55782)[0m f1_macro: 0.06688906390172529
[2m[36m(func pid=55782)[0m f1_weighted: 0.10923368717967678
[2m[36m(func pid=55782)[0m f1_per_class: [0.0, 0.005, 0.25, 0.375, 0.0, 0.0, 0.0, 0.039, 0.0, 0.0]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 85] | Train loss: 0.2203 | Steps: 2 | Val loss: 8.8178 | Batch size: 32 | lr: 0.001 | Duration: 2.71s
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 81] | Train loss: 0.7515 | Steps: 2 | Val loss: 1.7936 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 81] | Train loss: 0.3110 | Steps: 2 | Val loss: 7.9260 | Batch size: 32 | lr: 0.01 | Duration: 2.74s
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 2.8171 | Steps: 2 | Val loss: 2.3237 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=38679)[0m top1: 0.1310634328358209
[2m[36m(func pid=38679)[0m top5: 0.7112873134328358
[2m[36m(func pid=38679)[0m f1_micro: 0.1310634328358209
[2m[36m(func pid=38679)[0m f1_macro: 0.12426437476909324
[2m[36m(func pid=38679)[0m f1_weighted: 0.1192499188242461
[2m[36m(func pid=38679)[0m f1_per_class: [0.102, 0.335, 0.14, 0.167, 0.076, 0.032, 0.003, 0.0, 0.115, 0.273]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=38305)[0m top1: 0.3917910447761194
[2m[36m(func pid=38305)[0m top5: 0.9015858208955224
[2m[36m(func pid=38305)[0m f1_micro: 0.3917910447761195
[2m[36m(func pid=38305)[0m f1_macro: 0.33302388853701453
[2m[36m(func pid=38305)[0m f1_weighted: 0.42196906385641214
[2m[36m(func pid=38305)[0m f1_per_class: [0.174, 0.55, 0.31, 0.459, 0.081, 0.337, 0.385, 0.533, 0.165, 0.336]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39098)[0m top1: 0.35634328358208955
[2m[36m(func pid=39098)[0m top5: 0.8759328358208955
[2m[36m(func pid=39098)[0m f1_micro: 0.3563432835820895
[2m[36m(func pid=39098)[0m f1_macro: 0.22382610329512845
[2m[36m(func pid=39098)[0m f1_weighted: 0.3793252664426728
[2m[36m(func pid=39098)[0m f1_per_class: [0.0, 0.335, 0.0, 0.429, 0.186, 0.077, 0.533, 0.486, 0.114, 0.078]
[2m[36m(func pid=39098)[0m 
== Status ==
Current time: 2024-01-07 02:32:08 (running for 00:08:09.16)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=1
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (19 PENDING, 4 RUNNING, 1 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING    | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.751 |      0.333 |                   82 |
| train_6ed81_00001 | RUNNING    | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.22  |      0.124 |                   86 |
| train_6ed81_00002 | RUNNING    | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.311 |      0.224 |                   82 |
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.817 |      0.059 |                    8 |
| train_6ed81_00005 | PENDING    |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=55782)[0m top1: 0.22154850746268656
[2m[36m(func pid=55782)[0m top5: 0.5638992537313433
[2m[36m(func pid=55782)[0m f1_micro: 0.22154850746268656
[2m[36m(func pid=55782)[0m f1_macro: 0.05897029922213026
[2m[36m(func pid=55782)[0m f1_weighted: 0.11138704449278093
[2m[36m(func pid=55782)[0m f1_per_class: [0.0, 0.016, 0.154, 0.377, 0.0, 0.0, 0.0, 0.043, 0.0, 0.0]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 86] | Train loss: 0.0546 | Steps: 2 | Val loss: 10.4191 | Batch size: 32 | lr: 0.001 | Duration: 2.65s
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 82] | Train loss: 1.0712 | Steps: 2 | Val loss: 1.7542 | Batch size: 32 | lr: 0.0001 | Duration: 3.08s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 82] | Train loss: 0.4547 | Steps: 2 | Val loss: 8.5338 | Batch size: 32 | lr: 0.01 | Duration: 3.16s
[2m[36m(func pid=38679)[0m top1: 0.1287313432835821
[2m[36m(func pid=38679)[0m top5: 0.7201492537313433
[2m[36m(func pid=38679)[0m f1_micro: 0.1287313432835821
[2m[36m(func pid=38679)[0m f1_macro: 0.11865503185102547
[2m[36m(func pid=38679)[0m f1_weighted: 0.11406614060684296
[2m[36m(func pid=38679)[0m f1_per_class: [0.101, 0.364, 0.154, 0.15, 0.082, 0.008, 0.003, 0.0, 0.02, 0.306]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 2.7554 | Steps: 2 | Val loss: 2.3239 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
[2m[36m(func pid=38305)[0m top1: 0.4025186567164179
[2m[36m(func pid=38305)[0m top5: 0.9067164179104478
[2m[36m(func pid=38305)[0m f1_micro: 0.4025186567164179
[2m[36m(func pid=38305)[0m f1_macro: 0.3410221170221259
[2m[36m(func pid=38305)[0m f1_weighted: 0.43375347324492897
[2m[36m(func pid=38305)[0m f1_per_class: [0.184, 0.553, 0.31, 0.454, 0.079, 0.342, 0.425, 0.523, 0.162, 0.378]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39098)[0m top1: 0.31529850746268656
[2m[36m(func pid=39098)[0m top5: 0.8661380597014925
[2m[36m(func pid=39098)[0m f1_micro: 0.31529850746268656
[2m[36m(func pid=39098)[0m f1_macro: 0.18964640181185294
[2m[36m(func pid=39098)[0m f1_weighted: 0.3414689022061126
[2m[36m(func pid=39098)[0m f1_per_class: [0.0, 0.334, 0.0, 0.396, 0.171, 0.07, 0.497, 0.189, 0.112, 0.127]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 87] | Train loss: 0.0613 | Steps: 2 | Val loss: 10.6693 | Batch size: 32 | lr: 0.001 | Duration: 2.74s
== Status ==
Current time: 2024-01-07 02:32:13 (running for 00:08:14.69)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=1
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (19 PENDING, 4 RUNNING, 1 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING    | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  1.071 |      0.341 |                   83 |
| train_6ed81_00001 | RUNNING    | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.055 |      0.119 |                   87 |
| train_6ed81_00002 | RUNNING    | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.455 |      0.19  |                   83 |
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.755 |      0.059 |                    9 |
| train_6ed81_00005 | PENDING    |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=55782)[0m top1: 0.2224813432835821
[2m[36m(func pid=55782)[0m top5: 0.5583022388059702
[2m[36m(func pid=55782)[0m f1_micro: 0.2224813432835821
[2m[36m(func pid=55782)[0m f1_macro: 0.05942513427465711
[2m[36m(func pid=55782)[0m f1_weighted: 0.11510338844335759
[2m[36m(func pid=55782)[0m f1_per_class: [0.0, 0.031, 0.116, 0.377, 0.0, 0.0, 0.0, 0.071, 0.0, 0.0]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 83] | Train loss: 0.7812 | Steps: 2 | Val loss: 1.7657 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 83] | Train loss: 0.9946 | Steps: 2 | Val loss: 8.5085 | Batch size: 32 | lr: 0.01 | Duration: 2.68s
[2m[36m(func pid=38679)[0m top1: 0.13059701492537312
[2m[36m(func pid=38679)[0m top5: 0.7341417910447762
[2m[36m(func pid=38679)[0m f1_micro: 0.13059701492537312
[2m[36m(func pid=38679)[0m f1_macro: 0.11985988085088853
[2m[36m(func pid=38679)[0m f1_weighted: 0.1181475942410605
[2m[36m(func pid=38679)[0m f1_per_class: [0.098, 0.399, 0.174, 0.139, 0.073, 0.008, 0.009, 0.0, 0.0, 0.299]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=38305)[0m top1: 0.3969216417910448
[2m[36m(func pid=38305)[0m top5: 0.9057835820895522
[2m[36m(func pid=38305)[0m f1_micro: 0.3969216417910448
[2m[36m(func pid=38305)[0m f1_macro: 0.33798954528571934
[2m[36m(func pid=38305)[0m f1_weighted: 0.4304458124487061
[2m[36m(func pid=38305)[0m f1_per_class: [0.163, 0.556, 0.305, 0.443, 0.08, 0.342, 0.424, 0.51, 0.176, 0.381]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 2.7542 | Steps: 2 | Val loss: 2.3257 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=39098)[0m top1: 0.28591417910447764
[2m[36m(func pid=39098)[0m top5: 0.8703358208955224
[2m[36m(func pid=39098)[0m f1_micro: 0.28591417910447764
[2m[36m(func pid=39098)[0m f1_macro: 0.17115640121305067
[2m[36m(func pid=39098)[0m f1_weighted: 0.31211156594936745
[2m[36m(func pid=39098)[0m f1_per_class: [0.044, 0.356, 0.0, 0.366, 0.139, 0.077, 0.439, 0.03, 0.105, 0.155]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 88] | Train loss: 0.2783 | Steps: 2 | Val loss: 9.1570 | Batch size: 32 | lr: 0.001 | Duration: 2.70s
== Status ==
Current time: 2024-01-07 02:32:19 (running for 00:08:19.86)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=1
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (19 PENDING, 4 RUNNING, 1 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING    | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.781 |      0.338 |                   84 |
| train_6ed81_00001 | RUNNING    | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.061 |      0.12  |                   88 |
| train_6ed81_00002 | RUNNING    | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.995 |      0.171 |                   84 |
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.754 |      0.058 |                   10 |
| train_6ed81_00005 | PENDING    |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=55782)[0m top1: 0.21548507462686567
[2m[36m(func pid=55782)[0m top5: 0.5583022388059702
[2m[36m(func pid=55782)[0m f1_micro: 0.21548507462686567
[2m[36m(func pid=55782)[0m f1_macro: 0.058322762486289495
[2m[36m(func pid=55782)[0m f1_weighted: 0.11346944357040571
[2m[36m(func pid=55782)[0m f1_per_class: [0.0, 0.031, 0.096, 0.367, 0.0, 0.0, 0.0, 0.089, 0.0, 0.0]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 84] | Train loss: 0.9840 | Steps: 2 | Val loss: 1.7662 | Batch size: 32 | lr: 0.0001 | Duration: 2.76s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 84] | Train loss: 0.5202 | Steps: 2 | Val loss: 7.7693 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=38679)[0m top1: 0.14598880597014927
[2m[36m(func pid=38679)[0m top5: 0.7905783582089553
[2m[36m(func pid=38679)[0m f1_micro: 0.14598880597014927
[2m[36m(func pid=38679)[0m f1_macro: 0.12917705536861795
[2m[36m(func pid=38679)[0m f1_weighted: 0.13913146512756422
[2m[36m(func pid=38679)[0m f1_per_class: [0.106, 0.438, 0.177, 0.145, 0.056, 0.008, 0.051, 0.0, 0.0, 0.31]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=38305)[0m top1: 0.39505597014925375
[2m[36m(func pid=38305)[0m top5: 0.9043843283582089
[2m[36m(func pid=38305)[0m f1_micro: 0.39505597014925375
[2m[36m(func pid=38305)[0m f1_macro: 0.3409795040266427
[2m[36m(func pid=38305)[0m f1_weighted: 0.42700135689825547
[2m[36m(func pid=38305)[0m f1_per_class: [0.168, 0.562, 0.333, 0.429, 0.08, 0.346, 0.423, 0.495, 0.169, 0.405]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 2.6932 | Steps: 2 | Val loss: 2.3234 | Batch size: 32 | lr: 0.0001 | Duration: 2.78s
[2m[36m(func pid=39098)[0m top1: 0.3111007462686567
[2m[36m(func pid=39098)[0m top5: 0.8819962686567164
[2m[36m(func pid=39098)[0m f1_micro: 0.3111007462686567
[2m[36m(func pid=39098)[0m f1_macro: 0.24205804906773723
[2m[36m(func pid=39098)[0m f1_weighted: 0.3307092728824268
[2m[36m(func pid=39098)[0m f1_per_class: [0.137, 0.411, 0.476, 0.351, 0.189, 0.087, 0.467, 0.0, 0.109, 0.194]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 89] | Train loss: 0.0591 | Steps: 2 | Val loss: 6.8782 | Batch size: 32 | lr: 0.001 | Duration: 2.76s
== Status ==
Current time: 2024-01-07 02:32:24 (running for 00:08:25.08)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=1
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (19 PENDING, 4 RUNNING, 1 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING    | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.984 |      0.341 |                   85 |
| train_6ed81_00001 | RUNNING    | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.278 |      0.129 |                   89 |
| train_6ed81_00002 | RUNNING    | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.52  |      0.242 |                   85 |
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.693 |      0.07  |                   11 |
| train_6ed81_00005 | PENDING    |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=55782)[0m top1: 0.21175373134328357
[2m[36m(func pid=55782)[0m top5: 0.5578358208955224
[2m[36m(func pid=55782)[0m f1_micro: 0.21175373134328357
[2m[36m(func pid=55782)[0m f1_macro: 0.06993374555812101
[2m[36m(func pid=55782)[0m f1_weighted: 0.11928772596710771
[2m[36m(func pid=55782)[0m f1_per_class: [0.04, 0.039, 0.073, 0.36, 0.0, 0.0, 0.0, 0.187, 0.0, 0.0]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 85] | Train loss: 0.6827 | Steps: 2 | Val loss: 1.8065 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 85] | Train loss: 0.1021 | Steps: 2 | Val loss: 7.3175 | Batch size: 32 | lr: 0.01 | Duration: 2.76s
[2m[36m(func pid=38679)[0m top1: 0.22901119402985073
[2m[36m(func pid=38679)[0m top5: 0.8316231343283582
[2m[36m(func pid=38679)[0m f1_micro: 0.22901119402985073
[2m[36m(func pid=38679)[0m f1_macro: 0.17253986336783103
[2m[36m(func pid=38679)[0m f1_weighted: 0.2464799915049326
[2m[36m(func pid=38679)[0m f1_per_class: [0.124, 0.46, 0.152, 0.172, 0.052, 0.016, 0.363, 0.016, 0.0, 0.37]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=38305)[0m top1: 0.3805970149253731
[2m[36m(func pid=38305)[0m top5: 0.9048507462686567
[2m[36m(func pid=38305)[0m f1_micro: 0.3805970149253731
[2m[36m(func pid=38305)[0m f1_macro: 0.330426185510128
[2m[36m(func pid=38305)[0m f1_weighted: 0.413202807068483
[2m[36m(func pid=38305)[0m f1_per_class: [0.157, 0.563, 0.344, 0.405, 0.081, 0.347, 0.405, 0.477, 0.147, 0.378]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 2.6540 | Steps: 2 | Val loss: 2.3217 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=39098)[0m top1: 0.33675373134328357
[2m[36m(func pid=39098)[0m top5: 0.886660447761194
[2m[36m(func pid=39098)[0m f1_micro: 0.33675373134328357
[2m[36m(func pid=39098)[0m f1_macro: 0.27592340209901367
[2m[36m(func pid=39098)[0m f1_weighted: 0.3548370745833163
[2m[36m(func pid=39098)[0m f1_per_class: [0.143, 0.435, 0.621, 0.371, 0.217, 0.122, 0.496, 0.0, 0.107, 0.247]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 90] | Train loss: 0.0546 | Steps: 2 | Val loss: 6.4284 | Batch size: 32 | lr: 0.001 | Duration: 2.73s
== Status ==
Current time: 2024-01-07 02:32:29 (running for 00:08:30.36)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=1
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (19 PENDING, 4 RUNNING, 1 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING    | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.683 |      0.33  |                   86 |
| train_6ed81_00001 | RUNNING    | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.059 |      0.173 |                   90 |
| train_6ed81_00002 | RUNNING    | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.102 |      0.276 |                   86 |
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.654 |      0.075 |                   12 |
| train_6ed81_00005 | PENDING    |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=55782)[0m top1: 0.20755597014925373
[2m[36m(func pid=55782)[0m top5: 0.5611007462686567
[2m[36m(func pid=55782)[0m f1_micro: 0.20755597014925375
[2m[36m(func pid=55782)[0m f1_macro: 0.07496252511231725
[2m[36m(func pid=55782)[0m f1_weighted: 0.12416788599612245
[2m[36m(func pid=55782)[0m f1_per_class: [0.0, 0.051, 0.063, 0.354, 0.0, 0.0, 0.0, 0.281, 0.0, 0.0]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 86] | Train loss: 0.8332 | Steps: 2 | Val loss: 1.8331 | Batch size: 32 | lr: 0.0001 | Duration: 2.79s
[2m[36m(func pid=38679)[0m top1: 0.2994402985074627
[2m[36m(func pid=38679)[0m top5: 0.8138992537313433
[2m[36m(func pid=38679)[0m f1_micro: 0.2994402985074627
[2m[36m(func pid=38679)[0m f1_macro: 0.1997045040357926
[2m[36m(func pid=38679)[0m f1_weighted: 0.308594174234994
[2m[36m(func pid=38679)[0m f1_per_class: [0.122, 0.464, 0.174, 0.245, 0.059, 0.016, 0.501, 0.0, 0.024, 0.392]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 86] | Train loss: 0.2125 | Steps: 2 | Val loss: 7.0017 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=38305)[0m top1: 0.3829291044776119
[2m[36m(func pid=38305)[0m top5: 0.90625
[2m[36m(func pid=38305)[0m f1_micro: 0.3829291044776119
[2m[36m(func pid=38305)[0m f1_macro: 0.3324535234550833
[2m[36m(func pid=38305)[0m f1_weighted: 0.4159117909588042
[2m[36m(func pid=38305)[0m f1_per_class: [0.147, 0.585, 0.314, 0.397, 0.083, 0.351, 0.406, 0.482, 0.165, 0.395]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 2.6108 | Steps: 2 | Val loss: 2.3200 | Batch size: 32 | lr: 0.0001 | Duration: 2.77s
[2m[36m(func pid=39098)[0m top1: 0.34654850746268656
[2m[36m(func pid=39098)[0m top5: 0.8885261194029851
[2m[36m(func pid=39098)[0m f1_micro: 0.34654850746268656
[2m[36m(func pid=39098)[0m f1_macro: 0.2911946247224443
[2m[36m(func pid=39098)[0m f1_weighted: 0.36337653395860353
[2m[36m(func pid=39098)[0m f1_per_class: [0.12, 0.486, 0.667, 0.359, 0.286, 0.111, 0.509, 0.0, 0.113, 0.263]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 91] | Train loss: 0.0778 | Steps: 2 | Val loss: 6.8488 | Batch size: 32 | lr: 0.001 | Duration: 2.69s
== Status ==
Current time: 2024-01-07 02:32:34 (running for 00:08:35.43)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=1
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (19 PENDING, 4 RUNNING, 1 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING    | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.833 |      0.332 |                   87 |
| train_6ed81_00001 | RUNNING    | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.055 |      0.2   |                   91 |
| train_6ed81_00002 | RUNNING    | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.212 |      0.291 |                   87 |
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.611 |      0.081 |                   13 |
| train_6ed81_00005 | PENDING    |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=55782)[0m top1: 0.20009328358208955
[2m[36m(func pid=55782)[0m top5: 0.558768656716418
[2m[36m(func pid=55782)[0m f1_micro: 0.20009328358208955
[2m[36m(func pid=55782)[0m f1_macro: 0.08138430813012554
[2m[36m(func pid=55782)[0m f1_weighted: 0.1265203742263313
[2m[36m(func pid=55782)[0m f1_per_class: [0.0, 0.062, 0.058, 0.341, 0.0, 0.0, 0.0, 0.352, 0.0, 0.0]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 87] | Train loss: 0.6981 | Steps: 2 | Val loss: 1.8330 | Batch size: 32 | lr: 0.0001 | Duration: 2.81s
[2m[36m(func pid=38679)[0m top1: 0.30736940298507465
[2m[36m(func pid=38679)[0m top5: 0.8111007462686567
[2m[36m(func pid=38679)[0m f1_micro: 0.30736940298507465
[2m[36m(func pid=38679)[0m f1_macro: 0.21149136405962726
[2m[36m(func pid=38679)[0m f1_weighted: 0.3163607321574637
[2m[36m(func pid=38679)[0m f1_per_class: [0.118, 0.481, 0.185, 0.26, 0.082, 0.016, 0.5, 0.0, 0.024, 0.449]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 87] | Train loss: 0.5178 | Steps: 2 | Val loss: 7.0156 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=38305)[0m top1: 0.3829291044776119
[2m[36m(func pid=38305)[0m top5: 0.9090485074626866
[2m[36m(func pid=38305)[0m f1_micro: 0.3829291044776119
[2m[36m(func pid=38305)[0m f1_macro: 0.33579452451759634
[2m[36m(func pid=38305)[0m f1_weighted: 0.41673612129420157
[2m[36m(func pid=38305)[0m f1_per_class: [0.149, 0.585, 0.314, 0.395, 0.092, 0.354, 0.409, 0.482, 0.153, 0.425]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 2.6398 | Steps: 2 | Val loss: 2.3187 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 92] | Train loss: 0.1191 | Steps: 2 | Val loss: 7.0093 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=39098)[0m top1: 0.3358208955223881
[2m[36m(func pid=39098)[0m top5: 0.8889925373134329
[2m[36m(func pid=39098)[0m f1_micro: 0.3358208955223881
[2m[36m(func pid=39098)[0m f1_macro: 0.27302622430077694
[2m[36m(func pid=39098)[0m f1_weighted: 0.3561462617873384
[2m[36m(func pid=39098)[0m f1_per_class: [0.111, 0.496, 0.647, 0.355, 0.24, 0.11, 0.489, 0.0, 0.111, 0.171]
[2m[36m(func pid=39098)[0m 
== Status ==
Current time: 2024-01-07 02:32:39 (running for 00:08:40.81)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=1
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (19 PENDING, 4 RUNNING, 1 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING    | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.698 |      0.336 |                   88 |
| train_6ed81_00001 | RUNNING    | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.078 |      0.211 |                   92 |
| train_6ed81_00002 | RUNNING    | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.518 |      0.273 |                   88 |
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.64  |      0.086 |                   14 |
| train_6ed81_00005 | PENDING    |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=55782)[0m top1: 0.20009328358208955
[2m[36m(func pid=55782)[0m top5: 0.5634328358208955
[2m[36m(func pid=55782)[0m f1_micro: 0.20009328358208955
[2m[36m(func pid=55782)[0m f1_macro: 0.08648796885534002
[2m[36m(func pid=55782)[0m f1_weighted: 0.13018767736545633
[2m[36m(func pid=55782)[0m f1_per_class: [0.0, 0.065, 0.057, 0.342, 0.0, 0.0, 0.0, 0.4, 0.0, 0.0]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 88] | Train loss: 0.6685 | Steps: 2 | Val loss: 1.8451 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=38679)[0m top1: 0.31949626865671643
[2m[36m(func pid=38679)[0m top5: 0.8325559701492538
[2m[36m(func pid=38679)[0m f1_micro: 0.31949626865671643
[2m[36m(func pid=38679)[0m f1_macro: 0.21864776292557125
[2m[36m(func pid=38679)[0m f1_weighted: 0.3241360405122465
[2m[36m(func pid=38679)[0m f1_per_class: [0.123, 0.471, 0.205, 0.24, 0.087, 0.04, 0.539, 0.0, 0.043, 0.44]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 88] | Train loss: 0.3045 | Steps: 2 | Val loss: 6.7767 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=38305)[0m top1: 0.3805970149253731
[2m[36m(func pid=38305)[0m top5: 0.9076492537313433
[2m[36m(func pid=38305)[0m f1_micro: 0.3805970149253731
[2m[36m(func pid=38305)[0m f1_macro: 0.3342020518829305
[2m[36m(func pid=38305)[0m f1_weighted: 0.41629370658577813
[2m[36m(func pid=38305)[0m f1_per_class: [0.149, 0.588, 0.306, 0.387, 0.087, 0.345, 0.419, 0.472, 0.148, 0.442]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 2.5846 | Steps: 2 | Val loss: 2.3170 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 93] | Train loss: 0.2063 | Steps: 2 | Val loss: 6.5725 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=39098)[0m top1: 0.3353544776119403
[2m[36m(func pid=39098)[0m top5: 0.8843283582089553
[2m[36m(func pid=39098)[0m f1_micro: 0.3353544776119403
[2m[36m(func pid=39098)[0m f1_macro: 0.26922795451627585
[2m[36m(func pid=39098)[0m f1_weighted: 0.35380346363828635
[2m[36m(func pid=39098)[0m f1_per_class: [0.1, 0.495, 0.6, 0.339, 0.293, 0.109, 0.497, 0.0, 0.113, 0.147]
[2m[36m(func pid=39098)[0m 
== Status ==
Current time: 2024-01-07 02:32:45 (running for 00:08:45.94)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=1
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (19 PENDING, 4 RUNNING, 1 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING    | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.669 |      0.334 |                   89 |
| train_6ed81_00001 | RUNNING    | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.119 |      0.219 |                   93 |
| train_6ed81_00002 | RUNNING    | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.305 |      0.269 |                   89 |
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.585 |      0.091 |                   15 |
| train_6ed81_00005 | PENDING    |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=55782)[0m top1: 0.18936567164179105
[2m[36m(func pid=55782)[0m top5: 0.5625
[2m[36m(func pid=55782)[0m f1_micro: 0.18936567164179105
[2m[36m(func pid=55782)[0m f1_macro: 0.09080831287914296
[2m[36m(func pid=55782)[0m f1_weighted: 0.1271454232477045
[2m[36m(func pid=55782)[0m f1_per_class: [0.019, 0.067, 0.057, 0.327, 0.0, 0.0, 0.0, 0.402, 0.0, 0.036]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 89] | Train loss: 0.6685 | Steps: 2 | Val loss: 1.8237 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=38679)[0m top1: 0.3423507462686567
[2m[36m(func pid=38679)[0m top5: 0.8596082089552238
[2m[36m(func pid=38679)[0m f1_micro: 0.3423507462686567
[2m[36m(func pid=38679)[0m f1_macro: 0.28518694688328095
[2m[36m(func pid=38679)[0m f1_weighted: 0.36598372991084105
[2m[36m(func pid=38679)[0m f1_per_class: [0.126, 0.466, 0.211, 0.237, 0.105, 0.14, 0.562, 0.374, 0.122, 0.509]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 89] | Train loss: 0.2039 | Steps: 2 | Val loss: 6.4318 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 2.5544 | Steps: 2 | Val loss: 2.3163 | Batch size: 32 | lr: 0.0001 | Duration: 2.77s
[2m[36m(func pid=38305)[0m top1: 0.3871268656716418
[2m[36m(func pid=38305)[0m top5: 0.9104477611940298
[2m[36m(func pid=38305)[0m f1_micro: 0.3871268656716418
[2m[36m(func pid=38305)[0m f1_macro: 0.33768571525956825
[2m[36m(func pid=38305)[0m f1_weighted: 0.4239467468300026
[2m[36m(func pid=38305)[0m f1_per_class: [0.16, 0.594, 0.297, 0.399, 0.082, 0.336, 0.433, 0.462, 0.15, 0.462]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 94] | Train loss: 0.0546 | Steps: 2 | Val loss: 6.7321 | Batch size: 32 | lr: 0.001 | Duration: 2.72s
[2m[36m(func pid=39098)[0m top1: 0.34701492537313433
[2m[36m(func pid=39098)[0m top5: 0.8796641791044776
[2m[36m(func pid=39098)[0m f1_micro: 0.34701492537313433
[2m[36m(func pid=39098)[0m f1_macro: 0.28465238480083194
[2m[36m(func pid=39098)[0m f1_weighted: 0.37298978327487065
[2m[36m(func pid=39098)[0m f1_per_class: [0.108, 0.496, 0.558, 0.345, 0.255, 0.152, 0.505, 0.187, 0.111, 0.13]
[2m[36m(func pid=39098)[0m 
== Status ==
Current time: 2024-01-07 02:32:50 (running for 00:08:51.12)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=1
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (19 PENDING, 4 RUNNING, 1 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING    | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.668 |      0.338 |                   90 |
| train_6ed81_00001 | RUNNING    | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.206 |      0.285 |                   94 |
| train_6ed81_00002 | RUNNING    | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.204 |      0.285 |                   90 |
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.554 |      0.095 |                   16 |
| train_6ed81_00005 | PENDING    |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=55782)[0m top1: 0.18516791044776118
[2m[36m(func pid=55782)[0m top5: 0.5671641791044776
[2m[36m(func pid=55782)[0m f1_micro: 0.18516791044776118
[2m[36m(func pid=55782)[0m f1_macro: 0.09494461541797608
[2m[36m(func pid=55782)[0m f1_weighted: 0.1300715583933269
[2m[36m(func pid=55782)[0m f1_per_class: [0.015, 0.083, 0.055, 0.32, 0.0, 0.0, 0.0, 0.442, 0.0, 0.034]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 90] | Train loss: 0.7051 | Steps: 2 | Val loss: 1.8093 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=38679)[0m top1: 0.3278917910447761
[2m[36m(func pid=38679)[0m top5: 0.8591417910447762
[2m[36m(func pid=38679)[0m f1_micro: 0.3278917910447761
[2m[36m(func pid=38679)[0m f1_macro: 0.29447231132043167
[2m[36m(func pid=38679)[0m f1_weighted: 0.35904921499507053
[2m[36m(func pid=38679)[0m f1_per_class: [0.121, 0.454, 0.224, 0.233, 0.112, 0.224, 0.498, 0.475, 0.121, 0.481]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 90] | Train loss: 0.4447 | Steps: 2 | Val loss: 6.4581 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 2.5542 | Steps: 2 | Val loss: 2.3131 | Batch size: 32 | lr: 0.0001 | Duration: 2.79s
[2m[36m(func pid=38305)[0m top1: 0.394589552238806
[2m[36m(func pid=38305)[0m top5: 0.9090485074626866
[2m[36m(func pid=38305)[0m f1_micro: 0.394589552238806
[2m[36m(func pid=38305)[0m f1_macro: 0.3415927061260332
[2m[36m(func pid=38305)[0m f1_weighted: 0.42990147846992105
[2m[36m(func pid=38305)[0m f1_per_class: [0.177, 0.596, 0.293, 0.406, 0.08, 0.328, 0.449, 0.453, 0.15, 0.484]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 95] | Train loss: 0.0504 | Steps: 2 | Val loss: 7.0540 | Batch size: 32 | lr: 0.001 | Duration: 2.63s
[2m[36m(func pid=39098)[0m top1: 0.33115671641791045
[2m[36m(func pid=39098)[0m top5: 0.8736007462686567
[2m[36m(func pid=39098)[0m f1_micro: 0.33115671641791045
[2m[36m(func pid=39098)[0m f1_macro: 0.2930692910882083
[2m[36m(func pid=39098)[0m f1_weighted: 0.36791634802577844
[2m[36m(func pid=39098)[0m f1_per_class: [0.111, 0.479, 0.48, 0.363, 0.22, 0.265, 0.406, 0.359, 0.117, 0.132]
[2m[36m(func pid=39098)[0m 
== Status ==
Current time: 2024-01-07 02:32:55 (running for 00:08:56.39)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=1
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (19 PENDING, 4 RUNNING, 1 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING    | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.705 |      0.342 |                   91 |
| train_6ed81_00001 | RUNNING    | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.055 |      0.294 |                   95 |
| train_6ed81_00002 | RUNNING    | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.445 |      0.293 |                   91 |
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.554 |      0.098 |                   17 |
| train_6ed81_00005 | PENDING    |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=55782)[0m top1: 0.1814365671641791
[2m[36m(func pid=55782)[0m top5: 0.5685634328358209
[2m[36m(func pid=55782)[0m f1_micro: 0.1814365671641791
[2m[36m(func pid=55782)[0m f1_macro: 0.09784950379265189
[2m[36m(func pid=55782)[0m f1_weighted: 0.1308286539844729
[2m[36m(func pid=55782)[0m f1_per_class: [0.013, 0.1, 0.059, 0.308, 0.0, 0.0, 0.0, 0.462, 0.0, 0.036]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 91] | Train loss: 0.7705 | Steps: 2 | Val loss: 1.7926 | Batch size: 32 | lr: 0.0001 | Duration: 2.77s
[2m[36m(func pid=38679)[0m top1: 0.31343283582089554
[2m[36m(func pid=38679)[0m top5: 0.8544776119402985
[2m[36m(func pid=38679)[0m f1_micro: 0.31343283582089554
[2m[36m(func pid=38679)[0m f1_macro: 0.28918741246707597
[2m[36m(func pid=38679)[0m f1_weighted: 0.3482763166645789
[2m[36m(func pid=38679)[0m f1_per_class: [0.113, 0.449, 0.217, 0.242, 0.117, 0.228, 0.459, 0.451, 0.134, 0.481]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 91] | Train loss: 0.8055 | Steps: 2 | Val loss: 6.7364 | Batch size: 32 | lr: 0.01 | Duration: 2.74s
[2m[36m(func pid=38305)[0m top1: 0.39598880597014924
[2m[36m(func pid=38305)[0m top5: 0.9137126865671642
[2m[36m(func pid=38305)[0m f1_micro: 0.39598880597014924
[2m[36m(func pid=38305)[0m f1_macro: 0.33945366602316085
[2m[36m(func pid=38305)[0m f1_weighted: 0.4311040029412217
[2m[36m(func pid=38305)[0m f1_per_class: [0.196, 0.593, 0.289, 0.409, 0.081, 0.316, 0.457, 0.456, 0.136, 0.462]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 2.5061 | Steps: 2 | Val loss: 2.3092 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 96] | Train loss: 0.2309 | Steps: 2 | Val loss: 7.1674 | Batch size: 32 | lr: 0.001 | Duration: 2.61s
[2m[36m(func pid=39098)[0m top1: 0.3069029850746269
[2m[36m(func pid=39098)[0m top5: 0.8666044776119403
[2m[36m(func pid=39098)[0m f1_micro: 0.3069029850746269
[2m[36m(func pid=39098)[0m f1_macro: 0.278004664229924
[2m[36m(func pid=39098)[0m f1_weighted: 0.3463501179231445
[2m[36m(func pid=39098)[0m f1_per_class: [0.107, 0.403, 0.415, 0.368, 0.175, 0.306, 0.35, 0.401, 0.124, 0.13]
[2m[36m(func pid=39098)[0m 
== Status ==
Current time: 2024-01-07 02:33:00 (running for 00:09:01.77)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=1
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (19 PENDING, 4 RUNNING, 1 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING    | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.77  |      0.339 |                   92 |
| train_6ed81_00001 | RUNNING    | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.05  |      0.289 |                   96 |
| train_6ed81_00002 | RUNNING    | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.805 |      0.278 |                   92 |
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.506 |      0.104 |                   18 |
| train_6ed81_00005 | PENDING    |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=55782)[0m top1: 0.18190298507462688
[2m[36m(func pid=55782)[0m top5: 0.5746268656716418
[2m[36m(func pid=55782)[0m f1_micro: 0.1819029850746269
[2m[36m(func pid=55782)[0m f1_macro: 0.10385371467749016
[2m[36m(func pid=55782)[0m f1_weighted: 0.13538759620499524
[2m[36m(func pid=55782)[0m f1_per_class: [0.011, 0.129, 0.056, 0.304, 0.0, 0.0, 0.0, 0.466, 0.0, 0.073]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 92] | Train loss: 0.6060 | Steps: 2 | Val loss: 1.8253 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=38679)[0m top1: 0.31529850746268656
[2m[36m(func pid=38679)[0m top5: 0.8479477611940298
[2m[36m(func pid=38679)[0m f1_micro: 0.31529850746268656
[2m[36m(func pid=38679)[0m f1_macro: 0.28949978529208176
[2m[36m(func pid=38679)[0m f1_weighted: 0.35406392088133426
[2m[36m(func pid=38679)[0m f1_per_class: [0.11, 0.455, 0.213, 0.272, 0.117, 0.217, 0.455, 0.431, 0.136, 0.491]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 92] | Train loss: 0.5014 | Steps: 2 | Val loss: 7.2777 | Batch size: 32 | lr: 0.01 | Duration: 2.77s
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 2.5257 | Steps: 2 | Val loss: 2.3063 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=38305)[0m top1: 0.3871268656716418
[2m[36m(func pid=38305)[0m top5: 0.9076492537313433
[2m[36m(func pid=38305)[0m f1_micro: 0.3871268656716418
[2m[36m(func pid=38305)[0m f1_macro: 0.3347557947494022
[2m[36m(func pid=38305)[0m f1_weighted: 0.4231597727835045
[2m[36m(func pid=38305)[0m f1_per_class: [0.191, 0.592, 0.272, 0.413, 0.079, 0.32, 0.425, 0.462, 0.14, 0.455]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 97] | Train loss: 0.6188 | Steps: 2 | Val loss: 6.7479 | Batch size: 32 | lr: 0.001 | Duration: 2.68s
[2m[36m(func pid=39098)[0m top1: 0.2826492537313433
[2m[36m(func pid=39098)[0m top5: 0.8638059701492538
[2m[36m(func pid=39098)[0m f1_micro: 0.2826492537313433
[2m[36m(func pid=39098)[0m f1_macro: 0.2559635738298831
[2m[36m(func pid=39098)[0m f1_weighted: 0.3289564429099423
[2m[36m(func pid=39098)[0m f1_per_class: [0.1, 0.327, 0.323, 0.392, 0.157, 0.336, 0.316, 0.346, 0.116, 0.147]
[2m[36m(func pid=39098)[0m 
== Status ==
Current time: 2024-01-07 02:33:06 (running for 00:09:06.97)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=1
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (19 PENDING, 4 RUNNING, 1 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING    | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.606 |      0.335 |                   93 |
| train_6ed81_00001 | RUNNING    | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.231 |      0.289 |                   97 |
| train_6ed81_00002 | RUNNING    | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.501 |      0.256 |                   93 |
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.526 |      0.113 |                   19 |
| train_6ed81_00005 | PENDING    |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=55782)[0m top1: 0.18190298507462688
[2m[36m(func pid=55782)[0m top5: 0.5909514925373134
[2m[36m(func pid=55782)[0m f1_micro: 0.1819029850746269
[2m[36m(func pid=55782)[0m f1_macro: 0.11279571483733516
[2m[36m(func pid=55782)[0m f1_weighted: 0.1382864536098755
[2m[36m(func pid=55782)[0m f1_per_class: [0.025, 0.143, 0.058, 0.299, 0.0, 0.0, 0.0, 0.486, 0.0, 0.118]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=38679)[0m top1: 0.34095149253731344
[2m[36m(func pid=38679)[0m top5: 0.8432835820895522
[2m[36m(func pid=38679)[0m f1_micro: 0.34095149253731344
[2m[36m(func pid=38679)[0m f1_macro: 0.3087936581007896
[2m[36m(func pid=38679)[0m f1_weighted: 0.3810864391267076
[2m[36m(func pid=38679)[0m f1_per_class: [0.113, 0.465, 0.253, 0.312, 0.116, 0.202, 0.503, 0.448, 0.128, 0.549]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 93] | Train loss: 0.7474 | Steps: 2 | Val loss: 1.8982 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 93] | Train loss: 0.2281 | Steps: 2 | Val loss: 8.2115 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 2.4886 | Steps: 2 | Val loss: 2.3023 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=38305)[0m top1: 0.37220149253731344
[2m[36m(func pid=38305)[0m top5: 0.8987873134328358
[2m[36m(func pid=38305)[0m f1_micro: 0.3722014925373134
[2m[36m(func pid=38305)[0m f1_macro: 0.32039656901957636
[2m[36m(func pid=38305)[0m f1_weighted: 0.4093383328749294
[2m[36m(func pid=38305)[0m f1_per_class: [0.166, 0.599, 0.244, 0.397, 0.08, 0.321, 0.39, 0.48, 0.136, 0.389]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 98] | Train loss: 0.1357 | Steps: 2 | Val loss: 6.3573 | Batch size: 32 | lr: 0.001 | Duration: 2.69s
[2m[36m(func pid=39098)[0m top1: 0.24720149253731344
[2m[36m(func pid=39098)[0m top5: 0.8656716417910447
[2m[36m(func pid=39098)[0m f1_micro: 0.24720149253731344
[2m[36m(func pid=39098)[0m f1_macro: 0.21382282787778678
[2m[36m(func pid=39098)[0m f1_weighted: 0.2912301845059846
[2m[36m(func pid=39098)[0m f1_per_class: [0.101, 0.231, 0.253, 0.384, 0.125, 0.338, 0.293, 0.146, 0.106, 0.161]
[2m[36m(func pid=39098)[0m 
== Status ==
Current time: 2024-01-07 02:33:11 (running for 00:09:12.11)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=1
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (19 PENDING, 4 RUNNING, 1 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING    | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.747 |      0.32  |                   94 |
| train_6ed81_00001 | RUNNING    | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.619 |      0.309 |                   98 |
| train_6ed81_00002 | RUNNING    | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.228 |      0.214 |                   94 |
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.489 |      0.109 |                   20 |
| train_6ed81_00005 | PENDING    |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=55782)[0m top1: 0.17117537313432835
[2m[36m(func pid=55782)[0m top5: 0.6012126865671642
[2m[36m(func pid=55782)[0m f1_micro: 0.17117537313432835
[2m[36m(func pid=55782)[0m f1_macro: 0.10926035788518296
[2m[36m(func pid=55782)[0m f1_weighted: 0.13164846957973428
[2m[36m(func pid=55782)[0m f1_per_class: [0.026, 0.13, 0.06, 0.283, 0.0, 0.0, 0.0, 0.489, 0.0, 0.105]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=38679)[0m top1: 0.365205223880597
[2m[36m(func pid=38679)[0m top5: 0.8502798507462687
[2m[36m(func pid=38679)[0m f1_micro: 0.365205223880597
[2m[36m(func pid=38679)[0m f1_macro: 0.31465331496426563
[2m[36m(func pid=38679)[0m f1_weighted: 0.40769776891020937
[2m[36m(func pid=38679)[0m f1_per_class: [0.113, 0.497, 0.253, 0.369, 0.11, 0.16, 0.538, 0.442, 0.126, 0.538]
[2m[36m(func pid=38679)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 94] | Train loss: 0.5936 | Steps: 2 | Val loss: 1.9259 | Batch size: 32 | lr: 0.0001 | Duration: 2.78s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 94] | Train loss: 1.1789 | Steps: 2 | Val loss: 8.8711 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=38679)[0m [N0-GPU0] | [Epoch: 99] | Train loss: 0.1368 | Steps: 2 | Val loss: 6.4223 | Batch size: 32 | lr: 0.001 | Duration: 2.66s
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 2.4774 | Steps: 2 | Val loss: 2.2980 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=38305)[0m top1: 0.3670708955223881
[2m[36m(func pid=38305)[0m top5: 0.894589552238806
[2m[36m(func pid=38305)[0m f1_micro: 0.3670708955223881
[2m[36m(func pid=38305)[0m f1_macro: 0.31816936221640213
[2m[36m(func pid=38305)[0m f1_weighted: 0.4013192921896371
[2m[36m(func pid=38305)[0m f1_per_class: [0.152, 0.599, 0.232, 0.396, 0.082, 0.319, 0.364, 0.48, 0.146, 0.41]
[2m[36m(func pid=38305)[0m 
== Status ==
Current time: 2024-01-07 02:33:16 (running for 00:09:17.25)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=1
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (19 PENDING, 4 RUNNING, 1 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING    | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.594 |      0.318 |                   95 |
| train_6ed81_00001 | RUNNING    | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.136 |      0.315 |                   99 |
| train_6ed81_00002 | RUNNING    | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  1.179 |      0.198 |                   95 |
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.489 |      0.109 |                   20 |
| train_6ed81_00005 | PENDING    |                    | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=39098)[0m top1: 0.24207089552238806
[2m[36m(func pid=39098)[0m top5: 0.8638059701492538
[2m[36m(func pid=39098)[0m f1_micro: 0.24207089552238806
[2m[36m(func pid=39098)[0m f1_macro: 0.1983335815176751
[2m[36m(func pid=39098)[0m f1_weighted: 0.2864222767963391
[2m[36m(func pid=39098)[0m f1_per_class: [0.099, 0.213, 0.214, 0.353, 0.122, 0.312, 0.343, 0.062, 0.105, 0.16]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=38679)[0m top1: 0.34794776119402987
[2m[36m(func pid=38679)[0m top5: 0.8414179104477612
[2m[36m(func pid=38679)[0m f1_micro: 0.34794776119402987
[2m[36m(func pid=38679)[0m f1_macro: 0.29163304996730877
[2m[36m(func pid=38679)[0m f1_weighted: 0.39056083550542336
[2m[36m(func pid=38679)[0m f1_per_class: [0.106, 0.467, 0.23, 0.414, 0.106, 0.09, 0.487, 0.444, 0.12, 0.453]
[2m[36m(func pid=55782)[0m top1: 0.16791044776119404
[2m[36m(func pid=55782)[0m top5: 0.6086753731343284
[2m[36m(func pid=55782)[0m f1_micro: 0.16791044776119404
[2m[36m(func pid=55782)[0m f1_macro: 0.10955677085152304
[2m[36m(func pid=55782)[0m f1_weighted: 0.13178020435284846
[2m[36m(func pid=55782)[0m f1_per_class: [0.027, 0.145, 0.064, 0.275, 0.0, 0.0, 0.0, 0.488, 0.0, 0.098]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 95] | Train loss: 0.6834 | Steps: 2 | Val loss: 1.9022 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 95] | Train loss: 0.6144 | Steps: 2 | Val loss: 9.9321 | Batch size: 32 | lr: 0.01 | Duration: 3.03s
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 2.4843 | Steps: 2 | Val loss: 2.2971 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=38305)[0m top1: 0.3689365671641791
[2m[36m(func pid=38305)[0m top5: 0.8992537313432836
[2m[36m(func pid=38305)[0m f1_micro: 0.3689365671641791
[2m[36m(func pid=38305)[0m f1_macro: 0.31984557039568634
[2m[36m(func pid=38305)[0m f1_weighted: 0.4040368968773447
[2m[36m(func pid=38305)[0m f1_per_class: [0.158, 0.589, 0.229, 0.398, 0.086, 0.331, 0.372, 0.488, 0.142, 0.405]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=39098)[0m top1: 0.24067164179104478
[2m[36m(func pid=39098)[0m top5: 0.8558768656716418
[2m[36m(func pid=39098)[0m f1_micro: 0.24067164179104478
[2m[36m(func pid=39098)[0m f1_macro: 0.18179869650710573
[2m[36m(func pid=39098)[0m f1_weighted: 0.28001205046607563
[2m[36m(func pid=39098)[0m f1_per_class: [0.081, 0.195, 0.159, 0.262, 0.118, 0.261, 0.441, 0.061, 0.107, 0.133]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=55782)[0m top1: 0.16744402985074627
[2m[36m(func pid=55782)[0m top5: 0.6119402985074627
[2m[36m(func pid=55782)[0m f1_micro: 0.16744402985074627
[2m[36m(func pid=55782)[0m f1_macro: 0.11169116393913245
[2m[36m(func pid=55782)[0m f1_weighted: 0.13651575916148936
[2m[36m(func pid=55782)[0m f1_per_class: [0.028, 0.188, 0.065, 0.271, 0.0, 0.0, 0.0, 0.456, 0.0, 0.109]
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 96] | Train loss: 0.5274 | Steps: 2 | Val loss: 1.8828 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 96] | Train loss: 0.4794 | Steps: 2 | Val loss: 12.1483 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
[2m[36m(func pid=38305)[0m top1: 0.3829291044776119
[2m[36m(func pid=38305)[0m top5: 0.9034514925373134
[2m[36m(func pid=38305)[0m f1_micro: 0.3829291044776119
[2m[36m(func pid=38305)[0m f1_macro: 0.3342054828563338
[2m[36m(func pid=38305)[0m f1_weighted: 0.4192533532680061
[2m[36m(func pid=38305)[0m f1_per_class: [0.164, 0.59, 0.227, 0.41, 0.093, 0.343, 0.392, 0.556, 0.146, 0.421]
== Status ==
Current time: 2024-01-07 02:33:21 (running for 00:09:22.73)
Memory usage on this node: 22.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (18 PENDING, 4 RUNNING, 2 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING    | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.683 |      0.32  |                   96 |
| train_6ed81_00002 | RUNNING    | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.614 |      0.182 |                   96 |
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.477 |      0.11  |                   21 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=60934)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=60934)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=60934)[0m Configuration completed!
[2m[36m(func pid=60934)[0m New optimizer parameters:
[2m[36m(func pid=60934)[0m SGD (
[2m[36m(func pid=60934)[0m Parameter Group 0
[2m[36m(func pid=60934)[0m     dampening: 0
[2m[36m(func pid=60934)[0m     differentiable: False
[2m[36m(func pid=60934)[0m     foreach: None
[2m[36m(func pid=60934)[0m     lr: 0.001
[2m[36m(func pid=60934)[0m     maximize: False
[2m[36m(func pid=60934)[0m     momentum: 0.9
[2m[36m(func pid=60934)[0m     nesterov: False
[2m[36m(func pid=60934)[0m     weight_decay: 0
[2m[36m(func pid=60934)[0m )
[2m[36m(func pid=60934)[0m 
== Status ==
Current time: 2024-01-07 02:33:27 (running for 00:09:28.01)
Memory usage on this node: 24.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (18 PENDING, 4 RUNNING, 2 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING    | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.527 |      0.334 |                   97 |
| train_6ed81_00002 | RUNNING    | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.479 |      0.168 |                   97 |
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.484 |      0.112 |                   22 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=39098)[0m top1: 0.22154850746268656
[2m[36m(func pid=39098)[0m top5: 0.8339552238805971
[2m[36m(func pid=39098)[0m f1_micro: 0.22154850746268656
[2m[36m(func pid=39098)[0m f1_macro: 0.16805457861871775
[2m[36m(func pid=39098)[0m f1_weighted: 0.2549497684729843
[2m[36m(func pid=39098)[0m f1_per_class: [0.077, 0.235, 0.119, 0.165, 0.136, 0.194, 0.445, 0.106, 0.085, 0.118]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 2.4581 | Steps: 2 | Val loss: 2.2936 | Batch size: 32 | lr: 0.0001 | Duration: 2.76s
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 97] | Train loss: 0.5266 | Steps: 2 | Val loss: 1.8543 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 97] | Train loss: 0.2452 | Steps: 2 | Val loss: 14.0845 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 3.0933 | Steps: 2 | Val loss: 2.3732 | Batch size: 32 | lr: 0.001 | Duration: 4.88s
[2m[36m(func pid=55782)[0m top1: 0.1646455223880597
[2m[36m(func pid=55782)[0m top5: 0.6180037313432836
[2m[36m(func pid=55782)[0m f1_micro: 0.1646455223880597
[2m[36m(func pid=55782)[0m f1_macro: 0.11165074444702716
[2m[36m(func pid=55782)[0m f1_weighted: 0.13687514761390318
[2m[36m(func pid=55782)[0m f1_per_class: [0.024, 0.19, 0.07, 0.262, 0.0, 0.016, 0.0, 0.474, 0.0, 0.08]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=38305)[0m top1: 0.39225746268656714
[2m[36m(func pid=38305)[0m top5: 0.9053171641791045
[2m[36m(func pid=38305)[0m f1_micro: 0.39225746268656714
[2m[36m(func pid=38305)[0m f1_macro: 0.3417035323236267
[2m[36m(func pid=38305)[0m f1_weighted: 0.4276191021127818
[2m[36m(func pid=38305)[0m f1_per_class: [0.168, 0.594, 0.224, 0.412, 0.104, 0.308, 0.416, 0.614, 0.152, 0.424]
[2m[36m(func pid=38305)[0m 
== Status ==
Current time: 2024-01-07 02:33:32 (running for 00:09:33.28)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (18 PENDING, 4 RUNNING, 2 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING    | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.527 |      0.342 |                   98 |
| train_6ed81_00002 | RUNNING    | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.245 |      0.146 |                   98 |
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.458 |      0.112 |                   23 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |        |            |                      |
| train_6ed81_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=39098)[0m top1: 0.197294776119403
[2m[36m(func pid=39098)[0m top5: 0.8073694029850746
[2m[36m(func pid=39098)[0m f1_micro: 0.197294776119403
[2m[36m(func pid=39098)[0m f1_macro: 0.14604857550786027
[2m[36m(func pid=39098)[0m f1_weighted: 0.2256913451214686
[2m[36m(func pid=39098)[0m f1_per_class: [0.082, 0.28, 0.096, 0.117, 0.141, 0.142, 0.404, 0.016, 0.082, 0.1]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=60934)[0m top1: 0.07276119402985075
[2m[36m(func pid=60934)[0m top5: 0.32882462686567165
[2m[36m(func pid=60934)[0m f1_micro: 0.07276119402985075
[2m[36m(func pid=60934)[0m f1_macro: 0.020780157484400742
[2m[36m(func pid=60934)[0m f1_weighted: 0.03004290171078268
[2m[36m(func pid=60934)[0m f1_per_class: [0.0, 0.0, 0.0, 0.082, 0.0, 0.0, 0.0, 0.126, 0.0, 0.0]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 2.4196 | Steps: 2 | Val loss: 2.2893 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 98] | Train loss: 0.4964 | Steps: 2 | Val loss: 1.8412 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 98] | Train loss: 0.2450 | Steps: 2 | Val loss: 15.6434 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 2.9591 | Steps: 2 | Val loss: 2.3283 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=38305)[0m top1: 0.39598880597014924
[2m[36m(func pid=38305)[0m top5: 0.9090485074626866
[2m[36m(func pid=38305)[0m f1_micro: 0.39598880597014924
[2m[36m(func pid=38305)[0m f1_macro: 0.3440316892274484
[2m[36m(func pid=38305)[0m f1_weighted: 0.4256971510502743
[2m[36m(func pid=38305)[0m f1_per_class: [0.168, 0.594, 0.229, 0.424, 0.116, 0.299, 0.406, 0.58, 0.164, 0.459]
[2m[36m(func pid=38305)[0m 
[2m[36m(func pid=55782)[0m top1: 0.16977611940298507
[2m[36m(func pid=55782)[0m top5: 0.6226679104477612
[2m[36m(func pid=55782)[0m f1_micro: 0.16977611940298507
[2m[36m(func pid=55782)[0m f1_macro: 0.11690430505612073
[2m[36m(func pid=55782)[0m f1_weighted: 0.14178386430450196
[2m[36m(func pid=55782)[0m f1_per_class: [0.027, 0.208, 0.075, 0.269, 0.0, 0.016, 0.0, 0.463, 0.0, 0.111]
[2m[36m(func pid=55782)[0m 
== Status ==
Current time: 2024-01-07 02:33:38 (running for 00:09:38.89)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (18 PENDING, 4 RUNNING, 2 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | RUNNING    | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.496 |      0.344 |                   99 |
| train_6ed81_00002 | RUNNING    | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.245 |      0.143 |                   99 |
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.42  |      0.117 |                   24 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  3.093 |      0.021 |                    1 |
| train_6ed81_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=39098)[0m top1: 0.1767723880597015
[2m[36m(func pid=39098)[0m top5: 0.7667910447761194
[2m[36m(func pid=39098)[0m f1_micro: 0.1767723880597015
[2m[36m(func pid=39098)[0m f1_macro: 0.14349258410556998
[2m[36m(func pid=39098)[0m f1_weighted: 0.19618553623028887
[2m[36m(func pid=39098)[0m f1_per_class: [0.094, 0.311, 0.083, 0.048, 0.161, 0.143, 0.343, 0.047, 0.089, 0.116]
[2m[36m(func pid=39098)[0m 
[2m[36m(func pid=60934)[0m top1: 0.09421641791044776
[2m[36m(func pid=60934)[0m top5: 0.5130597014925373
[2m[36m(func pid=60934)[0m f1_micro: 0.09421641791044776
[2m[36m(func pid=60934)[0m f1_macro: 0.06551183248210701
[2m[36m(func pid=60934)[0m f1_weighted: 0.07734639124510674
[2m[36m(func pid=60934)[0m f1_per_class: [0.0, 0.0, 0.022, 0.184, 0.0, 0.0, 0.0, 0.45, 0.0, 0.0]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=38305)[0m [N0-GPU0] | [Epoch: 99] | Train loss: 0.6661 | Steps: 2 | Val loss: 1.8638 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 2.4204 | Steps: 2 | Val loss: 2.2879 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=39098)[0m [N0-GPU0] | [Epoch: 99] | Train loss: 0.5161 | Steps: 2 | Val loss: 15.7742 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 2.7494 | Steps: 2 | Val loss: 2.3134 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
[2m[36m(func pid=38305)[0m top1: 0.3871268656716418
[2m[36m(func pid=38305)[0m top5: 0.9085820895522388
[2m[36m(func pid=38305)[0m f1_micro: 0.3871268656716418
[2m[36m(func pid=38305)[0m f1_macro: 0.33401122711407527
[2m[36m(func pid=38305)[0m f1_weighted: 0.41433453237396206
[2m[36m(func pid=38305)[0m f1_per_class: [0.163, 0.587, 0.222, 0.421, 0.12, 0.275, 0.39, 0.554, 0.157, 0.452]
[2m[36m(func pid=55782)[0m top1: 0.17257462686567165
[2m[36m(func pid=55782)[0m top5: 0.6282649253731343
[2m[36m(func pid=55782)[0m f1_micro: 0.17257462686567165
[2m[36m(func pid=55782)[0m f1_macro: 0.11770078403487325
[2m[36m(func pid=55782)[0m f1_weighted: 0.14563242475676152
[2m[36m(func pid=55782)[0m f1_per_class: [0.029, 0.219, 0.076, 0.277, 0.0, 0.024, 0.0, 0.446, 0.0, 0.107]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=39098)[0m top1: 0.18003731343283583
[2m[36m(func pid=39098)[0m top5: 0.7476679104477612
[2m[36m(func pid=39098)[0m f1_micro: 0.1800373134328358
[2m[36m(func pid=39098)[0m f1_macro: 0.1595100168906259
[2m[36m(func pid=39098)[0m f1_weighted: 0.19629857833302236
[2m[36m(func pid=39098)[0m f1_per_class: [0.124, 0.357, 0.1, 0.038, 0.178, 0.166, 0.297, 0.135, 0.088, 0.111]
[2m[36m(func pid=60934)[0m top1: 0.018656716417910446
[2m[36m(func pid=60934)[0m top5: 0.5895522388059702
[2m[36m(func pid=60934)[0m f1_micro: 0.018656716417910446
[2m[36m(func pid=60934)[0m f1_macro: 0.018375739430376403
[2m[36m(func pid=60934)[0m f1_weighted: 0.02109374449873377
[2m[36m(func pid=60934)[0m f1_per_class: [0.0, 0.0, 0.013, 0.05, 0.0, 0.0, 0.0, 0.12, 0.0, 0.0]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 2.3802 | Steps: 2 | Val loss: 2.2835 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 2.5854 | Steps: 2 | Val loss: 2.3073 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=55782)[0m top1: 0.1767723880597015
[2m[36m(func pid=55782)[0m top5: 0.6333955223880597
[2m[36m(func pid=55782)[0m f1_micro: 0.1767723880597015
[2m[36m(func pid=55782)[0m f1_macro: 0.12044315149437497
[2m[36m(func pid=55782)[0m f1_weighted: 0.1518551357480042
[2m[36m(func pid=55782)[0m f1_per_class: [0.028, 0.226, 0.08, 0.286, 0.0, 0.047, 0.0, 0.446, 0.0, 0.092]
[2m[36m(func pid=60934)[0m top1: 0.015391791044776119
[2m[36m(func pid=60934)[0m top5: 0.6100746268656716
[2m[36m(func pid=60934)[0m f1_micro: 0.015391791044776119
[2m[36m(func pid=60934)[0m f1_macro: 0.0073948208982173875
[2m[36m(func pid=60934)[0m f1_weighted: 0.016011636335064295
[2m[36m(func pid=60934)[0m f1_per_class: [0.0, 0.011, 0.013, 0.051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
== Status ==
Current time: 2024-01-07 02:33:43 (running for 00:09:43.98)
Memory usage on this node: 22.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (17 PENDING, 4 RUNNING, 3 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00002 | RUNNING    | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.245 |      0.143 |                   99 |
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.42  |      0.118 |                   25 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  2.749 |      0.018 |                    3 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=62121)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=62121)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=62121)[0m Configuration completed!
[2m[36m(func pid=62121)[0m New optimizer parameters:
[2m[36m(func pid=62121)[0m SGD (
[2m[36m(func pid=62121)[0m Parameter Group 0
[2m[36m(func pid=62121)[0m     dampening: 0
[2m[36m(func pid=62121)[0m     differentiable: False
[2m[36m(func pid=62121)[0m     foreach: None
[2m[36m(func pid=62121)[0m     lr: 0.01
[2m[36m(func pid=62121)[0m     maximize: False
[2m[36m(func pid=62121)[0m     momentum: 0.9
[2m[36m(func pid=62121)[0m     nesterov: False
[2m[36m(func pid=62121)[0m     weight_decay: 0
[2m[36m(func pid=62121)[0m )
[2m[36m(func pid=62121)[0m 
== Status ==
Current time: 2024-01-07 02:33:50 (running for 00:09:50.91)
Memory usage on this node: 23.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (17 PENDING, 4 RUNNING, 3 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00002 | RUNNING    | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.245 |      0.143 |                   99 |
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.38  |      0.12  |                   26 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  2.749 |      0.018 |                    3 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 2.5902 | Steps: 2 | Val loss: 2.3016 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 2.3579 | Steps: 2 | Val loss: 2.2809 | Batch size: 32 | lr: 0.0001 | Duration: 3.04s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 3.0994 | Steps: 2 | Val loss: 2.6005 | Batch size: 32 | lr: 0.01 | Duration: 4.78s
[2m[36m(func pid=60934)[0m top1: 0.032182835820895525
[2m[36m(func pid=60934)[0m top5: 0.617070895522388
[2m[36m(func pid=60934)[0m f1_micro: 0.032182835820895525
[2m[36m(func pid=60934)[0m f1_macro: 0.019646729158893306
[2m[36m(func pid=60934)[0m f1_weighted: 0.03905599805281996
[2m[36m(func pid=60934)[0m f1_per_class: [0.0, 0.111, 0.014, 0.071, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=55782)[0m top1: 0.17537313432835822
[2m[36m(func pid=55782)[0m top5: 0.6357276119402985
[2m[36m(func pid=55782)[0m f1_micro: 0.17537313432835822
[2m[36m(func pid=55782)[0m f1_macro: 0.12456393524073565
[2m[36m(func pid=55782)[0m f1_weighted: 0.1530998892869355
[2m[36m(func pid=55782)[0m f1_per_class: [0.03, 0.219, 0.084, 0.277, 0.0, 0.082, 0.0, 0.462, 0.0, 0.092]
[2m[36m(func pid=62121)[0m top1: 0.006063432835820896
[2m[36m(func pid=62121)[0m top5: 0.53125
[2m[36m(func pid=62121)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=62121)[0m f1_macro: 0.0012115563839701772
[2m[36m(func pid=62121)[0m f1_weighted: 7.346190761013201e-05
[2m[36m(func pid=62121)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 2.4980 | Steps: 2 | Val loss: 2.2815 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
== Status ==
Current time: 2024-01-07 02:33:55 (running for 00:09:56.20)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.38  |      0.12  |                   26 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  2.59  |      0.02  |                    5 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |        |            |                      |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=62614)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=62614)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=62614)[0m Configuration completed!
[2m[36m(func pid=62614)[0m New optimizer parameters:
[2m[36m(func pid=62614)[0m SGD (
[2m[36m(func pid=62614)[0m Parameter Group 0
[2m[36m(func pid=62614)[0m     dampening: 0
[2m[36m(func pid=62614)[0m     differentiable: False
[2m[36m(func pid=62614)[0m     foreach: None
[2m[36m(func pid=62614)[0m     lr: 0.1
[2m[36m(func pid=62614)[0m     maximize: False
[2m[36m(func pid=62614)[0m     momentum: 0.9
[2m[36m(func pid=62614)[0m     nesterov: False
[2m[36m(func pid=62614)[0m     weight_decay: 0
[2m[36m(func pid=62614)[0m )
[2m[36m(func pid=62614)[0m 
== Status ==
Current time: 2024-01-07 02:34:00 (running for 00:10:01.51)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.358 |      0.125 |                   27 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  2.498 |      0.049 |                    6 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  3.099 |      0.001 |                    1 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |        |            |                      |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.11287313432835822
[2m[36m(func pid=60934)[0m top5: 0.6091417910447762
[2m[36m(func pid=60934)[0m f1_micro: 0.11287313432835822
[2m[36m(func pid=60934)[0m f1_macro: 0.04891875950043595
[2m[36m(func pid=60934)[0m f1_weighted: 0.07108503503378283
[2m[36m(func pid=60934)[0m f1_per_class: [0.039, 0.301, 0.027, 0.043, 0.0, 0.032, 0.0, 0.047, 0.0, 0.0]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 2.4067 | Steps: 2 | Val loss: 2.2790 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 2.6469 | Steps: 2 | Val loss: 2.9255 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 3.5157 | Steps: 2 | Val loss: 154.9846 | Batch size: 32 | lr: 0.1 | Duration: 4.50s
[2m[36m(func pid=55782)[0m top1: 0.17723880597014927
[2m[36m(func pid=55782)[0m top5: 0.6371268656716418
[2m[36m(func pid=55782)[0m f1_micro: 0.17723880597014927
[2m[36m(func pid=55782)[0m f1_macro: 0.13104842695808322
[2m[36m(func pid=55782)[0m f1_weighted: 0.15723743843900934
[2m[36m(func pid=55782)[0m f1_per_class: [0.035, 0.215, 0.088, 0.28, 0.051, 0.121, 0.0, 0.448, 0.0, 0.072]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 2.4026 | Steps: 2 | Val loss: 2.2543 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=62121)[0m top1: 0.025652985074626867
[2m[36m(func pid=62121)[0m top5: 0.7574626865671642
[2m[36m(func pid=62121)[0m f1_micro: 0.025652985074626867
[2m[36m(func pid=62121)[0m f1_macro: 0.020873528275668327
[2m[36m(func pid=62121)[0m f1_weighted: 0.02552841767541961
[2m[36m(func pid=62121)[0m f1_per_class: [0.014, 0.145, 0.049, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=62614)[0m top1: 0.006063432835820896
[2m[36m(func pid=62614)[0m top5: 0.4146455223880597
[2m[36m(func pid=62614)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=62614)[0m f1_macro: 0.001205377839592026
[2m[36m(func pid=62614)[0m f1_weighted: 7.308727572153144e-05
[2m[36m(func pid=62614)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=62614)[0m 
== Status ==
Current time: 2024-01-07 02:34:06 (running for 00:10:06.85)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.407 |      0.131 |                   28 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  2.403 |      0.077 |                    7 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  2.647 |      0.021 |                    2 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  3.516 |      0.001 |                    1 |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.15438432835820895
[2m[36m(func pid=60934)[0m top5: 0.6716417910447762
[2m[36m(func pid=60934)[0m f1_micro: 0.15438432835820895
[2m[36m(func pid=60934)[0m f1_macro: 0.07664484494133428
[2m[36m(func pid=60934)[0m f1_weighted: 0.091621983671545
[2m[36m(func pid=60934)[0m f1_per_class: [0.049, 0.311, 0.096, 0.013, 0.0, 0.19, 0.025, 0.062, 0.0, 0.019]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 2.3846 | Steps: 2 | Val loss: 2.2761 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 2.4184 | Steps: 2 | Val loss: 3.3439 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 6.5190 | Steps: 2 | Val loss: 7987.1538 | Batch size: 32 | lr: 0.1 | Duration: 2.78s
[2m[36m(func pid=55782)[0m top1: 0.18330223880597016
[2m[36m(func pid=55782)[0m top5: 0.6408582089552238
[2m[36m(func pid=55782)[0m f1_micro: 0.18330223880597016
[2m[36m(func pid=55782)[0m f1_macro: 0.13525017294263428
[2m[36m(func pid=55782)[0m f1_weighted: 0.16589372901765062
[2m[36m(func pid=55782)[0m f1_per_class: [0.04, 0.221, 0.094, 0.293, 0.049, 0.165, 0.0, 0.43, 0.0, 0.061]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 2.3400 | Steps: 2 | Val loss: 2.2245 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=62121)[0m top1: 0.09654850746268656
[2m[36m(func pid=62121)[0m top5: 0.7490671641791045
[2m[36m(func pid=62121)[0m f1_micro: 0.09654850746268658
[2m[36m(func pid=62121)[0m f1_macro: 0.04617701558780562
[2m[36m(func pid=62121)[0m f1_weighted: 0.07451664208307264
[2m[36m(func pid=62121)[0m f1_per_class: [0.01, 0.426, 0.018, 0.0, 0.0, 0.008, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=62614)[0m top1: 0.2789179104477612
[2m[36m(func pid=62614)[0m top5: 0.7821828358208955
[2m[36m(func pid=62614)[0m f1_micro: 0.2789179104477612
[2m[36m(func pid=62614)[0m f1_macro: 0.04361779722830051
[2m[36m(func pid=62614)[0m f1_weighted: 0.12165784861251727
[2m[36m(func pid=62614)[0m f1_per_class: [0.0, 0.0, 0.0, 0.436, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=62614)[0m 
== Status ==
Current time: 2024-01-07 02:34:11 (running for 00:10:12.08)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.385 |      0.135 |                   29 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  2.34  |      0.117 |                    8 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  2.418 |      0.046 |                    3 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  6.519 |      0.044 |                    2 |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.1921641791044776
[2m[36m(func pid=60934)[0m top5: 0.7425373134328358
[2m[36m(func pid=60934)[0m f1_micro: 0.1921641791044776
[2m[36m(func pid=60934)[0m f1_macro: 0.11719722593982981
[2m[36m(func pid=60934)[0m f1_weighted: 0.12827220595424987
[2m[36m(func pid=60934)[0m f1_per_class: [0.083, 0.352, 0.244, 0.007, 0.0, 0.363, 0.066, 0.0, 0.039, 0.018]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 2.4509 | Steps: 2 | Val loss: 2.2742 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 2.3198 | Steps: 2 | Val loss: 4.0150 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 9.2524 | Steps: 2 | Val loss: 81247.3281 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=55782)[0m top1: 0.1828358208955224
[2m[36m(func pid=55782)[0m top5: 0.648320895522388
[2m[36m(func pid=55782)[0m f1_micro: 0.1828358208955224
[2m[36m(func pid=55782)[0m f1_macro: 0.13525273606195282
[2m[36m(func pid=55782)[0m f1_weighted: 0.16958243670234005
[2m[36m(func pid=55782)[0m f1_per_class: [0.045, 0.21, 0.098, 0.297, 0.042, 0.215, 0.0, 0.408, 0.0, 0.037]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 2.2426 | Steps: 2 | Val loss: 2.1929 | Batch size: 32 | lr: 0.001 | Duration: 2.73s
[2m[36m(func pid=62121)[0m top1: 0.09654850746268656
[2m[36m(func pid=62121)[0m top5: 0.5951492537313433
[2m[36m(func pid=62121)[0m f1_micro: 0.09654850746268658
[2m[36m(func pid=62121)[0m f1_macro: 0.06515090781141959
[2m[36m(func pid=62121)[0m f1_weighted: 0.08122579257502069
[2m[36m(func pid=62121)[0m f1_per_class: [0.0, 0.428, 0.016, 0.0, 0.167, 0.032, 0.009, 0.0, 0.0, 0.0]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=62614)[0m top1: 0.006063432835820896
[2m[36m(func pid=62614)[0m top5: 0.5093283582089553
[2m[36m(func pid=62614)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=62614)[0m f1_macro: 0.001205377839592026
[2m[36m(func pid=62614)[0m f1_weighted: 7.308727572153144e-05
[2m[36m(func pid=62614)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=60934)[0m top1: 0.22807835820895522
[2m[36m(func pid=60934)[0m top5: 0.792910447761194
[2m[36m(func pid=60934)[0m f1_micro: 0.22807835820895522
[2m[36m(func pid=60934)[0m f1_macro: 0.1780365104322138
[2m[36m(func pid=60934)[0m f1_weighted: 0.17209917906070482
[2m[36m(func pid=60934)[0m f1_per_class: [0.101, 0.386, 0.324, 0.0, 0.0, 0.455, 0.096, 0.325, 0.047, 0.046]
== Status ==
Current time: 2024-01-07 02:34:16 (running for 00:10:17.31)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.451 |      0.135 |                   30 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  2.243 |      0.178 |                    9 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  2.32  |      0.065 |                    4 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  9.252 |      0.001 |                    3 |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 2.3114 | Steps: 2 | Val loss: 2.2689 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 2.5021 | Steps: 2 | Val loss: 3.5858 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 8.4476 | Steps: 2 | Val loss: 17518.3223 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
[2m[36m(func pid=55782)[0m top1: 0.18610074626865672
[2m[36m(func pid=55782)[0m top5: 0.6557835820895522
[2m[36m(func pid=55782)[0m f1_micro: 0.1861007462686567
[2m[36m(func pid=55782)[0m f1_macro: 0.14110966628294383
[2m[36m(func pid=55782)[0m f1_weighted: 0.1739163863970612
[2m[36m(func pid=55782)[0m f1_per_class: [0.043, 0.22, 0.11, 0.292, 0.033, 0.245, 0.0, 0.418, 0.0, 0.05]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 2.2476 | Steps: 2 | Val loss: 2.1639 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=62121)[0m top1: 0.07929104477611941
[2m[36m(func pid=62121)[0m top5: 0.5666977611940298
[2m[36m(func pid=62121)[0m f1_micro: 0.07929104477611941
[2m[36m(func pid=62121)[0m f1_macro: 0.07353237593956775
[2m[36m(func pid=62121)[0m f1_weighted: 0.07216218864623059
[2m[36m(func pid=62121)[0m f1_per_class: [0.0, 0.389, 0.022, 0.0, 0.161, 0.008, 0.0, 0.006, 0.042, 0.108]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=62614)[0m top1: 0.006063432835820896
[2m[36m(func pid=62614)[0m top5: 0.5088619402985075
[2m[36m(func pid=62614)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=62614)[0m f1_macro: 0.001205377839592026
[2m[36m(func pid=62614)[0m f1_weighted: 7.308727572153144e-05
[2m[36m(func pid=62614)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=62614)[0m 
== Status ==
Current time: 2024-01-07 02:34:21 (running for 00:10:22.52)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.311 |      0.141 |                   31 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  2.248 |      0.209 |                   10 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  2.502 |      0.074 |                    5 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  8.448 |      0.001 |                    4 |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.24766791044776118
[2m[36m(func pid=60934)[0m top5: 0.8106343283582089
[2m[36m(func pid=60934)[0m f1_micro: 0.24766791044776118
[2m[36m(func pid=60934)[0m f1_macro: 0.20918889438505298
[2m[36m(func pid=60934)[0m f1_weighted: 0.1838096666715261
[2m[36m(func pid=60934)[0m f1_per_class: [0.132, 0.388, 0.414, 0.0, 0.0, 0.448, 0.096, 0.514, 0.048, 0.051]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 2.3758 | Steps: 2 | Val loss: 2.2678 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 1.8990 | Steps: 2 | Val loss: 4.3998 | Batch size: 32 | lr: 0.01 | Duration: 2.75s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 3.5126 | Steps: 2 | Val loss: 1839.6664 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 2.1473 | Steps: 2 | Val loss: 2.1364 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
[2m[36m(func pid=55782)[0m top1: 0.18330223880597016
[2m[36m(func pid=55782)[0m top5: 0.6646455223880597
[2m[36m(func pid=55782)[0m f1_micro: 0.18330223880597016
[2m[36m(func pid=55782)[0m f1_macro: 0.15292839184725568
[2m[36m(func pid=55782)[0m f1_weighted: 0.1734496050153914
[2m[36m(func pid=55782)[0m f1_per_class: [0.04, 0.216, 0.115, 0.273, 0.046, 0.275, 0.0, 0.439, 0.0, 0.125]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=62121)[0m top1: 0.03311567164179104
[2m[36m(func pid=62121)[0m top5: 0.6012126865671642
[2m[36m(func pid=62121)[0m f1_micro: 0.03311567164179104
[2m[36m(func pid=62121)[0m f1_macro: 0.052081875670472164
[2m[36m(func pid=62121)[0m f1_weighted: 0.03551578431060087
[2m[36m(func pid=62121)[0m f1_per_class: [0.008, 0.058, 0.022, 0.069, 0.185, 0.008, 0.0, 0.013, 0.059, 0.1]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=62614)[0m top1: 0.020522388059701493
[2m[36m(func pid=62614)[0m top5: 0.5158582089552238
[2m[36m(func pid=62614)[0m f1_micro: 0.020522388059701493
[2m[36m(func pid=62614)[0m f1_macro: 0.0040219378427787935
[2m[36m(func pid=62614)[0m f1_weighted: 0.000825397691615051
[2m[36m(func pid=62614)[0m f1_per_class: [0.04, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=62614)[0m 
== Status ==
Current time: 2024-01-07 02:34:26 (running for 00:10:27.61)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.376 |      0.153 |                   32 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  2.147 |      0.228 |                   11 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  1.899 |      0.052 |                    6 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  3.513 |      0.004 |                    5 |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.2677238805970149
[2m[36m(func pid=60934)[0m top5: 0.8222947761194029
[2m[36m(func pid=60934)[0m f1_micro: 0.2677238805970149
[2m[36m(func pid=60934)[0m f1_macro: 0.22841202477495734
[2m[36m(func pid=60934)[0m f1_weighted: 0.19741697441462966
[2m[36m(func pid=60934)[0m f1_per_class: [0.168, 0.395, 0.387, 0.0, 0.101, 0.421, 0.14, 0.516, 0.064, 0.092]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 2.3662 | Steps: 2 | Val loss: 2.2653 | Batch size: 32 | lr: 0.0001 | Duration: 3.12s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 1.7167 | Steps: 2 | Val loss: 3.9679 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 3.1502 | Steps: 2 | Val loss: 285.8703 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 2.0881 | Steps: 2 | Val loss: 2.1065 | Batch size: 32 | lr: 0.001 | Duration: 2.70s
[2m[36m(func pid=55782)[0m top1: 0.1837686567164179
[2m[36m(func pid=55782)[0m top5: 0.6823694029850746
[2m[36m(func pid=55782)[0m f1_micro: 0.18376865671641787
[2m[36m(func pid=55782)[0m f1_macro: 0.16305157393047806
[2m[36m(func pid=55782)[0m f1_weighted: 0.17610100223530967
[2m[36m(func pid=55782)[0m f1_per_class: [0.041, 0.212, 0.126, 0.266, 0.055, 0.3, 0.003, 0.451, 0.0, 0.176]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=62121)[0m top1: 0.05223880597014925
[2m[36m(func pid=62121)[0m top5: 0.65625
[2m[36m(func pid=62121)[0m f1_micro: 0.05223880597014925
[2m[36m(func pid=62121)[0m f1_macro: 0.05947378540377796
[2m[36m(func pid=62121)[0m f1_weighted: 0.05759765867609468
[2m[36m(func pid=62121)[0m f1_per_class: [0.038, 0.187, 0.033, 0.067, 0.069, 0.0, 0.0, 0.024, 0.083, 0.093]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=62614)[0m top1: 0.006063432835820896
[2m[36m(func pid=62614)[0m top5: 0.4300373134328358
[2m[36m(func pid=62614)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=62614)[0m f1_macro: 0.0012138188608776842
[2m[36m(func pid=62614)[0m f1_weighted: 7.359909137784467e-05
[2m[36m(func pid=62614)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=62614)[0m 
== Status ==
Current time: 2024-01-07 02:34:31 (running for 00:10:32.72)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.366 |      0.163 |                   33 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  2.088 |      0.236 |                   12 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  1.717 |      0.059 |                    7 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  3.15  |      0.001 |                    6 |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.2621268656716418
[2m[36m(func pid=60934)[0m top5: 0.8250932835820896
[2m[36m(func pid=60934)[0m f1_micro: 0.2621268656716418
[2m[36m(func pid=60934)[0m f1_macro: 0.23560603794325846
[2m[36m(func pid=60934)[0m f1_weighted: 0.20136692841219225
[2m[36m(func pid=60934)[0m f1_per_class: [0.175, 0.369, 0.419, 0.0, 0.103, 0.423, 0.162, 0.526, 0.088, 0.091]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 2.3541 | Steps: 2 | Val loss: 2.2629 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 1.6789 | Steps: 2 | Val loss: 2.9379 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 2.0813 | Steps: 2 | Val loss: 2.0897 | Batch size: 32 | lr: 0.001 | Duration: 2.72s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 2.9679 | Steps: 2 | Val loss: 19955.0977 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=55782)[0m top1: 0.18003731343283583
[2m[36m(func pid=55782)[0m top5: 0.6935634328358209
[2m[36m(func pid=55782)[0m f1_micro: 0.1800373134328358
[2m[36m(func pid=55782)[0m f1_macro: 0.16389407509516024
[2m[36m(func pid=55782)[0m f1_weighted: 0.17173419567555762
[2m[36m(func pid=55782)[0m f1_per_class: [0.04, 0.202, 0.133, 0.263, 0.079, 0.283, 0.003, 0.449, 0.0, 0.188]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=62121)[0m top1: 0.12546641791044777
[2m[36m(func pid=62121)[0m top5: 0.7182835820895522
[2m[36m(func pid=62121)[0m f1_micro: 0.12546641791044777
[2m[36m(func pid=62121)[0m f1_macro: 0.11245763168145975
[2m[36m(func pid=62121)[0m f1_weighted: 0.12616917158678764
[2m[36m(func pid=62121)[0m f1_per_class: [0.043, 0.471, 0.071, 0.114, 0.174, 0.0, 0.006, 0.105, 0.059, 0.082]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=60934)[0m top1: 0.22994402985074627
[2m[36m(func pid=60934)[0m top5: 0.8232276119402985
[2m[36m(func pid=60934)[0m f1_micro: 0.22994402985074627
[2m[36m(func pid=60934)[0m f1_macro: 0.21621229202161757
[2m[36m(func pid=60934)[0m f1_weighted: 0.1749773784416397
[2m[36m(func pid=60934)[0m f1_per_class: [0.197, 0.341, 0.345, 0.007, 0.085, 0.382, 0.099, 0.525, 0.098, 0.084]
[2m[36m(func pid=60934)[0m 
== Status ==
Current time: 2024-01-07 02:34:37 (running for 00:10:37.88)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.354 |      0.164 |                   34 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  2.081 |      0.216 |                   13 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  1.679 |      0.112 |                    8 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  3.15  |      0.001 |                    6 |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=62614)[0m top1: 0.006063432835820896
[2m[36m(func pid=62614)[0m top5: 0.5153917910447762
[2m[36m(func pid=62614)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=62614)[0m f1_macro: 0.0012059369202226345
[2m[36m(func pid=62614)[0m f1_weighted: 7.312117520006647e-05
[2m[36m(func pid=62614)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 2.3183 | Steps: 2 | Val loss: 2.2583 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 1.5283 | Steps: 2 | Val loss: 2.6699 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 1.9715 | Steps: 2 | Val loss: 2.0653 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 2.3844 | Steps: 2 | Val loss: 5899.8882 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
[2m[36m(func pid=55782)[0m top1: 0.18516791044776118
[2m[36m(func pid=55782)[0m top5: 0.7056902985074627
[2m[36m(func pid=55782)[0m f1_micro: 0.18516791044776118
[2m[36m(func pid=55782)[0m f1_macro: 0.17012248764290427
[2m[36m(func pid=55782)[0m f1_weighted: 0.1787856110161412
[2m[36m(func pid=55782)[0m f1_per_class: [0.042, 0.217, 0.14, 0.27, 0.099, 0.303, 0.003, 0.45, 0.0, 0.176]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=62121)[0m top1: 0.21128731343283583
[2m[36m(func pid=62121)[0m top5: 0.7943097014925373
[2m[36m(func pid=62121)[0m f1_micro: 0.21128731343283583
[2m[36m(func pid=62121)[0m f1_macro: 0.15523319242818295
[2m[36m(func pid=62121)[0m f1_weighted: 0.1230503072057492
[2m[36m(func pid=62121)[0m f1_per_class: [0.0, 0.444, 0.286, 0.038, 0.235, 0.024, 0.033, 0.25, 0.125, 0.118]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=60934)[0m top1: 0.22994402985074627
[2m[36m(func pid=60934)[0m top5: 0.8442164179104478
[2m[36m(func pid=60934)[0m f1_micro: 0.22994402985074627
[2m[36m(func pid=60934)[0m f1_macro: 0.21909032951879998
[2m[36m(func pid=60934)[0m f1_weighted: 0.19272731524518122
[2m[36m(func pid=60934)[0m f1_per_class: [0.173, 0.336, 0.301, 0.052, 0.07, 0.369, 0.125, 0.503, 0.138, 0.124]
== Status ==
Current time: 2024-01-07 02:34:42 (running for 00:10:43.04)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.318 |      0.17  |                   35 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  1.971 |      0.219 |                   14 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  1.528 |      0.155 |                    9 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  2.968 |      0.001 |                    7 |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62614)[0m top1: 0.010727611940298507
[2m[36m(func pid=62614)[0m top5: 0.5111940298507462
[2m[36m(func pid=62614)[0m f1_micro: 0.010727611940298507
[2m[36m(func pid=62614)[0m f1_macro: 0.02054161292047455
[2m[36m(func pid=62614)[0m f1_weighted: 0.008459056737129541
[2m[36m(func pid=62614)[0m f1_per_class: [0.0, 0.037, 0.012, 0.0, 0.148, 0.008, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 2.3075 | Steps: 2 | Val loss: 2.2550 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 1.2939 | Steps: 2 | Val loss: 4.7472 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 1.8956 | Steps: 2 | Val loss: 2.0429 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 2.6112 | Steps: 2 | Val loss: 614.2805 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=55782)[0m top1: 0.18423507462686567
[2m[36m(func pid=55782)[0m top5: 0.710820895522388
[2m[36m(func pid=55782)[0m f1_micro: 0.1842350746268657
[2m[36m(func pid=55782)[0m f1_macro: 0.16924768585969757
[2m[36m(func pid=55782)[0m f1_weighted: 0.17609826834038408
[2m[36m(func pid=55782)[0m f1_per_class: [0.046, 0.193, 0.155, 0.27, 0.096, 0.317, 0.003, 0.45, 0.0, 0.162]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=62121)[0m top1: 0.08069029850746269
[2m[36m(func pid=62121)[0m top5: 0.6380597014925373
[2m[36m(func pid=62121)[0m f1_micro: 0.08069029850746269
[2m[36m(func pid=62121)[0m f1_macro: 0.10148988493708841
[2m[36m(func pid=62121)[0m f1_weighted: 0.08553209186701319
[2m[36m(func pid=62121)[0m f1_per_class: [0.024, 0.365, 0.036, 0.016, 0.267, 0.0, 0.003, 0.214, 0.053, 0.038]
[2m[36m(func pid=62121)[0m 
== Status ==
Current time: 2024-01-07 02:34:47 (running for 00:10:48.44)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.307 |      0.169 |                   36 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  1.896 |      0.231 |                   15 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  1.294 |      0.101 |                   10 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  2.384 |      0.021 |                    8 |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.23880597014925373
[2m[36m(func pid=60934)[0m top5: 0.8418843283582089
[2m[36m(func pid=60934)[0m f1_micro: 0.23880597014925373
[2m[36m(func pid=60934)[0m f1_macro: 0.23060139352954737
[2m[36m(func pid=60934)[0m f1_weighted: 0.2257559461327211
[2m[36m(func pid=60934)[0m f1_per_class: [0.222, 0.339, 0.256, 0.175, 0.064, 0.33, 0.13, 0.493, 0.159, 0.137]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62614)[0m top1: 0.029384328358208957
[2m[36m(func pid=62614)[0m top5: 0.34328358208955223
[2m[36m(func pid=62614)[0m f1_micro: 0.029384328358208953
[2m[36m(func pid=62614)[0m f1_macro: 0.03556993077640498
[2m[36m(func pid=62614)[0m f1_weighted: 0.03586355025372152
[2m[36m(func pid=62614)[0m f1_per_class: [0.0, 0.17, 0.015, 0.0, 0.143, 0.016, 0.012, 0.0, 0.0, 0.0]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 2.3114 | Steps: 2 | Val loss: 2.2447 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 1.1745 | Steps: 2 | Val loss: 5.9686 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 1.8378 | Steps: 2 | Val loss: 2.0276 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 2.2440 | Steps: 2 | Val loss: 186.4494 | Batch size: 32 | lr: 0.1 | Duration: 2.98s
[2m[36m(func pid=55782)[0m top1: 0.19169776119402984
[2m[36m(func pid=55782)[0m top5: 0.7206156716417911
[2m[36m(func pid=55782)[0m f1_micro: 0.19169776119402984
[2m[36m(func pid=55782)[0m f1_macro: 0.17870931823258374
[2m[36m(func pid=55782)[0m f1_weighted: 0.18364519242746682
[2m[36m(func pid=55782)[0m f1_per_class: [0.044, 0.198, 0.173, 0.286, 0.108, 0.332, 0.003, 0.449, 0.0, 0.195]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=62121)[0m top1: 0.11100746268656717
[2m[36m(func pid=62121)[0m top5: 0.6487873134328358
[2m[36m(func pid=62121)[0m f1_micro: 0.11100746268656717
[2m[36m(func pid=62121)[0m f1_macro: 0.11237529565897904
[2m[36m(func pid=62121)[0m f1_weighted: 0.09234251975530577
[2m[36m(func pid=62121)[0m f1_per_class: [0.028, 0.279, 0.037, 0.0, 0.159, 0.072, 0.033, 0.363, 0.07, 0.083]
[2m[36m(func pid=62121)[0m 
== Status ==
Current time: 2024-01-07 02:34:52 (running for 00:10:53.67)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.311 |      0.179 |                   37 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  1.838 |      0.231 |                   16 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  1.175 |      0.112 |                   11 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  2.611 |      0.036 |                    9 |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.2332089552238806
[2m[36m(func pid=60934)[0m top5: 0.8432835820895522
[2m[36m(func pid=60934)[0m f1_micro: 0.2332089552238806
[2m[36m(func pid=60934)[0m f1_macro: 0.23142277028317895
[2m[36m(func pid=60934)[0m f1_weighted: 0.22779536028681294
[2m[36m(func pid=60934)[0m f1_per_class: [0.247, 0.325, 0.256, 0.24, 0.058, 0.289, 0.098, 0.486, 0.179, 0.137]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62614)[0m top1: 0.06763059701492537
[2m[36m(func pid=62614)[0m top5: 0.4295708955223881
[2m[36m(func pid=62614)[0m f1_micro: 0.06763059701492537
[2m[36m(func pid=62614)[0m f1_macro: 0.057204363431714
[2m[36m(func pid=62614)[0m f1_weighted: 0.08215355167558767
[2m[36m(func pid=62614)[0m f1_per_class: [0.025, 0.252, 0.021, 0.0, 0.112, 0.052, 0.104, 0.006, 0.0, 0.0]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 2.2708 | Steps: 2 | Val loss: 2.2383 | Batch size: 32 | lr: 0.0001 | Duration: 2.81s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 1.0288 | Steps: 2 | Val loss: 4.1442 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 1.8002 | Steps: 2 | Val loss: 2.0024 | Batch size: 32 | lr: 0.001 | Duration: 2.68s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 2.0718 | Steps: 2 | Val loss: 98.9277 | Batch size: 32 | lr: 0.1 | Duration: 3.01s
[2m[36m(func pid=55782)[0m top1: 0.19916044776119404
[2m[36m(func pid=55782)[0m top5: 0.7248134328358209
[2m[36m(func pid=55782)[0m f1_micro: 0.19916044776119404
[2m[36m(func pid=55782)[0m f1_macro: 0.1851639765034959
[2m[36m(func pid=55782)[0m f1_weighted: 0.18797147443894602
[2m[36m(func pid=55782)[0m f1_per_class: [0.051, 0.191, 0.185, 0.296, 0.112, 0.369, 0.0, 0.432, 0.0, 0.217]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=62121)[0m top1: 0.17164179104477612
[2m[36m(func pid=62121)[0m top5: 0.7084888059701493
[2m[36m(func pid=62121)[0m f1_micro: 0.17164179104477612
[2m[36m(func pid=62121)[0m f1_macro: 0.17936161961580285
[2m[36m(func pid=62121)[0m f1_weighted: 0.16472332523420252
[2m[36m(func pid=62121)[0m f1_per_class: [0.048, 0.364, 0.063, 0.007, 0.172, 0.235, 0.151, 0.303, 0.131, 0.319]
[2m[36m(func pid=62121)[0m 
== Status ==
Current time: 2024-01-07 02:34:58 (running for 00:10:58.83)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.271 |      0.185 |                   38 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  1.8   |      0.221 |                   17 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  1.029 |      0.179 |                   12 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  2.244 |      0.057 |                   10 |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.2294776119402985
[2m[36m(func pid=60934)[0m top5: 0.8530783582089553
[2m[36m(func pid=60934)[0m f1_micro: 0.2294776119402985
[2m[36m(func pid=60934)[0m f1_macro: 0.22059333248587215
[2m[36m(func pid=60934)[0m f1_weighted: 0.22266107827136292
[2m[36m(func pid=60934)[0m f1_per_class: [0.242, 0.342, 0.278, 0.267, 0.058, 0.216, 0.082, 0.478, 0.121, 0.12]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62614)[0m top1: 0.12220149253731344
[2m[36m(func pid=62614)[0m top5: 0.5615671641791045
[2m[36m(func pid=62614)[0m f1_micro: 0.12220149253731344
[2m[36m(func pid=62614)[0m f1_macro: 0.08849656147624439
[2m[36m(func pid=62614)[0m f1_weighted: 0.1286759853164807
[2m[36m(func pid=62614)[0m f1_per_class: [0.017, 0.34, 0.039, 0.0, 0.104, 0.163, 0.155, 0.066, 0.0, 0.0]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 2.2892 | Steps: 2 | Val loss: 2.2389 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.8001 | Steps: 2 | Val loss: 3.7030 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 1.7823 | Steps: 2 | Val loss: 1.9753 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 2.1221 | Steps: 2 | Val loss: 34.5964 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
[2m[36m(func pid=55782)[0m top1: 0.20149253731343283
[2m[36m(func pid=55782)[0m top5: 0.7290111940298507
[2m[36m(func pid=55782)[0m f1_micro: 0.20149253731343283
[2m[36m(func pid=55782)[0m f1_macro: 0.18560188588054743
[2m[36m(func pid=55782)[0m f1_weighted: 0.19260446703728762
[2m[36m(func pid=55782)[0m f1_per_class: [0.048, 0.195, 0.179, 0.297, 0.111, 0.382, 0.006, 0.442, 0.0, 0.196]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=62121)[0m top1: 0.1912313432835821
[2m[36m(func pid=62121)[0m top5: 0.7402052238805971
[2m[36m(func pid=62121)[0m f1_micro: 0.19123134328358207
[2m[36m(func pid=62121)[0m f1_macro: 0.18309306676782683
[2m[36m(func pid=62121)[0m f1_weighted: 0.1843965101443836
[2m[36m(func pid=62121)[0m f1_per_class: [0.051, 0.439, 0.076, 0.048, 0.141, 0.084, 0.188, 0.324, 0.148, 0.333]
[2m[36m(func pid=62121)[0m 
== Status ==
Current time: 2024-01-07 02:35:03 (running for 00:11:03.89)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.289 |      0.186 |                   39 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  1.782 |      0.212 |                   18 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.8   |      0.183 |                   13 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  2.072 |      0.088 |                   11 |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.23414179104477612
[2m[36m(func pid=60934)[0m top5: 0.8558768656716418
[2m[36m(func pid=60934)[0m f1_micro: 0.23414179104477612
[2m[36m(func pid=60934)[0m f1_macro: 0.21219187075252316
[2m[36m(func pid=60934)[0m f1_weighted: 0.2214159450627824
[2m[36m(func pid=60934)[0m f1_per_class: [0.219, 0.352, 0.324, 0.328, 0.061, 0.182, 0.042, 0.438, 0.071, 0.104]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62614)[0m top1: 0.21688432835820895
[2m[36m(func pid=62614)[0m top5: 0.6791044776119403
[2m[36m(func pid=62614)[0m f1_micro: 0.21688432835820895
[2m[36m(func pid=62614)[0m f1_macro: 0.13019401230047983
[2m[36m(func pid=62614)[0m f1_weighted: 0.16295794679095618
[2m[36m(func pid=62614)[0m f1_per_class: [0.0, 0.401, 0.0, 0.192, 0.171, 0.212, 0.0, 0.217, 0.054, 0.055]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 2.2932 | Steps: 2 | Val loss: 2.2350 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 1.1694 | Steps: 2 | Val loss: 4.1331 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 1.6569 | Steps: 2 | Val loss: 1.9460 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 2.4754 | Steps: 2 | Val loss: 6.9475 | Batch size: 32 | lr: 0.1 | Duration: 2.76s
[2m[36m(func pid=55782)[0m top1: 0.20102611940298507
[2m[36m(func pid=55782)[0m top5: 0.7313432835820896
[2m[36m(func pid=55782)[0m f1_micro: 0.2010261194029851
[2m[36m(func pid=55782)[0m f1_macro: 0.18230352438079572
[2m[36m(func pid=55782)[0m f1_weighted: 0.1892277253049315
[2m[36m(func pid=55782)[0m f1_per_class: [0.048, 0.183, 0.182, 0.296, 0.107, 0.394, 0.0, 0.437, 0.0, 0.175]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=62121)[0m top1: 0.18330223880597016
[2m[36m(func pid=62121)[0m top5: 0.7630597014925373
[2m[36m(func pid=62121)[0m f1_micro: 0.18330223880597016
[2m[36m(func pid=62121)[0m f1_macro: 0.1735297533636848
[2m[36m(func pid=62121)[0m f1_weighted: 0.19402359022889634
[2m[36m(func pid=62121)[0m f1_per_class: [0.045, 0.343, 0.067, 0.14, 0.138, 0.063, 0.205, 0.329, 0.072, 0.333]
[2m[36m(func pid=62121)[0m 
== Status ==
Current time: 2024-01-07 02:35:08 (running for 00:11:09.20)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.293 |      0.182 |                   40 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  1.657 |      0.224 |                   19 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  1.169 |      0.174 |                   14 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  2.122 |      0.13  |                   12 |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.24440298507462688
[2m[36m(func pid=60934)[0m top5: 0.8596082089552238
[2m[36m(func pid=60934)[0m f1_micro: 0.24440298507462688
[2m[36m(func pid=60934)[0m f1_macro: 0.22423758542076574
[2m[36m(func pid=60934)[0m f1_weighted: 0.23169694011422778
[2m[36m(func pid=60934)[0m f1_per_class: [0.273, 0.338, 0.37, 0.341, 0.066, 0.227, 0.059, 0.415, 0.027, 0.126]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62614)[0m top1: 0.25046641791044777
[2m[36m(func pid=62614)[0m top5: 0.7523320895522388
[2m[36m(func pid=62614)[0m f1_micro: 0.25046641791044777
[2m[36m(func pid=62614)[0m f1_macro: 0.1568418669568299
[2m[36m(func pid=62614)[0m f1_weighted: 0.22369721375287466
[2m[36m(func pid=62614)[0m f1_per_class: [0.0, 0.431, 0.226, 0.351, 0.103, 0.055, 0.091, 0.265, 0.014, 0.033]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 2.2316 | Steps: 2 | Val loss: 2.2298 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 1.4006 | Steps: 2 | Val loss: 3.6928 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 1.5559 | Steps: 2 | Val loss: 1.9198 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 1.8921 | Steps: 2 | Val loss: 4.7665 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=55782)[0m top1: 0.20382462686567165
[2m[36m(func pid=55782)[0m top5: 0.7308768656716418
[2m[36m(func pid=55782)[0m f1_micro: 0.20382462686567165
[2m[36m(func pid=55782)[0m f1_macro: 0.18574549213432526
[2m[36m(func pid=55782)[0m f1_weighted: 0.19222289634716835
[2m[36m(func pid=55782)[0m f1_per_class: [0.05, 0.189, 0.183, 0.303, 0.106, 0.382, 0.003, 0.438, 0.0, 0.203]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=62121)[0m top1: 0.24253731343283583
[2m[36m(func pid=62121)[0m top5: 0.78125
[2m[36m(func pid=62121)[0m f1_micro: 0.24253731343283583
[2m[36m(func pid=62121)[0m f1_macro: 0.22466548138296086
[2m[36m(func pid=62121)[0m f1_weighted: 0.26607446442696187
[2m[36m(func pid=62121)[0m f1_per_class: [0.056, 0.433, 0.064, 0.18, 0.136, 0.176, 0.289, 0.413, 0.135, 0.366]
[2m[36m(func pid=62121)[0m 
== Status ==
Current time: 2024-01-07 02:35:13 (running for 00:11:14.26)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.232 |      0.186 |                   41 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  1.556 |      0.244 |                   20 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  1.401 |      0.225 |                   15 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  2.475 |      0.157 |                   13 |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.269589552238806
[2m[36m(func pid=60934)[0m top5: 0.8642723880597015
[2m[36m(func pid=60934)[0m f1_micro: 0.269589552238806
[2m[36m(func pid=60934)[0m f1_macro: 0.24430222539104257
[2m[36m(func pid=60934)[0m f1_weighted: 0.2696972658887819
[2m[36m(func pid=60934)[0m f1_per_class: [0.249, 0.335, 0.417, 0.392, 0.061, 0.254, 0.126, 0.451, 0.0, 0.158]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62614)[0m top1: 0.208955223880597
[2m[36m(func pid=62614)[0m top5: 0.7831156716417911
[2m[36m(func pid=62614)[0m f1_micro: 0.208955223880597
[2m[36m(func pid=62614)[0m f1_macro: 0.1584684944733616
[2m[36m(func pid=62614)[0m f1_weighted: 0.21271022503936743
[2m[36m(func pid=62614)[0m f1_per_class: [0.057, 0.28, 0.16, 0.143, 0.07, 0.139, 0.276, 0.376, 0.047, 0.036]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 2.2233 | Steps: 2 | Val loss: 2.2226 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.8527 | Steps: 2 | Val loss: 5.5142 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 1.6018 | Steps: 2 | Val loss: 1.8996 | Batch size: 32 | lr: 0.001 | Duration: 2.69s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 2.1625 | Steps: 2 | Val loss: 3.4240 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=55782)[0m top1: 0.20522388059701493
[2m[36m(func pid=55782)[0m top5: 0.7346082089552238
[2m[36m(func pid=55782)[0m f1_micro: 0.20522388059701493
[2m[36m(func pid=55782)[0m f1_macro: 0.18767450621782714
[2m[36m(func pid=55782)[0m f1_weighted: 0.19337520222387564
[2m[36m(func pid=55782)[0m f1_per_class: [0.055, 0.191, 0.185, 0.304, 0.095, 0.37, 0.006, 0.449, 0.0, 0.222]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=62121)[0m top1: 0.1669776119402985
[2m[36m(func pid=62121)[0m top5: 0.7131529850746269
[2m[36m(func pid=62121)[0m f1_micro: 0.1669776119402985
[2m[36m(func pid=62121)[0m f1_macro: 0.15405357771433104
[2m[36m(func pid=62121)[0m f1_weighted: 0.1493301458706244
[2m[36m(func pid=62121)[0m f1_per_class: [0.057, 0.418, 0.0, 0.081, 0.239, 0.068, 0.067, 0.328, 0.08, 0.202]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=60934)[0m top1: 0.2789179104477612
[2m[36m(func pid=60934)[0m top5: 0.871268656716418
[2m[36m(func pid=60934)[0m f1_micro: 0.2789179104477612
[2m[36m(func pid=60934)[0m f1_macro: 0.24067418415293657
[2m[36m(func pid=60934)[0m f1_weighted: 0.2724816387991274
[2m[36m(func pid=60934)[0m f1_per_class: [0.234, 0.334, 0.385, 0.432, 0.058, 0.273, 0.098, 0.423, 0.0, 0.169]
[2m[36m(func pid=60934)[0m 
== Status ==
Current time: 2024-01-07 02:35:18 (running for 00:11:19.35)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.223 |      0.188 |                   42 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  1.602 |      0.241 |                   21 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.853 |      0.154 |                   16 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.892 |      0.158 |                   14 |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=62614)[0m top1: 0.20848880597014927
[2m[36m(func pid=62614)[0m top5: 0.7971082089552238
[2m[36m(func pid=62614)[0m f1_micro: 0.20848880597014927
[2m[36m(func pid=62614)[0m f1_macro: 0.18956647764381734
[2m[36m(func pid=62614)[0m f1_weighted: 0.2082506875058893
[2m[36m(func pid=62614)[0m f1_per_class: [0.05, 0.267, 0.329, 0.013, 0.069, 0.202, 0.343, 0.449, 0.078, 0.095]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 2.2356 | Steps: 2 | Val loss: 2.2195 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 1.1645 | Steps: 2 | Val loss: 8.4853 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 1.5172 | Steps: 2 | Val loss: 1.8886 | Batch size: 32 | lr: 0.001 | Duration: 2.75s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 1.7187 | Steps: 2 | Val loss: 2.8588 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=62121)[0m top1: 0.10867537313432836
[2m[36m(func pid=62121)[0m top5: 0.6105410447761194
[2m[36m(func pid=62121)[0m f1_micro: 0.10867537313432836
[2m[36m(func pid=62121)[0m f1_macro: 0.1413666086493562
[2m[36m(func pid=62121)[0m f1_weighted: 0.1344425399383678
[2m[36m(func pid=62121)[0m f1_per_class: [0.03, 0.276, 0.065, 0.056, 0.279, 0.142, 0.118, 0.209, 0.082, 0.156]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=55782)[0m top1: 0.20755597014925373
[2m[36m(func pid=55782)[0m top5: 0.7336753731343284
[2m[36m(func pid=55782)[0m f1_micro: 0.20755597014925375
[2m[36m(func pid=55782)[0m f1_macro: 0.185226135149506
[2m[36m(func pid=55782)[0m f1_weighted: 0.1956240622044934
[2m[36m(func pid=55782)[0m f1_per_class: [0.055, 0.22, 0.171, 0.31, 0.097, 0.349, 0.0, 0.454, 0.0, 0.196]
[2m[36m(func pid=55782)[0m 
== Status ==
Current time: 2024-01-07 02:35:23 (running for 00:11:24.41)
Memory usage on this node: 24.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.236 |      0.185 |                   43 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  1.517 |      0.241 |                   22 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  1.165 |      0.141 |                   17 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  2.163 |      0.19  |                   15 |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.2887126865671642
[2m[36m(func pid=60934)[0m top5: 0.8708022388059702
[2m[36m(func pid=60934)[0m f1_micro: 0.2887126865671642
[2m[36m(func pid=60934)[0m f1_macro: 0.2411509817435101
[2m[36m(func pid=60934)[0m f1_weighted: 0.28172157562749656
[2m[36m(func pid=60934)[0m f1_per_class: [0.219, 0.287, 0.392, 0.478, 0.06, 0.283, 0.111, 0.424, 0.0, 0.158]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62614)[0m top1: 0.16744402985074627
[2m[36m(func pid=62614)[0m top5: 0.8376865671641791
[2m[36m(func pid=62614)[0m f1_micro: 0.16744402985074627
[2m[36m(func pid=62614)[0m f1_macro: 0.1498025483926389
[2m[36m(func pid=62614)[0m f1_weighted: 0.14230725465143582
[2m[36m(func pid=62614)[0m f1_per_class: [0.061, 0.33, 0.353, 0.023, 0.091, 0.0, 0.171, 0.367, 0.078, 0.025]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 2.1796 | Steps: 2 | Val loss: 2.2152 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 1.0589 | Steps: 2 | Val loss: 7.2438 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 1.4114 | Steps: 2 | Val loss: 1.8880 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 2.9441 | Steps: 2 | Val loss: 10.6567 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=55782)[0m top1: 0.2126865671641791
[2m[36m(func pid=55782)[0m top5: 0.7411380597014925
[2m[36m(func pid=55782)[0m f1_micro: 0.2126865671641791
[2m[36m(func pid=55782)[0m f1_macro: 0.19459215992218232
[2m[36m(func pid=55782)[0m f1_weighted: 0.2031856275590922
[2m[36m(func pid=55782)[0m f1_per_class: [0.053, 0.238, 0.171, 0.316, 0.095, 0.353, 0.006, 0.449, 0.0, 0.264]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=62121)[0m top1: 0.08069029850746269
[2m[36m(func pid=62121)[0m top5: 0.6371268656716418
[2m[36m(func pid=62121)[0m f1_micro: 0.08069029850746269
[2m[36m(func pid=62121)[0m f1_macro: 0.11496690207331772
[2m[36m(func pid=62121)[0m f1_weighted: 0.08963536704980755
[2m[36m(func pid=62121)[0m f1_per_class: [0.023, 0.077, 0.051, 0.023, 0.156, 0.173, 0.088, 0.299, 0.085, 0.175]
[2m[36m(func pid=62121)[0m 
== Status ==
Current time: 2024-01-07 02:35:28 (running for 00:11:29.73)
Memory usage on this node: 24.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.18  |      0.195 |                   44 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  1.411 |      0.252 |                   23 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  1.059 |      0.115 |                   18 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.719 |      0.15  |                   16 |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.3064365671641791
[2m[36m(func pid=60934)[0m top5: 0.8652052238805971
[2m[36m(func pid=60934)[0m f1_micro: 0.3064365671641791
[2m[36m(func pid=60934)[0m f1_macro: 0.25219329706081295
[2m[36m(func pid=60934)[0m f1_weighted: 0.3080958198803877
[2m[36m(func pid=60934)[0m f1_per_class: [0.227, 0.272, 0.345, 0.5, 0.058, 0.286, 0.173, 0.481, 0.027, 0.153]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62614)[0m top1: 0.1935634328358209
[2m[36m(func pid=62614)[0m top5: 0.7747201492537313
[2m[36m(func pid=62614)[0m f1_micro: 0.1935634328358209
[2m[36m(func pid=62614)[0m f1_macro: 0.1296791749945174
[2m[36m(func pid=62614)[0m f1_weighted: 0.17665433772399053
[2m[36m(func pid=62614)[0m f1_per_class: [0.022, 0.506, 0.068, 0.162, 0.074, 0.055, 0.072, 0.226, 0.038, 0.074]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.7696 | Steps: 2 | Val loss: 5.0045 | Batch size: 32 | lr: 0.01 | Duration: 3.06s
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 2.2040 | Steps: 2 | Val loss: 2.2128 | Batch size: 32 | lr: 0.0001 | Duration: 3.08s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 1.6367 | Steps: 2 | Val loss: 1.8881 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 2.1074 | Steps: 2 | Val loss: 265.2646 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=55782)[0m top1: 0.2080223880597015
[2m[36m(func pid=55782)[0m top5: 0.7527985074626866
[2m[36m(func pid=55782)[0m f1_micro: 0.2080223880597015
[2m[36m(func pid=55782)[0m f1_macro: 0.1847262990241459
[2m[36m(func pid=55782)[0m f1_weighted: 0.19898626191611882
[2m[36m(func pid=55782)[0m f1_per_class: [0.048, 0.224, 0.167, 0.309, 0.095, 0.373, 0.006, 0.429, 0.0, 0.197]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=62121)[0m top1: 0.10914179104477612
[2m[36m(func pid=62121)[0m top5: 0.6977611940298507
[2m[36m(func pid=62121)[0m f1_micro: 0.10914179104477612
[2m[36m(func pid=62121)[0m f1_macro: 0.14405119320482354
[2m[36m(func pid=62121)[0m f1_weighted: 0.13703432321980327
[2m[36m(func pid=62121)[0m f1_per_class: [0.029, 0.219, 0.054, 0.096, 0.116, 0.213, 0.109, 0.106, 0.09, 0.408]
[2m[36m(func pid=62121)[0m 
== Status ==
Current time: 2024-01-07 02:35:34 (running for 00:11:35.08)
Memory usage on this node: 24.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.204 |      0.185 |                   45 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  1.637 |      0.251 |                   24 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.77  |      0.144 |                   19 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  2.944 |      0.13  |                   17 |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.31156716417910446
[2m[36m(func pid=60934)[0m top5: 0.8614738805970149
[2m[36m(func pid=60934)[0m f1_micro: 0.31156716417910446
[2m[36m(func pid=60934)[0m f1_macro: 0.25084915967499255
[2m[36m(func pid=60934)[0m f1_weighted: 0.315010027380963
[2m[36m(func pid=60934)[0m f1_per_class: [0.214, 0.256, 0.328, 0.513, 0.059, 0.277, 0.196, 0.49, 0.027, 0.148]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62614)[0m top1: 0.11147388059701492
[2m[36m(func pid=62614)[0m top5: 0.5951492537313433
[2m[36m(func pid=62614)[0m f1_micro: 0.11147388059701491
[2m[36m(func pid=62614)[0m f1_macro: 0.09150636802076104
[2m[36m(func pid=62614)[0m f1_weighted: 0.10578202527863341
[2m[36m(func pid=62614)[0m f1_per_class: [0.0, 0.195, 0.024, 0.026, 0.129, 0.108, 0.114, 0.283, 0.037, 0.0]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 2.2614 | Steps: 2 | Val loss: 2.2140 | Batch size: 32 | lr: 0.0001 | Duration: 2.78s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.6975 | Steps: 2 | Val loss: 3.6984 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 1.4359 | Steps: 2 | Val loss: 1.8193 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 5.2151 | Steps: 2 | Val loss: 71.0689 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=55782)[0m top1: 0.20475746268656717
[2m[36m(func pid=55782)[0m top5: 0.7621268656716418
[2m[36m(func pid=55782)[0m f1_micro: 0.20475746268656717
[2m[36m(func pid=55782)[0m f1_macro: 0.1808339257132023
[2m[36m(func pid=55782)[0m f1_weighted: 0.19807896264722255
[2m[36m(func pid=55782)[0m f1_per_class: [0.05, 0.223, 0.162, 0.31, 0.093, 0.356, 0.009, 0.432, 0.0, 0.172]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=62121)[0m top1: 0.25046641791044777
[2m[36m(func pid=62121)[0m top5: 0.7588619402985075
[2m[36m(func pid=62121)[0m f1_micro: 0.25046641791044777
[2m[36m(func pid=62121)[0m f1_macro: 0.2009778388477963
[2m[36m(func pid=62121)[0m f1_weighted: 0.2958992481626179
[2m[36m(func pid=62121)[0m f1_per_class: [0.007, 0.418, 0.063, 0.163, 0.09, 0.223, 0.407, 0.436, 0.137, 0.066]
[2m[36m(func pid=62121)[0m 
== Status ==
Current time: 2024-01-07 02:35:39 (running for 00:11:40.28)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.261 |      0.181 |                   46 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  1.436 |      0.259 |                   25 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.697 |      0.201 |                   20 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  2.107 |      0.092 |                   18 |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.33348880597014924
[2m[36m(func pid=60934)[0m top5: 0.8838619402985075
[2m[36m(func pid=60934)[0m f1_micro: 0.33348880597014924
[2m[36m(func pid=60934)[0m f1_macro: 0.258966766153634
[2m[36m(func pid=60934)[0m f1_weighted: 0.32029005911988
[2m[36m(func pid=60934)[0m f1_per_class: [0.236, 0.247, 0.355, 0.535, 0.069, 0.286, 0.203, 0.437, 0.0, 0.222]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62614)[0m top1: 0.240205223880597
[2m[36m(func pid=62614)[0m top5: 0.6082089552238806
[2m[36m(func pid=62614)[0m f1_micro: 0.240205223880597
[2m[36m(func pid=62614)[0m f1_macro: 0.15899613040776733
[2m[36m(func pid=62614)[0m f1_weighted: 0.22348994696435298
[2m[36m(func pid=62614)[0m f1_per_class: [0.0, 0.293, 0.0, 0.0, 0.113, 0.271, 0.379, 0.444, 0.067, 0.023]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 2.2687 | Steps: 2 | Val loss: 2.2143 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.4978 | Steps: 2 | Val loss: 3.2169 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 1.2648 | Steps: 2 | Val loss: 1.8142 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 2.7181 | Steps: 2 | Val loss: 20.6895 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
[2m[36m(func pid=55782)[0m top1: 0.19916044776119404
[2m[36m(func pid=55782)[0m top5: 0.7672574626865671
[2m[36m(func pid=55782)[0m f1_micro: 0.19916044776119404
[2m[36m(func pid=55782)[0m f1_macro: 0.17535467879061578
[2m[36m(func pid=55782)[0m f1_weighted: 0.19550358652060382
[2m[36m(func pid=55782)[0m f1_per_class: [0.052, 0.229, 0.164, 0.308, 0.094, 0.324, 0.012, 0.438, 0.0, 0.132]
[2m[36m(func pid=62121)[0m top1: 0.261660447761194
[2m[36m(func pid=62121)[0m top5: 0.7686567164179104
[2m[36m(func pid=62121)[0m f1_micro: 0.261660447761194
[2m[36m(func pid=62121)[0m f1_macro: 0.22313292747831892
[2m[36m(func pid=62121)[0m f1_weighted: 0.29093001421592524
[2m[36m(func pid=62121)[0m f1_per_class: [0.034, 0.283, 0.083, 0.116, 0.121, 0.251, 0.48, 0.498, 0.129, 0.235]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=55782)[0m 
== Status ==
Current time: 2024-01-07 02:35:44 (running for 00:11:45.45)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.269 |      0.175 |                   47 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  1.265 |      0.263 |                   26 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.498 |      0.223 |                   21 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  5.215 |      0.159 |                   19 |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.3423507462686567
[2m[36m(func pid=60934)[0m top5: 0.8843283582089553
[2m[36m(func pid=60934)[0m f1_micro: 0.3423507462686567
[2m[36m(func pid=60934)[0m f1_macro: 0.26257557218762134
[2m[36m(func pid=60934)[0m f1_weighted: 0.3461989050232022
[2m[36m(func pid=60934)[0m f1_per_class: [0.209, 0.291, 0.344, 0.522, 0.078, 0.253, 0.284, 0.489, 0.0, 0.157]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62614)[0m top1: 0.11847014925373134
[2m[36m(func pid=62614)[0m top5: 0.6623134328358209
[2m[36m(func pid=62614)[0m f1_micro: 0.11847014925373134
[2m[36m(func pid=62614)[0m f1_macro: 0.09747971170851562
[2m[36m(func pid=62614)[0m f1_weighted: 0.08838063405547283
[2m[36m(func pid=62614)[0m f1_per_class: [0.0, 0.005, 0.0, 0.033, 0.13, 0.315, 0.07, 0.299, 0.086, 0.037]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 2.2045 | Steps: 2 | Val loss: 2.2096 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.4559 | Steps: 2 | Val loss: 3.5841 | Batch size: 32 | lr: 0.01 | Duration: 3.09s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 1.3125 | Steps: 2 | Val loss: 1.8430 | Batch size: 32 | lr: 0.001 | Duration: 3.04s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 2.1510 | Steps: 2 | Val loss: 12.0943 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 02:35:49 (running for 00:11:50.56)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.204 |      0.184 |                   48 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  1.265 |      0.263 |                   26 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.498 |      0.223 |                   21 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  2.718 |      0.097 |                   20 |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=55782)[0m top1: 0.20662313432835822
[2m[36m(func pid=55782)[0m top5: 0.769589552238806
[2m[36m(func pid=55782)[0m f1_micro: 0.20662313432835824
[2m[36m(func pid=55782)[0m f1_macro: 0.18376537303047774
[2m[36m(func pid=55782)[0m f1_weighted: 0.20248765430655155
[2m[36m(func pid=55782)[0m f1_per_class: [0.052, 0.233, 0.167, 0.308, 0.096, 0.349, 0.018, 0.458, 0.0, 0.157]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=62121)[0m top1: 0.2416044776119403
[2m[36m(func pid=62121)[0m top5: 0.7472014925373134
[2m[36m(func pid=62121)[0m f1_micro: 0.2416044776119403
[2m[36m(func pid=62121)[0m f1_macro: 0.20676501847324752
[2m[36m(func pid=62121)[0m f1_weighted: 0.269806592881128
[2m[36m(func pid=62121)[0m f1_per_class: [0.04, 0.101, 0.086, 0.15, 0.119, 0.201, 0.503, 0.519, 0.068, 0.281]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=60934)[0m top1: 0.3306902985074627
[2m[36m(func pid=60934)[0m top5: 0.8754664179104478
[2m[36m(func pid=60934)[0m f1_micro: 0.3306902985074627
[2m[36m(func pid=60934)[0m f1_macro: 0.2627194820169455
[2m[36m(func pid=60934)[0m f1_weighted: 0.34657848851945333
[2m[36m(func pid=60934)[0m f1_per_class: [0.208, 0.345, 0.357, 0.511, 0.083, 0.205, 0.278, 0.502, 0.027, 0.111]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62614)[0m top1: 0.11986940298507463
[2m[36m(func pid=62614)[0m top5: 0.7938432835820896
[2m[36m(func pid=62614)[0m f1_micro: 0.11986940298507463
[2m[36m(func pid=62614)[0m f1_macro: 0.09048987801634259
[2m[36m(func pid=62614)[0m f1_weighted: 0.08634589319560959
[2m[36m(func pid=62614)[0m f1_per_class: [0.011, 0.0, 0.053, 0.128, 0.09, 0.277, 0.0, 0.259, 0.087, 0.0]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 2.2839 | Steps: 2 | Val loss: 2.2034 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 1.0692 | Steps: 2 | Val loss: 2.9021 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 1.2503 | Steps: 2 | Val loss: 1.7883 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 1.8177 | Steps: 2 | Val loss: 8.0530 | Batch size: 32 | lr: 0.1 | Duration: 2.73s
== Status ==
Current time: 2024-01-07 02:35:54 (running for 00:11:55.78)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.284 |      0.187 |                   49 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  1.313 |      0.263 |                   27 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.456 |      0.207 |                   22 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  2.151 |      0.09  |                   21 |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=55782)[0m top1: 0.20708955223880596
[2m[36m(func pid=55782)[0m top5: 0.7807835820895522
[2m[36m(func pid=55782)[0m f1_micro: 0.20708955223880596
[2m[36m(func pid=55782)[0m f1_macro: 0.18664879209091978
[2m[36m(func pid=55782)[0m f1_weighted: 0.2008897506325368
[2m[36m(func pid=55782)[0m f1_per_class: [0.049, 0.217, 0.169, 0.302, 0.096, 0.365, 0.022, 0.448, 0.0, 0.198]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=62121)[0m top1: 0.34375
[2m[36m(func pid=62121)[0m top5: 0.8745335820895522
[2m[36m(func pid=62121)[0m f1_micro: 0.34375
[2m[36m(func pid=62121)[0m f1_macro: 0.2586787845918188
[2m[36m(func pid=62121)[0m f1_weighted: 0.36992262530983155
[2m[36m(func pid=62121)[0m f1_per_class: [0.102, 0.267, 0.0, 0.37, 0.076, 0.289, 0.494, 0.495, 0.169, 0.324]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=60934)[0m top1: 0.3694029850746269
[2m[36m(func pid=60934)[0m top5: 0.882929104477612
[2m[36m(func pid=60934)[0m f1_micro: 0.3694029850746269
[2m[36m(func pid=60934)[0m f1_macro: 0.30028644441893515
[2m[36m(func pid=60934)[0m f1_weighted: 0.3935528829287124
[2m[36m(func pid=60934)[0m f1_per_class: [0.248, 0.456, 0.364, 0.5, 0.077, 0.271, 0.344, 0.528, 0.053, 0.162]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62614)[0m top1: 0.22388059701492538
[2m[36m(func pid=62614)[0m top5: 0.8428171641791045
[2m[36m(func pid=62614)[0m f1_micro: 0.22388059701492538
[2m[36m(func pid=62614)[0m f1_macro: 0.1605928413261629
[2m[36m(func pid=62614)[0m f1_weighted: 0.23626963493059172
[2m[36m(func pid=62614)[0m f1_per_class: [0.045, 0.12, 0.073, 0.331, 0.109, 0.25, 0.233, 0.339, 0.106, 0.0]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 2.1771 | Steps: 2 | Val loss: 2.1897 | Batch size: 32 | lr: 0.0001 | Duration: 2.81s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.6492 | Steps: 2 | Val loss: 5.9957 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 1.0998 | Steps: 2 | Val loss: 1.7450 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 1.8599 | Steps: 2 | Val loss: 5.8273 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
== Status ==
Current time: 2024-01-07 02:36:00 (running for 00:12:01.06)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.177 |      0.196 |                   50 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  1.25  |      0.3   |                   28 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  1.069 |      0.259 |                   23 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.818 |      0.161 |                   22 |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=55782)[0m top1: 0.21455223880597016
[2m[36m(func pid=55782)[0m top5: 0.7919776119402985
[2m[36m(func pid=55782)[0m f1_micro: 0.21455223880597016
[2m[36m(func pid=55782)[0m f1_macro: 0.19646194576187445
[2m[36m(func pid=55782)[0m f1_weighted: 0.20749481831469235
[2m[36m(func pid=55782)[0m f1_per_class: [0.052, 0.238, 0.176, 0.302, 0.089, 0.376, 0.025, 0.457, 0.0, 0.25]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=60934)[0m top1: 0.3987873134328358
[2m[36m(func pid=60934)[0m top5: 0.8857276119402985
[2m[36m(func pid=60934)[0m f1_micro: 0.3987873134328358
[2m[36m(func pid=60934)[0m f1_macro: 0.3429993073905345
[2m[36m(func pid=60934)[0m f1_weighted: 0.42484703033075405
[2m[36m(func pid=60934)[0m f1_per_class: [0.27, 0.504, 0.408, 0.471, 0.071, 0.316, 0.41, 0.558, 0.125, 0.298]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62121)[0m top1: 0.2490671641791045
[2m[36m(func pid=62121)[0m top5: 0.7024253731343284
[2m[36m(func pid=62121)[0m f1_micro: 0.2490671641791045
[2m[36m(func pid=62121)[0m f1_macro: 0.22130355154716047
[2m[36m(func pid=62121)[0m f1_weighted: 0.27419306348639005
[2m[36m(func pid=62121)[0m f1_per_class: [0.08, 0.027, 0.124, 0.173, 0.143, 0.234, 0.524, 0.481, 0.111, 0.318]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=62614)[0m top1: 0.22807835820895522
[2m[36m(func pid=62614)[0m top5: 0.840018656716418
[2m[36m(func pid=62614)[0m f1_micro: 0.22807835820895522
[2m[36m(func pid=62614)[0m f1_macro: 0.17852480335777984
[2m[36m(func pid=62614)[0m f1_weighted: 0.24689124485672728
[2m[36m(func pid=62614)[0m f1_per_class: [0.06, 0.339, 0.098, 0.198, 0.126, 0.122, 0.301, 0.388, 0.128, 0.027]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 2.1279 | Steps: 2 | Val loss: 2.1847 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 1.2584 | Steps: 2 | Val loss: 1.7999 | Batch size: 32 | lr: 0.001 | Duration: 2.78s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.5347 | Steps: 2 | Val loss: 11.5445 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 1.7807 | Steps: 2 | Val loss: 4.0343 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
== Status ==
Current time: 2024-01-07 02:36:05 (running for 00:12:06.47)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.177 |      0.196 |                   50 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  1.258 |      0.318 |                   30 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.649 |      0.221 |                   24 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.86  |      0.179 |                   23 |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=55782)[0m top1: 0.21735074626865672
[2m[36m(func pid=55782)[0m top5: 0.7961753731343284
[2m[36m(func pid=55782)[0m f1_micro: 0.21735074626865672
[2m[36m(func pid=55782)[0m f1_macro: 0.19648635739742443
[2m[36m(func pid=55782)[0m f1_weighted: 0.20973073439563877
[2m[36m(func pid=55782)[0m f1_per_class: [0.055, 0.243, 0.186, 0.307, 0.09, 0.374, 0.025, 0.463, 0.0, 0.222]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=60934)[0m top1: 0.37080223880597013
[2m[36m(func pid=60934)[0m top5: 0.8736007462686567
[2m[36m(func pid=60934)[0m f1_micro: 0.37080223880597013
[2m[36m(func pid=60934)[0m f1_macro: 0.3176107141519679
[2m[36m(func pid=60934)[0m f1_weighted: 0.40274843849043823
[2m[36m(func pid=60934)[0m f1_per_class: [0.215, 0.525, 0.385, 0.436, 0.086, 0.286, 0.374, 0.552, 0.157, 0.159]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62121)[0m top1: 0.22061567164179105
[2m[36m(func pid=62121)[0m top5: 0.6091417910447762
[2m[36m(func pid=62121)[0m f1_micro: 0.22061567164179105
[2m[36m(func pid=62121)[0m f1_macro: 0.18997515862397513
[2m[36m(func pid=62121)[0m f1_weighted: 0.244647342974565
[2m[36m(func pid=62121)[0m f1_per_class: [0.074, 0.057, 0.194, 0.142, 0.145, 0.159, 0.507, 0.274, 0.106, 0.242]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=62614)[0m top1: 0.19076492537313433
[2m[36m(func pid=62614)[0m top5: 0.84375
[2m[36m(func pid=62614)[0m f1_micro: 0.19076492537313436
[2m[36m(func pid=62614)[0m f1_macro: 0.154473608081581
[2m[36m(func pid=62614)[0m f1_weighted: 0.1842229657249837
[2m[36m(func pid=62614)[0m f1_per_class: [0.063, 0.39, 0.145, 0.121, 0.148, 0.008, 0.187, 0.328, 0.129, 0.026]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 2.1286 | Steps: 2 | Val loss: 2.1815 | Batch size: 32 | lr: 0.0001 | Duration: 2.81s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 1.1336 | Steps: 2 | Val loss: 1.8323 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.8785 | Steps: 2 | Val loss: 6.2213 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 8.1437 | Steps: 2 | Val loss: 5.4618 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 02:36:10 (running for 00:12:11.51)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.128 |      0.196 |                   51 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  1.134 |      0.311 |                   31 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.535 |      0.19  |                   25 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.781 |      0.154 |                   24 |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.3582089552238806
[2m[36m(func pid=60934)[0m top5: 0.8680037313432836
[2m[36m(func pid=60934)[0m f1_micro: 0.35820895522388063
[2m[36m(func pid=60934)[0m f1_macro: 0.3112340943725324
[2m[36m(func pid=60934)[0m f1_weighted: 0.39490031006330933
[2m[36m(func pid=60934)[0m f1_per_class: [0.168, 0.539, 0.357, 0.4, 0.081, 0.293, 0.373, 0.546, 0.188, 0.168]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=55782)[0m top1: 0.22154850746268656
[2m[36m(func pid=55782)[0m top5: 0.7999067164179104
[2m[36m(func pid=55782)[0m f1_micro: 0.22154850746268656
[2m[36m(func pid=55782)[0m f1_macro: 0.19818486101528376
[2m[36m(func pid=55782)[0m f1_weighted: 0.21550509067656945
[2m[36m(func pid=55782)[0m f1_per_class: [0.061, 0.234, 0.198, 0.312, 0.099, 0.388, 0.04, 0.461, 0.0, 0.189]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=62121)[0m top1: 0.1814365671641791
[2m[36m(func pid=62121)[0m top5: 0.7024253731343284
[2m[36m(func pid=62121)[0m f1_micro: 0.1814365671641791
[2m[36m(func pid=62121)[0m f1_macro: 0.16503443098999207
[2m[36m(func pid=62121)[0m f1_weighted: 0.20873190593824564
[2m[36m(func pid=62121)[0m f1_per_class: [0.097, 0.227, 0.18, 0.215, 0.089, 0.148, 0.274, 0.0, 0.117, 0.304]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=62614)[0m top1: 0.23274253731343283
[2m[36m(func pid=62614)[0m top5: 0.8409514925373134
[2m[36m(func pid=62614)[0m f1_micro: 0.23274253731343286
[2m[36m(func pid=62614)[0m f1_macro: 0.17297319124769422
[2m[36m(func pid=62614)[0m f1_weighted: 0.246137827745391
[2m[36m(func pid=62614)[0m f1_per_class: [0.063, 0.353, 0.114, 0.307, 0.083, 0.094, 0.203, 0.375, 0.123, 0.014]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 1.0948 | Steps: 2 | Val loss: 1.7934 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 2.1832 | Steps: 2 | Val loss: 2.1756 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.9040 | Steps: 2 | Val loss: 3.0992 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 2.3538 | Steps: 2 | Val loss: 7.8752 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
== Status ==
Current time: 2024-01-07 02:36:16 (running for 00:12:16.83)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.183 |      0.188 |                   53 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  1.134 |      0.311 |                   31 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.879 |      0.165 |                   26 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  8.144 |      0.173 |                   25 |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=55782)[0m top1: 0.2150186567164179
[2m[36m(func pid=55782)[0m top5: 0.8059701492537313
[2m[36m(func pid=55782)[0m f1_micro: 0.2150186567164179
[2m[36m(func pid=55782)[0m f1_macro: 0.1879800421225118
[2m[36m(func pid=55782)[0m f1_weighted: 0.21481179571935502
[2m[36m(func pid=55782)[0m f1_per_class: [0.063, 0.22, 0.21, 0.325, 0.09, 0.357, 0.048, 0.462, 0.0, 0.106]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=60934)[0m top1: 0.36847014925373134
[2m[36m(func pid=60934)[0m top5: 0.8717350746268657
[2m[36m(func pid=60934)[0m f1_micro: 0.3684701492537314
[2m[36m(func pid=60934)[0m f1_macro: 0.32689269764610357
[2m[36m(func pid=60934)[0m f1_weighted: 0.3985605620119252
[2m[36m(func pid=60934)[0m f1_per_class: [0.192, 0.54, 0.379, 0.396, 0.073, 0.318, 0.375, 0.545, 0.173, 0.279]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62121)[0m top1: 0.25699626865671643
[2m[36m(func pid=62121)[0m top5: 0.8278917910447762
[2m[36m(func pid=62121)[0m f1_micro: 0.25699626865671643
[2m[36m(func pid=62121)[0m f1_macro: 0.21315056940709845
[2m[36m(func pid=62121)[0m f1_weighted: 0.2949664324684486
[2m[36m(func pid=62121)[0m f1_per_class: [0.129, 0.342, 0.213, 0.336, 0.06, 0.262, 0.333, 0.0, 0.151, 0.304]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=62614)[0m top1: 0.23600746268656717
[2m[36m(func pid=62614)[0m top5: 0.8334888059701493
[2m[36m(func pid=62614)[0m f1_micro: 0.23600746268656717
[2m[36m(func pid=62614)[0m f1_macro: 0.18598450866352464
[2m[36m(func pid=62614)[0m f1_weighted: 0.2563016721046617
[2m[36m(func pid=62614)[0m f1_per_class: [0.049, 0.31, 0.075, 0.214, 0.069, 0.296, 0.256, 0.471, 0.12, 0.0]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 2.1707 | Steps: 2 | Val loss: 2.1692 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 1.1359 | Steps: 2 | Val loss: 1.7612 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.7116 | Steps: 2 | Val loss: 1.9714 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 1.8135 | Steps: 2 | Val loss: 3.6925 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
== Status ==
Current time: 2024-01-07 02:36:21 (running for 00:12:22.19)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.171 |      0.189 |                   54 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  1.095 |      0.327 |                   32 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.904 |      0.213 |                   27 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  2.354 |      0.186 |                   26 |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=55782)[0m top1: 0.21548507462686567
[2m[36m(func pid=55782)[0m top5: 0.8129664179104478
[2m[36m(func pid=55782)[0m f1_micro: 0.21548507462686567
[2m[36m(func pid=55782)[0m f1_macro: 0.18865361705267003
[2m[36m(func pid=55782)[0m f1_weighted: 0.22244476378502812
[2m[36m(func pid=55782)[0m f1_per_class: [0.065, 0.232, 0.212, 0.335, 0.088, 0.33, 0.071, 0.449, 0.0, 0.105]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=60934)[0m top1: 0.37779850746268656
[2m[36m(func pid=60934)[0m top5: 0.8791977611940298
[2m[36m(func pid=60934)[0m f1_micro: 0.3777985074626865
[2m[36m(func pid=60934)[0m f1_macro: 0.33743045031965896
[2m[36m(func pid=60934)[0m f1_weighted: 0.40587918690211955
[2m[36m(func pid=60934)[0m f1_per_class: [0.234, 0.539, 0.4, 0.408, 0.068, 0.306, 0.395, 0.516, 0.156, 0.353]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62121)[0m top1: 0.3605410447761194
[2m[36m(func pid=62121)[0m top5: 0.9137126865671642
[2m[36m(func pid=62121)[0m f1_micro: 0.3605410447761194
[2m[36m(func pid=62121)[0m f1_macro: 0.30711430076833296
[2m[36m(func pid=62121)[0m f1_weighted: 0.386919498135855
[2m[36m(func pid=62121)[0m f1_per_class: [0.238, 0.307, 0.286, 0.49, 0.068, 0.284, 0.4, 0.471, 0.248, 0.28]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=62614)[0m top1: 0.314365671641791
[2m[36m(func pid=62614)[0m top5: 0.8404850746268657
[2m[36m(func pid=62614)[0m f1_micro: 0.314365671641791
[2m[36m(func pid=62614)[0m f1_macro: 0.23385829520068152
[2m[36m(func pid=62614)[0m f1_weighted: 0.32337633373019864
[2m[36m(func pid=62614)[0m f1_per_class: [0.072, 0.421, 0.166, 0.128, 0.111, 0.308, 0.476, 0.526, 0.13, 0.0]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.8680 | Steps: 2 | Val loss: 1.7906 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 2.1111 | Steps: 2 | Val loss: 2.1634 | Batch size: 32 | lr: 0.0001 | Duration: 3.03s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.9019 | Steps: 2 | Val loss: 2.6822 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 1.8064 | Steps: 2 | Val loss: 2.6796 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 02:36:26 (running for 00:12:27.56)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.171 |      0.189 |                   54 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.868 |      0.317 |                   34 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.712 |      0.307 |                   28 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.813 |      0.234 |                   27 |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=55782)[0m top1: 0.22108208955223882
[2m[36m(func pid=55782)[0m top5: 0.8218283582089553
[2m[36m(func pid=55782)[0m f1_micro: 0.22108208955223882
[2m[36m(func pid=55782)[0m f1_macro: 0.19426591261874487
[2m[36m(func pid=55782)[0m f1_weighted: 0.23122314686915058
[2m[36m(func pid=55782)[0m f1_per_class: [0.066, 0.23, 0.21, 0.337, 0.085, 0.307, 0.105, 0.455, 0.0, 0.148]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=60934)[0m top1: 0.36613805970149255
[2m[36m(func pid=60934)[0m top5: 0.8745335820895522
[2m[36m(func pid=60934)[0m f1_micro: 0.36613805970149255
[2m[36m(func pid=60934)[0m f1_macro: 0.31717649918690144
[2m[36m(func pid=60934)[0m f1_weighted: 0.39230464831210154
[2m[36m(func pid=60934)[0m f1_per_class: [0.171, 0.547, 0.349, 0.382, 0.082, 0.33, 0.361, 0.559, 0.148, 0.243]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62121)[0m top1: 0.2728544776119403
[2m[36m(func pid=62121)[0m top5: 0.9011194029850746
[2m[36m(func pid=62121)[0m f1_micro: 0.2728544776119403
[2m[36m(func pid=62121)[0m f1_macro: 0.17353641696698194
[2m[36m(func pid=62121)[0m f1_weighted: 0.2772902003321155
[2m[36m(func pid=62121)[0m f1_per_class: [0.0, 0.237, 0.0, 0.35, 0.064, 0.097, 0.337, 0.401, 0.043, 0.207]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=62614)[0m top1: 0.23740671641791045
[2m[36m(func pid=62614)[0m top5: 0.84375
[2m[36m(func pid=62614)[0m f1_micro: 0.23740671641791045
[2m[36m(func pid=62614)[0m f1_macro: 0.20619905951693807
[2m[36m(func pid=62614)[0m f1_weighted: 0.23480428469993556
[2m[36m(func pid=62614)[0m f1_per_class: [0.094, 0.366, 0.364, 0.101, 0.1, 0.16, 0.299, 0.485, 0.092, 0.0]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.8858 | Steps: 2 | Val loss: 1.7672 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 2.2340 | Steps: 2 | Val loss: 2.1629 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.5985 | Steps: 2 | Val loss: 2.8031 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 2.2044 | Steps: 2 | Val loss: 2.7376 | Batch size: 32 | lr: 0.1 | Duration: 3.01s
== Status ==
Current time: 2024-01-07 02:36:32 (running for 00:12:32.90)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.111 |      0.194 |                   55 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.886 |      0.319 |                   35 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.902 |      0.174 |                   29 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.806 |      0.206 |                   28 |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.37220149253731344
[2m[36m(func pid=60934)[0m top5: 0.8763992537313433
[2m[36m(func pid=60934)[0m f1_micro: 0.3722014925373134
[2m[36m(func pid=60934)[0m f1_macro: 0.3190634515419524
[2m[36m(func pid=60934)[0m f1_weighted: 0.38911393157626734
[2m[36m(func pid=60934)[0m f1_per_class: [0.186, 0.554, 0.301, 0.392, 0.073, 0.341, 0.334, 0.526, 0.169, 0.314]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=55782)[0m top1: 0.22154850746268656
[2m[36m(func pid=55782)[0m top5: 0.824160447761194
[2m[36m(func pid=55782)[0m f1_micro: 0.22154850746268656
[2m[36m(func pid=55782)[0m f1_macro: 0.19576201404181567
[2m[36m(func pid=55782)[0m f1_weighted: 0.23433134161860647
[2m[36m(func pid=55782)[0m f1_per_class: [0.055, 0.245, 0.179, 0.323, 0.083, 0.319, 0.115, 0.454, 0.0, 0.184]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=62121)[0m top1: 0.30550373134328357
[2m[36m(func pid=62121)[0m top5: 0.8894589552238806
[2m[36m(func pid=62121)[0m f1_micro: 0.30550373134328357
[2m[36m(func pid=62121)[0m f1_macro: 0.20459461862561762
[2m[36m(func pid=62121)[0m f1_weighted: 0.2998039819951092
[2m[36m(func pid=62121)[0m f1_per_class: [0.0, 0.251, 0.0, 0.19, 0.079, 0.056, 0.531, 0.532, 0.14, 0.267]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=62614)[0m top1: 0.1599813432835821
[2m[36m(func pid=62614)[0m top5: 0.7835820895522388
[2m[36m(func pid=62614)[0m f1_micro: 0.1599813432835821
[2m[36m(func pid=62614)[0m f1_macro: 0.17171347060214293
[2m[36m(func pid=62614)[0m f1_weighted: 0.11522769992773095
[2m[36m(func pid=62614)[0m f1_per_class: [0.095, 0.349, 0.45, 0.024, 0.107, 0.0, 0.042, 0.475, 0.041, 0.133]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.8098 | Steps: 2 | Val loss: 1.8082 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 2.0683 | Steps: 2 | Val loss: 2.1589 | Batch size: 32 | lr: 0.0001 | Duration: 3.06s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.4367 | Steps: 2 | Val loss: 3.9051 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 1.9159 | Steps: 2 | Val loss: 2.5314 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 02:36:37 (running for 00:12:38.20)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.234 |      0.196 |                   56 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.81  |      0.307 |                   36 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.599 |      0.205 |                   30 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  2.204 |      0.172 |                   29 |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.36427238805970147
[2m[36m(func pid=60934)[0m top5: 0.8642723880597015
[2m[36m(func pid=60934)[0m f1_micro: 0.3642723880597015
[2m[36m(func pid=60934)[0m f1_macro: 0.3072640241423051
[2m[36m(func pid=60934)[0m f1_weighted: 0.3826672072751087
[2m[36m(func pid=60934)[0m f1_per_class: [0.232, 0.542, 0.278, 0.409, 0.066, 0.302, 0.314, 0.567, 0.152, 0.21]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=55782)[0m top1: 0.2178171641791045
[2m[36m(func pid=55782)[0m top5: 0.8306902985074627
[2m[36m(func pid=55782)[0m f1_micro: 0.2178171641791045
[2m[36m(func pid=55782)[0m f1_macro: 0.19603046352036835
[2m[36m(func pid=55782)[0m f1_weighted: 0.2309642723757046
[2m[36m(func pid=55782)[0m f1_per_class: [0.058, 0.253, 0.183, 0.306, 0.079, 0.324, 0.115, 0.442, 0.0, 0.2]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=62121)[0m top1: 0.25326492537313433
[2m[36m(func pid=62121)[0m top5: 0.7597947761194029
[2m[36m(func pid=62121)[0m f1_micro: 0.25326492537313433
[2m[36m(func pid=62121)[0m f1_macro: 0.20473268103860925
[2m[36m(func pid=62121)[0m f1_weighted: 0.29553426571321323
[2m[36m(func pid=62121)[0m f1_per_class: [0.0, 0.332, 0.09, 0.179, 0.129, 0.327, 0.418, 0.335, 0.125, 0.111]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=62614)[0m top1: 0.21828358208955223
[2m[36m(func pid=62614)[0m top5: 0.8194962686567164
[2m[36m(func pid=62614)[0m f1_micro: 0.21828358208955223
[2m[36m(func pid=62614)[0m f1_macro: 0.1737538945974554
[2m[36m(func pid=62614)[0m f1_weighted: 0.17771458662554607
[2m[36m(func pid=62614)[0m f1_per_class: [0.099, 0.453, 0.474, 0.064, 0.034, 0.0, 0.173, 0.427, 0.014, 0.0]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.8888 | Steps: 2 | Val loss: 1.7230 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 2.0819 | Steps: 2 | Val loss: 2.1577 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 1.6918 | Steps: 2 | Val loss: 2.4933 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.7400 | Steps: 2 | Val loss: 5.5191 | Batch size: 32 | lr: 0.01 | Duration: 3.05s
== Status ==
Current time: 2024-01-07 02:36:42 (running for 00:12:43.40)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.068 |      0.196 |                   57 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.889 |      0.349 |                   37 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.437 |      0.205 |                   31 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.916 |      0.174 |                   30 |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.39505597014925375
[2m[36m(func pid=60934)[0m top5: 0.8852611940298507
[2m[36m(func pid=60934)[0m f1_micro: 0.39505597014925375
[2m[36m(func pid=60934)[0m f1_macro: 0.348504205634662
[2m[36m(func pid=60934)[0m f1_weighted: 0.41820757633317945
[2m[36m(func pid=60934)[0m f1_per_class: [0.271, 0.54, 0.293, 0.407, 0.067, 0.32, 0.415, 0.571, 0.172, 0.429]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=55782)[0m top1: 0.21641791044776118
[2m[36m(func pid=55782)[0m top5: 0.8283582089552238
[2m[36m(func pid=55782)[0m f1_micro: 0.21641791044776118
[2m[36m(func pid=55782)[0m f1_macro: 0.19565736929534094
[2m[36m(func pid=55782)[0m f1_weighted: 0.22687585136183147
[2m[36m(func pid=55782)[0m f1_per_class: [0.061, 0.24, 0.182, 0.313, 0.077, 0.331, 0.1, 0.441, 0.0, 0.213]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=62614)[0m top1: 0.3031716417910448
[2m[36m(func pid=62614)[0m top5: 0.8451492537313433
[2m[36m(func pid=62614)[0m f1_micro: 0.3031716417910448
[2m[36m(func pid=62614)[0m f1_macro: 0.21963394669451794
[2m[36m(func pid=62614)[0m f1_weighted: 0.2815883084235659
[2m[36m(func pid=62614)[0m f1_per_class: [0.104, 0.482, 0.462, 0.081, 0.0, 0.115, 0.428, 0.525, 0.0, 0.0]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=62121)[0m top1: 0.1333955223880597
[2m[36m(func pid=62121)[0m top5: 0.7033582089552238
[2m[36m(func pid=62121)[0m f1_micro: 0.1333955223880597
[2m[36m(func pid=62121)[0m f1_macro: 0.1269222628967686
[2m[36m(func pid=62121)[0m f1_weighted: 0.15187807230284395
[2m[36m(func pid=62121)[0m f1_per_class: [0.073, 0.364, 0.097, 0.192, 0.108, 0.102, 0.028, 0.152, 0.112, 0.043]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 1.0202 | Steps: 2 | Val loss: 1.7232 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 2.0697 | Steps: 2 | Val loss: 2.1530 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 2.3395 | Steps: 2 | Val loss: 2.5860 | Batch size: 32 | lr: 0.1 | Duration: 2.78s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.4004 | Steps: 2 | Val loss: 4.5950 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 02:36:47 (running for 00:12:48.61)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.082 |      0.196 |                   58 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  1.02  |      0.338 |                   38 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.74  |      0.127 |                   32 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.692 |      0.22  |                   31 |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.38992537313432835
[2m[36m(func pid=60934)[0m top5: 0.8871268656716418
[2m[36m(func pid=60934)[0m f1_micro: 0.38992537313432835
[2m[36m(func pid=60934)[0m f1_macro: 0.3382530559694862
[2m[36m(func pid=60934)[0m f1_weighted: 0.4174432702822268
[2m[36m(func pid=60934)[0m f1_per_class: [0.213, 0.538, 0.278, 0.399, 0.06, 0.306, 0.431, 0.566, 0.176, 0.414]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=55782)[0m top1: 0.2196828358208955
[2m[36m(func pid=55782)[0m top5: 0.8334888059701493
[2m[36m(func pid=55782)[0m f1_micro: 0.2196828358208955
[2m[36m(func pid=55782)[0m f1_macro: 0.1986882338392232
[2m[36m(func pid=55782)[0m f1_weighted: 0.23079137803688968
[2m[36m(func pid=55782)[0m f1_per_class: [0.066, 0.24, 0.19, 0.322, 0.075, 0.323, 0.106, 0.444, 0.0, 0.222]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=62614)[0m top1: 0.292910447761194
[2m[36m(func pid=62614)[0m top5: 0.8334888059701493
[2m[36m(func pid=62614)[0m f1_micro: 0.292910447761194
[2m[36m(func pid=62614)[0m f1_macro: 0.22403658355086464
[2m[36m(func pid=62614)[0m f1_weighted: 0.2527556789409579
[2m[36m(func pid=62614)[0m f1_per_class: [0.132, 0.462, 0.519, 0.07, 0.0, 0.228, 0.308, 0.506, 0.014, 0.0]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=62121)[0m top1: 0.14878731343283583
[2m[36m(func pid=62121)[0m top5: 0.7392723880597015
[2m[36m(func pid=62121)[0m f1_micro: 0.14878731343283583
[2m[36m(func pid=62121)[0m f1_macro: 0.13172145479328864
[2m[36m(func pid=62121)[0m f1_weighted: 0.1422673332289269
[2m[36m(func pid=62121)[0m f1_per_class: [0.082, 0.133, 0.136, 0.304, 0.103, 0.061, 0.006, 0.298, 0.133, 0.059]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.9033 | Steps: 2 | Val loss: 1.9426 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 2.0438 | Steps: 2 | Val loss: 2.1530 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.4054 | Steps: 2 | Val loss: 3.5851 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 1.5093 | Steps: 2 | Val loss: 2.5622 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
== Status ==
Current time: 2024-01-07 02:36:53 (running for 00:12:53.95)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.07  |      0.199 |                   59 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.903 |      0.27  |                   39 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.4   |      0.132 |                   33 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  2.34  |      0.224 |                   32 |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.31576492537313433
[2m[36m(func pid=60934)[0m top5: 0.8530783582089553
[2m[36m(func pid=60934)[0m f1_micro: 0.31576492537313433
[2m[36m(func pid=60934)[0m f1_macro: 0.27031972154393596
[2m[36m(func pid=60934)[0m f1_weighted: 0.3406939837042136
[2m[36m(func pid=60934)[0m f1_per_class: [0.14, 0.574, 0.262, 0.375, 0.068, 0.284, 0.223, 0.466, 0.135, 0.176]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=55782)[0m top1: 0.21875
[2m[36m(func pid=55782)[0m top5: 0.8316231343283582
[2m[36m(func pid=55782)[0m f1_micro: 0.21875
[2m[36m(func pid=55782)[0m f1_macro: 0.19478121093602876
[2m[36m(func pid=55782)[0m f1_weighted: 0.22997241531208223
[2m[36m(func pid=55782)[0m f1_per_class: [0.066, 0.229, 0.19, 0.326, 0.074, 0.331, 0.103, 0.449, 0.0, 0.18]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=62121)[0m top1: 0.16791044776119404
[2m[36m(func pid=62121)[0m top5: 0.8078358208955224
[2m[36m(func pid=62121)[0m f1_micro: 0.16791044776119404
[2m[36m(func pid=62121)[0m f1_macro: 0.15042610675505302
[2m[36m(func pid=62121)[0m f1_weighted: 0.1539122589736441
[2m[36m(func pid=62121)[0m f1_per_class: [0.118, 0.026, 0.25, 0.329, 0.087, 0.111, 0.059, 0.307, 0.117, 0.101]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=62614)[0m top1: 0.21875
[2m[36m(func pid=62614)[0m top5: 0.8157649253731343
[2m[36m(func pid=62614)[0m f1_micro: 0.21875
[2m[36m(func pid=62614)[0m f1_macro: 0.18799644166681337
[2m[36m(func pid=62614)[0m f1_weighted: 0.15013159485957953
[2m[36m(func pid=62614)[0m f1_per_class: [0.111, 0.468, 0.636, 0.013, 0.034, 0.008, 0.106, 0.422, 0.081, 0.0]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 1.0253 | Steps: 2 | Val loss: 1.8077 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 2.0884 | Steps: 2 | Val loss: 2.1512 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 2.3600 | Steps: 2 | Val loss: 2.4948 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.9837 | Steps: 2 | Val loss: 3.5265 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
== Status ==
Current time: 2024-01-07 02:36:58 (running for 00:12:59.19)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.044 |      0.195 |                   60 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  1.025 |      0.323 |                   40 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.405 |      0.15  |                   34 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.509 |      0.188 |                   33 |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.373134328358209
[2m[36m(func pid=60934)[0m top5: 0.8759328358208955
[2m[36m(func pid=60934)[0m f1_micro: 0.373134328358209
[2m[36m(func pid=60934)[0m f1_macro: 0.32272272406814134
[2m[36m(func pid=60934)[0m f1_weighted: 0.40542899524439513
[2m[36m(func pid=60934)[0m f1_per_class: [0.162, 0.562, 0.227, 0.38, 0.069, 0.321, 0.399, 0.553, 0.171, 0.385]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=55782)[0m top1: 0.2140858208955224
[2m[36m(func pid=55782)[0m top5: 0.8311567164179104
[2m[36m(func pid=55782)[0m f1_micro: 0.2140858208955224
[2m[36m(func pid=55782)[0m f1_macro: 0.18940940231312703
[2m[36m(func pid=55782)[0m f1_weighted: 0.22553539769767766
[2m[36m(func pid=55782)[0m f1_per_class: [0.063, 0.22, 0.191, 0.324, 0.073, 0.322, 0.1, 0.446, 0.0, 0.154]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=62614)[0m top1: 0.15858208955223882
[2m[36m(func pid=62614)[0m top5: 0.8115671641791045
[2m[36m(func pid=62614)[0m f1_micro: 0.15858208955223882
[2m[36m(func pid=62614)[0m f1_macro: 0.17954770606251982
[2m[36m(func pid=62614)[0m f1_weighted: 0.10984265921440477
[2m[36m(func pid=62614)[0m f1_per_class: [0.087, 0.391, 0.667, 0.0, 0.065, 0.0, 0.033, 0.384, 0.099, 0.069]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=62121)[0m top1: 0.17024253731343283
[2m[36m(func pid=62121)[0m top5: 0.8125
[2m[36m(func pid=62121)[0m f1_micro: 0.17024253731343283
[2m[36m(func pid=62121)[0m f1_macro: 0.18743864015500916
[2m[36m(func pid=62121)[0m f1_weighted: 0.19892420636841027
[2m[36m(func pid=62121)[0m f1_per_class: [0.094, 0.031, 0.429, 0.268, 0.089, 0.171, 0.23, 0.347, 0.143, 0.074]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.8668 | Steps: 2 | Val loss: 1.7658 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 2.0526 | Steps: 2 | Val loss: 2.1475 | Batch size: 32 | lr: 0.0001 | Duration: 2.76s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 1.5690 | Steps: 2 | Val loss: 2.4485 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.2893 | Steps: 2 | Val loss: 4.2545 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
== Status ==
Current time: 2024-01-07 02:37:03 (running for 00:13:04.52)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.088 |      0.189 |                   61 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.867 |      0.328 |                   41 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.984 |      0.187 |                   35 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  2.36  |      0.18  |                   34 |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.38386194029850745
[2m[36m(func pid=60934)[0m top5: 0.8885261194029851
[2m[36m(func pid=60934)[0m f1_micro: 0.38386194029850745
[2m[36m(func pid=60934)[0m f1_macro: 0.3281843064231293
[2m[36m(func pid=60934)[0m f1_weighted: 0.4097566762197194
[2m[36m(func pid=60934)[0m f1_per_class: [0.167, 0.556, 0.268, 0.356, 0.08, 0.346, 0.432, 0.536, 0.157, 0.382]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=55782)[0m top1: 0.22154850746268656
[2m[36m(func pid=55782)[0m top5: 0.8330223880597015
[2m[36m(func pid=55782)[0m f1_micro: 0.22154850746268656
[2m[36m(func pid=55782)[0m f1_macro: 0.19808247803287643
[2m[36m(func pid=55782)[0m f1_weighted: 0.23461156577735068
[2m[36m(func pid=55782)[0m f1_per_class: [0.069, 0.228, 0.206, 0.33, 0.074, 0.322, 0.119, 0.444, 0.0, 0.189]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=62614)[0m top1: 0.19682835820895522
[2m[36m(func pid=62614)[0m top5: 0.7994402985074627
[2m[36m(func pid=62614)[0m f1_micro: 0.1968283582089552
[2m[36m(func pid=62614)[0m f1_macro: 0.21417224056500744
[2m[36m(func pid=62614)[0m f1_weighted: 0.1859840002859633
[2m[36m(func pid=62614)[0m f1_per_class: [0.084, 0.474, 0.692, 0.003, 0.032, 0.0, 0.22, 0.486, 0.089, 0.061]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=62121)[0m top1: 0.13759328358208955
[2m[36m(func pid=62121)[0m top5: 0.7402052238805971
[2m[36m(func pid=62121)[0m f1_micro: 0.13759328358208955
[2m[36m(func pid=62121)[0m f1_macro: 0.15874476906809898
[2m[36m(func pid=62121)[0m f1_weighted: 0.14303485936235175
[2m[36m(func pid=62121)[0m f1_per_class: [0.091, 0.084, 0.519, 0.228, 0.099, 0.274, 0.076, 0.0, 0.134, 0.084]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.8721 | Steps: 2 | Val loss: 1.8009 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 2.1253 | Steps: 2 | Val loss: 2.1470 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 1.5765 | Steps: 2 | Val loss: 2.5445 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.6108 | Steps: 2 | Val loss: 4.2193 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 02:37:09 (running for 00:13:09.85)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.053 |      0.198 |                   62 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.872 |      0.331 |                   42 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.289 |      0.159 |                   36 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.569 |      0.214 |                   35 |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.37826492537313433
[2m[36m(func pid=60934)[0m top5: 0.8801305970149254
[2m[36m(func pid=60934)[0m f1_micro: 0.37826492537313433
[2m[36m(func pid=60934)[0m f1_macro: 0.33057694117947467
[2m[36m(func pid=60934)[0m f1_weighted: 0.4016348559056033
[2m[36m(func pid=60934)[0m f1_per_class: [0.156, 0.555, 0.278, 0.301, 0.083, 0.344, 0.449, 0.571, 0.183, 0.386]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=55782)[0m top1: 0.22061567164179105
[2m[36m(func pid=55782)[0m top5: 0.8362873134328358
[2m[36m(func pid=55782)[0m f1_micro: 0.22061567164179105
[2m[36m(func pid=55782)[0m f1_macro: 0.19915839892915785
[2m[36m(func pid=55782)[0m f1_weighted: 0.23680288972937577
[2m[36m(func pid=55782)[0m f1_per_class: [0.065, 0.229, 0.198, 0.328, 0.072, 0.316, 0.131, 0.433, 0.0, 0.22]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=62614)[0m top1: 0.2555970149253731
[2m[36m(func pid=62614)[0m top5: 0.8097014925373134
[2m[36m(func pid=62614)[0m f1_micro: 0.2555970149253731
[2m[36m(func pid=62614)[0m f1_macro: 0.2413176986920446
[2m[36m(func pid=62614)[0m f1_weighted: 0.25903424294556593
[2m[36m(func pid=62614)[0m f1_per_class: [0.082, 0.477, 0.692, 0.055, 0.0, 0.174, 0.352, 0.519, 0.0, 0.061]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=62121)[0m top1: 0.12733208955223882
[2m[36m(func pid=62121)[0m top5: 0.7425373134328358
[2m[36m(func pid=62121)[0m f1_micro: 0.12733208955223882
[2m[36m(func pid=62121)[0m f1_macro: 0.1645543139788499
[2m[36m(func pid=62121)[0m f1_weighted: 0.13565978955871152
[2m[36m(func pid=62121)[0m f1_per_class: [0.095, 0.18, 0.5, 0.207, 0.07, 0.185, 0.021, 0.156, 0.103, 0.128]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.9648 | Steps: 2 | Val loss: 1.8196 | Batch size: 32 | lr: 0.001 | Duration: 3.05s
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 2.1186 | Steps: 2 | Val loss: 2.1506 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 1.7811 | Steps: 2 | Val loss: 2.5010 | Batch size: 32 | lr: 0.1 | Duration: 2.76s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.7303 | Steps: 2 | Val loss: 4.0840 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 02:37:14 (running for 00:13:15.31)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.125 |      0.199 |                   63 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.965 |      0.326 |                   43 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.611 |      0.165 |                   37 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.576 |      0.241 |                   36 |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.36800373134328357
[2m[36m(func pid=60934)[0m top5: 0.8805970149253731
[2m[36m(func pid=60934)[0m f1_micro: 0.3680037313432836
[2m[36m(func pid=60934)[0m f1_macro: 0.32559068633513466
[2m[36m(func pid=60934)[0m f1_weighted: 0.3872672609282872
[2m[36m(func pid=60934)[0m f1_per_class: [0.147, 0.569, 0.297, 0.248, 0.08, 0.316, 0.455, 0.567, 0.159, 0.417]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=55782)[0m top1: 0.2150186567164179
[2m[36m(func pid=55782)[0m top5: 0.832089552238806
[2m[36m(func pid=55782)[0m f1_micro: 0.2150186567164179
[2m[36m(func pid=55782)[0m f1_macro: 0.19606895728307056
[2m[36m(func pid=55782)[0m f1_weighted: 0.23289094149703074
[2m[36m(func pid=55782)[0m f1_per_class: [0.061, 0.215, 0.188, 0.323, 0.071, 0.293, 0.14, 0.429, 0.0, 0.241]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=62614)[0m top1: 0.2826492537313433
[2m[36m(func pid=62614)[0m top5: 0.8097014925373134
[2m[36m(func pid=62614)[0m f1_micro: 0.2826492537313433
[2m[36m(func pid=62614)[0m f1_macro: 0.28555652775972673
[2m[36m(func pid=62614)[0m f1_weighted: 0.28676966010340915
[2m[36m(func pid=62614)[0m f1_per_class: [0.09, 0.476, 0.741, 0.076, 0.0, 0.307, 0.365, 0.526, 0.0, 0.276]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=62121)[0m top1: 0.12546641791044777
[2m[36m(func pid=62121)[0m top5: 0.8815298507462687
[2m[36m(func pid=62121)[0m f1_micro: 0.12546641791044777
[2m[36m(func pid=62121)[0m f1_macro: 0.18089412175262848
[2m[36m(func pid=62121)[0m f1_weighted: 0.1406275392671261
[2m[36m(func pid=62121)[0m f1_per_class: [0.099, 0.228, 0.609, 0.186, 0.056, 0.053, 0.101, 0.0, 0.077, 0.4]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.6312 | Steps: 2 | Val loss: 1.8013 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 1.4463 | Steps: 2 | Val loss: 2.3726 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 2.0673 | Steps: 2 | Val loss: 2.1528 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.2514 | Steps: 2 | Val loss: 6.6814 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=60934)[0m top1: 0.365205223880597
[2m[36m(func pid=60934)[0m top5: 0.8950559701492538
[2m[36m(func pid=60934)[0m f1_micro: 0.365205223880597
[2m[36m(func pid=60934)[0m f1_macro: 0.332816360683951
[2m[36m(func pid=60934)[0m f1_weighted: 0.39196563181580796
[2m[36m(func pid=60934)[0m f1_per_class: [0.148, 0.554, 0.364, 0.253, 0.086, 0.316, 0.474, 0.575, 0.134, 0.424]
== Status ==
Current time: 2024-01-07 02:37:19 (running for 00:13:20.62)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.119 |      0.196 |                   64 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.631 |      0.333 |                   44 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.73  |      0.181 |                   38 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.781 |      0.286 |                   37 |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62614)[0m top1: 0.2947761194029851
[2m[36m(func pid=62614)[0m top5: 0.8348880597014925
[2m[36m(func pid=62614)[0m f1_micro: 0.2947761194029851
[2m[36m(func pid=62614)[0m f1_macro: 0.31472641062532314
[2m[36m(func pid=62614)[0m f1_weighted: 0.32103293920919224
[2m[36m(func pid=62614)[0m f1_per_class: [0.1, 0.426, 0.8, 0.178, 0.03, 0.346, 0.387, 0.52, 0.084, 0.276]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=55782)[0m top1: 0.2103544776119403
[2m[36m(func pid=55782)[0m top5: 0.8292910447761194
[2m[36m(func pid=55782)[0m f1_micro: 0.2103544776119403
[2m[36m(func pid=55782)[0m f1_macro: 0.1915427880243054
[2m[36m(func pid=55782)[0m f1_weighted: 0.22934223970037151
[2m[36m(func pid=55782)[0m f1_per_class: [0.062, 0.231, 0.183, 0.32, 0.068, 0.274, 0.128, 0.435, 0.023, 0.192]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=62121)[0m top1: 0.1021455223880597
[2m[36m(func pid=62121)[0m top5: 0.7117537313432836
[2m[36m(func pid=62121)[0m f1_micro: 0.10214552238805971
[2m[36m(func pid=62121)[0m f1_macro: 0.1523596483794723
[2m[36m(func pid=62121)[0m f1_weighted: 0.09434380364085435
[2m[36m(func pid=62121)[0m f1_per_class: [0.086, 0.255, 0.645, 0.126, 0.049, 0.016, 0.006, 0.0, 0.08, 0.261]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.6972 | Steps: 2 | Val loss: 1.8510 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 1.6920 | Steps: 2 | Val loss: 2.4412 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 1.9944 | Steps: 2 | Val loss: 2.1497 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.2024 | Steps: 2 | Val loss: 6.2182 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
== Status ==
Current time: 2024-01-07 02:37:25 (running for 00:13:25.90)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.067 |      0.192 |                   65 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.697 |      0.321 |                   45 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.251 |      0.152 |                   39 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.446 |      0.315 |                   38 |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.34328358208955223
[2m[36m(func pid=60934)[0m top5: 0.8838619402985075
[2m[36m(func pid=60934)[0m f1_micro: 0.34328358208955223
[2m[36m(func pid=60934)[0m f1_macro: 0.3205959597891382
[2m[36m(func pid=60934)[0m f1_weighted: 0.36732553921110966
[2m[36m(func pid=60934)[0m f1_per_class: [0.145, 0.546, 0.4, 0.244, 0.085, 0.348, 0.398, 0.551, 0.155, 0.333]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62614)[0m top1: 0.21688432835820895
[2m[36m(func pid=62614)[0m top5: 0.8563432835820896
[2m[36m(func pid=62614)[0m f1_micro: 0.21688432835820895
[2m[36m(func pid=62614)[0m f1_macro: 0.25634675987528305
[2m[36m(func pid=62614)[0m f1_weighted: 0.2062897210332459
[2m[36m(func pid=62614)[0m f1_per_class: [0.104, 0.354, 0.833, 0.216, 0.099, 0.162, 0.103, 0.391, 0.087, 0.214]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=55782)[0m top1: 0.20522388059701493
[2m[36m(func pid=55782)[0m top5: 0.8325559701492538
[2m[36m(func pid=55782)[0m f1_micro: 0.20522388059701493
[2m[36m(func pid=55782)[0m f1_macro: 0.18834538255377736
[2m[36m(func pid=55782)[0m f1_weighted: 0.2218250606947222
[2m[36m(func pid=55782)[0m f1_per_class: [0.061, 0.217, 0.198, 0.319, 0.065, 0.271, 0.11, 0.447, 0.022, 0.171]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=62121)[0m top1: 0.11147388059701492
[2m[36m(func pid=62121)[0m top5: 0.7182835820895522
[2m[36m(func pid=62121)[0m f1_micro: 0.11147388059701491
[2m[36m(func pid=62121)[0m f1_macro: 0.138039648218138
[2m[36m(func pid=62121)[0m f1_weighted: 0.09897921532791601
[2m[36m(func pid=62121)[0m f1_per_class: [0.106, 0.27, 0.444, 0.125, 0.073, 0.062, 0.0, 0.0, 0.077, 0.222]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.9569 | Steps: 2 | Val loss: 1.8079 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 1.3339 | Steps: 2 | Val loss: 2.6315 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 2.0124 | Steps: 2 | Val loss: 2.1441 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.2112 | Steps: 2 | Val loss: 4.5557 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 02:37:30 (running for 00:13:31.16)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.994 |      0.188 |                   66 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.957 |      0.314 |                   46 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.202 |      0.138 |                   40 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.692 |      0.256 |                   39 |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.35401119402985076
[2m[36m(func pid=60934)[0m top5: 0.878731343283582
[2m[36m(func pid=60934)[0m f1_micro: 0.35401119402985076
[2m[36m(func pid=60934)[0m f1_macro: 0.3138576591810489
[2m[36m(func pid=60934)[0m f1_weighted: 0.3749947498009904
[2m[36m(func pid=60934)[0m f1_per_class: [0.204, 0.549, 0.311, 0.306, 0.093, 0.315, 0.376, 0.563, 0.135, 0.286]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62614)[0m top1: 0.21082089552238806
[2m[36m(func pid=62614)[0m top5: 0.840018656716418
[2m[36m(func pid=62614)[0m f1_micro: 0.21082089552238809
[2m[36m(func pid=62614)[0m f1_macro: 0.22860871380945444
[2m[36m(func pid=62614)[0m f1_weighted: 0.16481021401819895
[2m[36m(func pid=62614)[0m f1_per_class: [0.096, 0.436, 0.846, 0.186, 0.0, 0.0, 0.006, 0.403, 0.099, 0.214]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=55782)[0m top1: 0.20615671641791045
[2m[36m(func pid=55782)[0m top5: 0.8390858208955224
[2m[36m(func pid=55782)[0m f1_micro: 0.20615671641791045
[2m[36m(func pid=55782)[0m f1_macro: 0.18973771155362346
[2m[36m(func pid=55782)[0m f1_weighted: 0.22010111999647064
[2m[36m(func pid=55782)[0m f1_per_class: [0.072, 0.214, 0.204, 0.315, 0.066, 0.291, 0.103, 0.444, 0.022, 0.168]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=62121)[0m top1: 0.14878731343283583
[2m[36m(func pid=62121)[0m top5: 0.7392723880597015
[2m[36m(func pid=62121)[0m f1_micro: 0.14878731343283583
[2m[36m(func pid=62121)[0m f1_macro: 0.15469699025905753
[2m[36m(func pid=62121)[0m f1_weighted: 0.1502434982660619
[2m[36m(func pid=62121)[0m f1_per_class: [0.122, 0.282, 0.247, 0.254, 0.079, 0.073, 0.0, 0.227, 0.083, 0.179]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.6157 | Steps: 2 | Val loss: 1.8904 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 1.4026 | Steps: 2 | Val loss: 2.8008 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 2.0130 | Steps: 2 | Val loss: 2.1352 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.2362 | Steps: 2 | Val loss: 4.7401 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 02:37:35 (running for 00:13:36.27)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.012 |      0.19  |                   67 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.616 |      0.304 |                   47 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.211 |      0.155 |                   41 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.334 |      0.229 |                   40 |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.3362873134328358
[2m[36m(func pid=60934)[0m top5: 0.8628731343283582
[2m[36m(func pid=60934)[0m f1_micro: 0.3362873134328358
[2m[36m(func pid=60934)[0m f1_macro: 0.3042504454202487
[2m[36m(func pid=60934)[0m f1_weighted: 0.35270239459732555
[2m[36m(func pid=60934)[0m f1_per_class: [0.234, 0.545, 0.36, 0.326, 0.081, 0.291, 0.314, 0.425, 0.168, 0.298]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62614)[0m top1: 0.20055970149253732
[2m[36m(func pid=62614)[0m top5: 0.8236940298507462
[2m[36m(func pid=62614)[0m f1_micro: 0.20055970149253732
[2m[36m(func pid=62614)[0m f1_macro: 0.22213134402083315
[2m[36m(func pid=62614)[0m f1_weighted: 0.16189660522530752
[2m[36m(func pid=62614)[0m f1_per_class: [0.098, 0.432, 0.815, 0.162, 0.0, 0.008, 0.009, 0.482, 0.067, 0.148]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=55782)[0m top1: 0.21921641791044777
[2m[36m(func pid=55782)[0m top5: 0.8423507462686567
[2m[36m(func pid=55782)[0m f1_micro: 0.21921641791044777
[2m[36m(func pid=55782)[0m f1_macro: 0.20471295364998948
[2m[36m(func pid=55782)[0m f1_weighted: 0.23700357561775223
[2m[36m(func pid=55782)[0m f1_per_class: [0.076, 0.205, 0.229, 0.322, 0.064, 0.325, 0.14, 0.46, 0.021, 0.206]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=62121)[0m top1: 0.17490671641791045
[2m[36m(func pid=62121)[0m top5: 0.7178171641791045
[2m[36m(func pid=62121)[0m f1_micro: 0.17490671641791045
[2m[36m(func pid=62121)[0m f1_macro: 0.15007220320945353
[2m[36m(func pid=62121)[0m f1_weighted: 0.1722108333055526
[2m[36m(func pid=62121)[0m f1_per_class: [0.127, 0.323, 0.203, 0.345, 0.08, 0.067, 0.0, 0.047, 0.087, 0.221]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.8150 | Steps: 2 | Val loss: 1.8420 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 1.9501 | Steps: 2 | Val loss: 2.4259 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 1.9771 | Steps: 2 | Val loss: 2.1286 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.3733 | Steps: 2 | Val loss: 5.8303 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 02:37:40 (running for 00:13:41.38)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.013 |      0.205 |                   68 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.815 |      0.324 |                   48 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.236 |      0.15  |                   42 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.403 |      0.222 |                   41 |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.3614738805970149
[2m[36m(func pid=60934)[0m top5: 0.8773320895522388
[2m[36m(func pid=60934)[0m f1_micro: 0.3614738805970149
[2m[36m(func pid=60934)[0m f1_macro: 0.32372187775109484
[2m[36m(func pid=60934)[0m f1_weighted: 0.38392718058105524
[2m[36m(func pid=60934)[0m f1_per_class: [0.202, 0.551, 0.349, 0.34, 0.086, 0.319, 0.381, 0.475, 0.174, 0.36]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62614)[0m top1: 0.2719216417910448
[2m[36m(func pid=62614)[0m top5: 0.8530783582089553
[2m[36m(func pid=62614)[0m f1_micro: 0.2719216417910448
[2m[36m(func pid=62614)[0m f1_macro: 0.2600748818053459
[2m[36m(func pid=62614)[0m f1_weighted: 0.24677567437359507
[2m[36m(func pid=62614)[0m f1_per_class: [0.134, 0.448, 0.8, 0.305, 0.024, 0.0, 0.163, 0.405, 0.046, 0.276]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=55782)[0m top1: 0.228544776119403
[2m[36m(func pid=55782)[0m top5: 0.8456156716417911
[2m[36m(func pid=55782)[0m f1_micro: 0.228544776119403
[2m[36m(func pid=55782)[0m f1_macro: 0.21325254921920572
[2m[36m(func pid=55782)[0m f1_weighted: 0.24900050189000789
[2m[36m(func pid=55782)[0m f1_per_class: [0.078, 0.197, 0.227, 0.33, 0.064, 0.333, 0.173, 0.457, 0.021, 0.253]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=62121)[0m top1: 0.19496268656716417
[2m[36m(func pid=62121)[0m top5: 0.7192164179104478
[2m[36m(func pid=62121)[0m f1_micro: 0.19496268656716417
[2m[36m(func pid=62121)[0m f1_macro: 0.16817503298479652
[2m[36m(func pid=62121)[0m f1_weighted: 0.19468043738738217
[2m[36m(func pid=62121)[0m f1_per_class: [0.234, 0.396, 0.24, 0.406, 0.059, 0.008, 0.0, 0.0, 0.079, 0.26]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.6660 | Steps: 2 | Val loss: 1.7475 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 1.5822 | Steps: 2 | Val loss: 2.2397 | Batch size: 32 | lr: 0.1 | Duration: 2.78s
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 2.0095 | Steps: 2 | Val loss: 2.1269 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.4257 | Steps: 2 | Val loss: 3.1660 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 02:37:45 (running for 00:13:46.77)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.977 |      0.213 |                   69 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.666 |      0.336 |                   49 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.373 |      0.168 |                   43 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.95  |      0.26  |                   42 |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.38013059701492535
[2m[36m(func pid=60934)[0m top5: 0.8992537313432836
[2m[36m(func pid=60934)[0m f1_micro: 0.38013059701492535
[2m[36m(func pid=60934)[0m f1_macro: 0.33558984063706637
[2m[36m(func pid=60934)[0m f1_weighted: 0.4020167135068197
[2m[36m(func pid=60934)[0m f1_per_class: [0.189, 0.539, 0.328, 0.354, 0.113, 0.331, 0.423, 0.52, 0.148, 0.41]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62614)[0m top1: 0.29151119402985076
[2m[36m(func pid=62614)[0m top5: 0.8847947761194029
[2m[36m(func pid=62614)[0m f1_micro: 0.29151119402985076
[2m[36m(func pid=62614)[0m f1_macro: 0.28838574754931345
[2m[36m(func pid=62614)[0m f1_weighted: 0.2899872158609025
[2m[36m(func pid=62614)[0m f1_per_class: [0.136, 0.324, 0.8, 0.369, 0.072, 0.008, 0.308, 0.385, 0.118, 0.364]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=55782)[0m top1: 0.23507462686567165
[2m[36m(func pid=55782)[0m top5: 0.8484141791044776
[2m[36m(func pid=55782)[0m f1_micro: 0.23507462686567163
[2m[36m(func pid=55782)[0m f1_macro: 0.21974888175431267
[2m[36m(func pid=55782)[0m f1_weighted: 0.2583498002823637
[2m[36m(func pid=55782)[0m f1_per_class: [0.078, 0.182, 0.227, 0.343, 0.065, 0.339, 0.195, 0.456, 0.042, 0.27]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=62121)[0m top1: 0.24207089552238806
[2m[36m(func pid=62121)[0m top5: 0.8689365671641791
[2m[36m(func pid=62121)[0m f1_micro: 0.24207089552238806
[2m[36m(func pid=62121)[0m f1_macro: 0.19668356547363536
[2m[36m(func pid=62121)[0m f1_weighted: 0.2543435042775873
[2m[36m(func pid=62121)[0m f1_per_class: [0.222, 0.381, 0.511, 0.466, 0.055, 0.016, 0.149, 0.016, 0.084, 0.067]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.7976 | Steps: 2 | Val loss: 1.7583 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 2.9302 | Steps: 2 | Val loss: 1.9432 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 1.9847 | Steps: 2 | Val loss: 2.1278 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.2530 | Steps: 2 | Val loss: 2.3281 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 02:37:51 (running for 00:13:52.13)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  2.009 |      0.22  |                   70 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.798 |      0.336 |                   50 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.426 |      0.197 |                   44 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.582 |      0.288 |                   43 |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.38013059701492535
[2m[36m(func pid=60934)[0m top5: 0.9020522388059702
[2m[36m(func pid=60934)[0m f1_micro: 0.38013059701492535
[2m[36m(func pid=60934)[0m f1_macro: 0.33621291426045496
[2m[36m(func pid=60934)[0m f1_weighted: 0.4090888434454268
[2m[36m(func pid=60934)[0m f1_per_class: [0.166, 0.545, 0.328, 0.351, 0.111, 0.289, 0.464, 0.522, 0.14, 0.448]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62614)[0m top1: 0.41697761194029853
[2m[36m(func pid=62614)[0m top5: 0.8899253731343284
[2m[36m(func pid=62614)[0m f1_micro: 0.41697761194029853
[2m[36m(func pid=62614)[0m f1_macro: 0.35337361898849273
[2m[36m(func pid=62614)[0m f1_weighted: 0.4277749345118809
[2m[36m(func pid=62614)[0m f1_per_class: [0.111, 0.513, 0.667, 0.36, 0.052, 0.287, 0.544, 0.527, 0.073, 0.4]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=55782)[0m top1: 0.228544776119403
[2m[36m(func pid=55782)[0m top5: 0.8498134328358209
[2m[36m(func pid=55782)[0m f1_micro: 0.228544776119403
[2m[36m(func pid=55782)[0m f1_macro: 0.21211687063357934
[2m[36m(func pid=55782)[0m f1_weighted: 0.24822325720082222
[2m[36m(func pid=55782)[0m f1_per_class: [0.075, 0.183, 0.216, 0.342, 0.065, 0.337, 0.167, 0.445, 0.021, 0.27]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=62121)[0m top1: 0.408115671641791
[2m[36m(func pid=62121)[0m top5: 0.9291044776119403
[2m[36m(func pid=62121)[0m f1_micro: 0.408115671641791
[2m[36m(func pid=62121)[0m f1_macro: 0.263202987511919
[2m[36m(func pid=62121)[0m f1_weighted: 0.4054665908871155
[2m[36m(func pid=62121)[0m f1_per_class: [0.239, 0.36, 0.324, 0.51, 0.062, 0.039, 0.576, 0.194, 0.132, 0.196]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.7398 | Steps: 2 | Val loss: 2.1557 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 1.6420 | Steps: 2 | Val loss: 2.0648 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 1.9436 | Steps: 2 | Val loss: 2.1288 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.2997 | Steps: 2 | Val loss: 2.4833 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 02:37:56 (running for 00:13:57.36)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.985 |      0.212 |                   71 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.74  |      0.261 |                   51 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.253 |      0.263 |                   45 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  2.93  |      0.353 |                   44 |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.269589552238806
[2m[36m(func pid=60934)[0m top5: 0.8540111940298507
[2m[36m(func pid=60934)[0m f1_micro: 0.269589552238806
[2m[36m(func pid=60934)[0m f1_macro: 0.26074747871440396
[2m[36m(func pid=60934)[0m f1_weighted: 0.298057824117054
[2m[36m(func pid=60934)[0m f1_per_class: [0.123, 0.523, 0.357, 0.277, 0.095, 0.238, 0.206, 0.533, 0.134, 0.12]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62614)[0m top1: 0.333955223880597
[2m[36m(func pid=62614)[0m top5: 0.8796641791044776
[2m[36m(func pid=62614)[0m f1_micro: 0.333955223880597
[2m[36m(func pid=62614)[0m f1_macro: 0.28155982846873084
[2m[36m(func pid=62614)[0m f1_weighted: 0.36012495711242504
[2m[36m(func pid=62614)[0m f1_per_class: [0.106, 0.482, 0.19, 0.299, 0.068, 0.334, 0.387, 0.525, 0.046, 0.377]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=55782)[0m top1: 0.22108208955223882
[2m[36m(func pid=55782)[0m top5: 0.8456156716417911
[2m[36m(func pid=55782)[0m f1_micro: 0.22108208955223882
[2m[36m(func pid=55782)[0m f1_macro: 0.2071509681020151
[2m[36m(func pid=55782)[0m f1_weighted: 0.23361489573801947
[2m[36m(func pid=55782)[0m f1_per_class: [0.072, 0.192, 0.214, 0.343, 0.065, 0.324, 0.115, 0.45, 0.04, 0.257]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=62121)[0m top1: 0.3810634328358209
[2m[36m(func pid=62121)[0m top5: 0.9253731343283582
[2m[36m(func pid=62121)[0m f1_micro: 0.3810634328358209
[2m[36m(func pid=62121)[0m f1_macro: 0.2814904080109628
[2m[36m(func pid=62121)[0m f1_weighted: 0.394235067520824
[2m[36m(func pid=62121)[0m f1_per_class: [0.164, 0.346, 0.24, 0.443, 0.067, 0.124, 0.528, 0.437, 0.165, 0.3]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.5299 | Steps: 2 | Val loss: 1.9722 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 1.4371 | Steps: 2 | Val loss: 2.1151 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 1.9809 | Steps: 2 | Val loss: 2.1279 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.4476 | Steps: 2 | Val loss: 2.7780 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 02:38:01 (running for 00:14:02.66)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.944 |      0.207 |                   72 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.53  |      0.289 |                   52 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.3   |      0.281 |                   46 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.642 |      0.282 |                   45 |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.3283582089552239
[2m[36m(func pid=60934)[0m top5: 0.8544776119402985
[2m[36m(func pid=60934)[0m f1_micro: 0.3283582089552239
[2m[36m(func pid=60934)[0m f1_macro: 0.2894206977253342
[2m[36m(func pid=60934)[0m f1_weighted: 0.3577154055797283
[2m[36m(func pid=60934)[0m f1_per_class: [0.183, 0.55, 0.392, 0.405, 0.071, 0.272, 0.27, 0.43, 0.147, 0.173]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62614)[0m top1: 0.2621268656716418
[2m[36m(func pid=62614)[0m top5: 0.8647388059701493
[2m[36m(func pid=62614)[0m f1_micro: 0.2621268656716418
[2m[36m(func pid=62614)[0m f1_macro: 0.2600855122959243
[2m[36m(func pid=62614)[0m f1_weighted: 0.2840011098808771
[2m[36m(func pid=62614)[0m f1_per_class: [0.11, 0.331, 0.485, 0.304, 0.057, 0.3, 0.236, 0.491, 0.022, 0.265]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=62121)[0m top1: 0.3568097014925373
[2m[36m(func pid=62121)[0m top5: 0.9235074626865671
[2m[36m(func pid=62121)[0m f1_micro: 0.3568097014925374
[2m[36m(func pid=62121)[0m f1_macro: 0.2534878933489287
[2m[36m(func pid=62121)[0m f1_weighted: 0.3772363000262147
[2m[36m(func pid=62121)[0m f1_per_class: [0.123, 0.308, 0.0, 0.402, 0.068, 0.258, 0.491, 0.412, 0.174, 0.298]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=55782)[0m top1: 0.21455223880597016
[2m[36m(func pid=55782)[0m top5: 0.8456156716417911
[2m[36m(func pid=55782)[0m f1_micro: 0.21455223880597016
[2m[36m(func pid=55782)[0m f1_macro: 0.20050928939248241
[2m[36m(func pid=55782)[0m f1_weighted: 0.22761128893990445
[2m[36m(func pid=55782)[0m f1_per_class: [0.072, 0.196, 0.22, 0.334, 0.062, 0.313, 0.108, 0.443, 0.041, 0.216]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.6632 | Steps: 2 | Val loss: 1.8818 | Batch size: 32 | lr: 0.001 | Duration: 2.75s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 1.1647 | Steps: 2 | Val loss: 2.1919 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 1.9024 | Steps: 2 | Val loss: 2.1229 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.2568 | Steps: 2 | Val loss: 2.8984 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 02:38:06 (running for 00:14:07.78)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.981 |      0.201 |                   73 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.663 |      0.327 |                   53 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.448 |      0.253 |                   47 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.437 |      0.26  |                   46 |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.3670708955223881
[2m[36m(func pid=60934)[0m top5: 0.8731343283582089
[2m[36m(func pid=60934)[0m f1_micro: 0.3670708955223881
[2m[36m(func pid=60934)[0m f1_macro: 0.3272902739990461
[2m[36m(func pid=60934)[0m f1_weighted: 0.3977412762187521
[2m[36m(func pid=60934)[0m f1_per_class: [0.202, 0.559, 0.351, 0.416, 0.065, 0.304, 0.356, 0.471, 0.198, 0.351]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62614)[0m top1: 0.2989738805970149
[2m[36m(func pid=62614)[0m top5: 0.8656716417910447
[2m[36m(func pid=62614)[0m f1_micro: 0.2989738805970149
[2m[36m(func pid=62614)[0m f1_macro: 0.2756199503235161
[2m[36m(func pid=62614)[0m f1_weighted: 0.33842402620611733
[2m[36m(func pid=62614)[0m f1_per_class: [0.128, 0.19, 0.522, 0.416, 0.047, 0.213, 0.417, 0.53, 0.028, 0.264]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=62121)[0m top1: 0.3619402985074627
[2m[36m(func pid=62121)[0m top5: 0.9239738805970149
[2m[36m(func pid=62121)[0m f1_micro: 0.3619402985074627
[2m[36m(func pid=62121)[0m f1_macro: 0.2626491897297404
[2m[36m(func pid=62121)[0m f1_weighted: 0.37534929430335556
[2m[36m(func pid=62121)[0m f1_per_class: [0.123, 0.242, 0.0, 0.407, 0.062, 0.277, 0.506, 0.418, 0.177, 0.415]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=55782)[0m top1: 0.21548507462686567
[2m[36m(func pid=55782)[0m top5: 0.8460820895522388
[2m[36m(func pid=55782)[0m f1_micro: 0.21548507462686567
[2m[36m(func pid=55782)[0m f1_macro: 0.201347902177267
[2m[36m(func pid=55782)[0m f1_weighted: 0.22791317659911783
[2m[36m(func pid=55782)[0m f1_per_class: [0.081, 0.194, 0.232, 0.335, 0.06, 0.3, 0.111, 0.453, 0.042, 0.205]
[2m[36m(func pid=55782)[0m 
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.5013 | Steps: 2 | Val loss: 1.7849 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 1.2332 | Steps: 2 | Val loss: 2.1945 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=55782)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 1.9545 | Steps: 2 | Val loss: 2.1188 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.2160 | Steps: 2 | Val loss: 3.0356 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
== Status ==
Current time: 2024-01-07 02:38:12 (running for 00:14:13.00)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: 0.2285
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00004 | RUNNING    | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.902 |      0.201 |                   74 |
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.501 |      0.33  |                   54 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.257 |      0.263 |                   48 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.165 |      0.276 |                   47 |
| train_6ed81_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.3917910447761194
[2m[36m(func pid=60934)[0m top5: 0.8913246268656716
[2m[36m(func pid=60934)[0m f1_micro: 0.3917910447761195
[2m[36m(func pid=60934)[0m f1_macro: 0.3299728671679307
[2m[36m(func pid=60934)[0m f1_weighted: 0.4298875761613125
[2m[36m(func pid=60934)[0m f1_per_class: [0.18, 0.533, 0.263, 0.42, 0.078, 0.338, 0.467, 0.493, 0.134, 0.394]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62614)[0m top1: 0.341884328358209
[2m[36m(func pid=62614)[0m top5: 0.8736007462686567
[2m[36m(func pid=62614)[0m f1_micro: 0.341884328358209
[2m[36m(func pid=62614)[0m f1_macro: 0.2762408403234537
[2m[36m(func pid=62614)[0m f1_weighted: 0.3732265081081844
[2m[36m(func pid=62614)[0m f1_per_class: [0.133, 0.192, 0.471, 0.479, 0.048, 0.116, 0.511, 0.528, 0.054, 0.23]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=55782)[0m top1: 0.22061567164179105
[2m[36m(func pid=55782)[0m top5: 0.8451492537313433
[2m[36m(func pid=55782)[0m f1_micro: 0.22061567164179105
[2m[36m(func pid=55782)[0m f1_macro: 0.2081904156972839
[2m[36m(func pid=55782)[0m f1_weighted: 0.23728879441365755
[2m[36m(func pid=55782)[0m f1_per_class: [0.084, 0.217, 0.232, 0.335, 0.06, 0.294, 0.132, 0.446, 0.043, 0.24]
[2m[36m(func pid=62121)[0m top1: 0.384794776119403
[2m[36m(func pid=62121)[0m top5: 0.9281716417910447
[2m[36m(func pid=62121)[0m f1_micro: 0.384794776119403
[2m[36m(func pid=62121)[0m f1_macro: 0.24735317053841532
[2m[36m(func pid=62121)[0m f1_weighted: 0.37768477363118175
[2m[36m(func pid=62121)[0m f1_per_class: [0.133, 0.176, 0.0, 0.453, 0.068, 0.164, 0.571, 0.329, 0.147, 0.433]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.9041 | Steps: 2 | Val loss: 1.7589 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 1.2079 | Steps: 2 | Val loss: 2.0898 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.5434 | Steps: 2 | Val loss: 3.2464 | Batch size: 32 | lr: 0.01 | Duration: 3.07s
[2m[36m(func pid=60934)[0m top1: 0.40158582089552236
[2m[36m(func pid=60934)[0m top5: 0.8959888059701493
[2m[36m(func pid=60934)[0m f1_micro: 0.40158582089552236
[2m[36m(func pid=60934)[0m f1_macro: 0.33895706113069285
[2m[36m(func pid=60934)[0m f1_weighted: 0.4341536725122304
[2m[36m(func pid=60934)[0m f1_per_class: [0.176, 0.537, 0.256, 0.411, 0.078, 0.339, 0.472, 0.559, 0.144, 0.418]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62614)[0m top1: 0.34794776119402987
[2m[36m(func pid=62614)[0m top5: 0.8810634328358209
[2m[36m(func pid=62614)[0m f1_micro: 0.34794776119402987
[2m[36m(func pid=62614)[0m f1_macro: 0.28087108319391746
[2m[36m(func pid=62614)[0m f1_weighted: 0.3770449838178153
[2m[36m(func pid=62614)[0m f1_per_class: [0.148, 0.24, 0.49, 0.38, 0.058, 0.173, 0.585, 0.398, 0.099, 0.238]
[2m[36m(func pid=62121)[0m top1: 0.3805970149253731
[2m[36m(func pid=62121)[0m top5: 0.9216417910447762
[2m[36m(func pid=62121)[0m f1_micro: 0.3805970149253731
[2m[36m(func pid=62121)[0m f1_macro: 0.24340625545802555
[2m[36m(func pid=62121)[0m f1_weighted: 0.3667899329152322
[2m[36m(func pid=62121)[0m f1_per_class: [0.176, 0.158, 0.267, 0.436, 0.054, 0.175, 0.599, 0.115, 0.075, 0.378]
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.5311 | Steps: 2 | Val loss: 1.8230 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
== Status ==
Current time: 2024-01-07 02:38:17 (running for 00:14:18.53)
Memory usage on this node: 22.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: 0.208
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.904 |      0.339 |                   55 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.216 |      0.247 |                   49 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.233 |      0.276 |                   48 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=73645)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=73645)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=73645)[0m Configuration completed!
[2m[36m(func pid=73645)[0m New optimizer parameters:
[2m[36m(func pid=73645)[0m SGD (
[2m[36m(func pid=73645)[0m Parameter Group 0
[2m[36m(func pid=73645)[0m     dampening: 0
[2m[36m(func pid=73645)[0m     differentiable: False
[2m[36m(func pid=73645)[0m     foreach: None
[2m[36m(func pid=73645)[0m     lr: 0.0001
[2m[36m(func pid=73645)[0m     maximize: False
[2m[36m(func pid=73645)[0m     momentum: 0.99
[2m[36m(func pid=73645)[0m     nesterov: False
[2m[36m(func pid=73645)[0m     weight_decay: 0.0001
[2m[36m(func pid=73645)[0m )
[2m[36m(func pid=73645)[0m 
== Status ==
Current time: 2024-01-07 02:38:23 (running for 00:14:23.90)
Memory usage on this node: 23.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: 0.208
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.531 |      0.331 |                   56 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.543 |      0.243 |                   50 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.208 |      0.281 |                   49 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.38386194029850745
[2m[36m(func pid=60934)[0m top5: 0.8815298507462687
[2m[36m(func pid=60934)[0m f1_micro: 0.38386194029850745
[2m[36m(func pid=60934)[0m f1_macro: 0.33147938918640435
[2m[36m(func pid=60934)[0m f1_weighted: 0.41194455605693303
[2m[36m(func pid=60934)[0m f1_per_class: [0.196, 0.543, 0.297, 0.425, 0.079, 0.336, 0.379, 0.569, 0.17, 0.321]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 1.3937 | Steps: 2 | Val loss: 2.2154 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.0939 | Steps: 2 | Val loss: 3.3191 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.4940 | Steps: 2 | Val loss: 2.0932 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 3.1278 | Steps: 2 | Val loss: 2.3721 | Batch size: 32 | lr: 0.0001 | Duration: 4.85s
[2m[36m(func pid=62614)[0m top1: 0.2775186567164179
[2m[36m(func pid=62614)[0m top5: 0.8652052238805971
[2m[36m(func pid=62614)[0m f1_micro: 0.2775186567164179
[2m[36m(func pid=62614)[0m f1_macro: 0.2722290792841606
[2m[36m(func pid=62614)[0m f1_weighted: 0.3027559534742925
[2m[36m(func pid=62614)[0m f1_per_class: [0.139, 0.266, 0.585, 0.35, 0.069, 0.381, 0.314, 0.115, 0.125, 0.377]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=62121)[0m top1: 0.33722014925373134
[2m[36m(func pid=62121)[0m top5: 0.8936567164179104
[2m[36m(func pid=62121)[0m f1_micro: 0.33722014925373134
[2m[36m(func pid=62121)[0m f1_macro: 0.2588661850905552
[2m[36m(func pid=62121)[0m f1_weighted: 0.3321829556336077
[2m[36m(func pid=62121)[0m f1_per_class: [0.215, 0.129, 0.636, 0.321, 0.044, 0.237, 0.595, 0.057, 0.0, 0.354]
[2m[36m(func pid=62121)[0m 
== Status ==
Current time: 2024-01-07 02:38:28 (running for 00:14:29.19)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: 0.208
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.494 |      0.278 |                   57 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.094 |      0.259 |                   51 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.394 |      0.272 |                   50 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.3111007462686567
[2m[36m(func pid=60934)[0m top5: 0.8460820895522388
[2m[36m(func pid=60934)[0m f1_micro: 0.3111007462686567
[2m[36m(func pid=60934)[0m f1_macro: 0.2775488892362138
[2m[36m(func pid=60934)[0m f1_weighted: 0.33756074199786396
[2m[36m(func pid=60934)[0m f1_per_class: [0.192, 0.547, 0.324, 0.393, 0.074, 0.263, 0.205, 0.526, 0.131, 0.121]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=73645)[0m top1: 0.06576492537313433
[2m[36m(func pid=73645)[0m top5: 0.3824626865671642
[2m[36m(func pid=73645)[0m f1_micro: 0.06576492537313433
[2m[36m(func pid=73645)[0m f1_macro: 0.01636203638998887
[2m[36m(func pid=73645)[0m f1_weighted: 0.019774216888227548
[2m[36m(func pid=73645)[0m f1_per_class: [0.0, 0.0, 0.0, 0.047, 0.0, 0.0, 0.0, 0.117, 0.0, 0.0]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 1.5813 | Steps: 2 | Val loss: 2.3596 | Batch size: 32 | lr: 0.1 | Duration: 2.74s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.1227 | Steps: 2 | Val loss: 3.4638 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.8396 | Steps: 2 | Val loss: 1.9050 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 3.0988 | Steps: 2 | Val loss: 2.3276 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=62614)[0m top1: 0.2891791044776119
[2m[36m(func pid=62614)[0m top5: 0.816231343283582
[2m[36m(func pid=62614)[0m f1_micro: 0.2891791044776119
[2m[36m(func pid=62614)[0m f1_macro: 0.26926919512593817
[2m[36m(func pid=62614)[0m f1_weighted: 0.3089179401186417
[2m[36m(func pid=62614)[0m f1_per_class: [0.112, 0.43, 0.489, 0.337, 0.047, 0.317, 0.237, 0.408, 0.046, 0.27]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=62121)[0m top1: 0.29850746268656714
[2m[36m(func pid=62121)[0m top5: 0.875
[2m[36m(func pid=62121)[0m f1_micro: 0.29850746268656714
[2m[36m(func pid=62121)[0m f1_macro: 0.22864279816175076
[2m[36m(func pid=62121)[0m f1_weighted: 0.29325715015380904
[2m[36m(func pid=62121)[0m f1_per_class: [0.164, 0.048, 0.485, 0.243, 0.043, 0.191, 0.587, 0.153, 0.024, 0.349]
[2m[36m(func pid=62121)[0m 
== Status ==
Current time: 2024-01-07 02:38:33 (running for 00:14:34.61)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: 0.208
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.84  |      0.307 |                   58 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.123 |      0.229 |                   52 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.581 |      0.269 |                   51 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  3.128 |      0.016 |                    1 |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.35634328358208955
[2m[36m(func pid=60934)[0m top5: 0.8675373134328358
[2m[36m(func pid=60934)[0m f1_micro: 0.3563432835820895
[2m[36m(func pid=60934)[0m f1_macro: 0.3065163145487534
[2m[36m(func pid=60934)[0m f1_weighted: 0.3810395586156211
[2m[36m(func pid=60934)[0m f1_per_class: [0.199, 0.561, 0.299, 0.398, 0.081, 0.303, 0.316, 0.525, 0.167, 0.218]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=73645)[0m top1: 0.1417910447761194
[2m[36m(func pid=73645)[0m top5: 0.5177238805970149
[2m[36m(func pid=73645)[0m f1_micro: 0.1417910447761194
[2m[36m(func pid=73645)[0m f1_macro: 0.042249248454415536
[2m[36m(func pid=73645)[0m f1_weighted: 0.07996009000699347
[2m[36m(func pid=73645)[0m f1_per_class: [0.0, 0.0, 0.0, 0.251, 0.0, 0.0, 0.0, 0.171, 0.0, 0.0]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.1944 | Steps: 2 | Val loss: 3.5120 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 1.3352 | Steps: 2 | Val loss: 2.4637 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.4948 | Steps: 2 | Val loss: 1.8117 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 3.0544 | Steps: 2 | Val loss: 2.3164 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=62614)[0m top1: 0.3180970149253731
[2m[36m(func pid=62614)[0m top5: 0.8036380597014925
[2m[36m(func pid=62614)[0m f1_micro: 0.3180970149253731
[2m[36m(func pid=62614)[0m f1_macro: 0.28045392750721176
[2m[36m(func pid=62614)[0m f1_weighted: 0.29204245057558925
[2m[36m(func pid=62614)[0m f1_per_class: [0.142, 0.434, 0.537, 0.398, 0.0, 0.312, 0.099, 0.51, 0.05, 0.323]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=62121)[0m top1: 0.291044776119403
[2m[36m(func pid=62121)[0m top5: 0.8600746268656716
[2m[36m(func pid=62121)[0m f1_micro: 0.291044776119403
[2m[36m(func pid=62121)[0m f1_macro: 0.21269690210492773
[2m[36m(func pid=62121)[0m f1_weighted: 0.2994818956935965
[2m[36m(func pid=62121)[0m f1_per_class: [0.135, 0.05, 0.356, 0.285, 0.051, 0.175, 0.568, 0.228, 0.021, 0.259]
[2m[36m(func pid=62121)[0m 
== Status ==
Current time: 2024-01-07 02:38:39 (running for 00:14:39.90)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: 0.208
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.495 |      0.348 |                   59 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.194 |      0.213 |                   53 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.335 |      0.28  |                   52 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  3.099 |      0.042 |                    2 |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.3983208955223881
[2m[36m(func pid=60934)[0m top5: 0.8810634328358209
[2m[36m(func pid=60934)[0m f1_micro: 0.3983208955223881
[2m[36m(func pid=60934)[0m f1_macro: 0.34760017546520655
[2m[36m(func pid=60934)[0m f1_weighted: 0.4260315646955951
[2m[36m(func pid=60934)[0m f1_per_class: [0.175, 0.574, 0.286, 0.376, 0.084, 0.355, 0.444, 0.563, 0.179, 0.441]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=73645)[0m top1: 0.18330223880597016
[2m[36m(func pid=73645)[0m top5: 0.5625
[2m[36m(func pid=73645)[0m f1_micro: 0.18330223880597016
[2m[36m(func pid=73645)[0m f1_macro: 0.04836117740652347
[2m[36m(func pid=73645)[0m f1_weighted: 0.0980409705648369
[2m[36m(func pid=73645)[0m f1_per_class: [0.0, 0.0, 0.0, 0.317, 0.0, 0.0, 0.0, 0.167, 0.0, 0.0]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.0855 | Steps: 2 | Val loss: 3.5746 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 1.3589 | Steps: 2 | Val loss: 2.6325 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.6295 | Steps: 2 | Val loss: 1.7563 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 2.9723 | Steps: 2 | Val loss: 2.3126 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=62121)[0m top1: 0.271455223880597
[2m[36m(func pid=62121)[0m top5: 0.8423507462686567
[2m[36m(func pid=62121)[0m f1_micro: 0.271455223880597
[2m[36m(func pid=62121)[0m f1_macro: 0.218486862007977
[2m[36m(func pid=62121)[0m f1_weighted: 0.2899057802120681
[2m[36m(func pid=62121)[0m f1_per_class: [0.125, 0.091, 0.28, 0.297, 0.063, 0.142, 0.505, 0.255, 0.018, 0.409]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=62614)[0m top1: 0.28404850746268656
[2m[36m(func pid=62614)[0m top5: 0.804570895522388
[2m[36m(func pid=62614)[0m f1_micro: 0.28404850746268656
[2m[36m(func pid=62614)[0m f1_macro: 0.28160588786507124
[2m[36m(func pid=62614)[0m f1_weighted: 0.2693935212179759
[2m[36m(func pid=62614)[0m f1_per_class: [0.14, 0.451, 0.537, 0.292, 0.039, 0.293, 0.112, 0.517, 0.094, 0.341]
[2m[36m(func pid=62614)[0m 
== Status ==
Current time: 2024-01-07 02:38:44 (running for 00:14:45.50)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: 0.208
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.63  |      0.352 |                   60 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.085 |      0.218 |                   54 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.359 |      0.282 |                   53 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  3.054 |      0.048 |                    3 |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.40671641791044777
[2m[36m(func pid=60934)[0m top5: 0.8880597014925373
[2m[36m(func pid=60934)[0m f1_micro: 0.40671641791044777
[2m[36m(func pid=60934)[0m f1_macro: 0.35205794773479665
[2m[36m(func pid=60934)[0m f1_weighted: 0.4264582041111771
[2m[36m(func pid=60934)[0m f1_per_class: [0.184, 0.568, 0.289, 0.388, 0.105, 0.329, 0.451, 0.517, 0.189, 0.5]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=73645)[0m top1: 0.20335820895522388
[2m[36m(func pid=73645)[0m top5: 0.5760261194029851
[2m[36m(func pid=73645)[0m f1_micro: 0.20335820895522388
[2m[36m(func pid=73645)[0m f1_macro: 0.0454824751189961
[2m[36m(func pid=73645)[0m f1_weighted: 0.10475056026660293
[2m[36m(func pid=73645)[0m f1_per_class: [0.0, 0.0, 0.0, 0.355, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.0757 | Steps: 2 | Val loss: 3.5886 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 1.0468 | Steps: 2 | Val loss: 2.7750 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.4419 | Steps: 2 | Val loss: 1.7483 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 2.9244 | Steps: 2 | Val loss: 2.3123 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=62121)[0m top1: 0.2644589552238806
[2m[36m(func pid=62121)[0m top5: 0.8446828358208955
[2m[36m(func pid=62121)[0m f1_micro: 0.2644589552238806
[2m[36m(func pid=62121)[0m f1_macro: 0.23276378816720777
[2m[36m(func pid=62121)[0m f1_weighted: 0.2985710252729367
[2m[36m(func pid=62121)[0m f1_per_class: [0.136, 0.184, 0.28, 0.298, 0.041, 0.207, 0.454, 0.227, 0.043, 0.457]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=62614)[0m top1: 0.25279850746268656
[2m[36m(func pid=62614)[0m top5: 0.840018656716418
[2m[36m(func pid=62614)[0m f1_micro: 0.25279850746268656
[2m[36m(func pid=62614)[0m f1_macro: 0.26442640080155994
[2m[36m(func pid=62614)[0m f1_weighted: 0.2936677555037642
[2m[36m(func pid=62614)[0m f1_per_class: [0.138, 0.213, 0.526, 0.257, 0.055, 0.287, 0.39, 0.426, 0.041, 0.311]
[2m[36m(func pid=62614)[0m 
== Status ==
Current time: 2024-01-07 02:38:49 (running for 00:14:50.76)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: 0.208
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.442 |      0.357 |                   61 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.076 |      0.233 |                   55 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.047 |      0.264 |                   54 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  2.972 |      0.045 |                    4 |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.41091417910447764
[2m[36m(func pid=60934)[0m top5: 0.8857276119402985
[2m[36m(func pid=60934)[0m f1_micro: 0.4109141791044776
[2m[36m(func pid=60934)[0m f1_macro: 0.35665631844305634
[2m[36m(func pid=60934)[0m f1_weighted: 0.43623183900914975
[2m[36m(func pid=60934)[0m f1_per_class: [0.219, 0.568, 0.314, 0.4, 0.079, 0.359, 0.462, 0.518, 0.175, 0.473]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=73645)[0m top1: 0.21641791044776118
[2m[36m(func pid=73645)[0m top5: 0.582089552238806
[2m[36m(func pid=73645)[0m f1_micro: 0.21641791044776118
[2m[36m(func pid=73645)[0m f1_macro: 0.07880728608568627
[2m[36m(func pid=73645)[0m f1_weighted: 0.10869587945279556
[2m[36m(func pid=73645)[0m f1_per_class: [0.0, 0.0, 0.364, 0.371, 0.0, 0.0, 0.0, 0.054, 0.0, 0.0]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 1.2266 | Steps: 2 | Val loss: 2.6332 | Batch size: 32 | lr: 0.1 | Duration: 2.71s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.0861 | Steps: 2 | Val loss: 3.6291 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.4671 | Steps: 2 | Val loss: 1.8289 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 2.9232 | Steps: 2 | Val loss: 2.3154 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=62614)[0m top1: 0.27658582089552236
[2m[36m(func pid=62614)[0m top5: 0.8605410447761194
[2m[36m(func pid=62614)[0m f1_micro: 0.27658582089552236
[2m[36m(func pid=62614)[0m f1_macro: 0.23779849369234443
[2m[36m(func pid=62614)[0m f1_weighted: 0.30833069227856363
[2m[36m(func pid=62614)[0m f1_per_class: [0.151, 0.219, 0.571, 0.276, 0.053, 0.274, 0.506, 0.016, 0.0, 0.312]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=62121)[0m top1: 0.2751865671641791
[2m[36m(func pid=62121)[0m top5: 0.8507462686567164
[2m[36m(func pid=62121)[0m f1_micro: 0.2751865671641791
[2m[36m(func pid=62121)[0m f1_macro: 0.2308562808229849
[2m[36m(func pid=62121)[0m f1_weighted: 0.30873397062178004
[2m[36m(func pid=62121)[0m f1_per_class: [0.155, 0.228, 0.333, 0.359, 0.037, 0.236, 0.398, 0.244, 0.024, 0.294]
[2m[36m(func pid=62121)[0m 
== Status ==
Current time: 2024-01-07 02:38:55 (running for 00:14:55.88)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: 0.208
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.467 |      0.34  |                   62 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.086 |      0.231 |                   56 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.227 |      0.238 |                   55 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  2.924 |      0.079 |                    5 |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.3941231343283582
[2m[36m(func pid=60934)[0m top5: 0.8768656716417911
[2m[36m(func pid=60934)[0m f1_micro: 0.3941231343283582
[2m[36m(func pid=60934)[0m f1_macro: 0.34043494982230005
[2m[36m(func pid=60934)[0m f1_weighted: 0.41741940275363076
[2m[36m(func pid=60934)[0m f1_per_class: [0.257, 0.569, 0.282, 0.42, 0.074, 0.354, 0.399, 0.417, 0.181, 0.452]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=73645)[0m top1: 0.22667910447761194
[2m[36m(func pid=73645)[0m top5: 0.582089552238806
[2m[36m(func pid=73645)[0m f1_micro: 0.22667910447761194
[2m[36m(func pid=73645)[0m f1_macro: 0.059648232625121755
[2m[36m(func pid=73645)[0m f1_weighted: 0.11324822376541925
[2m[36m(func pid=73645)[0m f1_per_class: [0.0, 0.005, 0.138, 0.386, 0.0, 0.0, 0.0, 0.067, 0.0, 0.0]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.0684 | Steps: 2 | Val loss: 3.5527 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 1.3063 | Steps: 2 | Val loss: 2.4662 | Batch size: 32 | lr: 0.1 | Duration: 2.99s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.5086 | Steps: 2 | Val loss: 1.8545 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 2.7697 | Steps: 2 | Val loss: 2.3166 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=62121)[0m top1: 0.30736940298507465
[2m[36m(func pid=62121)[0m top5: 0.8572761194029851
[2m[36m(func pid=62121)[0m f1_micro: 0.30736940298507465
[2m[36m(func pid=62121)[0m f1_macro: 0.26766442445160415
[2m[36m(func pid=62121)[0m f1_weighted: 0.33617530261819895
[2m[36m(func pid=62121)[0m f1_per_class: [0.197, 0.261, 0.516, 0.447, 0.034, 0.212, 0.38, 0.296, 0.026, 0.308]
[2m[36m(func pid=62614)[0m top1: 0.3787313432835821
[2m[36m(func pid=62614)[0m top5: 0.863339552238806
[2m[36m(func pid=62614)[0m f1_micro: 0.3787313432835821
[2m[36m(func pid=62614)[0m f1_macro: 0.32114119588978507
[2m[36m(func pid=62614)[0m f1_weighted: 0.3983557090435056
[2m[36m(func pid=62614)[0m f1_per_class: [0.195, 0.457, 0.562, 0.372, 0.022, 0.29, 0.48, 0.456, 0.065, 0.312]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=62121)[0m 
== Status ==
Current time: 2024-01-07 02:39:00 (running for 00:15:01.17)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: 0.208
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.509 |      0.32  |                   63 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.068 |      0.268 |                   57 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.306 |      0.321 |                   56 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  2.923 |      0.06  |                    6 |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.38572761194029853
[2m[36m(func pid=60934)[0m top5: 0.8726679104477612
[2m[36m(func pid=60934)[0m f1_micro: 0.3857276119402986
[2m[36m(func pid=60934)[0m f1_macro: 0.3195022662315664
[2m[36m(func pid=60934)[0m f1_weighted: 0.40732639819437383
[2m[36m(func pid=60934)[0m f1_per_class: [0.224, 0.564, 0.278, 0.428, 0.081, 0.302, 0.369, 0.542, 0.153, 0.252]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=73645)[0m top1: 0.2224813432835821
[2m[36m(func pid=73645)[0m top5: 0.5806902985074627
[2m[36m(func pid=73645)[0m f1_micro: 0.2224813432835821
[2m[36m(func pid=73645)[0m f1_macro: 0.05636939222532307
[2m[36m(func pid=73645)[0m f1_weighted: 0.12344039884591405
[2m[36m(func pid=73645)[0m f1_per_class: [0.0, 0.016, 0.049, 0.414, 0.0, 0.0, 0.0, 0.085, 0.0, 0.0]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.0786 | Steps: 2 | Val loss: 3.4850 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 1.3363 | Steps: 2 | Val loss: 2.4511 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.5004 | Steps: 2 | Val loss: 1.7766 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=62614)[0m top1: 0.3218283582089552
[2m[36m(func pid=62614)[0m top5: 0.8605410447761194
[2m[36m(func pid=62614)[0m f1_micro: 0.3218283582089552
[2m[36m(func pid=62614)[0m f1_macro: 0.28937285998888224
[2m[36m(func pid=62614)[0m f1_weighted: 0.31277307283083644
[2m[36m(func pid=62614)[0m f1_per_class: [0.203, 0.334, 0.562, 0.47, 0.065, 0.341, 0.164, 0.396, 0.059, 0.299]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=62121)[0m top1: 0.3125
[2m[36m(func pid=62121)[0m top5: 0.8638059701492538
[2m[36m(func pid=62121)[0m f1_micro: 0.3125
[2m[36m(func pid=62121)[0m f1_macro: 0.28840434430388856
[2m[36m(func pid=62121)[0m f1_weighted: 0.3327875086623845
[2m[36m(func pid=62121)[0m f1_per_class: [0.232, 0.236, 0.615, 0.488, 0.037, 0.225, 0.324, 0.343, 0.027, 0.356]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 2.7286 | Steps: 2 | Val loss: 2.3191 | Batch size: 32 | lr: 0.0001 | Duration: 3.14s
== Status ==
Current time: 2024-01-07 02:39:05 (running for 00:15:06.42)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: 0.208
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.5   |      0.332 |                   64 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.079 |      0.288 |                   58 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.336 |      0.289 |                   57 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  2.77  |      0.056 |                    7 |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.40578358208955223
[2m[36m(func pid=60934)[0m top5: 0.8819962686567164
[2m[36m(func pid=60934)[0m f1_micro: 0.40578358208955223
[2m[36m(func pid=60934)[0m f1_macro: 0.33249195718748126
[2m[36m(func pid=60934)[0m f1_weighted: 0.4227845766269404
[2m[36m(func pid=60934)[0m f1_per_class: [0.211, 0.567, 0.272, 0.431, 0.086, 0.348, 0.396, 0.547, 0.158, 0.309]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=73645)[0m top1: 0.1828358208955224
[2m[36m(func pid=73645)[0m top5: 0.5764925373134329
[2m[36m(func pid=73645)[0m f1_micro: 0.1828358208955224
[2m[36m(func pid=73645)[0m f1_macro: 0.052694377488210375
[2m[36m(func pid=73645)[0m f1_weighted: 0.12001877431808752
[2m[36m(func pid=73645)[0m f1_per_class: [0.037, 0.005, 0.027, 0.415, 0.0, 0.0, 0.0, 0.043, 0.0, 0.0]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 1.1664 | Steps: 2 | Val loss: 2.5845 | Batch size: 32 | lr: 0.1 | Duration: 2.76s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.0206 | Steps: 2 | Val loss: 3.5753 | Batch size: 32 | lr: 0.01 | Duration: 2.76s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.8560 | Steps: 2 | Val loss: 1.8784 | Batch size: 32 | lr: 0.001 | Duration: 2.75s
[2m[36m(func pid=62614)[0m top1: 0.2896455223880597
[2m[36m(func pid=62614)[0m top5: 0.8577425373134329
[2m[36m(func pid=62614)[0m f1_micro: 0.2896455223880597
[2m[36m(func pid=62614)[0m f1_macro: 0.26354321516376084
[2m[36m(func pid=62614)[0m f1_weighted: 0.26913293421994877
[2m[36m(func pid=62614)[0m f1_per_class: [0.089, 0.284, 0.562, 0.475, 0.079, 0.31, 0.064, 0.345, 0.108, 0.317]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=62121)[0m top1: 0.29151119402985076
[2m[36m(func pid=62121)[0m top5: 0.8498134328358209
[2m[36m(func pid=62121)[0m f1_micro: 0.29151119402985076
[2m[36m(func pid=62121)[0m f1_macro: 0.2874448081822367
[2m[36m(func pid=62121)[0m f1_weighted: 0.29774839371700357
[2m[36m(func pid=62121)[0m f1_per_class: [0.288, 0.16, 0.72, 0.493, 0.051, 0.239, 0.228, 0.363, 0.088, 0.245]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 2.6611 | Steps: 2 | Val loss: 2.3205 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 02:39:10 (running for 00:15:11.47)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: 0.208
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.856 |      0.318 |                   65 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.021 |      0.287 |                   59 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.166 |      0.264 |                   58 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  2.729 |      0.053 |                    8 |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.3810634328358209
[2m[36m(func pid=60934)[0m top5: 0.8638059701492538
[2m[36m(func pid=60934)[0m f1_micro: 0.3810634328358209
[2m[36m(func pid=60934)[0m f1_macro: 0.3178144834626157
[2m[36m(func pid=60934)[0m f1_weighted: 0.3926856676303872
[2m[36m(func pid=60934)[0m f1_per_class: [0.213, 0.563, 0.275, 0.436, 0.083, 0.329, 0.303, 0.531, 0.175, 0.27]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=73645)[0m top1: 0.12779850746268656
[2m[36m(func pid=73645)[0m top5: 0.5792910447761194
[2m[36m(func pid=73645)[0m f1_micro: 0.12779850746268656
[2m[36m(func pid=73645)[0m f1_macro: 0.03889079738199741
[2m[36m(func pid=73645)[0m f1_weighted: 0.09973616773801255
[2m[36m(func pid=73645)[0m f1_per_class: [0.0, 0.0, 0.019, 0.354, 0.0, 0.0, 0.0, 0.016, 0.0, 0.0]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 1.3540 | Steps: 2 | Val loss: 2.5486 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.0235 | Steps: 2 | Val loss: 3.7379 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.6210 | Steps: 2 | Val loss: 2.0766 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=62614)[0m top1: 0.3148320895522388
[2m[36m(func pid=62614)[0m top5: 0.8544776119402985
[2m[36m(func pid=62614)[0m f1_micro: 0.3148320895522388
[2m[36m(func pid=62614)[0m f1_macro: 0.31929181857534383
[2m[36m(func pid=62614)[0m f1_weighted: 0.33337270342342706
[2m[36m(func pid=62614)[0m f1_per_class: [0.181, 0.344, 0.645, 0.348, 0.079, 0.304, 0.331, 0.45, 0.159, 0.351]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=62121)[0m top1: 0.2737873134328358
[2m[36m(func pid=62121)[0m top5: 0.84375
[2m[36m(func pid=62121)[0m f1_micro: 0.2737873134328358
[2m[36m(func pid=62121)[0m f1_macro: 0.2636687365397324
[2m[36m(func pid=62121)[0m f1_weighted: 0.2759750250181064
[2m[36m(func pid=62121)[0m f1_per_class: [0.278, 0.144, 0.636, 0.504, 0.052, 0.197, 0.173, 0.365, 0.107, 0.18]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 2.6908 | Steps: 2 | Val loss: 2.3226 | Batch size: 32 | lr: 0.0001 | Duration: 2.68s
== Status ==
Current time: 2024-01-07 02:39:15 (running for 00:15:16.81)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: 0.208
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.621 |      0.283 |                   66 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.024 |      0.264 |                   60 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.354 |      0.319 |                   59 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  2.661 |      0.039 |                    9 |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.33908582089552236
[2m[36m(func pid=60934)[0m top5: 0.8362873134328358
[2m[36m(func pid=60934)[0m f1_micro: 0.33908582089552236
[2m[36m(func pid=60934)[0m f1_macro: 0.28308393128424136
[2m[36m(func pid=60934)[0m f1_weighted: 0.3402339723629363
[2m[36m(func pid=60934)[0m f1_per_class: [0.202, 0.584, 0.259, 0.444, 0.073, 0.304, 0.155, 0.329, 0.185, 0.296]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=73645)[0m top1: 0.08488805970149253
[2m[36m(func pid=73645)[0m top5: 0.5727611940298507
[2m[36m(func pid=73645)[0m f1_micro: 0.08488805970149253
[2m[36m(func pid=73645)[0m f1_macro: 0.030798947626573103
[2m[36m(func pid=73645)[0m f1_weighted: 0.08014018198301773
[2m[36m(func pid=73645)[0m f1_per_class: [0.0, 0.01, 0.017, 0.281, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 1.2883 | Steps: 2 | Val loss: 2.5306 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.0344 | Steps: 2 | Val loss: 3.7677 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.4638 | Steps: 2 | Val loss: 1.8527 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=62614)[0m top1: 0.314365671641791
[2m[36m(func pid=62614)[0m top5: 0.8549440298507462
[2m[36m(func pid=62614)[0m f1_micro: 0.314365671641791
[2m[36m(func pid=62614)[0m f1_macro: 0.2876667108044146
[2m[36m(func pid=62614)[0m f1_weighted: 0.33822146505402784
[2m[36m(func pid=62614)[0m f1_per_class: [0.145, 0.293, 0.645, 0.259, 0.072, 0.306, 0.536, 0.063, 0.157, 0.4]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=62121)[0m top1: 0.2719216417910448
[2m[36m(func pid=62121)[0m top5: 0.8498134328358209
[2m[36m(func pid=62121)[0m f1_micro: 0.2719216417910448
[2m[36m(func pid=62121)[0m f1_macro: 0.2889859871179833
[2m[36m(func pid=62121)[0m f1_weighted: 0.274569520085278
[2m[36m(func pid=62121)[0m f1_per_class: [0.271, 0.14, 0.783, 0.486, 0.051, 0.211, 0.164, 0.405, 0.171, 0.211]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 2.5815 | Steps: 2 | Val loss: 2.3228 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
== Status ==
Current time: 2024-01-07 02:39:21 (running for 00:15:22.03)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: 0.208
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.464 |      0.331 |                   67 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.034 |      0.289 |                   61 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.288 |      0.288 |                   60 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  2.691 |      0.031 |                   10 |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.384794776119403
[2m[36m(func pid=60934)[0m top5: 0.8852611940298507
[2m[36m(func pid=60934)[0m f1_micro: 0.384794776119403
[2m[36m(func pid=60934)[0m f1_macro: 0.3308440971243952
[2m[36m(func pid=60934)[0m f1_weighted: 0.4099053941702715
[2m[36m(func pid=60934)[0m f1_per_class: [0.226, 0.54, 0.258, 0.459, 0.078, 0.345, 0.363, 0.383, 0.219, 0.438]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=73645)[0m top1: 0.061567164179104475
[2m[36m(func pid=73645)[0m top5: 0.5713619402985075
[2m[36m(func pid=73645)[0m f1_micro: 0.061567164179104475
[2m[36m(func pid=73645)[0m f1_macro: 0.026938800966860393
[2m[36m(func pid=73645)[0m f1_weighted: 0.06727919296391861
[2m[36m(func pid=73645)[0m f1_per_class: [0.0, 0.033, 0.016, 0.22, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 1.2867 | Steps: 2 | Val loss: 2.4366 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.0209 | Steps: 2 | Val loss: 3.6912 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.4137 | Steps: 2 | Val loss: 1.8110 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=62614)[0m top1: 0.2980410447761194
[2m[36m(func pid=62614)[0m top5: 0.8460820895522388
[2m[36m(func pid=62614)[0m f1_micro: 0.2980410447761194
[2m[36m(func pid=62614)[0m f1_macro: 0.277660007444798
[2m[36m(func pid=62614)[0m f1_weighted: 0.32404266266972764
[2m[36m(func pid=62614)[0m f1_per_class: [0.122, 0.236, 0.606, 0.246, 0.067, 0.193, 0.54, 0.323, 0.058, 0.385]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=62121)[0m top1: 0.271455223880597
[2m[36m(func pid=62121)[0m top5: 0.8544776119402985
[2m[36m(func pid=62121)[0m f1_micro: 0.271455223880597
[2m[36m(func pid=62121)[0m f1_macro: 0.3006773931960075
[2m[36m(func pid=62121)[0m f1_weighted: 0.27706152181934124
[2m[36m(func pid=62121)[0m f1_per_class: [0.273, 0.124, 0.8, 0.478, 0.05, 0.215, 0.177, 0.414, 0.211, 0.264]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 2.5498 | Steps: 2 | Val loss: 2.3225 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 02:39:26 (running for 00:15:27.35)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: 0.208
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.414 |      0.341 |                   68 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.021 |      0.301 |                   62 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.287 |      0.278 |                   61 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  2.582 |      0.027 |                   11 |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.3931902985074627
[2m[36m(func pid=60934)[0m top5: 0.8917910447761194
[2m[36m(func pid=60934)[0m f1_micro: 0.39319029850746273
[2m[36m(func pid=60934)[0m f1_macro: 0.34066652441686285
[2m[36m(func pid=60934)[0m f1_weighted: 0.4231547324285593
[2m[36m(func pid=60934)[0m f1_per_class: [0.186, 0.542, 0.247, 0.453, 0.1, 0.374, 0.385, 0.485, 0.217, 0.418]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=73645)[0m top1: 0.041044776119402986
[2m[36m(func pid=73645)[0m top5: 0.5657649253731343
[2m[36m(func pid=73645)[0m f1_micro: 0.041044776119402986
[2m[36m(func pid=73645)[0m f1_macro: 0.02366381285672171
[2m[36m(func pid=73645)[0m f1_weighted: 0.05028027174202224
[2m[36m(func pid=73645)[0m f1_per_class: [0.0, 0.076, 0.015, 0.13, 0.0, 0.0, 0.0, 0.016, 0.0, 0.0]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 1.1027 | Steps: 2 | Val loss: 2.4403 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.0161 | Steps: 2 | Val loss: 3.5954 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.6096 | Steps: 2 | Val loss: 2.1017 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=62614)[0m top1: 0.2439365671641791
[2m[36m(func pid=62614)[0m top5: 0.8348880597014925
[2m[36m(func pid=62614)[0m f1_micro: 0.2439365671641791
[2m[36m(func pid=62614)[0m f1_macro: 0.2550534040354352
[2m[36m(func pid=62614)[0m f1_weighted: 0.23360792693239052
[2m[36m(func pid=62614)[0m f1_per_class: [0.153, 0.236, 0.606, 0.356, 0.059, 0.355, 0.067, 0.359, 0.041, 0.318]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=62121)[0m top1: 0.2751865671641791
[2m[36m(func pid=62121)[0m top5: 0.8596082089552238
[2m[36m(func pid=62121)[0m f1_micro: 0.2751865671641791
[2m[36m(func pid=62121)[0m f1_macro: 0.3021270824402339
[2m[36m(func pid=62121)[0m f1_weighted: 0.2864693105192221
[2m[36m(func pid=62121)[0m f1_per_class: [0.292, 0.124, 0.741, 0.474, 0.049, 0.233, 0.204, 0.429, 0.21, 0.267]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 2.5396 | Steps: 2 | Val loss: 2.3226 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
== Status ==
Current time: 2024-01-07 02:39:31 (running for 00:15:32.67)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: 0.208
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.61  |      0.29  |                   69 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.016 |      0.302 |                   63 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.103 |      0.255 |                   62 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  2.55  |      0.024 |                   12 |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.3199626865671642
[2m[36m(func pid=60934)[0m top5: 0.8619402985074627
[2m[36m(func pid=60934)[0m f1_micro: 0.3199626865671642
[2m[36m(func pid=60934)[0m f1_macro: 0.28973194849435013
[2m[36m(func pid=60934)[0m f1_weighted: 0.3495221658894264
[2m[36m(func pid=60934)[0m f1_per_class: [0.132, 0.526, 0.21, 0.429, 0.097, 0.33, 0.197, 0.524, 0.123, 0.33]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 1.1278 | Steps: 2 | Val loss: 2.5516 | Batch size: 32 | lr: 0.1 | Duration: 2.73s
[2m[36m(func pid=73645)[0m top1: 0.04151119402985075
[2m[36m(func pid=73645)[0m top5: 0.5634328358208955
[2m[36m(func pid=73645)[0m f1_micro: 0.04151119402985075
[2m[36m(func pid=73645)[0m f1_macro: 0.026333955231146195
[2m[36m(func pid=73645)[0m f1_weighted: 0.05210684259586958
[2m[36m(func pid=73645)[0m f1_per_class: [0.0, 0.162, 0.015, 0.087, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.0123 | Steps: 2 | Val loss: 3.5453 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.3300 | Steps: 2 | Val loss: 2.0855 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=62614)[0m top1: 0.22294776119402984
[2m[36m(func pid=62614)[0m top5: 0.8232276119402985
[2m[36m(func pid=62614)[0m f1_micro: 0.22294776119402981
[2m[36m(func pid=62614)[0m f1_macro: 0.22775948600442092
[2m[36m(func pid=62614)[0m f1_weighted: 0.2019733789698134
[2m[36m(func pid=62614)[0m f1_per_class: [0.113, 0.298, 0.571, 0.341, 0.032, 0.209, 0.003, 0.335, 0.048, 0.328]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=62121)[0m top1: 0.2733208955223881
[2m[36m(func pid=62121)[0m top5: 0.8661380597014925
[2m[36m(func pid=62121)[0m f1_micro: 0.2733208955223881
[2m[36m(func pid=62121)[0m f1_macro: 0.2960890304728236
[2m[36m(func pid=62121)[0m f1_weighted: 0.2920094210206005
[2m[36m(func pid=62121)[0m f1_per_class: [0.298, 0.116, 0.645, 0.456, 0.048, 0.246, 0.24, 0.413, 0.24, 0.259]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 2.5003 | Steps: 2 | Val loss: 2.3185 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 02:39:37 (running for 00:15:38.03)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: 0.208
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.33  |      0.282 |                   70 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.012 |      0.296 |                   64 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.128 |      0.228 |                   63 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  2.54  |      0.026 |                   13 |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.3278917910447761
[2m[36m(func pid=60934)[0m top5: 0.867070895522388
[2m[36m(func pid=60934)[0m f1_micro: 0.3278917910447761
[2m[36m(func pid=60934)[0m f1_macro: 0.28234000502884643
[2m[36m(func pid=60934)[0m f1_weighted: 0.35301039003729223
[2m[36m(func pid=60934)[0m f1_per_class: [0.145, 0.516, 0.227, 0.434, 0.107, 0.312, 0.22, 0.508, 0.153, 0.201]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.9458 | Steps: 2 | Val loss: 2.5922 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
[2m[36m(func pid=73645)[0m top1: 0.05037313432835821
[2m[36m(func pid=73645)[0m top5: 0.5797574626865671
[2m[36m(func pid=73645)[0m f1_micro: 0.05037313432835821
[2m[36m(func pid=73645)[0m f1_macro: 0.032885915438188335
[2m[36m(func pid=73645)[0m f1_weighted: 0.05879772514881497
[2m[36m(func pid=73645)[0m f1_per_class: [0.0, 0.235, 0.016, 0.062, 0.0, 0.0, 0.0, 0.016, 0.0, 0.0]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.2245 | Steps: 2 | Val loss: 3.5630 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.3256 | Steps: 2 | Val loss: 1.7756 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=62614)[0m top1: 0.26072761194029853
[2m[36m(func pid=62614)[0m top5: 0.832089552238806
[2m[36m(func pid=62614)[0m f1_micro: 0.26072761194029853
[2m[36m(func pid=62614)[0m f1_macro: 0.2890905749876812
[2m[36m(func pid=62614)[0m f1_weighted: 0.2322264601058138
[2m[36m(func pid=62614)[0m f1_per_class: [0.173, 0.319, 0.714, 0.333, 0.069, 0.378, 0.003, 0.389, 0.162, 0.35]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=62121)[0m top1: 0.27052238805970147
[2m[36m(func pid=62121)[0m top5: 0.8596082089552238
[2m[36m(func pid=62121)[0m f1_micro: 0.27052238805970147
[2m[36m(func pid=62121)[0m f1_macro: 0.2805624281442447
[2m[36m(func pid=62121)[0m f1_weighted: 0.27728206621487606
[2m[36m(func pid=62121)[0m f1_per_class: [0.247, 0.128, 0.526, 0.456, 0.05, 0.249, 0.182, 0.431, 0.257, 0.278]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 2.4970 | Steps: 2 | Val loss: 2.3196 | Batch size: 32 | lr: 0.0001 | Duration: 2.79s
== Status ==
Current time: 2024-01-07 02:39:42 (running for 00:15:43.47)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: 0.208
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.326 |      0.348 |                   71 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.225 |      0.281 |                   65 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  0.946 |      0.289 |                   64 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  2.5   |      0.033 |                   14 |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.4099813432835821
[2m[36m(func pid=60934)[0m top5: 0.8936567164179104
[2m[36m(func pid=60934)[0m f1_micro: 0.4099813432835821
[2m[36m(func pid=60934)[0m f1_macro: 0.347640420838926
[2m[36m(func pid=60934)[0m f1_weighted: 0.4397832503327693
[2m[36m(func pid=60934)[0m f1_per_class: [0.187, 0.538, 0.275, 0.478, 0.115, 0.369, 0.415, 0.536, 0.196, 0.368]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 1.1526 | Steps: 2 | Val loss: 2.5807 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
[2m[36m(func pid=73645)[0m top1: 0.06296641791044776
[2m[36m(func pid=73645)[0m top5: 0.5816231343283582
[2m[36m(func pid=73645)[0m f1_micro: 0.06296641791044776
[2m[36m(func pid=73645)[0m f1_macro: 0.039080126891381475
[2m[36m(func pid=73645)[0m f1_weighted: 0.0645246586873239
[2m[36m(func pid=73645)[0m f1_per_class: [0.015, 0.303, 0.018, 0.04, 0.0, 0.0, 0.0, 0.016, 0.0, 0.0]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.0332 | Steps: 2 | Val loss: 3.8716 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.3549 | Steps: 2 | Val loss: 1.7294 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=62614)[0m top1: 0.23880597014925373
[2m[36m(func pid=62614)[0m top5: 0.8423507462686567
[2m[36m(func pid=62614)[0m f1_micro: 0.23880597014925373
[2m[36m(func pid=62614)[0m f1_macro: 0.27430372574184825
[2m[36m(func pid=62614)[0m f1_weighted: 0.23132189196821984
[2m[36m(func pid=62614)[0m f1_per_class: [0.14, 0.325, 0.714, 0.245, 0.077, 0.307, 0.12, 0.363, 0.102, 0.349]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=62121)[0m top1: 0.2537313432835821
[2m[36m(func pid=62121)[0m top5: 0.8171641791044776
[2m[36m(func pid=62121)[0m f1_micro: 0.2537313432835821
[2m[36m(func pid=62121)[0m f1_macro: 0.24900655220196813
[2m[36m(func pid=62121)[0m f1_weighted: 0.23882339099490363
[2m[36m(func pid=62121)[0m f1_per_class: [0.206, 0.139, 0.476, 0.466, 0.054, 0.287, 0.045, 0.396, 0.156, 0.265]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 2.4533 | Steps: 2 | Val loss: 2.3214 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 02:39:47 (running for 00:15:48.68)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: 0.208
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.355 |      0.347 |                   72 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.033 |      0.249 |                   66 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.153 |      0.274 |                   65 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  2.497 |      0.039 |                   15 |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.41884328358208955
[2m[36m(func pid=60934)[0m top5: 0.9020522388059702
[2m[36m(func pid=60934)[0m f1_micro: 0.41884328358208955
[2m[36m(func pid=60934)[0m f1_macro: 0.3471121676552832
[2m[36m(func pid=60934)[0m f1_weighted: 0.4460510053999683
[2m[36m(func pid=60934)[0m f1_per_class: [0.198, 0.539, 0.278, 0.46, 0.091, 0.333, 0.47, 0.516, 0.173, 0.412]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.9772 | Steps: 2 | Val loss: 2.6762 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=73645)[0m top1: 0.06529850746268656
[2m[36m(func pid=73645)[0m top5: 0.6012126865671642
[2m[36m(func pid=73645)[0m f1_micro: 0.06529850746268656
[2m[36m(func pid=73645)[0m f1_macro: 0.036145142774986094
[2m[36m(func pid=73645)[0m f1_weighted: 0.05932435550976254
[2m[36m(func pid=73645)[0m f1_per_class: [0.013, 0.304, 0.021, 0.024, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.0202 | Steps: 2 | Val loss: 4.0851 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.2723 | Steps: 2 | Val loss: 1.7923 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=62614)[0m top1: 0.29244402985074625
[2m[36m(func pid=62614)[0m top5: 0.8530783582089553
[2m[36m(func pid=62614)[0m f1_micro: 0.29244402985074625
[2m[36m(func pid=62614)[0m f1_macro: 0.3311501438831054
[2m[36m(func pid=62614)[0m f1_weighted: 0.31258135043664753
[2m[36m(func pid=62614)[0m f1_per_class: [0.116, 0.346, 0.714, 0.161, 0.093, 0.364, 0.404, 0.489, 0.148, 0.476]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=62121)[0m top1: 0.25046641791044777
[2m[36m(func pid=62121)[0m top5: 0.8027052238805971
[2m[36m(func pid=62121)[0m f1_micro: 0.25046641791044777
[2m[36m(func pid=62121)[0m f1_macro: 0.22605518806931615
[2m[36m(func pid=62121)[0m f1_weighted: 0.2227839071514023
[2m[36m(func pid=62121)[0m f1_per_class: [0.175, 0.169, 0.408, 0.451, 0.054, 0.318, 0.006, 0.262, 0.148, 0.269]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 2.4426 | Steps: 2 | Val loss: 2.3232 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
== Status ==
Current time: 2024-01-07 02:39:53 (running for 00:15:54.01)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: 0.208
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.272 |      0.339 |                   73 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.02  |      0.226 |                   67 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  0.977 |      0.331 |                   66 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  2.453 |      0.036 |                   16 |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.39972014925373134
[2m[36m(func pid=60934)[0m top5: 0.9011194029850746
[2m[36m(func pid=60934)[0m f1_micro: 0.39972014925373134
[2m[36m(func pid=60934)[0m f1_macro: 0.33875689926285235
[2m[36m(func pid=60934)[0m f1_weighted: 0.42891244276171786
[2m[36m(func pid=60934)[0m f1_per_class: [0.173, 0.53, 0.278, 0.437, 0.09, 0.322, 0.446, 0.505, 0.184, 0.424]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.9449 | Steps: 2 | Val loss: 2.7085 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=73645)[0m top1: 0.07602611940298508
[2m[36m(func pid=73645)[0m top5: 0.6296641791044776
[2m[36m(func pid=73645)[0m f1_micro: 0.07602611940298508
[2m[36m(func pid=73645)[0m f1_macro: 0.04304495439938191
[2m[36m(func pid=73645)[0m f1_weighted: 0.06746317027146052
[2m[36m(func pid=73645)[0m f1_per_class: [0.015, 0.314, 0.028, 0.018, 0.0, 0.024, 0.015, 0.0, 0.016, 0.0]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.0621 | Steps: 2 | Val loss: 4.2152 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.2897 | Steps: 2 | Val loss: 1.8679 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=62614)[0m top1: 0.35027985074626866
[2m[36m(func pid=62614)[0m top5: 0.8610074626865671
[2m[36m(func pid=62614)[0m f1_micro: 0.35027985074626866
[2m[36m(func pid=62614)[0m f1_macro: 0.32232077068884146
[2m[36m(func pid=62614)[0m f1_weighted: 0.3636634893657235
[2m[36m(func pid=62614)[0m f1_per_class: [0.124, 0.363, 0.692, 0.239, 0.161, 0.437, 0.527, 0.165, 0.188, 0.329]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=62121)[0m top1: 0.23041044776119404
[2m[36m(func pid=62121)[0m top5: 0.832089552238806
[2m[36m(func pid=62121)[0m f1_micro: 0.23041044776119404
[2m[36m(func pid=62121)[0m f1_macro: 0.20379721373110735
[2m[36m(func pid=62121)[0m f1_weighted: 0.19774164821087936
[2m[36m(func pid=62121)[0m f1_per_class: [0.167, 0.176, 0.377, 0.399, 0.06, 0.211, 0.009, 0.253, 0.18, 0.205]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 2.4986 | Steps: 2 | Val loss: 2.3280 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
== Status ==
Current time: 2024-01-07 02:39:58 (running for 00:15:59.14)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: 0.208
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.29  |      0.341 |                   74 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.062 |      0.204 |                   68 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  0.945 |      0.322 |                   67 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  2.443 |      0.043 |                   17 |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.38992537313432835
[2m[36m(func pid=60934)[0m top5: 0.8959888059701493
[2m[36m(func pid=60934)[0m f1_micro: 0.38992537313432835
[2m[36m(func pid=60934)[0m f1_macro: 0.34138047592067233
[2m[36m(func pid=60934)[0m f1_weighted: 0.42695896481578355
[2m[36m(func pid=60934)[0m f1_per_class: [0.159, 0.534, 0.303, 0.427, 0.08, 0.337, 0.438, 0.516, 0.184, 0.435]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 1.0478 | Steps: 2 | Val loss: 2.6906 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.0295 | Steps: 2 | Val loss: 4.0264 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=73645)[0m top1: 0.09095149253731344
[2m[36m(func pid=73645)[0m top5: 0.6781716417910447
[2m[36m(func pid=73645)[0m f1_micro: 0.09095149253731345
[2m[36m(func pid=73645)[0m f1_macro: 0.06504732051296609
[2m[36m(func pid=73645)[0m f1_weighted: 0.09769788570771591
[2m[36m(func pid=73645)[0m f1_per_class: [0.017, 0.31, 0.04, 0.006, 0.0, 0.116, 0.093, 0.0, 0.009, 0.059]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.2767 | Steps: 2 | Val loss: 1.8631 | Batch size: 32 | lr: 0.001 | Duration: 2.76s
[2m[36m(func pid=62614)[0m top1: 0.37220149253731344
[2m[36m(func pid=62614)[0m top5: 0.8572761194029851
[2m[36m(func pid=62614)[0m f1_micro: 0.3722014925373134
[2m[36m(func pid=62614)[0m f1_macro: 0.28441504152729513
[2m[36m(func pid=62614)[0m f1_weighted: 0.36777903673151
[2m[36m(func pid=62614)[0m f1_per_class: [0.185, 0.394, 0.667, 0.342, 0.073, 0.136, 0.57, 0.077, 0.078, 0.323]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=62121)[0m top1: 0.22574626865671643
[2m[36m(func pid=62121)[0m top5: 0.8479477611940298
[2m[36m(func pid=62121)[0m f1_micro: 0.22574626865671643
[2m[36m(func pid=62121)[0m f1_macro: 0.19684335830982616
[2m[36m(func pid=62121)[0m f1_weighted: 0.20982489637025012
[2m[36m(func pid=62121)[0m f1_per_class: [0.134, 0.181, 0.323, 0.361, 0.066, 0.193, 0.094, 0.236, 0.208, 0.172]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 2.5563 | Steps: 2 | Val loss: 2.3334 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
== Status ==
Current time: 2024-01-07 02:40:03 (running for 00:16:04.20)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: 0.292
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.277 |      0.339 |                   75 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.029 |      0.197 |                   69 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.048 |      0.284 |                   68 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  2.499 |      0.065 |                   18 |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.3917910447761194
[2m[36m(func pid=60934)[0m top5: 0.8917910447761194
[2m[36m(func pid=60934)[0m f1_micro: 0.3917910447761195
[2m[36m(func pid=60934)[0m f1_macro: 0.33938383320226995
[2m[36m(func pid=60934)[0m f1_weighted: 0.42944276007115006
[2m[36m(func pid=60934)[0m f1_per_class: [0.18, 0.544, 0.303, 0.447, 0.067, 0.309, 0.438, 0.48, 0.191, 0.435]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 1.1286 | Steps: 2 | Val loss: 2.6681 | Batch size: 32 | lr: 0.1 | Duration: 2.78s
[2m[36m(func pid=73645)[0m top1: 0.11287313432835822
[2m[36m(func pid=73645)[0m top5: 0.7145522388059702
[2m[36m(func pid=73645)[0m f1_micro: 0.11287313432835822
[2m[36m(func pid=73645)[0m f1_macro: 0.08813564488881405
[2m[36m(func pid=73645)[0m f1_weighted: 0.13543310631208025
[2m[36m(func pid=73645)[0m f1_per_class: [0.019, 0.326, 0.052, 0.0, 0.0, 0.208, 0.178, 0.0, 0.03, 0.069]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.0087 | Steps: 2 | Val loss: 3.8577 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 75] | Train loss: 0.2670 | Steps: 2 | Val loss: 1.8129 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=62614)[0m top1: 0.3474813432835821
[2m[36m(func pid=62614)[0m top5: 0.8563432835820896
[2m[36m(func pid=62614)[0m f1_micro: 0.3474813432835821
[2m[36m(func pid=62614)[0m f1_macro: 0.32215588153515573
[2m[36m(func pid=62614)[0m f1_weighted: 0.34640145088570506
[2m[36m(func pid=62614)[0m f1_per_class: [0.127, 0.417, 0.667, 0.369, 0.084, 0.213, 0.347, 0.447, 0.21, 0.342]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=62121)[0m top1: 0.24207089552238806
[2m[36m(func pid=62121)[0m top5: 0.8544776119402985
[2m[36m(func pid=62121)[0m f1_micro: 0.24207089552238806
[2m[36m(func pid=62121)[0m f1_macro: 0.19603535742864622
[2m[36m(func pid=62121)[0m f1_weighted: 0.2487104915915023
[2m[36m(func pid=62121)[0m f1_per_class: [0.123, 0.188, 0.313, 0.361, 0.068, 0.169, 0.254, 0.134, 0.187, 0.164]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 2.3640 | Steps: 2 | Val loss: 2.3306 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
== Status ==
Current time: 2024-01-07 02:40:08 (running for 00:16:09.57)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: 0.292
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.267 |      0.353 |                   76 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.009 |      0.196 |                   70 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.129 |      0.322 |                   69 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  2.556 |      0.088 |                   19 |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.40625
[2m[36m(func pid=60934)[0m top5: 0.8964552238805971
[2m[36m(func pid=60934)[0m f1_micro: 0.40625
[2m[36m(func pid=60934)[0m f1_macro: 0.3533814774135654
[2m[36m(func pid=60934)[0m f1_weighted: 0.43923610150835296
[2m[36m(func pid=60934)[0m f1_per_class: [0.194, 0.542, 0.317, 0.459, 0.098, 0.347, 0.436, 0.515, 0.207, 0.417]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 1.0374 | Steps: 2 | Val loss: 2.6943 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=73645)[0m top1: 0.13246268656716417
[2m[36m(func pid=73645)[0m top5: 0.7397388059701493
[2m[36m(func pid=73645)[0m f1_micro: 0.13246268656716417
[2m[36m(func pid=73645)[0m f1_macro: 0.10644158672612755
[2m[36m(func pid=73645)[0m f1_weighted: 0.16687832499654698
[2m[36m(func pid=73645)[0m f1_per_class: [0.024, 0.326, 0.074, 0.0, 0.0, 0.274, 0.255, 0.016, 0.022, 0.074]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.0097 | Steps: 2 | Val loss: 3.8325 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 76] | Train loss: 0.2205 | Steps: 2 | Val loss: 1.7973 | Batch size: 32 | lr: 0.001 | Duration: 2.69s
[2m[36m(func pid=62614)[0m top1: 0.3255597014925373
[2m[36m(func pid=62614)[0m top5: 0.8558768656716418
[2m[36m(func pid=62614)[0m f1_micro: 0.3255597014925373
[2m[36m(func pid=62614)[0m f1_macro: 0.31058287332109336
[2m[36m(func pid=62614)[0m f1_weighted: 0.31580427430289326
[2m[36m(func pid=62614)[0m f1_per_class: [0.137, 0.427, 0.667, 0.365, 0.053, 0.342, 0.205, 0.423, 0.135, 0.351]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=62121)[0m top1: 0.25419776119402987
[2m[36m(func pid=62121)[0m top5: 0.8493470149253731
[2m[36m(func pid=62121)[0m f1_micro: 0.25419776119402987
[2m[36m(func pid=62121)[0m f1_macro: 0.18965319817892706
[2m[36m(func pid=62121)[0m f1_weighted: 0.27056872399067994
[2m[36m(func pid=62121)[0m f1_per_class: [0.111, 0.186, 0.313, 0.356, 0.066, 0.162, 0.36, 0.016, 0.181, 0.146]
[2m[36m(func pid=62121)[0m 
== Status ==
Current time: 2024-01-07 02:40:13 (running for 00:16:14.71)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: 0.292
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.22  |      0.355 |                   77 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.19  |                   71 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.037 |      0.311 |                   70 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  2.364 |      0.106 |                   20 |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.40718283582089554
[2m[36m(func pid=60934)[0m top5: 0.8969216417910447
[2m[36m(func pid=60934)[0m f1_micro: 0.40718283582089554
[2m[36m(func pid=60934)[0m f1_macro: 0.35485266341124716
[2m[36m(func pid=60934)[0m f1_weighted: 0.4363858427667493
[2m[36m(func pid=60934)[0m f1_per_class: [0.192, 0.545, 0.328, 0.459, 0.111, 0.35, 0.42, 0.53, 0.229, 0.386]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 2.3512 | Steps: 2 | Val loss: 2.3244 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.9554 | Steps: 2 | Val loss: 2.7269 | Batch size: 32 | lr: 0.1 | Duration: 2.76s
[2m[36m(func pid=73645)[0m top1: 0.15438432835820895
[2m[36m(func pid=73645)[0m top5: 0.7425373134328358
[2m[36m(func pid=73645)[0m f1_micro: 0.15438432835820895
[2m[36m(func pid=73645)[0m f1_macro: 0.13209617560670855
[2m[36m(func pid=73645)[0m f1_weighted: 0.1935497219757036
[2m[36m(func pid=73645)[0m f1_per_class: [0.027, 0.322, 0.093, 0.0, 0.107, 0.306, 0.327, 0.032, 0.031, 0.077]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 77] | Train loss: 0.2746 | Steps: 2 | Val loss: 1.7782 | Batch size: 32 | lr: 0.001 | Duration: 2.71s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.0237 | Steps: 2 | Val loss: 3.7428 | Batch size: 32 | lr: 0.01 | Duration: 3.03s
[2m[36m(func pid=62614)[0m top1: 0.30550373134328357
[2m[36m(func pid=62614)[0m top5: 0.8502798507462687
[2m[36m(func pid=62614)[0m f1_micro: 0.30550373134328357
[2m[36m(func pid=62614)[0m f1_macro: 0.28686477472632976
[2m[36m(func pid=62614)[0m f1_weighted: 0.3119095678703669
[2m[36m(func pid=62614)[0m f1_per_class: [0.151, 0.341, 0.72, 0.42, 0.027, 0.203, 0.25, 0.47, 0.0, 0.286]
[2m[36m(func pid=62614)[0m 
== Status ==
Current time: 2024-01-07 02:40:18 (running for 00:16:19.78)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: 0.292
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.22  |      0.355 |                   77 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.024 |      0.204 |                   72 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  0.955 |      0.287 |                   71 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  2.351 |      0.132 |                   21 |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.4118470149253731
[2m[36m(func pid=60934)[0m top5: 0.8987873134328358
[2m[36m(func pid=60934)[0m f1_micro: 0.4118470149253731
[2m[36m(func pid=60934)[0m f1_macro: 0.35873603485983413
[2m[36m(func pid=60934)[0m f1_weighted: 0.4383028058848091
[2m[36m(func pid=60934)[0m f1_per_class: [0.202, 0.557, 0.344, 0.46, 0.111, 0.345, 0.421, 0.529, 0.209, 0.41]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62121)[0m top1: 0.28078358208955223
[2m[36m(func pid=62121)[0m top5: 0.8507462686567164
[2m[36m(func pid=62121)[0m f1_micro: 0.28078358208955223
[2m[36m(func pid=62121)[0m f1_macro: 0.2037317519438567
[2m[36m(func pid=62121)[0m f1_weighted: 0.30111300940662994
[2m[36m(func pid=62121)[0m f1_per_class: [0.113, 0.183, 0.308, 0.38, 0.069, 0.197, 0.428, 0.016, 0.185, 0.159]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 2.3304 | Steps: 2 | Val loss: 2.3204 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 1.2662 | Steps: 2 | Val loss: 2.5059 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=73645)[0m top1: 0.1669776119402985
[2m[36m(func pid=73645)[0m top5: 0.7369402985074627
[2m[36m(func pid=73645)[0m f1_micro: 0.1669776119402985
[2m[36m(func pid=73645)[0m f1_macro: 0.14528306259967796
[2m[36m(func pid=73645)[0m f1_weighted: 0.20486694794583385
[2m[36m(func pid=73645)[0m f1_per_class: [0.029, 0.305, 0.117, 0.0, 0.182, 0.347, 0.362, 0.0, 0.033, 0.077]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 78] | Train loss: 0.2423 | Steps: 2 | Val loss: 1.8031 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.0198 | Steps: 2 | Val loss: 3.6320 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=62614)[0m top1: 0.36986940298507465
[2m[36m(func pid=62614)[0m top5: 0.8586753731343284
[2m[36m(func pid=62614)[0m f1_micro: 0.36986940298507465
[2m[36m(func pid=62614)[0m f1_macro: 0.33658900855893137
[2m[36m(func pid=62614)[0m f1_weighted: 0.3850611249003511
[2m[36m(func pid=62614)[0m f1_per_class: [0.128, 0.248, 0.88, 0.508, 0.045, 0.26, 0.428, 0.505, 0.067, 0.296]
[2m[36m(func pid=62614)[0m 
== Status ==
Current time: 2024-01-07 02:40:24 (running for 00:16:25.08)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: 0.292
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.242 |      0.355 |                   79 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.024 |      0.204 |                   72 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.266 |      0.337 |                   72 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  2.33  |      0.145 |                   22 |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.41044776119402987
[2m[36m(func pid=60934)[0m top5: 0.894589552238806
[2m[36m(func pid=60934)[0m f1_micro: 0.41044776119402987
[2m[36m(func pid=60934)[0m f1_macro: 0.3549362751187349
[2m[36m(func pid=60934)[0m f1_weighted: 0.4412428734730695
[2m[36m(func pid=60934)[0m f1_per_class: [0.197, 0.565, 0.317, 0.461, 0.103, 0.345, 0.431, 0.506, 0.207, 0.417]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62121)[0m top1: 0.2989738805970149
[2m[36m(func pid=62121)[0m top5: 0.855410447761194
[2m[36m(func pid=62121)[0m f1_micro: 0.2989738805970149
[2m[36m(func pid=62121)[0m f1_macro: 0.21166634885420083
[2m[36m(func pid=62121)[0m f1_weighted: 0.3187533858770489
[2m[36m(func pid=62121)[0m f1_per_class: [0.112, 0.166, 0.286, 0.424, 0.072, 0.271, 0.43, 0.0, 0.186, 0.169]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 2.2931 | Steps: 2 | Val loss: 2.3152 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.8433 | Steps: 2 | Val loss: 2.5100 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=73645)[0m top1: 0.1669776119402985
[2m[36m(func pid=73645)[0m top5: 0.7299440298507462
[2m[36m(func pid=73645)[0m f1_micro: 0.1669776119402985
[2m[36m(func pid=73645)[0m f1_macro: 0.14293992907381597
[2m[36m(func pid=73645)[0m f1_weighted: 0.2026243062727143
[2m[36m(func pid=73645)[0m f1_per_class: [0.03, 0.251, 0.136, 0.0, 0.173, 0.34, 0.389, 0.0, 0.033, 0.077]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 79] | Train loss: 0.1937 | Steps: 2 | Val loss: 1.8384 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.0075 | Steps: 2 | Val loss: 3.5385 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=62614)[0m top1: 0.3591417910447761
[2m[36m(func pid=62614)[0m top5: 0.8694029850746269
[2m[36m(func pid=62614)[0m f1_micro: 0.3591417910447761
[2m[36m(func pid=62614)[0m f1_macro: 0.30079783573563074
[2m[36m(func pid=62614)[0m f1_weighted: 0.36564797860971154
[2m[36m(func pid=62614)[0m f1_per_class: [0.115, 0.271, 0.833, 0.509, 0.048, 0.318, 0.411, 0.045, 0.124, 0.333]
[2m[36m(func pid=62614)[0m 
== Status ==
Current time: 2024-01-07 02:40:29 (running for 00:16:30.37)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: 0.292
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.194 |      0.347 |                   80 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.02  |      0.212 |                   73 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  0.843 |      0.301 |                   73 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  2.293 |      0.143 |                   23 |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.39972014925373134
[2m[36m(func pid=60934)[0m top5: 0.8931902985074627
[2m[36m(func pid=60934)[0m f1_micro: 0.39972014925373134
[2m[36m(func pid=60934)[0m f1_macro: 0.34654557966242594
[2m[36m(func pid=60934)[0m f1_weighted: 0.43357266220351215
[2m[36m(func pid=60934)[0m f1_per_class: [0.192, 0.559, 0.328, 0.456, 0.097, 0.328, 0.431, 0.455, 0.188, 0.431]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62121)[0m top1: 0.31203358208955223
[2m[36m(func pid=62121)[0m top5: 0.8577425373134329
[2m[36m(func pid=62121)[0m f1_micro: 0.31203358208955223
[2m[36m(func pid=62121)[0m f1_macro: 0.23664673373327774
[2m[36m(func pid=62121)[0m f1_weighted: 0.3314381537386467
[2m[36m(func pid=62121)[0m f1_per_class: [0.112, 0.161, 0.267, 0.454, 0.079, 0.341, 0.388, 0.162, 0.191, 0.212]
[2m[36m(func pid=62121)[0m 
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 2.2280 | Steps: 2 | Val loss: 2.3150 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 1.0212 | Steps: 2 | Val loss: 2.5512 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=73645)[0m top1: 0.1707089552238806
[2m[36m(func pid=73645)[0m top5: 0.7136194029850746
[2m[36m(func pid=73645)[0m f1_micro: 0.1707089552238806
[2m[36m(func pid=73645)[0m f1_macro: 0.14782043582381416
[2m[36m(func pid=73645)[0m f1_weighted: 0.20388400772187318
[2m[36m(func pid=73645)[0m f1_per_class: [0.034, 0.231, 0.167, 0.0, 0.182, 0.34, 0.4, 0.016, 0.034, 0.074]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 80] | Train loss: 0.4220 | Steps: 2 | Val loss: 1.7572 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=62121)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.0098 | Steps: 2 | Val loss: 3.5309 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
[2m[36m(func pid=62614)[0m top1: 0.353544776119403
[2m[36m(func pid=62614)[0m top5: 0.8740671641791045
[2m[36m(func pid=62614)[0m f1_micro: 0.353544776119403
[2m[36m(func pid=62614)[0m f1_macro: 0.30976443429138656
[2m[36m(func pid=62614)[0m f1_weighted: 0.3764170311469312
[2m[36m(func pid=62614)[0m f1_per_class: [0.13, 0.319, 0.833, 0.448, 0.037, 0.288, 0.486, 0.015, 0.166, 0.375]
[2m[36m(func pid=62614)[0m 
== Status ==
Current time: 2024-01-07 02:40:34 (running for 00:16:35.58)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: 0.292
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.422 |      0.363 |                   81 |
| train_6ed81_00006 | RUNNING    | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.007 |      0.237 |                   74 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.021 |      0.31  |                   74 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  2.228 |      0.148 |                   24 |
| train_6ed81_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.425839552238806
[2m[36m(func pid=60934)[0m top5: 0.9095149253731343
[2m[36m(func pid=60934)[0m f1_micro: 0.42583955223880593
[2m[36m(func pid=60934)[0m f1_macro: 0.3632141539499586
[2m[36m(func pid=60934)[0m f1_weighted: 0.4583558086183814
[2m[36m(func pid=60934)[0m f1_per_class: [0.221, 0.562, 0.355, 0.469, 0.092, 0.334, 0.489, 0.483, 0.198, 0.429]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 2.2118 | Steps: 2 | Val loss: 2.3165 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=62121)[0m top1: 0.31296641791044777
[2m[36m(func pid=62121)[0m top5: 0.8540111940298507
[2m[36m(func pid=62121)[0m f1_micro: 0.31296641791044777
[2m[36m(func pid=62121)[0m f1_macro: 0.25020092114357023
[2m[36m(func pid=62121)[0m f1_weighted: 0.3259259270232205
[2m[36m(func pid=62121)[0m f1_per_class: [0.113, 0.154, 0.272, 0.466, 0.089, 0.389, 0.315, 0.311, 0.177, 0.216]
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.9846 | Steps: 2 | Val loss: 2.4782 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=73645)[0m top1: 0.17257462686567165
[2m[36m(func pid=73645)[0m top5: 0.7028917910447762
[2m[36m(func pid=73645)[0m f1_micro: 0.17257462686567165
[2m[36m(func pid=73645)[0m f1_macro: 0.14975180207563396
[2m[36m(func pid=73645)[0m f1_weighted: 0.20348318231190118
[2m[36m(func pid=73645)[0m f1_per_class: [0.038, 0.228, 0.194, 0.0, 0.189, 0.317, 0.409, 0.016, 0.033, 0.074]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 81] | Train loss: 0.2763 | Steps: 2 | Val loss: 1.8438 | Batch size: 32 | lr: 0.001 | Duration: 3.10s
[2m[36m(func pid=62614)[0m top1: 0.37033582089552236
[2m[36m(func pid=62614)[0m top5: 0.8722014925373134
[2m[36m(func pid=62614)[0m f1_micro: 0.37033582089552236
[2m[36m(func pid=62614)[0m f1_macro: 0.32709992789163556
[2m[36m(func pid=62614)[0m f1_weighted: 0.3878125705666743
[2m[36m(func pid=62614)[0m f1_per_class: [0.166, 0.284, 0.8, 0.396, 0.063, 0.095, 0.58, 0.513, 0.1, 0.275]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=60934)[0m top1: 0.40158582089552236
[2m[36m(func pid=60934)[0m top5: 0.9001865671641791
[2m[36m(func pid=60934)[0m f1_micro: 0.40158582089552236
[2m[36m(func pid=60934)[0m f1_macro: 0.35231743567972706
[2m[36m(func pid=60934)[0m f1_weighted: 0.43463528205464297
[2m[36m(func pid=60934)[0m f1_per_class: [0.232, 0.553, 0.361, 0.464, 0.082, 0.318, 0.429, 0.448, 0.222, 0.413]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 2.2098 | Steps: 2 | Val loss: 2.3103 | Batch size: 32 | lr: 0.0001 | Duration: 2.77s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 75] | Train loss: 0.9221 | Steps: 2 | Val loss: 2.4409 | Batch size: 32 | lr: 0.1 | Duration: 2.76s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 82] | Train loss: 0.3043 | Steps: 2 | Val loss: 1.9157 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
[2m[36m(func pid=73645)[0m top1: 0.18050373134328357
[2m[36m(func pid=73645)[0m top5: 0.7038246268656716
[2m[36m(func pid=73645)[0m f1_micro: 0.18050373134328357
[2m[36m(func pid=73645)[0m f1_macro: 0.14800024215840113
[2m[36m(func pid=73645)[0m f1_weighted: 0.20936498949575846
[2m[36m(func pid=73645)[0m f1_per_class: [0.044, 0.24, 0.229, 0.0, 0.185, 0.321, 0.425, 0.0, 0.037, 0.0]
== Status ==
Current time: 2024-01-07 02:40:40 (running for 00:16:41.02)
Memory usage on this node: 22.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.276 |      0.352 |                   82 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  0.985 |      0.327 |                   75 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  2.212 |      0.15  |                   25 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=79460)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=79460)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=79460)[0m Configuration completed!
[2m[36m(func pid=79460)[0m New optimizer parameters:
[2m[36m(func pid=79460)[0m SGD (
[2m[36m(func pid=79460)[0m Parameter Group 0
[2m[36m(func pid=79460)[0m     dampening: 0
[2m[36m(func pid=79460)[0m     differentiable: False
[2m[36m(func pid=79460)[0m     foreach: None
[2m[36m(func pid=79460)[0m     lr: 0.001
[2m[36m(func pid=79460)[0m     maximize: False
[2m[36m(func pid=79460)[0m     momentum: 0.99
[2m[36m(func pid=79460)[0m     nesterov: False
[2m[36m(func pid=79460)[0m     weight_decay: 0.0001
[2m[36m(func pid=79460)[0m )
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=62614)[0m top1: 0.35074626865671643
[2m[36m(func pid=62614)[0m top5: 0.867070895522388
[2m[36m(func pid=62614)[0m f1_micro: 0.35074626865671643
[2m[36m(func pid=62614)[0m f1_macro: 0.31425467262709506
[2m[36m(func pid=62614)[0m f1_weighted: 0.3663863379352205
[2m[36m(func pid=62614)[0m f1_per_class: [0.152, 0.314, 0.741, 0.397, 0.047, 0.152, 0.473, 0.484, 0.132, 0.25]
[2m[36m(func pid=62614)[0m 
== Status ==
Current time: 2024-01-07 02:40:45 (running for 00:16:46.25)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.304 |      0.324 |                   83 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  0.922 |      0.314 |                   76 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  2.21  |      0.148 |                   26 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.36847014925373134
[2m[36m(func pid=60934)[0m top5: 0.8964552238805971
[2m[36m(func pid=60934)[0m f1_micro: 0.3684701492537314
[2m[36m(func pid=60934)[0m f1_macro: 0.3236513754986786
[2m[36m(func pid=60934)[0m f1_weighted: 0.39695796704837216
[2m[36m(func pid=60934)[0m f1_per_class: [0.262, 0.516, 0.333, 0.467, 0.079, 0.299, 0.355, 0.321, 0.204, 0.4]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 2.1754 | Steps: 2 | Val loss: 2.3119 | Batch size: 32 | lr: 0.0001 | Duration: 3.13s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 76] | Train loss: 0.7332 | Steps: 2 | Val loss: 2.3416 | Batch size: 32 | lr: 0.1 | Duration: 2.98s
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 3.0763 | Steps: 2 | Val loss: 2.3733 | Batch size: 32 | lr: 0.001 | Duration: 4.60s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 83] | Train loss: 0.4252 | Steps: 2 | Val loss: 1.8934 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=73645)[0m top1: 0.1912313432835821
[2m[36m(func pid=73645)[0m top5: 0.7168843283582089
[2m[36m(func pid=73645)[0m f1_micro: 0.19123134328358207
[2m[36m(func pid=73645)[0m f1_macro: 0.15619819321871303
[2m[36m(func pid=73645)[0m f1_weighted: 0.22016277577752905
[2m[36m(func pid=73645)[0m f1_per_class: [0.049, 0.263, 0.247, 0.0, 0.182, 0.336, 0.438, 0.016, 0.03, 0.0]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=62614)[0m top1: 0.3805970149253731
[2m[36m(func pid=62614)[0m top5: 0.8726679104477612
[2m[36m(func pid=62614)[0m f1_micro: 0.3805970149253731
[2m[36m(func pid=62614)[0m f1_macro: 0.34961219740926563
[2m[36m(func pid=62614)[0m f1_weighted: 0.39730576381814364
[2m[36m(func pid=62614)[0m f1_per_class: [0.143, 0.312, 0.759, 0.482, 0.074, 0.326, 0.423, 0.479, 0.196, 0.302]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=79460)[0m top1: 0.07276119402985075
[2m[36m(func pid=79460)[0m top5: 0.30177238805970147
[2m[36m(func pid=79460)[0m f1_micro: 0.07276119402985075
[2m[36m(func pid=79460)[0m f1_macro: 0.021168842638209555
[2m[36m(func pid=79460)[0m f1_weighted: 0.03087280671907231
[2m[36m(func pid=79460)[0m f1_per_class: [0.0, 0.005, 0.0, 0.081, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0]
[2m[36m(func pid=79460)[0m 
== Status ==
Current time: 2024-01-07 02:40:50 (running for 00:16:51.50)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.425 |      0.337 |                   84 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  0.733 |      0.35  |                   77 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  2.175 |      0.156 |                   27 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  3.076 |      0.021 |                    1 |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.3773320895522388
[2m[36m(func pid=60934)[0m top5: 0.8936567164179104
[2m[36m(func pid=60934)[0m f1_micro: 0.3773320895522388
[2m[36m(func pid=60934)[0m f1_macro: 0.33651120954621344
[2m[36m(func pid=60934)[0m f1_weighted: 0.4075777658590051
[2m[36m(func pid=60934)[0m f1_per_class: [0.213, 0.504, 0.345, 0.471, 0.105, 0.34, 0.351, 0.493, 0.189, 0.354]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 2.2208 | Steps: 2 | Val loss: 2.3150 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 77] | Train loss: 0.8129 | Steps: 2 | Val loss: 2.4255 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 2.9282 | Steps: 2 | Val loss: 2.3304 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 84] | Train loss: 0.3449 | Steps: 2 | Val loss: 1.7675 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=73645)[0m top1: 0.19636194029850745
[2m[36m(func pid=73645)[0m top5: 0.7248134328358209
[2m[36m(func pid=73645)[0m f1_micro: 0.19636194029850748
[2m[36m(func pid=73645)[0m f1_macro: 0.16594191798903082
[2m[36m(func pid=73645)[0m f1_weighted: 0.22189413817195153
[2m[36m(func pid=73645)[0m f1_per_class: [0.054, 0.257, 0.278, 0.0, 0.169, 0.345, 0.443, 0.0, 0.038, 0.074]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=62614)[0m top1: 0.39505597014925375
[2m[36m(func pid=62614)[0m top5: 0.8652052238805971
[2m[36m(func pid=62614)[0m f1_micro: 0.39505597014925375
[2m[36m(func pid=62614)[0m f1_macro: 0.35563050211998315
[2m[36m(func pid=62614)[0m f1_weighted: 0.4130633369975705
[2m[36m(func pid=62614)[0m f1_per_class: [0.182, 0.249, 0.71, 0.513, 0.068, 0.371, 0.462, 0.512, 0.146, 0.344]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=79460)[0m top1: 0.08908582089552239
[2m[36m(func pid=79460)[0m top5: 0.47154850746268656
[2m[36m(func pid=79460)[0m f1_micro: 0.08908582089552237
[2m[36m(func pid=79460)[0m f1_macro: 0.06211492356447186
[2m[36m(func pid=79460)[0m f1_weighted: 0.07464295292141943
[2m[36m(func pid=79460)[0m f1_per_class: [0.0, 0.005, 0.018, 0.177, 0.0, 0.0, 0.0, 0.421, 0.0, 0.0]
[2m[36m(func pid=79460)[0m 
== Status ==
Current time: 2024-01-07 02:40:56 (running for 00:16:56.82)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.345 |      0.347 |                   85 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  0.813 |      0.356 |                   78 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  2.221 |      0.166 |                   28 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  2.928 |      0.062 |                    2 |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.4099813432835821
[2m[36m(func pid=60934)[0m top5: 0.9057835820895522
[2m[36m(func pid=60934)[0m f1_micro: 0.4099813432835821
[2m[36m(func pid=60934)[0m f1_macro: 0.3474854532238898
[2m[36m(func pid=60934)[0m f1_weighted: 0.43862326463769047
[2m[36m(func pid=60934)[0m f1_per_class: [0.193, 0.472, 0.317, 0.496, 0.121, 0.329, 0.449, 0.517, 0.191, 0.388]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 2.1087 | Steps: 2 | Val loss: 2.2987 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 78] | Train loss: 0.6756 | Steps: 2 | Val loss: 2.5430 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 2.7409 | Steps: 2 | Val loss: 2.3183 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 85] | Train loss: 0.2994 | Steps: 2 | Val loss: 1.7609 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=73645)[0m top1: 0.21735074626865672
[2m[36m(func pid=73645)[0m top5: 0.7402052238805971
[2m[36m(func pid=73645)[0m f1_micro: 0.21735074626865672
[2m[36m(func pid=73645)[0m f1_macro: 0.1807366864758023
[2m[36m(func pid=73645)[0m f1_weighted: 0.2385572042925348
[2m[36m(func pid=73645)[0m f1_per_class: [0.059, 0.276, 0.324, 0.0, 0.172, 0.36, 0.475, 0.031, 0.037, 0.074]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=62614)[0m top1: 0.38899253731343286
[2m[36m(func pid=62614)[0m top5: 0.8502798507462687
[2m[36m(func pid=62614)[0m f1_micro: 0.38899253731343286
[2m[36m(func pid=62614)[0m f1_macro: 0.3297001399988078
[2m[36m(func pid=62614)[0m f1_weighted: 0.4065435531636496
[2m[36m(func pid=62614)[0m f1_per_class: [0.238, 0.353, 0.688, 0.469, 0.05, 0.233, 0.487, 0.517, 0.038, 0.224]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=79460)[0m top1: 0.008395522388059701
[2m[36m(func pid=79460)[0m top5: 0.5489738805970149
[2m[36m(func pid=79460)[0m f1_micro: 0.008395522388059701
[2m[36m(func pid=79460)[0m f1_macro: 0.002799041889847032
[2m[36m(func pid=79460)[0m f1_weighted: 0.004446433975067779
[2m[36m(func pid=79460)[0m f1_per_class: [0.0, 0.0, 0.012, 0.016, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=79460)[0m 
== Status ==
Current time: 2024-01-07 02:41:01 (running for 00:17:02.21)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.299 |      0.348 |                   86 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  0.676 |      0.33  |                   79 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  2.109 |      0.181 |                   29 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  2.741 |      0.003 |                    3 |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.42350746268656714
[2m[36m(func pid=60934)[0m top5: 0.9095149253731343
[2m[36m(func pid=60934)[0m f1_micro: 0.42350746268656714
[2m[36m(func pid=60934)[0m f1_macro: 0.3481426117414734
[2m[36m(func pid=60934)[0m f1_weighted: 0.44412410489263326
[2m[36m(func pid=60934)[0m f1_per_class: [0.217, 0.494, 0.328, 0.51, 0.122, 0.231, 0.483, 0.482, 0.194, 0.421]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 2.0702 | Steps: 2 | Val loss: 2.2780 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 79] | Train loss: 1.2576 | Steps: 2 | Val loss: 2.6260 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 2.6081 | Steps: 2 | Val loss: 2.3136 | Batch size: 32 | lr: 0.001 | Duration: 3.05s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 86] | Train loss: 0.2974 | Steps: 2 | Val loss: 1.7287 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=73645)[0m top1: 0.228544776119403
[2m[36m(func pid=73645)[0m top5: 0.7574626865671642
[2m[36m(func pid=73645)[0m f1_micro: 0.228544776119403
[2m[36m(func pid=73645)[0m f1_macro: 0.1851472346142354
[2m[36m(func pid=73645)[0m f1_weighted: 0.2442206196220852
[2m[36m(func pid=73645)[0m f1_per_class: [0.064, 0.269, 0.349, 0.0, 0.156, 0.354, 0.496, 0.047, 0.041, 0.074]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=62614)[0m top1: 0.4141791044776119
[2m[36m(func pid=62614)[0m top5: 0.8652052238805971
[2m[36m(func pid=62614)[0m f1_micro: 0.4141791044776119
[2m[36m(func pid=62614)[0m f1_macro: 0.35740621374585146
[2m[36m(func pid=62614)[0m f1_weighted: 0.43397757053319497
[2m[36m(func pid=62614)[0m f1_per_class: [0.235, 0.442, 0.71, 0.481, 0.089, 0.291, 0.491, 0.506, 0.067, 0.263]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=79460)[0m top1: 0.009794776119402986
[2m[36m(func pid=79460)[0m top5: 0.5466417910447762
[2m[36m(func pid=79460)[0m f1_micro: 0.009794776119402986
[2m[36m(func pid=79460)[0m f1_macro: 0.00522242851028254
[2m[36m(func pid=79460)[0m f1_weighted: 0.0073155889183750995
[2m[36m(func pid=79460)[0m f1_per_class: [0.0, 0.037, 0.012, 0.003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=79460)[0m 
== Status ==
Current time: 2024-01-07 02:41:06 (running for 00:17:07.66)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.297 |      0.363 |                   87 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.258 |      0.357 |                   80 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  2.07  |      0.185 |                   30 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  2.608 |      0.005 |                    4 |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.43050373134328357
[2m[36m(func pid=60934)[0m top5: 0.9057835820895522
[2m[36m(func pid=60934)[0m f1_micro: 0.43050373134328357
[2m[36m(func pid=60934)[0m f1_macro: 0.3631340237131372
[2m[36m(func pid=60934)[0m f1_weighted: 0.45788605892582424
[2m[36m(func pid=60934)[0m f1_per_class: [0.218, 0.513, 0.323, 0.499, 0.125, 0.338, 0.482, 0.51, 0.191, 0.433]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 2.0420 | Steps: 2 | Val loss: 2.2553 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 80] | Train loss: 0.5416 | Steps: 2 | Val loss: 2.8477 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 2.5956 | Steps: 2 | Val loss: 2.3002 | Batch size: 32 | lr: 0.001 | Duration: 2.78s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 87] | Train loss: 0.1972 | Steps: 2 | Val loss: 1.8159 | Batch size: 32 | lr: 0.001 | Duration: 2.78s
[2m[36m(func pid=73645)[0m top1: 0.23647388059701493
[2m[36m(func pid=73645)[0m top5: 0.7667910447761194
[2m[36m(func pid=73645)[0m f1_micro: 0.23647388059701493
[2m[36m(func pid=73645)[0m f1_macro: 0.18316393419163135
[2m[36m(func pid=73645)[0m f1_weighted: 0.24434352001799967
[2m[36m(func pid=73645)[0m f1_per_class: [0.072, 0.3, 0.379, 0.0, 0.158, 0.314, 0.503, 0.0, 0.031, 0.074]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=62614)[0m top1: 0.3666044776119403
[2m[36m(func pid=62614)[0m top5: 0.8661380597014925
[2m[36m(func pid=62614)[0m f1_micro: 0.3666044776119403
[2m[36m(func pid=62614)[0m f1_macro: 0.3333967081473421
[2m[36m(func pid=62614)[0m f1_weighted: 0.37827559941465
[2m[36m(func pid=62614)[0m f1_per_class: [0.182, 0.436, 0.733, 0.467, 0.081, 0.326, 0.316, 0.467, 0.093, 0.233]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=79460)[0m top1: 0.052705223880597014
[2m[36m(func pid=79460)[0m top5: 0.6753731343283582
[2m[36m(func pid=79460)[0m f1_micro: 0.05270522388059702
[2m[36m(func pid=79460)[0m f1_macro: 0.035028816124150805
[2m[36m(func pid=79460)[0m f1_weighted: 0.058275258979900074
[2m[36m(func pid=79460)[0m f1_per_class: [0.0, 0.333, 0.014, 0.003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=79460)[0m 
== Status ==
Current time: 2024-01-07 02:41:12 (running for 00:17:12.86)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.197 |      0.358 |                   88 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  0.542 |      0.333 |                   81 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  2.042 |      0.183 |                   31 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  2.596 |      0.035 |                    5 |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.41091417910447764
[2m[36m(func pid=60934)[0m top5: 0.8908582089552238
[2m[36m(func pid=60934)[0m f1_micro: 0.4109141791044776
[2m[36m(func pid=60934)[0m f1_macro: 0.35809378165541644
[2m[36m(func pid=60934)[0m f1_weighted: 0.44580624260942253
[2m[36m(func pid=60934)[0m f1_per_class: [0.187, 0.522, 0.333, 0.478, 0.129, 0.368, 0.441, 0.538, 0.197, 0.388]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 2.0274 | Steps: 2 | Val loss: 2.2380 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 81] | Train loss: 0.8458 | Steps: 2 | Val loss: 3.1472 | Batch size: 32 | lr: 0.1 | Duration: 2.74s
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 2.4682 | Steps: 2 | Val loss: 2.2765 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 88] | Train loss: 0.2099 | Steps: 2 | Val loss: 1.7969 | Batch size: 32 | lr: 0.001 | Duration: 2.76s
[2m[36m(func pid=62614)[0m top1: 0.31203358208955223
[2m[36m(func pid=62614)[0m top5: 0.8754664179104478
[2m[36m(func pid=62614)[0m f1_micro: 0.31203358208955223
[2m[36m(func pid=62614)[0m f1_macro: 0.2983552283445932
[2m[36m(func pid=62614)[0m f1_weighted: 0.32754361711088903
[2m[36m(func pid=62614)[0m f1_per_class: [0.143, 0.408, 0.759, 0.412, 0.102, 0.191, 0.274, 0.444, 0.092, 0.159]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=73645)[0m top1: 0.25046641791044777
[2m[36m(func pid=73645)[0m top5: 0.7793843283582089
[2m[36m(func pid=73645)[0m f1_micro: 0.25046641791044777
[2m[36m(func pid=73645)[0m f1_macro: 0.1835703514885198
[2m[36m(func pid=73645)[0m f1_weighted: 0.2549620828798497
[2m[36m(func pid=73645)[0m f1_per_class: [0.076, 0.333, 0.357, 0.0, 0.143, 0.307, 0.524, 0.0, 0.022, 0.074]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=79460)[0m top1: 0.1142723880597015
[2m[36m(func pid=79460)[0m top5: 0.7425373134328358
[2m[36m(func pid=79460)[0m f1_micro: 0.1142723880597015
[2m[36m(func pid=79460)[0m f1_macro: 0.051492837043866736
[2m[36m(func pid=79460)[0m f1_weighted: 0.07745292991802241
[2m[36m(func pid=79460)[0m f1_per_class: [0.024, 0.435, 0.05, 0.0, 0.0, 0.0, 0.006, 0.0, 0.0, 0.0]
[2m[36m(func pid=79460)[0m 
== Status ==
Current time: 2024-01-07 02:41:17 (running for 00:17:17.91)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.21  |      0.355 |                   89 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  0.846 |      0.298 |                   82 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  2.027 |      0.184 |                   32 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  2.468 |      0.051 |                    6 |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.4123134328358209
[2m[36m(func pid=60934)[0m top5: 0.8922574626865671
[2m[36m(func pid=60934)[0m f1_micro: 0.4123134328358209
[2m[36m(func pid=60934)[0m f1_macro: 0.3548320830999082
[2m[36m(func pid=60934)[0m f1_weighted: 0.4409319460601393
[2m[36m(func pid=60934)[0m f1_per_class: [0.227, 0.535, 0.299, 0.488, 0.114, 0.354, 0.417, 0.495, 0.219, 0.4]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 82] | Train loss: 1.3070 | Steps: 2 | Val loss: 2.7319 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 1.9761 | Steps: 2 | Val loss: 2.2200 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 2.4289 | Steps: 2 | Val loss: 2.2493 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 89] | Train loss: 0.2208 | Steps: 2 | Val loss: 1.7478 | Batch size: 32 | lr: 0.001 | Duration: 2.78s
[2m[36m(func pid=62614)[0m top1: 0.39972014925373134
[2m[36m(func pid=62614)[0m top5: 0.8973880597014925
[2m[36m(func pid=62614)[0m f1_micro: 0.39972014925373134
[2m[36m(func pid=62614)[0m f1_macro: 0.33574238555939717
[2m[36m(func pid=62614)[0m f1_weighted: 0.40832272865707947
[2m[36m(func pid=62614)[0m f1_per_class: [0.205, 0.47, 0.733, 0.304, 0.051, 0.27, 0.573, 0.462, 0.084, 0.205]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=73645)[0m top1: 0.26119402985074625
[2m[36m(func pid=73645)[0m top5: 0.789179104477612
[2m[36m(func pid=73645)[0m f1_micro: 0.26119402985074625
[2m[36m(func pid=73645)[0m f1_macro: 0.18866888463195436
[2m[36m(func pid=73645)[0m f1_weighted: 0.2626496110146571
[2m[36m(func pid=73645)[0m f1_per_class: [0.078, 0.364, 0.37, 0.0, 0.141, 0.292, 0.537, 0.0, 0.031, 0.074]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=79460)[0m top1: 0.12126865671641791
[2m[36m(func pid=79460)[0m top5: 0.7056902985074627
[2m[36m(func pid=79460)[0m f1_micro: 0.12126865671641791
[2m[36m(func pid=79460)[0m f1_macro: 0.06876435500047653
[2m[36m(func pid=79460)[0m f1_weighted: 0.10030165672864474
[2m[36m(func pid=79460)[0m f1_per_class: [0.032, 0.471, 0.125, 0.0, 0.0, 0.0, 0.06, 0.0, 0.0, 0.0]
[2m[36m(func pid=79460)[0m 
== Status ==
Current time: 2024-01-07 02:41:22 (running for 00:17:23.14)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.221 |      0.37  |                   90 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.307 |      0.336 |                   83 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  1.976 |      0.189 |                   33 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  2.429 |      0.069 |                    7 |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.4295708955223881
[2m[36m(func pid=60934)[0m top5: 0.9043843283582089
[2m[36m(func pid=60934)[0m f1_micro: 0.4295708955223881
[2m[36m(func pid=60934)[0m f1_macro: 0.37027717650147723
[2m[36m(func pid=60934)[0m f1_weighted: 0.4571754214083133
[2m[36m(func pid=60934)[0m f1_per_class: [0.248, 0.545, 0.364, 0.498, 0.105, 0.354, 0.456, 0.482, 0.211, 0.441]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 83] | Train loss: 1.4034 | Steps: 2 | Val loss: 2.8368 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 2.1614 | Steps: 2 | Val loss: 2.2073 | Batch size: 32 | lr: 0.0001 | Duration: 3.07s
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 2.2974 | Steps: 2 | Val loss: 2.2069 | Batch size: 32 | lr: 0.001 | Duration: 2.78s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 90] | Train loss: 0.2352 | Steps: 2 | Val loss: 1.7371 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=62614)[0m top1: 0.3558768656716418
[2m[36m(func pid=62614)[0m top5: 0.882929104477612
[2m[36m(func pid=62614)[0m f1_micro: 0.3558768656716418
[2m[36m(func pid=62614)[0m f1_macro: 0.29466629479776396
[2m[36m(func pid=62614)[0m f1_weighted: 0.38256095670196477
[2m[36m(func pid=62614)[0m f1_per_class: [0.138, 0.403, 0.688, 0.26, 0.048, 0.3, 0.588, 0.353, 0.057, 0.111]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=73645)[0m top1: 0.26865671641791045
[2m[36m(func pid=73645)[0m top5: 0.7961753731343284
[2m[36m(func pid=73645)[0m f1_micro: 0.26865671641791045
[2m[36m(func pid=73645)[0m f1_macro: 0.19727784042370888
[2m[36m(func pid=73645)[0m f1_weighted: 0.2668585932850879
[2m[36m(func pid=73645)[0m f1_per_class: [0.081, 0.371, 0.364, 0.0, 0.146, 0.296, 0.542, 0.0, 0.03, 0.143]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=79460)[0m top1: 0.20615671641791045
[2m[36m(func pid=79460)[0m top5: 0.7192164179104478
[2m[36m(func pid=79460)[0m f1_micro: 0.20615671641791045
[2m[36m(func pid=79460)[0m f1_macro: 0.11350847144095044
[2m[36m(func pid=79460)[0m f1_weighted: 0.19302573028006625
[2m[36m(func pid=79460)[0m f1_per_class: [0.06, 0.467, 0.19, 0.0, 0.05, 0.0, 0.369, 0.0, 0.0, 0.0]
[2m[36m(func pid=79460)[0m 
== Status ==
Current time: 2024-01-07 02:41:27 (running for 00:17:28.42)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.235 |      0.373 |                   91 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.403 |      0.295 |                   84 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  2.161 |      0.197 |                   34 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  2.297 |      0.114 |                    8 |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.44076492537313433
[2m[36m(func pid=60934)[0m top5: 0.9053171641791045
[2m[36m(func pid=60934)[0m f1_micro: 0.44076492537313433
[2m[36m(func pid=60934)[0m f1_macro: 0.37265112770763775
[2m[36m(func pid=60934)[0m f1_weighted: 0.47059431138646796
[2m[36m(func pid=60934)[0m f1_per_class: [0.235, 0.558, 0.301, 0.501, 0.109, 0.368, 0.481, 0.514, 0.206, 0.453]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 84] | Train loss: 1.1058 | Steps: 2 | Val loss: 3.1658 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 2.0636 | Steps: 2 | Val loss: 2.1865 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 2.3185 | Steps: 2 | Val loss: 2.1604 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 91] | Train loss: 0.1823 | Steps: 2 | Val loss: 1.8011 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=62614)[0m top1: 0.3414179104477612
[2m[36m(func pid=62614)[0m top5: 0.8372201492537313
[2m[36m(func pid=62614)[0m f1_micro: 0.3414179104477612
[2m[36m(func pid=62614)[0m f1_macro: 0.3035896443562124
[2m[36m(func pid=62614)[0m f1_weighted: 0.37206260363054083
[2m[36m(func pid=62614)[0m f1_per_class: [0.139, 0.211, 0.733, 0.462, 0.083, 0.334, 0.455, 0.35, 0.088, 0.18]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=79460)[0m top1: 0.2887126865671642
[2m[36m(func pid=79460)[0m top5: 0.7555970149253731
[2m[36m(func pid=79460)[0m f1_micro: 0.2887126865671642
[2m[36m(func pid=79460)[0m f1_macro: 0.1424182199647172
[2m[36m(func pid=79460)[0m f1_weighted: 0.23721551727858
[2m[36m(func pid=79460)[0m f1_per_class: [0.088, 0.451, 0.282, 0.0, 0.081, 0.0, 0.522, 0.0, 0.0, 0.0]
[2m[36m(func pid=73645)[0m top1: 0.2775186567164179
[2m[36m(func pid=73645)[0m top5: 0.804570895522388
[2m[36m(func pid=73645)[0m f1_micro: 0.2775186567164179
[2m[36m(func pid=73645)[0m f1_macro: 0.21534786510473775
[2m[36m(func pid=73645)[0m f1_weighted: 0.2708469136035412
[2m[36m(func pid=73645)[0m f1_per_class: [0.089, 0.371, 0.407, 0.0, 0.138, 0.276, 0.553, 0.016, 0.046, 0.258]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=79460)[0m 
== Status ==
Current time: 2024-01-07 02:41:32 (running for 00:17:33.67)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.182 |      0.363 |                   92 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.106 |      0.304 |                   85 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  2.064 |      0.215 |                   35 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  2.318 |      0.142 |                    9 |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.4300373134328358
[2m[36m(func pid=60934)[0m top5: 0.9020522388059702
[2m[36m(func pid=60934)[0m f1_micro: 0.4300373134328358
[2m[36m(func pid=60934)[0m f1_macro: 0.36347456798727906
[2m[36m(func pid=60934)[0m f1_weighted: 0.4617467241406382
[2m[36m(func pid=60934)[0m f1_per_class: [0.218, 0.559, 0.297, 0.506, 0.108, 0.357, 0.465, 0.446, 0.209, 0.471]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 85] | Train loss: 0.8978 | Steps: 2 | Val loss: 2.9995 | Batch size: 32 | lr: 0.1 | Duration: 2.78s
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 2.1415 | Steps: 2 | Val loss: 2.1161 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 1.9530 | Steps: 2 | Val loss: 2.1542 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 92] | Train loss: 0.4564 | Steps: 2 | Val loss: 1.9387 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=62614)[0m top1: 0.31763059701492535
[2m[36m(func pid=62614)[0m top5: 0.8306902985074627
[2m[36m(func pid=62614)[0m f1_micro: 0.31763059701492535
[2m[36m(func pid=62614)[0m f1_macro: 0.2786314968779117
[2m[36m(func pid=62614)[0m f1_weighted: 0.30871860774809423
[2m[36m(func pid=62614)[0m f1_per_class: [0.0, 0.219, 0.759, 0.511, 0.088, 0.311, 0.188, 0.467, 0.081, 0.163]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=79460)[0m top1: 0.3204291044776119
[2m[36m(func pid=79460)[0m top5: 0.800839552238806
[2m[36m(func pid=79460)[0m f1_micro: 0.3204291044776119
[2m[36m(func pid=79460)[0m f1_macro: 0.1602492830272346
[2m[36m(func pid=79460)[0m f1_weighted: 0.24721048797262563
[2m[36m(func pid=79460)[0m f1_per_class: [0.12, 0.435, 0.379, 0.0, 0.109, 0.0, 0.559, 0.0, 0.0, 0.0]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=73645)[0m top1: 0.28824626865671643
[2m[36m(func pid=73645)[0m top5: 0.8138992537313433
[2m[36m(func pid=73645)[0m f1_micro: 0.28824626865671643
[2m[36m(func pid=73645)[0m f1_macro: 0.22350640259284846
[2m[36m(func pid=73645)[0m f1_weighted: 0.2772634328857076
[2m[36m(func pid=73645)[0m f1_per_class: [0.097, 0.393, 0.44, 0.0, 0.125, 0.245, 0.564, 0.047, 0.075, 0.25]
[2m[36m(func pid=73645)[0m 
== Status ==
Current time: 2024-01-07 02:41:38 (running for 00:17:38.96)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.456 |      0.335 |                   93 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  0.898 |      0.279 |                   86 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  1.953 |      0.224 |                   36 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  2.141 |      0.16  |                   10 |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.38992537313432835
[2m[36m(func pid=60934)[0m top5: 0.8843283582089553
[2m[36m(func pid=60934)[0m f1_micro: 0.38992537313432835
[2m[36m(func pid=60934)[0m f1_macro: 0.33456663641779705
[2m[36m(func pid=60934)[0m f1_weighted: 0.4076542603719786
[2m[36m(func pid=60934)[0m f1_per_class: [0.231, 0.573, 0.296, 0.488, 0.1, 0.325, 0.321, 0.342, 0.241, 0.429]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 86] | Train loss: 0.8619 | Steps: 2 | Val loss: 2.9015 | Batch size: 32 | lr: 0.1 | Duration: 2.78s
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 2.1681 | Steps: 2 | Val loss: 2.0870 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 1.9908 | Steps: 2 | Val loss: 2.1241 | Batch size: 32 | lr: 0.0001 | Duration: 3.03s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 93] | Train loss: 0.1628 | Steps: 2 | Val loss: 1.9203 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=62614)[0m top1: 0.28078358208955223
[2m[36m(func pid=62614)[0m top5: 0.8479477611940298
[2m[36m(func pid=62614)[0m f1_micro: 0.28078358208955223
[2m[36m(func pid=62614)[0m f1_macro: 0.268444901398435
[2m[36m(func pid=62614)[0m f1_weighted: 0.2740551839128582
[2m[36m(func pid=62614)[0m f1_per_class: [0.019, 0.321, 0.759, 0.44, 0.069, 0.228, 0.121, 0.377, 0.122, 0.229]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=79460)[0m top1: 0.32322761194029853
[2m[36m(func pid=79460)[0m top5: 0.840018656716418
[2m[36m(func pid=79460)[0m f1_micro: 0.32322761194029853
[2m[36m(func pid=79460)[0m f1_macro: 0.18021334908664863
[2m[36m(func pid=79460)[0m f1_weighted: 0.24627378517911172
[2m[36m(func pid=79460)[0m f1_per_class: [0.16, 0.371, 0.386, 0.0, 0.088, 0.0, 0.583, 0.0, 0.0, 0.214]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=73645)[0m top1: 0.291044776119403
[2m[36m(func pid=73645)[0m top5: 0.8264925373134329
[2m[36m(func pid=73645)[0m f1_micro: 0.291044776119403
[2m[36m(func pid=73645)[0m f1_macro: 0.2232829117142598
[2m[36m(func pid=73645)[0m f1_weighted: 0.27526971501945263
[2m[36m(func pid=73645)[0m f1_per_class: [0.112, 0.378, 0.449, 0.0, 0.111, 0.242, 0.565, 0.047, 0.079, 0.25]
[2m[36m(func pid=73645)[0m 
== Status ==
Current time: 2024-01-07 02:41:43 (running for 00:17:44.41)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.163 |      0.345 |                   94 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  0.862 |      0.268 |                   87 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  1.991 |      0.223 |                   37 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  2.168 |      0.18  |                   11 |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.3927238805970149
[2m[36m(func pid=60934)[0m top5: 0.8796641791044776
[2m[36m(func pid=60934)[0m f1_micro: 0.39272388059701496
[2m[36m(func pid=60934)[0m f1_macro: 0.3448885456783008
[2m[36m(func pid=60934)[0m f1_weighted: 0.40744679271804973
[2m[36m(func pid=60934)[0m f1_per_class: [0.246, 0.578, 0.308, 0.486, 0.097, 0.33, 0.306, 0.383, 0.254, 0.462]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 87] | Train loss: 0.9402 | Steps: 2 | Val loss: 2.8299 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 2.0137 | Steps: 2 | Val loss: 2.0675 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 1.9107 | Steps: 2 | Val loss: 2.1072 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 94] | Train loss: 0.4205 | Steps: 2 | Val loss: 2.0240 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=62614)[0m top1: 0.29151119402985076
[2m[36m(func pid=62614)[0m top5: 0.8572761194029851
[2m[36m(func pid=62614)[0m f1_micro: 0.29151119402985076
[2m[36m(func pid=62614)[0m f1_macro: 0.27037182643609353
[2m[36m(func pid=62614)[0m f1_weighted: 0.3080567908289285
[2m[36m(func pid=62614)[0m f1_per_class: [0.139, 0.385, 0.537, 0.336, 0.07, 0.118, 0.32, 0.434, 0.144, 0.22]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=79460)[0m top1: 0.3138992537313433
[2m[36m(func pid=79460)[0m top5: 0.8535447761194029
[2m[36m(func pid=79460)[0m f1_micro: 0.3138992537313433
[2m[36m(func pid=79460)[0m f1_macro: 0.16880411503059028
[2m[36m(func pid=79460)[0m f1_weighted: 0.2413812090153745
[2m[36m(func pid=79460)[0m f1_per_class: [0.138, 0.341, 0.367, 0.0, 0.077, 0.0, 0.587, 0.0, 0.0, 0.179]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=73645)[0m top1: 0.291044776119403
[2m[36m(func pid=73645)[0m top5: 0.84375
[2m[36m(func pid=73645)[0m f1_micro: 0.291044776119403
[2m[36m(func pid=73645)[0m f1_macro: 0.22438597770654206
[2m[36m(func pid=73645)[0m f1_weighted: 0.2734659120680678
[2m[36m(func pid=73645)[0m f1_per_class: [0.121, 0.386, 0.458, 0.0, 0.104, 0.21, 0.56, 0.076, 0.086, 0.242]
[2m[36m(func pid=73645)[0m 
== Status ==
Current time: 2024-01-07 02:41:48 (running for 00:17:49.66)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.421 |      0.301 |                   95 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  0.94  |      0.27  |                   88 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  1.911 |      0.224 |                   38 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  2.014 |      0.169 |                   12 |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.3619402985074627
[2m[36m(func pid=60934)[0m top5: 0.8628731343283582
[2m[36m(func pid=60934)[0m f1_micro: 0.3619402985074627
[2m[36m(func pid=60934)[0m f1_macro: 0.3010608346484466
[2m[36m(func pid=60934)[0m f1_weighted: 0.36930008960145405
[2m[36m(func pid=60934)[0m f1_per_class: [0.265, 0.571, 0.282, 0.472, 0.104, 0.296, 0.236, 0.314, 0.179, 0.291]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 88] | Train loss: 0.6024 | Steps: 2 | Val loss: 2.8467 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 1.9154 | Steps: 2 | Val loss: 2.0461 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 1.8564 | Steps: 2 | Val loss: 2.0748 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 95] | Train loss: 0.5730 | Steps: 2 | Val loss: 1.9374 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=62614)[0m top1: 0.35494402985074625
[2m[36m(func pid=62614)[0m top5: 0.8675373134328358
[2m[36m(func pid=62614)[0m f1_micro: 0.35494402985074625
[2m[36m(func pid=62614)[0m f1_macro: 0.2979346478931437
[2m[36m(func pid=62614)[0m f1_weighted: 0.3761942554278792
[2m[36m(func pid=62614)[0m f1_per_class: [0.154, 0.44, 0.629, 0.284, 0.082, 0.143, 0.582, 0.275, 0.158, 0.233]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=79460)[0m top1: 0.2756529850746269
[2m[36m(func pid=79460)[0m top5: 0.8642723880597015
[2m[36m(func pid=79460)[0m f1_micro: 0.2756529850746269
[2m[36m(func pid=79460)[0m f1_macro: 0.13856123104869097
[2m[36m(func pid=79460)[0m f1_weighted: 0.23005075600366773
[2m[36m(func pid=79460)[0m f1_per_class: [0.021, 0.327, 0.328, 0.016, 0.082, 0.0, 0.555, 0.0, 0.0, 0.056]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=73645)[0m top1: 0.2966417910447761
[2m[36m(func pid=73645)[0m top5: 0.8582089552238806
[2m[36m(func pid=73645)[0m f1_micro: 0.2966417910447761
[2m[36m(func pid=73645)[0m f1_macro: 0.2589454852127121
[2m[36m(func pid=73645)[0m f1_weighted: 0.28410568570421313
[2m[36m(func pid=73645)[0m f1_per_class: [0.134, 0.379, 0.5, 0.0, 0.09, 0.248, 0.554, 0.193, 0.103, 0.389]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=60934)[0m top1: 0.384794776119403
[2m[36m(func pid=60934)[0m top5: 0.8843283582089553
[2m[36m(func pid=60934)[0m f1_micro: 0.384794776119403
[2m[36m(func pid=60934)[0m f1_macro: 0.3260553363755859
[2m[36m(func pid=60934)[0m f1_weighted: 0.40712023970262917
[2m[36m(func pid=60934)[0m f1_per_class: [0.206, 0.566, 0.32, 0.453, 0.098, 0.345, 0.369, 0.264, 0.209, 0.431]
== Status ==
Current time: 2024-01-07 02:41:54 (running for 00:17:54.93)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.573 |      0.326 |                   96 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  0.602 |      0.298 |                   89 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  1.856 |      0.259 |                   39 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  1.915 |      0.139 |                   13 |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 89] | Train loss: 0.8797 | Steps: 2 | Val loss: 2.8500 | Batch size: 32 | lr: 0.1 | Duration: 3.03s
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 1.8392 | Steps: 2 | Val loss: 1.9915 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 1.8181 | Steps: 2 | Val loss: 2.0542 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 96] | Train loss: 0.3521 | Steps: 2 | Val loss: 1.9180 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=62614)[0m top1: 0.37453358208955223
[2m[36m(func pid=62614)[0m top5: 0.8666044776119403
[2m[36m(func pid=62614)[0m f1_micro: 0.3745335820895522
[2m[36m(func pid=62614)[0m f1_macro: 0.3162930791557192
[2m[36m(func pid=62614)[0m f1_weighted: 0.3974129137909216
[2m[36m(func pid=62614)[0m f1_per_class: [0.161, 0.479, 0.846, 0.397, 0.088, 0.311, 0.513, 0.0, 0.126, 0.242]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=79460)[0m top1: 0.20615671641791045
[2m[36m(func pid=79460)[0m top5: 0.8894589552238806
[2m[36m(func pid=79460)[0m f1_micro: 0.20615671641791045
[2m[36m(func pid=79460)[0m f1_macro: 0.14546840659532592
[2m[36m(func pid=79460)[0m f1_weighted: 0.18225562995569888
[2m[36m(func pid=79460)[0m f1_per_class: [0.0, 0.322, 0.333, 0.082, 0.079, 0.0, 0.284, 0.243, 0.057, 0.054]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=73645)[0m top1: 0.3045708955223881
[2m[36m(func pid=73645)[0m top5: 0.8731343283582089
[2m[36m(func pid=73645)[0m f1_micro: 0.3045708955223881
[2m[36m(func pid=73645)[0m f1_macro: 0.26649565921036
[2m[36m(func pid=73645)[0m f1_weighted: 0.29294620453465386
[2m[36m(func pid=73645)[0m f1_per_class: [0.149, 0.385, 0.431, 0.0, 0.09, 0.283, 0.544, 0.311, 0.113, 0.359]
[2m[36m(func pid=73645)[0m 
== Status ==
Current time: 2024-01-07 02:41:59 (running for 00:18:00.21)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.352 |      0.355 |                   97 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  0.88  |      0.316 |                   90 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  1.818 |      0.266 |                   40 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  1.839 |      0.145 |                   14 |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.4006529850746269
[2m[36m(func pid=60934)[0m top5: 0.8997201492537313
[2m[36m(func pid=60934)[0m f1_micro: 0.4006529850746269
[2m[36m(func pid=60934)[0m f1_macro: 0.3549616760462518
[2m[36m(func pid=60934)[0m f1_weighted: 0.44145309210334954
[2m[36m(func pid=60934)[0m f1_per_class: [0.163, 0.557, 0.345, 0.435, 0.096, 0.378, 0.458, 0.455, 0.207, 0.456]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 90] | Train loss: 1.0342 | Steps: 2 | Val loss: 3.1010 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 2.0988 | Steps: 2 | Val loss: 1.9695 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 1.7892 | Steps: 2 | Val loss: 2.0313 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 97] | Train loss: 0.2044 | Steps: 2 | Val loss: 1.9358 | Batch size: 32 | lr: 0.001 | Duration: 2.71s
[2m[36m(func pid=62614)[0m top1: 0.3736007462686567
[2m[36m(func pid=62614)[0m top5: 0.8600746268656716
[2m[36m(func pid=62614)[0m f1_micro: 0.3736007462686567
[2m[36m(func pid=62614)[0m f1_macro: 0.35253772327968896
[2m[36m(func pid=62614)[0m f1_weighted: 0.3829300781016112
[2m[36m(func pid=62614)[0m f1_per_class: [0.276, 0.385, 0.818, 0.493, 0.092, 0.378, 0.309, 0.464, 0.099, 0.211]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=79460)[0m top1: 0.2080223880597015
[2m[36m(func pid=79460)[0m top5: 0.8936567164179104
[2m[36m(func pid=79460)[0m f1_micro: 0.2080223880597015
[2m[36m(func pid=79460)[0m f1_macro: 0.14867683512561142
[2m[36m(func pid=79460)[0m f1_weighted: 0.16372887463510213
[2m[36m(func pid=79460)[0m f1_per_class: [0.0, 0.353, 0.324, 0.169, 0.076, 0.016, 0.098, 0.35, 0.037, 0.065]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=73645)[0m top1: 0.30970149253731344
[2m[36m(func pid=73645)[0m top5: 0.8880597014925373
[2m[36m(func pid=73645)[0m f1_micro: 0.30970149253731344
[2m[36m(func pid=73645)[0m f1_macro: 0.2760753761335438
[2m[36m(func pid=73645)[0m f1_weighted: 0.2942453898219365
[2m[36m(func pid=73645)[0m f1_per_class: [0.178, 0.387, 0.407, 0.0, 0.089, 0.292, 0.532, 0.36, 0.098, 0.417]
[2m[36m(func pid=73645)[0m 
== Status ==
Current time: 2024-01-07 02:42:04 (running for 00:18:05.38)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.204 |      0.349 |                   98 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.034 |      0.353 |                   91 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  1.789 |      0.276 |                   41 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  2.099 |      0.149 |                   15 |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.384794776119403
[2m[36m(func pid=60934)[0m top5: 0.8987873134328358
[2m[36m(func pid=60934)[0m f1_micro: 0.384794776119403
[2m[36m(func pid=60934)[0m f1_macro: 0.34920760957418373
[2m[36m(func pid=60934)[0m f1_weighted: 0.4246885530331947
[2m[36m(func pid=60934)[0m f1_per_class: [0.148, 0.54, 0.367, 0.409, 0.102, 0.373, 0.426, 0.535, 0.192, 0.4]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 91] | Train loss: 0.9961 | Steps: 2 | Val loss: 3.3393 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 1.7287 | Steps: 2 | Val loss: 1.9768 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 1.7119 | Steps: 2 | Val loss: 2.0084 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 98] | Train loss: 0.1905 | Steps: 2 | Val loss: 2.0082 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=62614)[0m top1: 0.35027985074626866
[2m[36m(func pid=62614)[0m top5: 0.8493470149253731
[2m[36m(func pid=62614)[0m f1_micro: 0.35027985074626866
[2m[36m(func pid=62614)[0m f1_macro: 0.32518520388462446
[2m[36m(func pid=62614)[0m f1_weighted: 0.33825794859692415
[2m[36m(func pid=62614)[0m f1_per_class: [0.292, 0.375, 0.632, 0.458, 0.053, 0.386, 0.184, 0.517, 0.127, 0.228]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=79460)[0m top1: 0.21875
[2m[36m(func pid=79460)[0m top5: 0.8801305970149254
[2m[36m(func pid=79460)[0m f1_micro: 0.21875
[2m[36m(func pid=79460)[0m f1_macro: 0.15078642270222123
[2m[36m(func pid=79460)[0m f1_weighted: 0.16598335497375294
[2m[36m(func pid=79460)[0m f1_per_class: [0.0, 0.372, 0.319, 0.263, 0.076, 0.024, 0.006, 0.345, 0.021, 0.082]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=73645)[0m top1: 0.31716417910447764
[2m[36m(func pid=73645)[0m top5: 0.8973880597014925
[2m[36m(func pid=73645)[0m f1_micro: 0.31716417910447764
[2m[36m(func pid=73645)[0m f1_macro: 0.28715057925852944
[2m[36m(func pid=73645)[0m f1_weighted: 0.29877408382477333
[2m[36m(func pid=73645)[0m f1_per_class: [0.196, 0.404, 0.393, 0.0, 0.089, 0.277, 0.518, 0.475, 0.11, 0.408]
[2m[36m(func pid=73645)[0m 
== Status ==
Current time: 2024-01-07 02:42:09 (running for 00:18:10.55)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.19  |      0.344 |                   99 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  0.996 |      0.325 |                   92 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  1.712 |      0.287 |                   42 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  1.729 |      0.151 |                   16 |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60934)[0m top1: 0.3656716417910448
[2m[36m(func pid=60934)[0m top5: 0.8894589552238806
[2m[36m(func pid=60934)[0m f1_micro: 0.3656716417910448
[2m[36m(func pid=60934)[0m f1_macro: 0.34438597665024206
[2m[36m(func pid=60934)[0m f1_weighted: 0.39550622294518956
[2m[36m(func pid=60934)[0m f1_per_class: [0.156, 0.551, 0.391, 0.406, 0.109, 0.343, 0.333, 0.542, 0.196, 0.417]
[2m[36m(func pid=60934)[0m 
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 92] | Train loss: 0.6241 | Steps: 2 | Val loss: 3.7292 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 1.6434 | Steps: 2 | Val loss: 1.9919 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 1.6764 | Steps: 2 | Val loss: 1.9905 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
[2m[36m(func pid=60934)[0m [N0-GPU0] | [Epoch: 99] | Train loss: 0.1623 | Steps: 2 | Val loss: 2.0036 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=62614)[0m top1: 0.2835820895522388
[2m[36m(func pid=62614)[0m top5: 0.8255597014925373
[2m[36m(func pid=62614)[0m f1_micro: 0.2835820895522388
[2m[36m(func pid=62614)[0m f1_macro: 0.2920403565765671
[2m[36m(func pid=62614)[0m f1_weighted: 0.2852791888202716
[2m[36m(func pid=62614)[0m f1_per_class: [0.157, 0.383, 0.762, 0.255, 0.0, 0.238, 0.256, 0.506, 0.157, 0.206]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=79460)[0m top1: 0.24766791044776118
[2m[36m(func pid=79460)[0m top5: 0.8773320895522388
[2m[36m(func pid=79460)[0m f1_micro: 0.24766791044776118
[2m[36m(func pid=79460)[0m f1_macro: 0.16303222426965847
[2m[36m(func pid=79460)[0m f1_weighted: 0.1967022640787505
[2m[36m(func pid=79460)[0m f1_per_class: [0.0, 0.397, 0.301, 0.355, 0.074, 0.061, 0.0, 0.313, 0.021, 0.109]
[2m[36m(func pid=79460)[0m 
== Status ==
Current time: 2024-01-07 02:42:14 (running for 00:18:15.70)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00005 | RUNNING    | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.19  |      0.344 |                   99 |
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  0.624 |      0.292 |                   93 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  1.676 |      0.284 |                   43 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  1.643 |      0.163 |                   17 |
| train_6ed81_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=73645)[0m top1: 0.32136194029850745
[2m[36m(func pid=73645)[0m top5: 0.902518656716418
[2m[36m(func pid=73645)[0m f1_micro: 0.32136194029850745
[2m[36m(func pid=73645)[0m f1_macro: 0.28358691093342914
[2m[36m(func pid=73645)[0m f1_weighted: 0.2989652068963521
[2m[36m(func pid=73645)[0m f1_per_class: [0.217, 0.403, 0.355, 0.0, 0.084, 0.262, 0.519, 0.516, 0.103, 0.377]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=60934)[0m top1: 0.365205223880597
[2m[36m(func pid=60934)[0m top5: 0.8796641791044776
[2m[36m(func pid=60934)[0m f1_micro: 0.365205223880597
[2m[36m(func pid=60934)[0m f1_macro: 0.33475382437599677
[2m[36m(func pid=60934)[0m f1_weighted: 0.38424212952153036
[2m[36m(func pid=60934)[0m f1_per_class: [0.195, 0.559, 0.426, 0.419, 0.104, 0.333, 0.292, 0.496, 0.184, 0.34]
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 93] | Train loss: 0.6674 | Steps: 2 | Val loss: 3.5124 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 1.5506 | Steps: 2 | Val loss: 1.9905 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 1.7544 | Steps: 2 | Val loss: 1.9873 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=62614)[0m top1: 0.2789179104477612
[2m[36m(func pid=62614)[0m top5: 0.8414179104477612
[2m[36m(func pid=62614)[0m f1_micro: 0.2789179104477612
[2m[36m(func pid=62614)[0m f1_macro: 0.29868302205081043
[2m[36m(func pid=62614)[0m f1_weighted: 0.2968690381216674
[2m[36m(func pid=62614)[0m f1_per_class: [0.109, 0.386, 0.87, 0.227, 0.0, 0.122, 0.366, 0.499, 0.13, 0.277]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=79460)[0m top1: 0.28777985074626866
[2m[36m(func pid=79460)[0m top5: 0.8656716417910447
[2m[36m(func pid=79460)[0m f1_micro: 0.28777985074626866
[2m[36m(func pid=79460)[0m f1_macro: 0.19050292733753993
[2m[36m(func pid=79460)[0m f1_weighted: 0.2379378534652877
[2m[36m(func pid=79460)[0m f1_per_class: [0.0, 0.438, 0.234, 0.432, 0.078, 0.152, 0.003, 0.303, 0.055, 0.21]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=73645)[0m top1: 0.31763059701492535
[2m[36m(func pid=73645)[0m top5: 0.9085820895522388
[2m[36m(func pid=73645)[0m f1_micro: 0.31763059701492535
[2m[36m(func pid=73645)[0m f1_macro: 0.279051182012003
[2m[36m(func pid=73645)[0m f1_weighted: 0.2921590517311946
[2m[36m(func pid=73645)[0m f1_per_class: [0.235, 0.394, 0.31, 0.0, 0.082, 0.251, 0.506, 0.5, 0.119, 0.393]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 94] | Train loss: 0.7188 | Steps: 2 | Val loss: 2.8758 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 1.6020 | Steps: 2 | Val loss: 1.9950 | Batch size: 32 | lr: 0.001 | Duration: 2.78s
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 1.6820 | Steps: 2 | Val loss: 1.9796 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=62614)[0m top1: 0.3596082089552239
[2m[36m(func pid=62614)[0m top5: 0.8694029850746269
[2m[36m(func pid=62614)[0m f1_micro: 0.35960820895522383
[2m[36m(func pid=62614)[0m f1_macro: 0.35133503027730967
[2m[36m(func pid=62614)[0m f1_weighted: 0.3865884211131141
[2m[36m(func pid=62614)[0m f1_per_class: [0.141, 0.375, 0.846, 0.386, 0.076, 0.148, 0.502, 0.514, 0.158, 0.367]
== Status ==
Current time: 2024-01-07 02:42:20 (running for 00:18:21.03)
Memory usage on this node: 22.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (13 PENDING, 4 RUNNING, 7 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  0.667 |      0.299 |                   94 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  1.754 |      0.279 |                   44 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  1.551 |      0.191 |                   18 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=83696)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=83696)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=83696)[0m Configuration completed!
[2m[36m(func pid=83696)[0m New optimizer parameters:
[2m[36m(func pid=83696)[0m SGD (
[2m[36m(func pid=83696)[0m Parameter Group 0
[2m[36m(func pid=83696)[0m     dampening: 0
[2m[36m(func pid=83696)[0m     differentiable: False
[2m[36m(func pid=83696)[0m     foreach: None
[2m[36m(func pid=83696)[0m     lr: 0.01
[2m[36m(func pid=83696)[0m     maximize: False
[2m[36m(func pid=83696)[0m     momentum: 0.99
[2m[36m(func pid=83696)[0m     nesterov: False
[2m[36m(func pid=83696)[0m     weight_decay: 0.0001
[2m[36m(func pid=83696)[0m )
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=79460)[0m top1: 0.3050373134328358
[2m[36m(func pid=79460)[0m top5: 0.8544776119402985
[2m[36m(func pid=79460)[0m f1_micro: 0.3050373134328358
[2m[36m(func pid=79460)[0m f1_macro: 0.20735947241788005
[2m[36m(func pid=79460)[0m f1_weighted: 0.2595009074429421
[2m[36m(func pid=79460)[0m f1_per_class: [0.0, 0.455, 0.168, 0.463, 0.073, 0.227, 0.0, 0.315, 0.096, 0.277]
[2m[36m(func pid=79460)[0m 
== Status ==
Current time: 2024-01-07 02:42:25 (running for 00:18:26.51)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (13 PENDING, 4 RUNNING, 7 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  0.719 |      0.351 |                   95 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  1.682 |      0.277 |                   45 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  1.602 |      0.207 |                   19 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=73645)[0m top1: 0.3138992537313433
[2m[36m(func pid=73645)[0m top5: 0.9085820895522388
[2m[36m(func pid=73645)[0m f1_micro: 0.3138992537313433
[2m[36m(func pid=73645)[0m f1_macro: 0.27687470631618083
[2m[36m(func pid=73645)[0m f1_weighted: 0.2867966053690936
[2m[36m(func pid=73645)[0m f1_per_class: [0.269, 0.386, 0.268, 0.0, 0.081, 0.254, 0.49, 0.506, 0.116, 0.4]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 95] | Train loss: 0.8177 | Steps: 2 | Val loss: 2.8252 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 1.3656 | Steps: 2 | Val loss: 2.0032 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 2.9840 | Steps: 2 | Val loss: 2.6999 | Batch size: 32 | lr: 0.01 | Duration: 4.49s
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 1.6497 | Steps: 2 | Val loss: 1.9741 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=62614)[0m top1: 0.4388992537313433
[2m[36m(func pid=62614)[0m top5: 0.8666044776119403
[2m[36m(func pid=62614)[0m f1_micro: 0.4388992537313433
[2m[36m(func pid=62614)[0m f1_macro: 0.32079157675388015
[2m[36m(func pid=62614)[0m f1_weighted: 0.42309630603666937
[2m[36m(func pid=62614)[0m f1_per_class: [0.168, 0.368, 0.786, 0.521, 0.097, 0.008, 0.594, 0.407, 0.046, 0.212]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=79460)[0m top1: 0.32509328358208955
[2m[36m(func pid=79460)[0m top5: 0.8526119402985075
[2m[36m(func pid=79460)[0m f1_micro: 0.32509328358208955
[2m[36m(func pid=79460)[0m f1_macro: 0.23959276559584844
[2m[36m(func pid=79460)[0m f1_weighted: 0.28581413186493815
[2m[36m(func pid=79460)[0m f1_per_class: [0.036, 0.475, 0.157, 0.486, 0.065, 0.31, 0.003, 0.332, 0.216, 0.316]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=83696)[0m top1: 0.006063432835820896
[2m[36m(func pid=83696)[0m top5: 0.3512126865671642
[2m[36m(func pid=83696)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=83696)[0m f1_macro: 0.001205377839592026
[2m[36m(func pid=83696)[0m f1_weighted: 7.308727572153144e-05
[2m[36m(func pid=83696)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=83696)[0m 
== Status ==
Current time: 2024-01-07 02:42:30 (running for 00:18:31.67)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (13 PENDING, 4 RUNNING, 7 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  0.818 |      0.321 |                   96 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  1.65  |      0.272 |                   46 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  1.366 |      0.24  |                   20 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  2.984 |      0.001 |                    1 |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=73645)[0m top1: 0.31203358208955223
[2m[36m(func pid=73645)[0m top5: 0.9127798507462687
[2m[36m(func pid=73645)[0m f1_micro: 0.31203358208955223
[2m[36m(func pid=73645)[0m f1_macro: 0.2723142542506731
[2m[36m(func pid=73645)[0m f1_weighted: 0.2817889716008576
[2m[36m(func pid=73645)[0m f1_per_class: [0.263, 0.393, 0.265, 0.0, 0.081, 0.24, 0.474, 0.505, 0.133, 0.369]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 96] | Train loss: 1.1065 | Steps: 2 | Val loss: 2.7181 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 1.3419 | Steps: 2 | Val loss: 2.0062 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 2.7145 | Steps: 2 | Val loss: 3.5743 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 1.7068 | Steps: 2 | Val loss: 1.9557 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=62614)[0m top1: 0.3987873134328358
[2m[36m(func pid=62614)[0m top5: 0.8768656716417911
[2m[36m(func pid=62614)[0m f1_micro: 0.3987873134328358
[2m[36m(func pid=62614)[0m f1_macro: 0.33714360631433393
[2m[36m(func pid=62614)[0m f1_weighted: 0.42075543875073895
[2m[36m(func pid=62614)[0m f1_per_class: [0.152, 0.34, 0.759, 0.429, 0.109, 0.251, 0.573, 0.535, 0.04, 0.183]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=79460)[0m top1: 0.31949626865671643
[2m[36m(func pid=79460)[0m top5: 0.8544776119402985
[2m[36m(func pid=79460)[0m f1_micro: 0.31949626865671643
[2m[36m(func pid=79460)[0m f1_macro: 0.2416007822550239
[2m[36m(func pid=79460)[0m f1_weighted: 0.28557132502714727
[2m[36m(func pid=79460)[0m f1_per_class: [0.085, 0.496, 0.152, 0.462, 0.058, 0.335, 0.003, 0.338, 0.18, 0.308]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=83696)[0m top1: 0.006063432835820896
[2m[36m(func pid=83696)[0m top5: 0.5461753731343284
[2m[36m(func pid=83696)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=83696)[0m f1_macro: 0.001284584980237154
[2m[36m(func pid=83696)[0m f1_weighted: 7.788994749572297e-05
[2m[36m(func pid=83696)[0m f1_per_class: [0.0, 0.0, 0.013, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=83696)[0m 
== Status ==
Current time: 2024-01-07 02:42:36 (running for 00:18:37.01)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (13 PENDING, 4 RUNNING, 7 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.106 |      0.337 |                   97 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  1.707 |      0.257 |                   47 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  1.342 |      0.242 |                   21 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  2.715 |      0.001 |                    2 |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=73645)[0m top1: 0.29524253731343286
[2m[36m(func pid=73645)[0m top5: 0.9155783582089553
[2m[36m(func pid=73645)[0m f1_micro: 0.29524253731343286
[2m[36m(func pid=73645)[0m f1_macro: 0.25749056692010275
[2m[36m(func pid=73645)[0m f1_weighted: 0.26126065733189574
[2m[36m(func pid=73645)[0m f1_per_class: [0.23, 0.389, 0.282, 0.003, 0.08, 0.201, 0.427, 0.483, 0.133, 0.348]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 97] | Train loss: 0.7160 | Steps: 2 | Val loss: 3.9695 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 1.3891 | Steps: 2 | Val loss: 2.0383 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 2.5403 | Steps: 2 | Val loss: 4.7564 | Batch size: 32 | lr: 0.01 | Duration: 3.03s
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 1.5910 | Steps: 2 | Val loss: 1.9435 | Batch size: 32 | lr: 0.0001 | Duration: 3.07s
[2m[36m(func pid=62614)[0m top1: 0.23787313432835822
[2m[36m(func pid=62614)[0m top5: 0.8190298507462687
[2m[36m(func pid=62614)[0m f1_micro: 0.23787313432835822
[2m[36m(func pid=62614)[0m f1_macro: 0.25840625652619187
[2m[36m(func pid=62614)[0m f1_weighted: 0.25358173827675495
[2m[36m(func pid=62614)[0m f1_per_class: [0.124, 0.395, 0.706, 0.317, 0.117, 0.11, 0.15, 0.473, 0.116, 0.075]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=79460)[0m top1: 0.31343283582089554
[2m[36m(func pid=79460)[0m top5: 0.8507462686567164
[2m[36m(func pid=79460)[0m f1_micro: 0.31343283582089554
[2m[36m(func pid=79460)[0m f1_macro: 0.2452843325663439
[2m[36m(func pid=79460)[0m f1_weighted: 0.285241808626608
[2m[36m(func pid=79460)[0m f1_per_class: [0.177, 0.511, 0.149, 0.436, 0.062, 0.35, 0.009, 0.34, 0.158, 0.26]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=83696)[0m top1: 0.012126865671641791
[2m[36m(func pid=83696)[0m top5: 0.5634328358208955
[2m[36m(func pid=83696)[0m f1_micro: 0.012126865671641791
[2m[36m(func pid=83696)[0m f1_macro: 0.022541069129135068
[2m[36m(func pid=83696)[0m f1_weighted: 0.007021270210174559
[2m[36m(func pid=83696)[0m f1_per_class: [0.009, 0.032, 0.024, 0.0, 0.16, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=83696)[0m 
== Status ==
Current time: 2024-01-07 02:42:41 (running for 00:18:42.48)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (13 PENDING, 4 RUNNING, 7 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  0.716 |      0.258 |                   98 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  1.591 |      0.264 |                   48 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  1.389 |      0.245 |                   22 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  2.54  |      0.023 |                    3 |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=73645)[0m top1: 0.29757462686567165
[2m[36m(func pid=73645)[0m top5: 0.917910447761194
[2m[36m(func pid=73645)[0m f1_micro: 0.29757462686567165
[2m[36m(func pid=73645)[0m f1_macro: 0.2637634771849309
[2m[36m(func pid=73645)[0m f1_weighted: 0.26513623464556163
[2m[36m(func pid=73645)[0m f1_per_class: [0.286, 0.388, 0.289, 0.013, 0.08, 0.224, 0.418, 0.488, 0.136, 0.316]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 98] | Train loss: 1.2069 | Steps: 2 | Val loss: 5.4362 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 1.2295 | Steps: 2 | Val loss: 2.1485 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 2.5080 | Steps: 2 | Val loss: 6.0057 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 1.5094 | Steps: 2 | Val loss: 1.9216 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=62614)[0m top1: 0.21175373134328357
[2m[36m(func pid=62614)[0m top5: 0.7527985074626866
[2m[36m(func pid=62614)[0m f1_micro: 0.21175373134328357
[2m[36m(func pid=62614)[0m f1_macro: 0.2116922594662872
[2m[36m(func pid=62614)[0m f1_weighted: 0.21489128830782003
[2m[36m(func pid=62614)[0m f1_per_class: [0.114, 0.39, 0.615, 0.333, 0.09, 0.0, 0.074, 0.425, 0.026, 0.049]
[2m[36m(func pid=62614)[0m 
[2m[36m(func pid=79460)[0m top1: 0.28591417910447764
[2m[36m(func pid=79460)[0m top5: 0.8498134328358209
[2m[36m(func pid=79460)[0m f1_micro: 0.28591417910447764
[2m[36m(func pid=79460)[0m f1_macro: 0.2222305505481527
[2m[36m(func pid=79460)[0m f1_weighted: 0.2684095789975053
[2m[36m(func pid=79460)[0m f1_per_class: [0.148, 0.511, 0.138, 0.388, 0.066, 0.327, 0.015, 0.352, 0.102, 0.173]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=83696)[0m top1: 0.04477611940298507
[2m[36m(func pid=83696)[0m top5: 0.5984141791044776
[2m[36m(func pid=83696)[0m f1_micro: 0.04477611940298508
[2m[36m(func pid=83696)[0m f1_macro: 0.05567950085773059
[2m[36m(func pid=83696)[0m f1_weighted: 0.046937931428456266
[2m[36m(func pid=83696)[0m f1_per_class: [0.025, 0.258, 0.073, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=73645)[0m top1: 0.2947761194029851
[2m[36m(func pid=73645)[0m top5: 0.9193097014925373
[2m[36m(func pid=73645)[0m f1_micro: 0.2947761194029851
[2m[36m(func pid=73645)[0m f1_macro: 0.2674584645370217
[2m[36m(func pid=73645)[0m f1_weighted: 0.26707082965964013
[2m[36m(func pid=73645)[0m f1_per_class: [0.294, 0.386, 0.306, 0.026, 0.076, 0.265, 0.399, 0.482, 0.127, 0.313]
== Status ==
Current time: 2024-01-07 02:42:46 (running for 00:18:47.74)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (13 PENDING, 4 RUNNING, 7 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00007 | RUNNING    | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.207 |      0.212 |                   99 |
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  1.509 |      0.267 |                   49 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  1.229 |      0.222 |                   23 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  2.508 |      0.056 |                    4 |
| train_6ed81_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=62614)[0m [N0-GPU0] | [Epoch: 99] | Train loss: 1.0278 | Steps: 2 | Val loss: 4.0311 | Batch size: 32 | lr: 0.1 | Duration: 2.78s
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 1.3006 | Steps: 2 | Val loss: 2.1958 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 2.1969 | Steps: 2 | Val loss: 9.0451 | Batch size: 32 | lr: 0.01 | Duration: 2.76s
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 1.5192 | Steps: 2 | Val loss: 1.9052 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=62614)[0m top1: 0.24486940298507462
[2m[36m(func pid=62614)[0m top5: 0.8432835820895522
[2m[36m(func pid=62614)[0m f1_micro: 0.24486940298507462
[2m[36m(func pid=62614)[0m f1_macro: 0.23168605294532982
[2m[36m(func pid=62614)[0m f1_weighted: 0.24713447030380592
[2m[36m(func pid=62614)[0m f1_per_class: [0.169, 0.373, 0.5, 0.32, 0.11, 0.0, 0.181, 0.492, 0.09, 0.081]
[2m[36m(func pid=79460)[0m top1: 0.27798507462686567
[2m[36m(func pid=79460)[0m top5: 0.8577425373134329
[2m[36m(func pid=79460)[0m f1_micro: 0.27798507462686567
[2m[36m(func pid=79460)[0m f1_macro: 0.2181713157311318
[2m[36m(func pid=79460)[0m f1_weighted: 0.2743012771759571
[2m[36m(func pid=79460)[0m f1_per_class: [0.134, 0.52, 0.144, 0.345, 0.071, 0.275, 0.088, 0.379, 0.099, 0.127]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=83696)[0m top1: 0.04011194029850746
[2m[36m(func pid=83696)[0m top5: 0.5597014925373134
[2m[36m(func pid=83696)[0m f1_micro: 0.04011194029850746
[2m[36m(func pid=83696)[0m f1_macro: 0.04959460329819428
[2m[36m(func pid=83696)[0m f1_weighted: 0.025950984492691846
[2m[36m(func pid=83696)[0m f1_per_class: [0.0, 0.126, 0.026, 0.0, 0.286, 0.0, 0.0, 0.0, 0.058, 0.0]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=73645)[0m top1: 0.30223880597014924
[2m[36m(func pid=73645)[0m top5: 0.9235074626865671
[2m[36m(func pid=73645)[0m f1_micro: 0.30223880597014924
[2m[36m(func pid=73645)[0m f1_macro: 0.2751633118022915
[2m[36m(func pid=73645)[0m f1_weighted: 0.2813313113365454
[2m[36m(func pid=73645)[0m f1_per_class: [0.283, 0.396, 0.314, 0.058, 0.073, 0.269, 0.407, 0.498, 0.11, 0.341]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 1.1615 | Steps: 2 | Val loss: 2.3027 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 2.0773 | Steps: 2 | Val loss: 9.9586 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 1.5569 | Steps: 2 | Val loss: 1.8852 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
[2m[36m(func pid=79460)[0m top1: 0.2630597014925373
[2m[36m(func pid=79460)[0m top5: 0.8614738805970149
[2m[36m(func pid=79460)[0m f1_micro: 0.2630597014925373
[2m[36m(func pid=79460)[0m f1_macro: 0.20981201466135246
[2m[36m(func pid=79460)[0m f1_weighted: 0.2648566445157025
[2m[36m(func pid=79460)[0m f1_per_class: [0.118, 0.527, 0.147, 0.295, 0.073, 0.201, 0.123, 0.411, 0.099, 0.103]
[2m[36m(func pid=83696)[0m top1: 0.05503731343283582
[2m[36m(func pid=83696)[0m top5: 0.6669776119402985
[2m[36m(func pid=83696)[0m f1_micro: 0.05503731343283582
[2m[36m(func pid=83696)[0m f1_macro: 0.060506132681439596
[2m[36m(func pid=83696)[0m f1_weighted: 0.05768339853828623
[2m[36m(func pid=83696)[0m f1_per_class: [0.0, 0.073, 0.028, 0.145, 0.24, 0.0, 0.0, 0.0, 0.062, 0.057]
[2m[36m(func pid=73645)[0m top1: 0.30223880597014924
[2m[36m(func pid=73645)[0m top5: 0.9239738805970149
[2m[36m(func pid=73645)[0m f1_micro: 0.30223880597014924
[2m[36m(func pid=73645)[0m f1_macro: 0.28207957155921976
[2m[36m(func pid=73645)[0m f1_weighted: 0.28767676838359174
[2m[36m(func pid=73645)[0m f1_per_class: [0.277, 0.404, 0.344, 0.099, 0.07, 0.288, 0.376, 0.493, 0.144, 0.326]
== Status ==
Current time: 2024-01-07 02:42:52 (running for 00:18:53.20)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  1.519 |      0.275 |                   50 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  1.301 |      0.218 |                   24 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  2.197 |      0.05  |                    5 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


== Status ==
Current time: 2024-01-07 02:42:58 (running for 00:18:59.21)
Memory usage on this node: 23.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  1.557 |      0.282 |                   51 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  1.301 |      0.218 |                   24 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  2.197 |      0.05  |                    5 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=85373)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=85373)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=85373)[0m Configuration completed!
[2m[36m(func pid=85373)[0m New optimizer parameters:
[2m[36m(func pid=85373)[0m SGD (
[2m[36m(func pid=85373)[0m Parameter Group 0
[2m[36m(func pid=85373)[0m     dampening: 0
[2m[36m(func pid=85373)[0m     differentiable: False
[2m[36m(func pid=85373)[0m     foreach: None
[2m[36m(func pid=85373)[0m     lr: 0.1
[2m[36m(func pid=85373)[0m     maximize: False
[2m[36m(func pid=85373)[0m     momentum: 0.99
[2m[36m(func pid=85373)[0m     nesterov: False
[2m[36m(func pid=85373)[0m     weight_decay: 0.0001
[2m[36m(func pid=85373)[0m )
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.9863 | Steps: 2 | Val loss: 2.5660 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 1.5652 | Steps: 2 | Val loss: 1.8867 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 2.9236 | Steps: 2 | Val loss: 6.9361 | Batch size: 32 | lr: 0.01 | Duration: 3.06s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 3.8136 | Steps: 2 | Val loss: 454.0351 | Batch size: 32 | lr: 0.1 | Duration: 4.73s
== Status ==
Current time: 2024-01-07 02:43:03 (running for 00:19:04.24)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  1.557 |      0.282 |                   51 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  1.161 |      0.21  |                   25 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  2.077 |      0.061 |                    6 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |        |            |                      |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=79460)[0m top1: 0.23647388059701493
[2m[36m(func pid=79460)[0m top5: 0.8610074626865671
[2m[36m(func pid=79460)[0m f1_micro: 0.23647388059701493
[2m[36m(func pid=79460)[0m f1_macro: 0.1960033579845903
[2m[36m(func pid=79460)[0m f1_weighted: 0.24389252925957752
[2m[36m(func pid=79460)[0m f1_per_class: [0.106, 0.529, 0.152, 0.273, 0.083, 0.118, 0.102, 0.437, 0.089, 0.071]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=73645)[0m top1: 0.29990671641791045
[2m[36m(func pid=73645)[0m top5: 0.9221082089552238
[2m[36m(func pid=73645)[0m f1_micro: 0.29990671641791045
[2m[36m(func pid=73645)[0m f1_macro: 0.2831850269184086
[2m[36m(func pid=73645)[0m f1_weighted: 0.28984544431792864
[2m[36m(func pid=73645)[0m f1_per_class: [0.275, 0.418, 0.338, 0.151, 0.069, 0.32, 0.316, 0.488, 0.154, 0.303]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=83696)[0m top1: 0.09794776119402986
[2m[36m(func pid=83696)[0m top5: 0.6865671641791045
[2m[36m(func pid=83696)[0m f1_micro: 0.09794776119402987
[2m[36m(func pid=83696)[0m f1_macro: 0.06449957386378066
[2m[36m(func pid=83696)[0m f1_weighted: 0.09079139349818541
[2m[36m(func pid=83696)[0m f1_per_class: [0.0, 0.319, 0.039, 0.11, 0.0, 0.008, 0.0, 0.006, 0.075, 0.088]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=85373)[0m top1: 0.006063432835820896
[2m[36m(func pid=85373)[0m top5: 0.23973880597014927
[2m[36m(func pid=85373)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=85373)[0m f1_macro: 0.001205377839592026
[2m[36m(func pid=85373)[0m f1_weighted: 7.308727572153144e-05
[2m[36m(func pid=85373)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 1.2864 | Steps: 2 | Val loss: 2.7263 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 1.4260 | Steps: 2 | Val loss: 1.8765 | Batch size: 32 | lr: 0.0001 | Duration: 2.81s
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 1.9929 | Steps: 2 | Val loss: 5.8606 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 5.6725 | Steps: 2 | Val loss: 45395.6992 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
== Status ==
Current time: 2024-01-07 02:43:09 (running for 00:19:09.82)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  1.565 |      0.283 |                   52 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  1.286 |      0.204 |                   27 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  2.924 |      0.064 |                    7 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  3.814 |      0.001 |                    1 |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=79460)[0m top1: 0.23973880597014927
[2m[36m(func pid=79460)[0m top5: 0.8638059701492538
[2m[36m(func pid=79460)[0m f1_micro: 0.23973880597014927
[2m[36m(func pid=79460)[0m f1_macro: 0.2040664528498529
[2m[36m(func pid=79460)[0m f1_weighted: 0.24517385501880867
[2m[36m(func pid=79460)[0m f1_per_class: [0.096, 0.542, 0.166, 0.239, 0.156, 0.119, 0.13, 0.436, 0.087, 0.071]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=73645)[0m top1: 0.292910447761194
[2m[36m(func pid=73645)[0m top5: 0.9216417910447762
[2m[36m(func pid=73645)[0m f1_micro: 0.292910447761194
[2m[36m(func pid=73645)[0m f1_macro: 0.2807882583530019
[2m[36m(func pid=73645)[0m f1_weighted: 0.2861924162825876
[2m[36m(func pid=73645)[0m f1_per_class: [0.278, 0.419, 0.333, 0.203, 0.066, 0.306, 0.263, 0.463, 0.163, 0.314]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=83696)[0m top1: 0.10634328358208955
[2m[36m(func pid=83696)[0m top5: 0.5946828358208955
[2m[36m(func pid=83696)[0m f1_micro: 0.10634328358208955
[2m[36m(func pid=83696)[0m f1_macro: 0.05200422097703182
[2m[36m(func pid=83696)[0m f1_weighted: 0.0669637829331022
[2m[36m(func pid=83696)[0m f1_per_class: [0.0, 0.352, 0.063, 0.0, 0.0, 0.0, 0.012, 0.0, 0.059, 0.033]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=85373)[0m top1: 0.006063432835820896
[2m[36m(func pid=85373)[0m top5: 0.5093283582089553
[2m[36m(func pid=85373)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=85373)[0m f1_macro: 0.001205377839592026
[2m[36m(func pid=85373)[0m f1_weighted: 7.308727572153144e-05
[2m[36m(func pid=85373)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 1.0571 | Steps: 2 | Val loss: 2.4222 | Batch size: 32 | lr: 0.001 | Duration: 2.78s
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 1.7366 | Steps: 2 | Val loss: 1.8826 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 1.4727 | Steps: 2 | Val loss: 7.2749 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 5.3845 | Steps: 2 | Val loss: 1911547.6250 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
== Status ==
Current time: 2024-01-07 02:43:14 (running for 00:19:14.94)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  1.426 |      0.281 |                   53 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  1.057 |      0.222 |                   28 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  1.993 |      0.052 |                    8 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  5.673 |      0.001 |                    2 |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=79460)[0m top1: 0.2835820895522388
[2m[36m(func pid=79460)[0m top5: 0.8754664179104478
[2m[36m(func pid=79460)[0m f1_micro: 0.2835820895522388
[2m[36m(func pid=79460)[0m f1_macro: 0.2215561562729013
[2m[36m(func pid=79460)[0m f1_weighted: 0.27939637559083935
[2m[36m(func pid=79460)[0m f1_per_class: [0.102, 0.538, 0.167, 0.213, 0.136, 0.138, 0.262, 0.424, 0.1, 0.136]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=73645)[0m top1: 0.28824626865671643
[2m[36m(func pid=73645)[0m top5: 0.9174440298507462
[2m[36m(func pid=73645)[0m f1_micro: 0.28824626865671643
[2m[36m(func pid=73645)[0m f1_macro: 0.276978587385313
[2m[36m(func pid=73645)[0m f1_weighted: 0.27372636872723793
[2m[36m(func pid=73645)[0m f1_per_class: [0.294, 0.432, 0.328, 0.245, 0.066, 0.308, 0.173, 0.46, 0.164, 0.299]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=83696)[0m top1: 0.06623134328358209
[2m[36m(func pid=83696)[0m top5: 0.523320895522388
[2m[36m(func pid=83696)[0m f1_micro: 0.06623134328358209
[2m[36m(func pid=83696)[0m f1_macro: 0.0497592788650231
[2m[36m(func pid=83696)[0m f1_weighted: 0.06808081632337501
[2m[36m(func pid=83696)[0m f1_per_class: [0.0, 0.326, 0.042, 0.0, 0.062, 0.0, 0.037, 0.0, 0.0, 0.031]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=85373)[0m top1: 0.006063432835820896
[2m[36m(func pid=85373)[0m top5: 0.5093283582089553
[2m[36m(func pid=85373)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=85373)[0m f1_macro: 0.001205377839592026
[2m[36m(func pid=85373)[0m f1_weighted: 7.308727572153144e-05
[2m[36m(func pid=85373)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.9062 | Steps: 2 | Val loss: 2.4245 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 1.4768 | Steps: 2 | Val loss: 1.8647 | Batch size: 32 | lr: 0.0001 | Duration: 3.18s
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 1.3104 | Steps: 2 | Val loss: 7.9458 | Batch size: 32 | lr: 0.01 | Duration: 3.14s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 13.1536 | Steps: 2 | Val loss: 2216873.7500 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
== Status ==
Current time: 2024-01-07 02:43:19 (running for 00:19:20.26)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  1.737 |      0.277 |                   54 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.906 |      0.239 |                   29 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  1.473 |      0.05  |                    9 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  5.385 |      0.001 |                    3 |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=79460)[0m top1: 0.30363805970149255
[2m[36m(func pid=79460)[0m top5: 0.8824626865671642
[2m[36m(func pid=79460)[0m f1_micro: 0.30363805970149255
[2m[36m(func pid=79460)[0m f1_macro: 0.23910354785773147
[2m[36m(func pid=79460)[0m f1_weighted: 0.29452078291407385
[2m[36m(func pid=79460)[0m f1_per_class: [0.104, 0.543, 0.158, 0.184, 0.122, 0.173, 0.317, 0.421, 0.125, 0.243]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=73645)[0m top1: 0.28777985074626866
[2m[36m(func pid=73645)[0m top5: 0.9113805970149254
[2m[36m(func pid=73645)[0m f1_micro: 0.28777985074626866
[2m[36m(func pid=73645)[0m f1_macro: 0.2720848713259764
[2m[36m(func pid=73645)[0m f1_weighted: 0.26788222333599
[2m[36m(func pid=73645)[0m f1_per_class: [0.306, 0.435, 0.333, 0.303, 0.069, 0.292, 0.11, 0.426, 0.17, 0.276]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=83696)[0m top1: 0.05317164179104478
[2m[36m(func pid=83696)[0m top5: 0.4878731343283582
[2m[36m(func pid=83696)[0m f1_micro: 0.05317164179104478
[2m[36m(func pid=83696)[0m f1_macro: 0.05137819268926637
[2m[36m(func pid=83696)[0m f1_weighted: 0.05348960231785002
[2m[36m(func pid=83696)[0m f1_per_class: [0.013, 0.281, 0.052, 0.0, 0.111, 0.008, 0.006, 0.009, 0.0, 0.033]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=85373)[0m top1: 0.006063432835820896
[2m[36m(func pid=85373)[0m top5: 0.5093283582089553
[2m[36m(func pid=85373)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=85373)[0m f1_macro: 0.001205377839592026
[2m[36m(func pid=85373)[0m f1_weighted: 7.308727572153144e-05
[2m[36m(func pid=85373)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.8945 | Steps: 2 | Val loss: 2.4288 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 1.3130 | Steps: 2 | Val loss: 1.8534 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 1.8937 | Steps: 2 | Val loss: 18.7487 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 3.1902 | Steps: 2 | Val loss: 160443.4375 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 02:43:24 (running for 00:19:25.56)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  1.477 |      0.272 |                   55 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.894 |      0.262 |                   30 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  1.31  |      0.051 |                   10 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 | 13.154 |      0.001 |                    4 |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=79460)[0m top1: 0.3199626865671642
[2m[36m(func pid=79460)[0m top5: 0.8875932835820896
[2m[36m(func pid=79460)[0m f1_micro: 0.3199626865671642
[2m[36m(func pid=79460)[0m f1_macro: 0.26154154716792094
[2m[36m(func pid=79460)[0m f1_weighted: 0.30942356613719835
[2m[36m(func pid=79460)[0m f1_per_class: [0.102, 0.549, 0.18, 0.204, 0.098, 0.173, 0.335, 0.434, 0.139, 0.4]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=83696)[0m top1: 0.04617537313432836
[2m[36m(func pid=83696)[0m top5: 0.28824626865671643
[2m[36m(func pid=83696)[0m f1_micro: 0.04617537313432836
[2m[36m(func pid=83696)[0m f1_macro: 0.03559444734299458
[2m[36m(func pid=83696)[0m f1_weighted: 0.04615657612248127
[2m[36m(func pid=83696)[0m f1_per_class: [0.024, 0.262, 0.045, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=73645)[0m top1: 0.300839552238806
[2m[36m(func pid=73645)[0m top5: 0.9113805970149254
[2m[36m(func pid=73645)[0m f1_micro: 0.300839552238806
[2m[36m(func pid=73645)[0m f1_macro: 0.2810455712131473
[2m[36m(func pid=73645)[0m f1_weighted: 0.279974853920673
[2m[36m(func pid=73645)[0m f1_per_class: [0.347, 0.449, 0.361, 0.372, 0.07, 0.293, 0.079, 0.408, 0.168, 0.264]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=85373)[0m top1: 0.006063432835820896
[2m[36m(func pid=85373)[0m top5: 0.5093283582089553
[2m[36m(func pid=85373)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=85373)[0m f1_macro: 0.001205377839592026
[2m[36m(func pid=85373)[0m f1_weighted: 7.308727572153144e-05
[2m[36m(func pid=85373)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 1.0652 | Steps: 2 | Val loss: 2.5502 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 1.2690 | Steps: 2 | Val loss: 1.8475 | Batch size: 32 | lr: 0.0001 | Duration: 2.77s
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 1.6404 | Steps: 2 | Val loss: 33.4166 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 9.4725 | Steps: 2 | Val loss: 7257915.5000 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
== Status ==
Current time: 2024-01-07 02:43:29 (running for 00:19:30.78)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  1.313 |      0.281 |                   56 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  1.065 |      0.261 |                   31 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  1.894 |      0.036 |                   11 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  3.19  |      0.001 |                    5 |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=79460)[0m top1: 0.3162313432835821
[2m[36m(func pid=79460)[0m top5: 0.8922574626865671
[2m[36m(func pid=79460)[0m f1_micro: 0.3162313432835821
[2m[36m(func pid=79460)[0m f1_macro: 0.26052558947710364
[2m[36m(func pid=79460)[0m f1_weighted: 0.3070827476054967
[2m[36m(func pid=79460)[0m f1_per_class: [0.098, 0.551, 0.172, 0.209, 0.105, 0.146, 0.331, 0.433, 0.149, 0.411]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=73645)[0m top1: 0.30736940298507465
[2m[36m(func pid=73645)[0m top5: 0.9039179104477612
[2m[36m(func pid=73645)[0m f1_micro: 0.30736940298507465
[2m[36m(func pid=73645)[0m f1_macro: 0.2805150888035222
[2m[36m(func pid=73645)[0m f1_weighted: 0.28421999491485034
[2m[36m(func pid=73645)[0m f1_per_class: [0.328, 0.463, 0.393, 0.41, 0.07, 0.297, 0.051, 0.401, 0.164, 0.227]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=83696)[0m top1: 0.03264925373134328
[2m[36m(func pid=83696)[0m top5: 0.28404850746268656
[2m[36m(func pid=83696)[0m f1_micro: 0.03264925373134328
[2m[36m(func pid=83696)[0m f1_macro: 0.03410827328784859
[2m[36m(func pid=83696)[0m f1_weighted: 0.03296105406538067
[2m[36m(func pid=83696)[0m f1_per_class: [0.0, 0.184, 0.031, 0.0, 0.105, 0.0, 0.0, 0.0, 0.0, 0.02]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=85373)[0m top1: 0.006063432835820896
[2m[36m(func pid=85373)[0m top5: 0.5093283582089553
[2m[36m(func pid=85373)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=85373)[0m f1_macro: 0.001205377839592026
[2m[36m(func pid=85373)[0m f1_weighted: 7.308727572153144e-05
[2m[36m(func pid=85373)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 1.6011 | Steps: 2 | Val loss: 2.6244 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 1.3626 | Steps: 2 | Val loss: 1.8414 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 1.6903 | Steps: 2 | Val loss: 21.2614 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 02:43:35 (running for 00:19:35.94)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  1.269 |      0.281 |                   57 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  1.601 |      0.255 |                   32 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  1.64  |      0.034 |                   12 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  9.473 |      0.001 |                    6 |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=79460)[0m top1: 0.3069029850746269
[2m[36m(func pid=79460)[0m top5: 0.8838619402985075
[2m[36m(func pid=79460)[0m f1_micro: 0.3069029850746269
[2m[36m(func pid=79460)[0m f1_macro: 0.2551557078926491
[2m[36m(func pid=79460)[0m f1_weighted: 0.3064108211766526
[2m[36m(func pid=79460)[0m f1_per_class: [0.088, 0.545, 0.195, 0.255, 0.092, 0.126, 0.298, 0.443, 0.141, 0.368]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 2.4967 | Steps: 2 | Val loss: 922358.1875 | Batch size: 32 | lr: 0.1 | Duration: 3.08s
[2m[36m(func pid=83696)[0m top1: 0.05317164179104478
[2m[36m(func pid=83696)[0m top5: 0.3969216417910448
[2m[36m(func pid=83696)[0m f1_micro: 0.05317164179104478
[2m[36m(func pid=83696)[0m f1_macro: 0.06241853021599132
[2m[36m(func pid=83696)[0m f1_weighted: 0.06374429536282203
[2m[36m(func pid=83696)[0m f1_per_class: [0.0, 0.181, 0.03, 0.013, 0.279, 0.008, 0.085, 0.0, 0.0, 0.027]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=73645)[0m top1: 0.3125
[2m[36m(func pid=73645)[0m top5: 0.9006529850746269
[2m[36m(func pid=73645)[0m f1_micro: 0.3125
[2m[36m(func pid=73645)[0m f1_macro: 0.2794184880690833
[2m[36m(func pid=73645)[0m f1_weighted: 0.2860833281918443
[2m[36m(func pid=73645)[0m f1_per_class: [0.329, 0.448, 0.407, 0.455, 0.072, 0.294, 0.027, 0.392, 0.159, 0.209]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.9366 | Steps: 2 | Val loss: 2.8121 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=85373)[0m top1: 0.006063432835820896
[2m[36m(func pid=85373)[0m top5: 0.5093283582089553
[2m[36m(func pid=85373)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=85373)[0m f1_macro: 0.001205377839592026
[2m[36m(func pid=85373)[0m f1_weighted: 7.308727572153144e-05
[2m[36m(func pid=85373)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 2.1762 | Steps: 2 | Val loss: 47.6236 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 1.3208 | Steps: 2 | Val loss: 1.8369 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
== Status ==
Current time: 2024-01-07 02:43:40 (running for 00:19:41.15)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  1.363 |      0.279 |                   58 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.937 |      0.286 |                   33 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  1.69  |      0.062 |                   13 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  2.497 |      0.001 |                    7 |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=79460)[0m top1: 0.3185634328358209
[2m[36m(func pid=79460)[0m top5: 0.8656716417910447
[2m[36m(func pid=79460)[0m f1_micro: 0.3185634328358209
[2m[36m(func pid=79460)[0m f1_macro: 0.2863642660083911
[2m[36m(func pid=79460)[0m f1_weighted: 0.34008029343770785
[2m[36m(func pid=79460)[0m f1_per_class: [0.091, 0.54, 0.237, 0.282, 0.081, 0.316, 0.3, 0.516, 0.165, 0.337]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 2.7682 | Steps: 2 | Val loss: 198945.9219 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=83696)[0m top1: 0.042444029850746266
[2m[36m(func pid=83696)[0m top5: 0.3302238805970149
[2m[36m(func pid=83696)[0m f1_micro: 0.042444029850746266
[2m[36m(func pid=83696)[0m f1_macro: 0.0421685652569955
[2m[36m(func pid=83696)[0m f1_weighted: 0.0552664291793715
[2m[36m(func pid=83696)[0m f1_per_class: [0.0, 0.185, 0.024, 0.01, 0.087, 0.048, 0.047, 0.0, 0.0, 0.02]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=73645)[0m top1: 0.3162313432835821
[2m[36m(func pid=73645)[0m top5: 0.8955223880597015
[2m[36m(func pid=73645)[0m f1_micro: 0.3162313432835821
[2m[36m(func pid=73645)[0m f1_macro: 0.27327345530788516
[2m[36m(func pid=73645)[0m f1_weighted: 0.2883964942266913
[2m[36m(func pid=73645)[0m f1_per_class: [0.318, 0.448, 0.4, 0.479, 0.076, 0.263, 0.03, 0.387, 0.134, 0.198]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 1.0478 | Steps: 2 | Val loss: 3.3532 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=85373)[0m top1: 0.0065298507462686565
[2m[36m(func pid=85373)[0m top5: 0.5097947761194029
[2m[36m(func pid=85373)[0m f1_micro: 0.0065298507462686565
[2m[36m(func pid=85373)[0m f1_macro: 0.0017464774607631752
[2m[36m(func pid=85373)[0m f1_weighted: 0.0010034358182012767
[2m[36m(func pid=85373)[0m f1_per_class: [0.0, 0.005, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 1.4772 | Steps: 2 | Val loss: 83.7818 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 1.2321 | Steps: 2 | Val loss: 1.8285 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
== Status ==
Current time: 2024-01-07 02:43:45 (running for 00:19:46.38)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  1.321 |      0.273 |                   59 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  1.048 |      0.252 |                   34 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  2.176 |      0.042 |                   14 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  2.768 |      0.002 |                    8 |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=79460)[0m top1: 0.261660447761194
[2m[36m(func pid=79460)[0m top5: 0.8386194029850746
[2m[36m(func pid=79460)[0m f1_micro: 0.261660447761194
[2m[36m(func pid=79460)[0m f1_macro: 0.2520170614094374
[2m[36m(func pid=79460)[0m f1_weighted: 0.27384082875098376
[2m[36m(func pid=79460)[0m f1_per_class: [0.09, 0.532, 0.275, 0.256, 0.097, 0.319, 0.116, 0.507, 0.113, 0.216]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 2.9347 | Steps: 2 | Val loss: 64512.5859 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=83696)[0m top1: 0.04151119402985075
[2m[36m(func pid=83696)[0m top5: 0.3003731343283582
[2m[36m(func pid=83696)[0m f1_micro: 0.04151119402985075
[2m[36m(func pid=83696)[0m f1_macro: 0.05607040496685992
[2m[36m(func pid=83696)[0m f1_weighted: 0.047724381101226496
[2m[36m(func pid=83696)[0m f1_per_class: [0.009, 0.242, 0.025, 0.0, 0.222, 0.032, 0.0, 0.0, 0.0, 0.029]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=73645)[0m top1: 0.3218283582089552
[2m[36m(func pid=73645)[0m top5: 0.8931902985074627
[2m[36m(func pid=73645)[0m f1_micro: 0.3218283582089552
[2m[36m(func pid=73645)[0m f1_macro: 0.27084053678979436
[2m[36m(func pid=73645)[0m f1_weighted: 0.2893088020767415
[2m[36m(func pid=73645)[0m f1_per_class: [0.301, 0.442, 0.407, 0.502, 0.077, 0.256, 0.021, 0.381, 0.118, 0.203]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.8882 | Steps: 2 | Val loss: 4.1808 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=85373)[0m top1: 0.007462686567164179
[2m[36m(func pid=85373)[0m top5: 0.5111940298507462
[2m[36m(func pid=85373)[0m f1_micro: 0.007462686567164179
[2m[36m(func pid=85373)[0m f1_macro: 0.02280158019041211
[2m[36m(func pid=85373)[0m f1_weighted: 0.002572258320162907
[2m[36m(func pid=85373)[0m f1_per_class: [0.0, 0.005, 0.012, 0.0, 0.211, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 1.2546 | Steps: 2 | Val loss: 84.7301 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 1.2965 | Steps: 2 | Val loss: 1.8336 | Batch size: 32 | lr: 0.0001 | Duration: 2.81s
== Status ==
Current time: 2024-01-07 02:43:50 (running for 00:19:51.46)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  1.232 |      0.271 |                   60 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.888 |      0.223 |                   35 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  1.477 |      0.056 |                   15 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  2.935 |      0.023 |                    9 |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=79460)[0m top1: 0.2140858208955224
[2m[36m(func pid=79460)[0m top5: 0.784981343283582
[2m[36m(func pid=79460)[0m f1_micro: 0.2140858208955224
[2m[36m(func pid=79460)[0m f1_macro: 0.22339700897916148
[2m[36m(func pid=79460)[0m f1_weighted: 0.22592419998683128
[2m[36m(func pid=79460)[0m f1_per_class: [0.091, 0.514, 0.338, 0.229, 0.101, 0.243, 0.03, 0.476, 0.09, 0.121]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 2.4138 | Steps: 2 | Val loss: 26895.3340 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=83696)[0m top1: 0.029850746268656716
[2m[36m(func pid=83696)[0m top5: 0.31576492537313433
[2m[36m(func pid=83696)[0m f1_micro: 0.029850746268656716
[2m[36m(func pid=83696)[0m f1_macro: 0.047121398938710625
[2m[36m(func pid=83696)[0m f1_weighted: 0.027135714925969404
[2m[36m(func pid=83696)[0m f1_per_class: [0.008, 0.131, 0.027, 0.0, 0.222, 0.016, 0.0, 0.0, 0.0, 0.067]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=73645)[0m top1: 0.3246268656716418
[2m[36m(func pid=73645)[0m top5: 0.8880597014925373
[2m[36m(func pid=73645)[0m f1_micro: 0.3246268656716418
[2m[36m(func pid=73645)[0m f1_macro: 0.2653969762851064
[2m[36m(func pid=73645)[0m f1_weighted: 0.2920251479398094
[2m[36m(func pid=73645)[0m f1_per_class: [0.276, 0.45, 0.393, 0.521, 0.081, 0.234, 0.021, 0.367, 0.119, 0.19]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.6803 | Steps: 2 | Val loss: 3.6079 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=85373)[0m top1: 0.009794776119402986
[2m[36m(func pid=85373)[0m top5: 0.5121268656716418
[2m[36m(func pid=85373)[0m f1_micro: 0.009794776119402986
[2m[36m(func pid=85373)[0m f1_macro: 0.031930598774163134
[2m[36m(func pid=85373)[0m f1_weighted: 0.0058781657483445585
[2m[36m(func pid=85373)[0m f1_per_class: [0.0, 0.021, 0.012, 0.0, 0.286, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 1.3065 | Steps: 2 | Val loss: 58.3782 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 1.3241 | Steps: 2 | Val loss: 1.8366 | Batch size: 32 | lr: 0.0001 | Duration: 2.77s
== Status ==
Current time: 2024-01-07 02:43:55 (running for 00:19:56.72)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  1.296 |      0.265 |                   61 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.68  |      0.273 |                   36 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  1.255 |      0.047 |                   16 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  2.414 |      0.032 |                   10 |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=79460)[0m top1: 0.2677238805970149
[2m[36m(func pid=79460)[0m top5: 0.8255597014925373
[2m[36m(func pid=79460)[0m f1_micro: 0.2677238805970149
[2m[36m(func pid=79460)[0m f1_macro: 0.2726550019560976
[2m[36m(func pid=79460)[0m f1_weighted: 0.2905122097637903
[2m[36m(func pid=79460)[0m f1_per_class: [0.108, 0.487, 0.37, 0.268, 0.079, 0.315, 0.178, 0.517, 0.15, 0.254]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 2.2818 | Steps: 2 | Val loss: 12724.8057 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=83696)[0m top1: 0.03451492537313433
[2m[36m(func pid=83696)[0m top5: 0.35494402985074625
[2m[36m(func pid=83696)[0m f1_micro: 0.03451492537313433
[2m[36m(func pid=83696)[0m f1_macro: 0.05826771800918188
[2m[36m(func pid=83696)[0m f1_weighted: 0.026646023779745728
[2m[36m(func pid=83696)[0m f1_per_class: [0.024, 0.117, 0.04, 0.0, 0.327, 0.024, 0.0, 0.0, 0.0, 0.052]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=73645)[0m top1: 0.3260261194029851
[2m[36m(func pid=73645)[0m top5: 0.886660447761194
[2m[36m(func pid=73645)[0m f1_micro: 0.3260261194029851
[2m[36m(func pid=73645)[0m f1_macro: 0.2609286144881942
[2m[36m(func pid=73645)[0m f1_weighted: 0.2916633287703216
[2m[36m(func pid=73645)[0m f1_per_class: [0.275, 0.447, 0.379, 0.524, 0.079, 0.24, 0.021, 0.365, 0.085, 0.194]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.7021 | Steps: 2 | Val loss: 3.6269 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=85373)[0m top1: 0.014458955223880597
[2m[36m(func pid=85373)[0m top5: 0.5097947761194029
[2m[36m(func pid=85373)[0m f1_micro: 0.014458955223880597
[2m[36m(func pid=85373)[0m f1_macro: 0.03763241451597616
[2m[36m(func pid=85373)[0m f1_weighted: 0.013872500577194146
[2m[36m(func pid=85373)[0m f1_per_class: [0.0, 0.067, 0.013, 0.0, 0.296, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 1.6607 | Steps: 2 | Val loss: 50.3132 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 1.2266 | Steps: 2 | Val loss: 1.8394 | Batch size: 32 | lr: 0.0001 | Duration: 2.81s
== Status ==
Current time: 2024-01-07 02:44:01 (running for 00:20:02.08)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  1.324 |      0.261 |                   62 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.702 |      0.295 |                   37 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  1.306 |      0.058 |                   17 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  2.282 |      0.038 |                   11 |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=79460)[0m top1: 0.2896455223880597
[2m[36m(func pid=79460)[0m top5: 0.8316231343283582
[2m[36m(func pid=79460)[0m f1_micro: 0.2896455223880597
[2m[36m(func pid=79460)[0m f1_macro: 0.294881823892578
[2m[36m(func pid=79460)[0m f1_weighted: 0.32335037055388194
[2m[36m(func pid=79460)[0m f1_per_class: [0.109, 0.475, 0.4, 0.298, 0.089, 0.357, 0.243, 0.547, 0.16, 0.272]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 2.2389 | Steps: 2 | Val loss: 6906.0532 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=83696)[0m top1: 0.04617537313432836
[2m[36m(func pid=83696)[0m top5: 0.373134328358209
[2m[36m(func pid=83696)[0m f1_micro: 0.04617537313432836
[2m[36m(func pid=83696)[0m f1_macro: 0.05330048644441736
[2m[36m(func pid=83696)[0m f1_weighted: 0.039931136653502126
[2m[36m(func pid=83696)[0m f1_per_class: [0.031, 0.215, 0.061, 0.0, 0.162, 0.0, 0.0, 0.0, 0.0, 0.065]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=73645)[0m top1: 0.32276119402985076
[2m[36m(func pid=73645)[0m top5: 0.8857276119402985
[2m[36m(func pid=73645)[0m f1_micro: 0.32276119402985076
[2m[36m(func pid=73645)[0m f1_macro: 0.255582098846554
[2m[36m(func pid=73645)[0m f1_weighted: 0.2879047044733259
[2m[36m(func pid=73645)[0m f1_per_class: [0.265, 0.436, 0.367, 0.528, 0.081, 0.218, 0.021, 0.357, 0.088, 0.193]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 1.2109 | Steps: 2 | Val loss: 3.5232 | Batch size: 32 | lr: 0.001 | Duration: 2.72s
[2m[36m(func pid=85373)[0m top1: 0.04337686567164179
[2m[36m(func pid=85373)[0m top5: 0.34841417910447764
[2m[36m(func pid=85373)[0m f1_micro: 0.04337686567164179
[2m[36m(func pid=85373)[0m f1_macro: 0.0530868649261077
[2m[36m(func pid=85373)[0m f1_weighted: 0.04029408617624928
[2m[36m(func pid=85373)[0m f1_per_class: [0.0, 0.21, 0.015, 0.0, 0.294, 0.008, 0.003, 0.0, 0.0, 0.0]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 1.9815 | Steps: 2 | Val loss: 59.0331 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 1.3635 | Steps: 2 | Val loss: 1.8320 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
== Status ==
Current time: 2024-01-07 02:44:06 (running for 00:20:07.19)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  1.227 |      0.256 |                   63 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  1.211 |      0.289 |                   38 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  1.661 |      0.053 |                   18 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  2.239 |      0.053 |                   12 |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=79460)[0m top1: 0.292910447761194
[2m[36m(func pid=79460)[0m top5: 0.8418843283582089
[2m[36m(func pid=79460)[0m f1_micro: 0.292910447761194
[2m[36m(func pid=79460)[0m f1_macro: 0.2893777063424879
[2m[36m(func pid=79460)[0m f1_weighted: 0.3216406527032343
[2m[36m(func pid=79460)[0m f1_per_class: [0.11, 0.476, 0.35, 0.315, 0.125, 0.325, 0.238, 0.523, 0.151, 0.281]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 2.2278 | Steps: 2 | Val loss: 4984.3027 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
[2m[36m(func pid=83696)[0m top1: 0.07695895522388059
[2m[36m(func pid=83696)[0m top5: 0.4221082089552239
[2m[36m(func pid=83696)[0m f1_micro: 0.07695895522388059
[2m[36m(func pid=83696)[0m f1_macro: 0.07032008103358209
[2m[36m(func pid=83696)[0m f1_weighted: 0.0693641780735522
[2m[36m(func pid=83696)[0m f1_per_class: [0.051, 0.315, 0.0, 0.0, 0.133, 0.008, 0.034, 0.0, 0.0, 0.161]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=73645)[0m top1: 0.3260261194029851
[2m[36m(func pid=73645)[0m top5: 0.8871268656716418
[2m[36m(func pid=73645)[0m f1_micro: 0.3260261194029851
[2m[36m(func pid=73645)[0m f1_macro: 0.25916837485036215
[2m[36m(func pid=73645)[0m f1_weighted: 0.29266701824556907
[2m[36m(func pid=73645)[0m f1_per_class: [0.277, 0.436, 0.367, 0.532, 0.081, 0.225, 0.03, 0.361, 0.089, 0.194]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.5455 | Steps: 2 | Val loss: 3.3046 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=85373)[0m top1: 0.15298507462686567
[2m[36m(func pid=85373)[0m top5: 0.503731343283582
[2m[36m(func pid=85373)[0m f1_micro: 0.15298507462686567
[2m[36m(func pid=85373)[0m f1_macro: 0.05083797950503013
[2m[36m(func pid=85373)[0m f1_weighted: 0.05285917824578453
[2m[36m(func pid=85373)[0m f1_per_class: [0.0, 0.282, 0.0, 0.0, 0.217, 0.0, 0.009, 0.0, 0.0, 0.0]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 1.2163 | Steps: 2 | Val loss: 1.8205 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 1.4413 | Steps: 2 | Val loss: 58.9823 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
== Status ==
Current time: 2024-01-07 02:44:11 (running for 00:20:12.33)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  1.363 |      0.259 |                   64 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.546 |      0.286 |                   39 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  1.981 |      0.07  |                   19 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  2.228 |      0.051 |                   13 |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=79460)[0m top1: 0.291044776119403
[2m[36m(func pid=79460)[0m top5: 0.8540111940298507
[2m[36m(func pid=79460)[0m f1_micro: 0.291044776119403
[2m[36m(func pid=79460)[0m f1_macro: 0.2855786463847702
[2m[36m(func pid=79460)[0m f1_weighted: 0.3050342755823675
[2m[36m(func pid=79460)[0m f1_per_class: [0.128, 0.498, 0.467, 0.35, 0.164, 0.222, 0.2, 0.376, 0.135, 0.315]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 2.6116 | Steps: 2 | Val loss: 3414.3823 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=73645)[0m top1: 0.3292910447761194
[2m[36m(func pid=73645)[0m top5: 0.8838619402985075
[2m[36m(func pid=73645)[0m f1_micro: 0.3292910447761194
[2m[36m(func pid=73645)[0m f1_macro: 0.2649977555187536
[2m[36m(func pid=73645)[0m f1_weighted: 0.29752499621942397
[2m[36m(func pid=73645)[0m f1_per_class: [0.25, 0.443, 0.373, 0.528, 0.081, 0.254, 0.033, 0.368, 0.093, 0.227]
[2m[36m(func pid=83696)[0m top1: 0.08348880597014925
[2m[36m(func pid=83696)[0m top5: 0.5303171641791045
[2m[36m(func pid=83696)[0m f1_micro: 0.08348880597014925
[2m[36m(func pid=83696)[0m f1_macro: 0.07248197285193193
[2m[36m(func pid=83696)[0m f1_weighted: 0.09085990083066936
[2m[36m(func pid=83696)[0m f1_per_class: [0.051, 0.288, 0.0, 0.003, 0.059, 0.055, 0.098, 0.029, 0.0, 0.141]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.6460 | Steps: 2 | Val loss: 3.3583 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=85373)[0m top1: 0.016791044776119403
[2m[36m(func pid=85373)[0m top5: 0.4375
[2m[36m(func pid=85373)[0m f1_micro: 0.016791044776119403
[2m[36m(func pid=85373)[0m f1_macro: 0.028251433690320897
[2m[36m(func pid=85373)[0m f1_weighted: 0.014577960430361692
[2m[36m(func pid=85373)[0m f1_per_class: [0.0, 0.066, 0.018, 0.0, 0.175, 0.0, 0.003, 0.015, 0.0, 0.006]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 1.2442 | Steps: 2 | Val loss: 1.8061 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 1.7119 | Steps: 2 | Val loss: 47.1697 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 02:44:16 (running for 00:20:17.64)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  1.216 |      0.265 |                   65 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.646 |      0.268 |                   40 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  1.441 |      0.072 |                   20 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  2.612 |      0.028 |                   14 |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=79460)[0m top1: 0.28544776119402987
[2m[36m(func pid=79460)[0m top5: 0.8530783582089553
[2m[36m(func pid=79460)[0m f1_micro: 0.28544776119402987
[2m[36m(func pid=79460)[0m f1_macro: 0.2679803701097722
[2m[36m(func pid=79460)[0m f1_weighted: 0.2976194801123763
[2m[36m(func pid=79460)[0m f1_per_class: [0.133, 0.517, 0.368, 0.36, 0.171, 0.217, 0.165, 0.36, 0.119, 0.27]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 2.1981 | Steps: 2 | Val loss: 2745.8457 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=83696)[0m top1: 0.10587686567164178
[2m[36m(func pid=83696)[0m top5: 0.6240671641791045
[2m[36m(func pid=83696)[0m f1_micro: 0.10587686567164178
[2m[36m(func pid=83696)[0m f1_macro: 0.10965650431409393
[2m[36m(func pid=83696)[0m f1_weighted: 0.13715579269313233
[2m[36m(func pid=83696)[0m f1_per_class: [0.019, 0.324, 0.028, 0.026, 0.14, 0.099, 0.18, 0.096, 0.0, 0.185]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=73645)[0m top1: 0.33722014925373134
[2m[36m(func pid=73645)[0m top5: 0.8843283582089553
[2m[36m(func pid=73645)[0m f1_micro: 0.33722014925373134
[2m[36m(func pid=73645)[0m f1_macro: 0.274083473517881
[2m[36m(func pid=73645)[0m f1_weighted: 0.3070803087149727
[2m[36m(func pid=73645)[0m f1_per_class: [0.242, 0.462, 0.373, 0.529, 0.085, 0.273, 0.044, 0.369, 0.093, 0.27]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.9573 | Steps: 2 | Val loss: 2.9711 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=85373)[0m top1: 0.01632462686567164
[2m[36m(func pid=85373)[0m top5: 0.480410447761194
[2m[36m(func pid=85373)[0m f1_micro: 0.01632462686567164
[2m[36m(func pid=85373)[0m f1_macro: 0.026436921768673814
[2m[36m(func pid=85373)[0m f1_weighted: 0.00552853987046116
[2m[36m(func pid=85373)[0m f1_per_class: [0.0, 0.0, 0.019, 0.0, 0.182, 0.0, 0.003, 0.052, 0.0, 0.008]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 1.0931 | Steps: 2 | Val loss: 1.7984 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 1.4208 | Steps: 2 | Val loss: 43.6253 | Batch size: 32 | lr: 0.01 | Duration: 3.13s
== Status ==
Current time: 2024-01-07 02:44:22 (running for 00:20:22.98)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  1.244 |      0.274 |                   66 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.957 |      0.284 |                   41 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  1.712 |      0.11  |                   21 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  2.198 |      0.026 |                   15 |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=79460)[0m top1: 0.333955223880597
[2m[36m(func pid=79460)[0m top5: 0.8628731343283582
[2m[36m(func pid=79460)[0m f1_micro: 0.333955223880597
[2m[36m(func pid=79460)[0m f1_macro: 0.2842892939593609
[2m[36m(func pid=79460)[0m f1_weighted: 0.3529663006197632
[2m[36m(func pid=79460)[0m f1_per_class: [0.156, 0.521, 0.32, 0.406, 0.117, 0.206, 0.304, 0.391, 0.122, 0.301]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 39.3225 | Steps: 2 | Val loss: 1986.5852 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=73645)[0m top1: 0.34701492537313433
[2m[36m(func pid=73645)[0m top5: 0.8847947761194029
[2m[36m(func pid=73645)[0m f1_micro: 0.34701492537313433
[2m[36m(func pid=73645)[0m f1_macro: 0.2854264418975795
[2m[36m(func pid=73645)[0m f1_weighted: 0.32544342154409556
[2m[36m(func pid=73645)[0m f1_per_class: [0.245, 0.446, 0.386, 0.527, 0.085, 0.3, 0.102, 0.393, 0.092, 0.279]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=83696)[0m top1: 0.11520522388059702
[2m[36m(func pid=83696)[0m top5: 0.6030783582089553
[2m[36m(func pid=83696)[0m f1_micro: 0.11520522388059702
[2m[36m(func pid=83696)[0m f1_macro: 0.0989384165111351
[2m[36m(func pid=83696)[0m f1_weighted: 0.1443085501592261
[2m[36m(func pid=83696)[0m f1_per_class: [0.019, 0.392, 0.019, 0.029, 0.155, 0.04, 0.191, 0.087, 0.0, 0.057]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.7172 | Steps: 2 | Val loss: 2.9211 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=85373)[0m top1: 0.032182835820895525
[2m[36m(func pid=85373)[0m top5: 0.5032649253731343
[2m[36m(func pid=85373)[0m f1_micro: 0.032182835820895525
[2m[36m(func pid=85373)[0m f1_macro: 0.015432682406393788
[2m[36m(func pid=85373)[0m f1_weighted: 0.007339677311917464
[2m[36m(func pid=85373)[0m f1_per_class: [0.0, 0.0, 0.026, 0.0, 0.0, 0.0, 0.0, 0.123, 0.0, 0.005]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 1.0428 | Steps: 2 | Val loss: 1.7923 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 1.1643 | Steps: 2 | Val loss: 34.0792 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
== Status ==
Current time: 2024-01-07 02:44:27 (running for 00:20:28.25)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  1.093 |      0.285 |                   67 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.717 |      0.293 |                   42 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  1.421 |      0.099 |                   22 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 | 39.323 |      0.015 |                   16 |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=79460)[0m top1: 0.373134328358209
[2m[36m(func pid=79460)[0m top5: 0.8512126865671642
[2m[36m(func pid=79460)[0m f1_micro: 0.373134328358209
[2m[36m(func pid=79460)[0m f1_macro: 0.2928998282293206
[2m[36m(func pid=79460)[0m f1_weighted: 0.40102846888060956
[2m[36m(func pid=79460)[0m f1_per_class: [0.17, 0.518, 0.278, 0.412, 0.083, 0.169, 0.459, 0.492, 0.111, 0.236]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=73645)[0m top1: 0.3582089552238806
[2m[36m(func pid=73645)[0m top5: 0.8852611940298507
[2m[36m(func pid=73645)[0m f1_micro: 0.35820895522388063
[2m[36m(func pid=73645)[0m f1_macro: 0.2955419131656989
[2m[36m(func pid=73645)[0m f1_weighted: 0.34537087649244125
[2m[36m(func pid=73645)[0m f1_per_class: [0.244, 0.454, 0.386, 0.528, 0.084, 0.3, 0.158, 0.416, 0.092, 0.293]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=83696)[0m top1: 0.14878731343283583
[2m[36m(func pid=83696)[0m top5: 0.5788246268656716
[2m[36m(func pid=83696)[0m f1_micro: 0.14878731343283583
[2m[36m(func pid=83696)[0m f1_macro: 0.09644363731680963
[2m[36m(func pid=83696)[0m f1_weighted: 0.14648934820525744
[2m[36m(func pid=83696)[0m f1_per_class: [0.0, 0.484, 0.018, 0.007, 0.178, 0.07, 0.166, 0.041, 0.0, 0.0]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 2.2645 | Steps: 2 | Val loss: 886.5050 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.6875 | Steps: 2 | Val loss: 2.8005 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=85373)[0m top1: 0.04011194029850746
[2m[36m(func pid=85373)[0m top5: 0.4808768656716418
[2m[36m(func pid=85373)[0m f1_micro: 0.04011194029850746
[2m[36m(func pid=85373)[0m f1_macro: 0.020105940661358464
[2m[36m(func pid=85373)[0m f1_weighted: 0.010211806413432178
[2m[36m(func pid=85373)[0m f1_per_class: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17, 0.0, 0.031]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 1.0117 | Steps: 2 | Val loss: 29.5883 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 02:44:32 (running for 00:20:33.47)
Memory usage on this node: 24.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  1.043 |      0.296 |                   68 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.687 |      0.297 |                   43 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  1.164 |      0.096 |                   23 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  2.265 |      0.02  |                   17 |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 1.1050 | Steps: 2 | Val loss: 1.8032 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=79460)[0m top1: 0.38899253731343286
[2m[36m(func pid=79460)[0m top5: 0.8582089552238806
[2m[36m(func pid=79460)[0m f1_micro: 0.38899253731343286
[2m[36m(func pid=79460)[0m f1_macro: 0.29653367426752686
[2m[36m(func pid=79460)[0m f1_weighted: 0.4147671292968306
[2m[36m(func pid=79460)[0m f1_per_class: [0.192, 0.519, 0.216, 0.414, 0.075, 0.145, 0.498, 0.553, 0.145, 0.208]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 1.9818 | Steps: 2 | Val loss: 883.9489 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
[2m[36m(func pid=83696)[0m top1: 0.21128731343283583
[2m[36m(func pid=83696)[0m top5: 0.5914179104477612
[2m[36m(func pid=83696)[0m f1_micro: 0.21128731343283583
[2m[36m(func pid=83696)[0m f1_macro: 0.08369649417486254
[2m[36m(func pid=83696)[0m f1_weighted: 0.14880103705979353
[2m[36m(func pid=83696)[0m f1_per_class: [0.0, 0.395, 0.0, 0.003, 0.0, 0.093, 0.208, 0.112, 0.026, 0.0]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=73645)[0m top1: 0.3619402985074627
[2m[36m(func pid=73645)[0m top5: 0.882929104477612
[2m[36m(func pid=73645)[0m f1_micro: 0.3619402985074627
[2m[36m(func pid=73645)[0m f1_macro: 0.29985495731031075
[2m[36m(func pid=73645)[0m f1_weighted: 0.3537471565002729
[2m[36m(func pid=73645)[0m f1_per_class: [0.233, 0.441, 0.386, 0.526, 0.076, 0.315, 0.182, 0.465, 0.092, 0.283]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 1.6846 | Steps: 2 | Val loss: 3.0534 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=85373)[0m top1: 0.011194029850746268
[2m[36m(func pid=85373)[0m top5: 0.5228544776119403
[2m[36m(func pid=85373)[0m f1_micro: 0.01119402985074627
[2m[36m(func pid=85373)[0m f1_macro: 0.0063797847233677905
[2m[36m(func pid=85373)[0m f1_weighted: 0.0036320342612662913
[2m[36m(func pid=85373)[0m f1_per_class: [0.0, 0.0, 0.015, 0.0, 0.0, 0.0, 0.003, 0.045, 0.0, 0.0]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 1.1780 | Steps: 2 | Val loss: 31.4048 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
[2m[36m(func pid=79460)[0m top1: 0.36986940298507465== Status ==
Current time: 2024-01-07 02:44:37 (running for 00:20:38.66)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  1.105 |      0.3   |                   69 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  1.685 |      0.296 |                   44 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  1.012 |      0.084 |                   24 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  1.982 |      0.006 |                   18 |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)



[2m[36m(func pid=79460)[0m top5: 0.8530783582089553
[2m[36m(func pid=79460)[0m f1_micro: 0.36986940298507465
[2m[36m(func pid=79460)[0m f1_macro: 0.29587475467405383
[2m[36m(func pid=79460)[0m f1_weighted: 0.4020171883442004
[2m[36m(func pid=79460)[0m f1_per_class: [0.151, 0.545, 0.144, 0.382, 0.063, 0.329, 0.405, 0.544, 0.131, 0.264]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 1.1363 | Steps: 2 | Val loss: 1.8186 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=83696)[0m top1: 0.2042910447761194
[2m[36m(func pid=83696)[0m top5: 0.5993470149253731
[2m[36m(func pid=83696)[0m f1_micro: 0.20429104477611942
[2m[36m(func pid=83696)[0m f1_macro: 0.07002837892244701
[2m[36m(func pid=83696)[0m f1_weighted: 0.13265887487241435
[2m[36m(func pid=83696)[0m f1_per_class: [0.0, 0.36, 0.0, 0.007, 0.0, 0.032, 0.201, 0.074, 0.026, 0.0]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=73645)[0m top1: 0.3628731343283582
[2m[36m(func pid=73645)[0m top5: 0.8810634328358209
[2m[36m(func pid=73645)[0m f1_micro: 0.3628731343283582
[2m[36m(func pid=73645)[0m f1_macro: 0.3010272576808313
[2m[36m(func pid=73645)[0m f1_weighted: 0.3623408911733467
[2m[36m(func pid=73645)[0m f1_per_class: [0.221, 0.436, 0.379, 0.53, 0.066, 0.298, 0.212, 0.485, 0.11, 0.272]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 1.9516 | Steps: 2 | Val loss: 942.0772 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.4796 | Steps: 2 | Val loss: 3.1114 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=85373)[0m top1: 0.006996268656716418
[2m[36m(func pid=85373)[0m top5: 0.5527052238805971
[2m[36m(func pid=85373)[0m f1_micro: 0.006996268656716418
[2m[36m(func pid=85373)[0m f1_macro: 0.002277499839921851
[2m[36m(func pid=85373)[0m f1_weighted: 0.0013127072417956306
[2m[36m(func pid=85373)[0m f1_per_class: [0.0, 0.0, 0.014, 0.0, 0.0, 0.0, 0.003, 0.005, 0.0, 0.0]
[2m[36m(func pid=85373)[0m 
== Status ==
Current time: 2024-01-07 02:44:43 (running for 00:20:43.83)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  1.136 |      0.301 |                   70 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.48  |      0.295 |                   45 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  1.178 |      0.07  |                   25 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  1.952 |      0.002 |                   19 |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=79460)[0m top1: 0.37220149253731344
[2m[36m(func pid=79460)[0m top5: 0.8530783582089553
[2m[36m(func pid=79460)[0m f1_micro: 0.3722014925373134
[2m[36m(func pid=79460)[0m f1_macro: 0.29465846916797117
[2m[36m(func pid=79460)[0m f1_weighted: 0.4006497899684232
[2m[36m(func pid=79460)[0m f1_per_class: [0.156, 0.541, 0.158, 0.39, 0.057, 0.284, 0.413, 0.536, 0.122, 0.288]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 1.4031 | Steps: 2 | Val loss: 37.1364 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 1.0287 | Steps: 2 | Val loss: 1.8367 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=73645)[0m top1: 0.36427238805970147
[2m[36m(func pid=73645)[0m top5: 0.8819962686567164
[2m[36m(func pid=73645)[0m f1_micro: 0.3642723880597015
[2m[36m(func pid=73645)[0m f1_macro: 0.30396960383821814
[2m[36m(func pid=73645)[0m f1_weighted: 0.3700126055563822
[2m[36m(func pid=73645)[0m f1_per_class: [0.213, 0.431, 0.379, 0.525, 0.066, 0.298, 0.24, 0.519, 0.106, 0.263]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=83696)[0m top1: 0.134794776119403
[2m[36m(func pid=83696)[0m top5: 0.5638992537313433
[2m[36m(func pid=83696)[0m f1_micro: 0.134794776119403
[2m[36m(func pid=83696)[0m f1_macro: 0.044317249361617586
[2m[36m(func pid=83696)[0m f1_weighted: 0.07577037263686534
[2m[36m(func pid=83696)[0m f1_per_class: [0.0, 0.3, 0.0, 0.0, 0.0, 0.008, 0.076, 0.0, 0.0, 0.06]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 2.1017 | Steps: 2 | Val loss: 824.6396 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.6056 | Steps: 2 | Val loss: 2.8834 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=85373)[0m top1: 0.007462686567164179
[2m[36m(func pid=85373)[0m top5: 0.5666977611940298
[2m[36m(func pid=85373)[0m f1_micro: 0.007462686567164179
[2m[36m(func pid=85373)[0m f1_macro: 0.002567091943073665
[2m[36m(func pid=85373)[0m f1_weighted: 0.0021920704933888514
[2m[36m(func pid=85373)[0m f1_per_class: [0.0, 0.0, 0.015, 0.0, 0.0, 0.0, 0.006, 0.005, 0.0, 0.0]
[2m[36m(func pid=85373)[0m 
== Status ==
Current time: 2024-01-07 02:44:48 (running for 00:20:49.03)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  1.029 |      0.304 |                   71 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.48  |      0.295 |                   45 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  1.403 |      0.044 |                   26 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  2.102 |      0.003 |                   20 |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=79460)[0m top1: 0.3978544776119403
[2m[36m(func pid=79460)[0m top5: 0.867070895522388
[2m[36m(func pid=79460)[0m f1_micro: 0.3978544776119403
[2m[36m(func pid=79460)[0m f1_macro: 0.29792932283470963
[2m[36m(func pid=79460)[0m f1_weighted: 0.41579178013025847
[2m[36m(func pid=79460)[0m f1_per_class: [0.137, 0.534, 0.173, 0.373, 0.065, 0.206, 0.518, 0.5, 0.152, 0.322]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 1.0926 | Steps: 2 | Val loss: 1.8424 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 1.2998 | Steps: 2 | Val loss: 61.1376 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=73645)[0m top1: 0.35867537313432835
[2m[36m(func pid=73645)[0m top5: 0.8810634328358209
[2m[36m(func pid=73645)[0m f1_micro: 0.35867537313432835
[2m[36m(func pid=73645)[0m f1_macro: 0.2974594809958068
[2m[36m(func pid=73645)[0m f1_weighted: 0.36448179502864925
[2m[36m(func pid=73645)[0m f1_per_class: [0.217, 0.42, 0.364, 0.527, 0.066, 0.296, 0.231, 0.506, 0.1, 0.248]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=83696)[0m top1: 0.06949626865671642
[2m[36m(func pid=83696)[0m top5: 0.48274253731343286
[2m[36m(func pid=83696)[0m f1_micro: 0.06949626865671642
[2m[36m(func pid=83696)[0m f1_macro: 0.03532496350218679
[2m[36m(func pid=83696)[0m f1_weighted: 0.035940612061048066
[2m[36m(func pid=83696)[0m f1_per_class: [0.0, 0.194, 0.023, 0.0, 0.0, 0.0, 0.003, 0.0, 0.0, 0.133]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.6275 | Steps: 2 | Val loss: 3.1496 | Batch size: 32 | lr: 0.001 | Duration: 2.78s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 2.1279 | Steps: 2 | Val loss: 621.7230 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 02:44:53 (running for 00:20:54.48)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  1.093 |      0.297 |                   72 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.628 |      0.262 |                   47 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  1.3   |      0.035 |                   27 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  2.102 |      0.003 |                   20 |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=79460)[0m top1: 0.35494402985074625
[2m[36m(func pid=79460)[0m top5: 0.8582089552238806
[2m[36m(func pid=79460)[0m f1_micro: 0.35494402985074625
[2m[36m(func pid=79460)[0m f1_macro: 0.26245389255417423
[2m[36m(func pid=79460)[0m f1_weighted: 0.36857261569548916
[2m[36m(func pid=79460)[0m f1_per_class: [0.073, 0.532, 0.191, 0.351, 0.095, 0.149, 0.434, 0.354, 0.169, 0.275]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=85373)[0m top1: 0.01166044776119403
[2m[36m(func pid=85373)[0m top5: 0.574160447761194
[2m[36m(func pid=85373)[0m f1_micro: 0.01166044776119403
[2m[36m(func pid=85373)[0m f1_macro: 0.008464307718047242
[2m[36m(func pid=85373)[0m f1_weighted: 0.008011898580820423
[2m[36m(func pid=85373)[0m f1_per_class: [0.0, 0.005, 0.015, 0.0, 0.0, 0.0, 0.018, 0.005, 0.041, 0.0]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.9933 | Steps: 2 | Val loss: 1.8476 | Batch size: 32 | lr: 0.0001 | Duration: 3.03s
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 1.2835 | Steps: 2 | Val loss: 63.9040 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=73645)[0m top1: 0.365205223880597
[2m[36m(func pid=73645)[0m top5: 0.8819962686567164
[2m[36m(func pid=73645)[0m f1_micro: 0.365205223880597
[2m[36m(func pid=73645)[0m f1_macro: 0.3067923493647036
[2m[36m(func pid=73645)[0m f1_weighted: 0.37725251532259246
[2m[36m(func pid=73645)[0m f1_per_class: [0.211, 0.417, 0.364, 0.527, 0.061, 0.302, 0.263, 0.53, 0.148, 0.245]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.4908 | Steps: 2 | Val loss: 3.2707 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=83696)[0m top1: 0.11147388059701492
[2m[36m(func pid=83696)[0m top5: 0.5764925373134329
[2m[36m(func pid=83696)[0m f1_micro: 0.11147388059701491
[2m[36m(func pid=83696)[0m f1_macro: 0.06965706218744408
[2m[36m(func pid=83696)[0m f1_weighted: 0.11081428955359679
[2m[36m(func pid=83696)[0m f1_per_class: [0.0, 0.202, 0.025, 0.0, 0.0, 0.062, 0.217, 0.045, 0.0, 0.146]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 1.9008 | Steps: 2 | Val loss: 477.2573 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 02:44:58 (running for 00:20:59.77)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  0.993 |      0.307 |                   73 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.491 |      0.262 |                   48 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  1.283 |      0.07  |                   28 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  2.128 |      0.008 |                   21 |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=79460)[0m top1: 0.34281716417910446
[2m[36m(func pid=79460)[0m top5: 0.8465485074626866
[2m[36m(func pid=79460)[0m f1_micro: 0.34281716417910446
[2m[36m(func pid=79460)[0m f1_macro: 0.2619795847848624
[2m[36m(func pid=79460)[0m f1_weighted: 0.35301791285819795
[2m[36m(func pid=79460)[0m f1_per_class: [0.067, 0.533, 0.196, 0.333, 0.103, 0.148, 0.402, 0.322, 0.169, 0.346]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=85373)[0m top1: 0.010727611940298507
[2m[36m(func pid=85373)[0m top5: 0.5942164179104478
[2m[36m(func pid=85373)[0m f1_micro: 0.010727611940298507
[2m[36m(func pid=85373)[0m f1_macro: 0.006231787826231778
[2m[36m(func pid=85373)[0m f1_weighted: 0.006453304540384746
[2m[36m(func pid=85373)[0m f1_per_class: [0.0, 0.0, 0.016, 0.0, 0.0, 0.0, 0.018, 0.005, 0.024, 0.0]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 1.3993 | Steps: 2 | Val loss: 51.0007 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 1.0045 | Steps: 2 | Val loss: 1.8376 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=73645)[0m top1: 0.36847014925373134
[2m[36m(func pid=73645)[0m top5: 0.8847947761194029
[2m[36m(func pid=73645)[0m f1_micro: 0.3684701492537314
[2m[36m(func pid=73645)[0m f1_macro: 0.30937497193568864
[2m[36m(func pid=73645)[0m f1_weighted: 0.38367583359772717
[2m[36m(func pid=73645)[0m f1_per_class: [0.204, 0.423, 0.364, 0.523, 0.063, 0.315, 0.282, 0.525, 0.144, 0.25]
[2m[36m(func pid=73645)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.4275 | Steps: 2 | Val loss: 3.1472 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=83696)[0m top1: 0.08208955223880597
[2m[36m(func pid=83696)[0m top5: 0.5471082089552238
[2m[36m(func pid=83696)[0m f1_micro: 0.08208955223880597
[2m[36m(func pid=83696)[0m f1_macro: 0.04354117622377442
[2m[36m(func pid=83696)[0m f1_weighted: 0.05765874144250321
[2m[36m(func pid=83696)[0m f1_per_class: [0.0, 0.177, 0.03, 0.003, 0.0, 0.008, 0.079, 0.0, 0.0, 0.138]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 2.1598 | Steps: 2 | Val loss: 336.7460 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 02:45:04 (running for 00:21:05.03)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00008 | RUNNING    | 192.168.7.53:73645 | 0.0001 |       0.99 |         0.0001 |  1.005 |      0.309 |                   74 |
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.427 |      0.273 |                   49 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  1.399 |      0.044 |                   29 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  1.901 |      0.006 |                   22 |
| train_6ed81_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=79460)[0m top1: 0.353544776119403
[2m[36m(func pid=79460)[0m top5: 0.8591417910447762
[2m[36m(func pid=79460)[0m f1_micro: 0.353544776119403
[2m[36m(func pid=79460)[0m f1_macro: 0.27272692703855905
[2m[36m(func pid=79460)[0m f1_weighted: 0.36110908055895846
[2m[36m(func pid=79460)[0m f1_per_class: [0.09, 0.544, 0.159, 0.347, 0.109, 0.185, 0.376, 0.415, 0.181, 0.321]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=85373)[0m top1: 0.015391791044776119
[2m[36m(func pid=85373)[0m top5: 0.6086753731343284
[2m[36m(func pid=85373)[0m f1_micro: 0.015391791044776119
[2m[36m(func pid=85373)[0m f1_macro: 0.011758559131177179
[2m[36m(func pid=85373)[0m f1_weighted: 0.013351049715917506
[2m[36m(func pid=85373)[0m f1_per_class: [0.0, 0.011, 0.016, 0.0, 0.0, 0.0, 0.031, 0.004, 0.055, 0.0]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=73645)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.9109 | Steps: 2 | Val loss: 1.8302 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 1.0498 | Steps: 2 | Val loss: 39.3171 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.3999 | Steps: 2 | Val loss: 3.3108 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=83696)[0m top1: 0.08069029850746269
[2m[36m(func pid=83696)[0m top5: 0.5004664179104478
[2m[36m(func pid=83696)[0m f1_micro: 0.08069029850746269
[2m[36m(func pid=83696)[0m f1_macro: 0.04367169981770726
[2m[36m(func pid=83696)[0m f1_weighted: 0.04152227767802335
[2m[36m(func pid=83696)[0m f1_per_class: [0.022, 0.191, 0.036, 0.006, 0.0, 0.0, 0.012, 0.0, 0.027, 0.141]
[2m[36m(func pid=73645)[0m top1: 0.375
[2m[36m(func pid=73645)[0m top5: 0.8885261194029851
[2m[36m(func pid=73645)[0m f1_micro: 0.375
[2m[36m(func pid=73645)[0m f1_macro: 0.31616343563258303
[2m[36m(func pid=73645)[0m f1_weighted: 0.39634811739530257
[2m[36m(func pid=73645)[0m f1_per_class: [0.203, 0.432, 0.364, 0.52, 0.064, 0.315, 0.32, 0.536, 0.146, 0.263]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 16.2920 | Steps: 2 | Val loss: 184.1328 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
[2m[36m(func pid=79460)[0m top1: 0.33955223880597013
[2m[36m(func pid=79460)[0m top5: 0.8544776119402985
[2m[36m(func pid=79460)[0m f1_micro: 0.33955223880597013
[2m[36m(func pid=79460)[0m f1_macro: 0.2677118812395286
[2m[36m(func pid=79460)[0m f1_weighted: 0.3554438122534371
[2m[36m(func pid=79460)[0m f1_per_class: [0.077, 0.561, 0.113, 0.346, 0.116, 0.202, 0.343, 0.409, 0.206, 0.304]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=85373)[0m top1: 0.021921641791044777
[2m[36m(func pid=85373)[0m top5: 0.6301305970149254
[2m[36m(func pid=85373)[0m f1_micro: 0.021921641791044777
[2m[36m(func pid=85373)[0m f1_macro: 0.01318877704043051
[2m[36m(func pid=85373)[0m f1_weighted: 0.013022761804760996
[2m[36m(func pid=85373)[0m f1_per_class: [0.0, 0.016, 0.023, 0.003, 0.0, 0.0, 0.023, 0.004, 0.062, 0.0]
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.7959 | Steps: 2 | Val loss: 28.0946 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.3699 | Steps: 2 | Val loss: 3.5815 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=83696)[0m top1: 0.07649253731343283
[2m[36m(func pid=83696)[0m top5: 0.5247201492537313
[2m[36m(func pid=83696)[0m f1_micro: 0.07649253731343283
[2m[36m(func pid=83696)[0m f1_macro: 0.05300724789085291
[2m[36m(func pid=83696)[0m f1_weighted: 0.0402808636809289
[2m[36m(func pid=83696)[0m f1_per_class: [0.013, 0.199, 0.051, 0.0, 0.0, 0.0, 0.006, 0.0, 0.024, 0.237]
[2m[36m(func pid=79460)[0m top1: 0.31949626865671643
[2m[36m(func pid=79460)[0m top5: 0.8493470149253731
[2m[36m(func pid=79460)[0m f1_micro: 0.31949626865671643
[2m[36m(func pid=79460)[0m f1_macro: 0.25702372640973553
[2m[36m(func pid=79460)[0m f1_weighted: 0.35335745320237916
[2m[36m(func pid=79460)[0m f1_per_class: [0.06, 0.539, 0.096, 0.306, 0.1, 0.257, 0.369, 0.422, 0.185, 0.235]
== Status ==
Current time: 2024-01-07 02:45:09 (running for 00:21:10.38)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.4   |      0.268 |                   50 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  1.05  |      0.044 |                   30 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  2.16  |      0.012 |                   23 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054 | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


== Status ==
Current time: 2024-01-07 02:45:15 (running for 00:21:16.07)
Memory usage on this node: 23.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.37  |      0.257 |                   51 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  1.05  |      0.044 |                   30 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  2.16  |      0.012 |                   23 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054 | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=91054)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=91054)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=91054)[0m Configuration completed!
[2m[36m(func pid=91054)[0m New optimizer parameters:
[2m[36m(func pid=91054)[0m SGD (
[2m[36m(func pid=91054)[0m Parameter Group 0
[2m[36m(func pid=91054)[0m     dampening: 0
[2m[36m(func pid=91054)[0m     differentiable: False
[2m[36m(func pid=91054)[0m     foreach: None
[2m[36m(func pid=91054)[0m     lr: 0.0001
[2m[36m(func pid=91054)[0m     maximize: False
[2m[36m(func pid=91054)[0m     momentum: 0.9
[2m[36m(func pid=91054)[0m     nesterov: False
[2m[36m(func pid=91054)[0m     weight_decay: 0.0001
[2m[36m(func pid=91054)[0m )
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.5254 | Steps: 2 | Val loss: 3.4300 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.8083 | Steps: 2 | Val loss: 19.5843 | Batch size: 32 | lr: 0.01 | Duration: 3.06s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 3.0912 | Steps: 2 | Val loss: 77.1807 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 3.1198 | Steps: 2 | Val loss: 2.3724 | Batch size: 32 | lr: 0.0001 | Duration: 4.68s
== Status ==
Current time: 2024-01-07 02:45:20 (running for 00:21:21.10)
Memory usage on this node: 25.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.37  |      0.257 |                   51 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  0.796 |      0.053 |                   31 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 | 16.292 |      0.013 |                   24 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054 | 0.0001 |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=79460)[0m top1: 0.3568097014925373
[2m[36m(func pid=79460)[0m top5: 0.8502798507462687
[2m[36m(func pid=79460)[0m f1_micro: 0.3568097014925374
[2m[36m(func pid=79460)[0m f1_macro: 0.26869173650837996
[2m[36m(func pid=79460)[0m f1_weighted: 0.3933170752457702
[2m[36m(func pid=79460)[0m f1_per_class: [0.059, 0.541, 0.108, 0.361, 0.094, 0.166, 0.482, 0.456, 0.152, 0.268]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=83696)[0m top1: 0.08628731343283583
[2m[36m(func pid=83696)[0m top5: 0.558768656716418
[2m[36m(func pid=83696)[0m f1_micro: 0.08628731343283583
[2m[36m(func pid=83696)[0m f1_macro: 0.05712785784437406
[2m[36m(func pid=83696)[0m f1_weighted: 0.04885409124709746
[2m[36m(func pid=83696)[0m f1_per_class: [0.016, 0.246, 0.076, 0.0, 0.0, 0.0, 0.009, 0.0, 0.02, 0.204]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=85373)[0m top1: 0.033582089552238806
[2m[36m(func pid=85373)[0m top5: 0.5419776119402985
[2m[36m(func pid=85373)[0m f1_micro: 0.033582089552238806
[2m[36m(func pid=85373)[0m f1_macro: 0.015426946676523357
[2m[36m(func pid=85373)[0m f1_weighted: 0.014182719312161257
[2m[36m(func pid=85373)[0m f1_per_class: [0.023, 0.021, 0.0, 0.01, 0.0, 0.0, 0.014, 0.006, 0.08, 0.0]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=91054)[0m top1: 0.06576492537313433
[2m[36m(func pid=91054)[0m top5: 0.3824626865671642
[2m[36m(func pid=91054)[0m f1_micro: 0.06576492537313433
[2m[36m(func pid=91054)[0m f1_macro: 0.016350132077787037
[2m[36m(func pid=91054)[0m f1_weighted: 0.01975320713863015
[2m[36m(func pid=91054)[0m f1_per_class: [0.0, 0.0, 0.0, 0.047, 0.0, 0.0, 0.0, 0.117, 0.0, 0.0]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 6.3855 | Steps: 2 | Val loss: 90.2237 | Batch size: 32 | lr: 0.1 | Duration: 2.76s
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.5606 | Steps: 2 | Val loss: 3.6967 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.9464 | Steps: 2 | Val loss: 13.9439 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 3.0806 | Steps: 2 | Val loss: 2.3277 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
== Status ==
Current time: 2024-01-07 02:45:25 (running for 00:21:26.76)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.525 |      0.269 |                   52 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  0.946 |      0.068 |                   33 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  3.091 |      0.015 |                   25 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054 | 0.0001 |       0.9  |         0.0001 |  3.12  |      0.016 |                    1 |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=83696)[0m top1: 0.09841417910447761
[2m[36m(func pid=83696)[0m top5: 0.590018656716418
[2m[36m(func pid=83696)[0m f1_micro: 0.0984141791044776
[2m[36m(func pid=83696)[0m f1_macro: 0.068204668713534
[2m[36m(func pid=83696)[0m f1_weighted: 0.060386184147787944
[2m[36m(func pid=83696)[0m f1_per_class: [0.024, 0.293, 0.148, 0.01, 0.0, 0.0, 0.012, 0.0, 0.0, 0.195]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=79460)[0m top1: 0.30177238805970147
[2m[36m(func pid=79460)[0m top5: 0.8386194029850746
[2m[36m(func pid=79460)[0m f1_micro: 0.30177238805970147
[2m[36m(func pid=79460)[0m f1_macro: 0.21903618158741534
[2m[36m(func pid=79460)[0m f1_weighted: 0.34183625541831986
[2m[36m(func pid=79460)[0m f1_per_class: [0.053, 0.511, 0.121, 0.318, 0.07, 0.069, 0.44, 0.309, 0.105, 0.193]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=85373)[0m top1: 0.02845149253731343
[2m[36m(func pid=85373)[0m top5: 0.5680970149253731
[2m[36m(func pid=85373)[0m f1_micro: 0.02845149253731343
[2m[36m(func pid=85373)[0m f1_macro: 0.012951479602146954
[2m[36m(func pid=85373)[0m f1_weighted: 0.01899532993358319
[2m[36m(func pid=85373)[0m f1_per_class: [0.051, 0.035, 0.0, 0.01, 0.0, 0.0, 0.03, 0.004, 0.0, 0.0]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=91054)[0m top1: 0.13992537313432835
[2m[36m(func pid=91054)[0m top5: 0.5167910447761194
[2m[36m(func pid=91054)[0m f1_micro: 0.13992537313432835
[2m[36m(func pid=91054)[0m f1_macro: 0.04170314111411679
[2m[36m(func pid=91054)[0m f1_weighted: 0.07877212564730246
[2m[36m(func pid=91054)[0m f1_per_class: [0.0, 0.0, 0.0, 0.247, 0.0, 0.0, 0.0, 0.17, 0.0, 0.0]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.6161 | Steps: 2 | Val loss: 3.9489 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 1.0998 | Steps: 2 | Val loss: 12.3316 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 2.3834 | Steps: 2 | Val loss: 206.4014 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 3.0607 | Steps: 2 | Val loss: 2.3162 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=83696)[0m top1: 0.10261194029850747
[2m[36m(func pid=83696)[0m top5: 0.5676305970149254
[2m[36m(func pid=83696)[0m f1_micro: 0.10261194029850747
[2m[36m(func pid=83696)[0m f1_macro: 0.07871880531340207
[2m[36m(func pid=83696)[0m f1_weighted: 0.0715397331528942
[2m[36m(func pid=83696)[0m f1_per_class: [0.025, 0.327, 0.231, 0.041, 0.0, 0.0, 0.0, 0.0, 0.0, 0.163]
== Status ==
Current time: 2024-01-07 02:45:31 (running for 00:21:32.12)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.561 |      0.219 |                   53 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  1.1   |      0.079 |                   34 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  6.385 |      0.013 |                   26 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054 | 0.0001 |       0.9  |         0.0001 |  3.081 |      0.042 |                    2 |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=79460)[0m top1: 0.279384328358209
[2m[36m(func pid=79460)[0m top5: 0.8348880597014925
[2m[36m(func pid=79460)[0m f1_micro: 0.279384328358209
[2m[36m(func pid=79460)[0m f1_macro: 0.20467018083606286
[2m[36m(func pid=79460)[0m f1_weighted: 0.3168032348946864
[2m[36m(func pid=79460)[0m f1_per_class: [0.052, 0.494, 0.133, 0.267, 0.077, 0.07, 0.423, 0.294, 0.044, 0.191]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=85373)[0m top1: 0.037779850746268655
[2m[36m(func pid=85373)[0m top5: 0.6380597014925373
[2m[36m(func pid=85373)[0m f1_micro: 0.037779850746268655
[2m[36m(func pid=85373)[0m f1_macro: 0.024542631084489414
[2m[36m(func pid=85373)[0m f1_weighted: 0.05137600012711896
[2m[36m(func pid=85373)[0m f1_per_class: [0.0, 0.103, 0.017, 0.016, 0.0, 0.012, 0.091, 0.005, 0.0, 0.0]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=91054)[0m top1: 0.1828358208955224
[2m[36m(func pid=91054)[0m top5: 0.5611007462686567
[2m[36m(func pid=91054)[0m f1_micro: 0.1828358208955224
[2m[36m(func pid=91054)[0m f1_macro: 0.04823923370054202
[2m[36m(func pid=91054)[0m f1_weighted: 0.09784882770781086
[2m[36m(func pid=91054)[0m f1_per_class: [0.0, 0.0, 0.0, 0.316, 0.0, 0.0, 0.0, 0.166, 0.0, 0.0]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.5482 | Steps: 2 | Val loss: 3.8181 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.6458 | Steps: 2 | Val loss: 9.8311 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 2.0998 | Steps: 2 | Val loss: 377.9148 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 3.0168 | Steps: 2 | Val loss: 2.3157 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
== Status ==
Current time: 2024-01-07 02:45:36 (running for 00:21:37.45)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.616 |      0.205 |                   54 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  0.646 |      0.102 |                   35 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  2.383 |      0.025 |                   27 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054 | 0.0001 |       0.9  |         0.0001 |  3.061 |      0.048 |                    3 |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=79460)[0m top1: 0.30130597014925375
[2m[36m(func pid=79460)[0m top5: 0.8498134328358209
[2m[36m(func pid=79460)[0m f1_micro: 0.30130597014925375
[2m[36m(func pid=79460)[0m f1_macro: 0.2239501403648397
[2m[36m(func pid=79460)[0m f1_weighted: 0.32317184762695766
[2m[36m(func pid=79460)[0m f1_per_class: [0.082, 0.474, 0.16, 0.207, 0.089, 0.09, 0.478, 0.407, 0.064, 0.19]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=83696)[0m top1: 0.1394589552238806
[2m[36m(func pid=83696)[0m top5: 0.6487873134328358
[2m[36m(func pid=83696)[0m f1_micro: 0.1394589552238806
[2m[36m(func pid=83696)[0m f1_macro: 0.10228492005825433
[2m[36m(func pid=83696)[0m f1_weighted: 0.12451040223969871
[2m[36m(func pid=83696)[0m f1_per_class: [0.025, 0.36, 0.253, 0.163, 0.0, 0.008, 0.041, 0.0, 0.0, 0.173]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=85373)[0m top1: 0.034981343283582086
[2m[36m(func pid=85373)[0m top5: 0.6571828358208955
[2m[36m(func pid=85373)[0m f1_micro: 0.034981343283582086
[2m[36m(func pid=85373)[0m f1_macro: 0.025700828673314597
[2m[36m(func pid=85373)[0m f1_weighted: 0.046791216907463434
[2m[36m(func pid=85373)[0m f1_per_class: [0.0, 0.121, 0.016, 0.003, 0.0, 0.017, 0.074, 0.007, 0.019, 0.0]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=91054)[0m top1: 0.19169776119402984
[2m[36m(func pid=91054)[0m top5: 0.5718283582089553
[2m[36m(func pid=91054)[0m f1_micro: 0.19169776119402984
[2m[36m(func pid=91054)[0m f1_macro: 0.041757281279663175
[2m[36m(func pid=91054)[0m f1_weighted: 0.09991693611769728
[2m[36m(func pid=91054)[0m f1_per_class: [0.0, 0.0, 0.0, 0.343, 0.0, 0.0, 0.0, 0.075, 0.0, 0.0]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.2820 | Steps: 2 | Val loss: 3.8742 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.7613 | Steps: 2 | Val loss: 7.1939 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 1.7745 | Steps: 2 | Val loss: 504.5948 | Batch size: 32 | lr: 0.1 | Duration: 2.98s
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 2.9575 | Steps: 2 | Val loss: 2.3193 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
== Status ==
Current time: 2024-01-07 02:45:41 (running for 00:21:42.61)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.282 |      0.249 |                   56 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  0.646 |      0.102 |                   35 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  2.1   |      0.026 |                   28 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054 | 0.0001 |       0.9  |         0.0001 |  3.017 |      0.042 |                    4 |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=79460)[0m top1: 0.31343283582089554
[2m[36m(func pid=79460)[0m top5: 0.851679104477612
[2m[36m(func pid=79460)[0m f1_micro: 0.31343283582089554
[2m[36m(func pid=79460)[0m f1_macro: 0.24938527663975757
[2m[36m(func pid=79460)[0m f1_weighted: 0.33223808987149184
[2m[36m(func pid=79460)[0m f1_per_class: [0.103, 0.455, 0.187, 0.196, 0.106, 0.163, 0.482, 0.447, 0.135, 0.219]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=83696)[0m top1: 0.23087686567164178
[2m[36m(func pid=83696)[0m top5: 0.7597947761194029
[2m[36m(func pid=83696)[0m f1_micro: 0.23087686567164178
[2m[36m(func pid=83696)[0m f1_macro: 0.18062197391119883
[2m[36m(func pid=83696)[0m f1_weighted: 0.23050606951858552
[2m[36m(func pid=83696)[0m f1_per_class: [0.038, 0.386, 0.476, 0.247, 0.042, 0.0, 0.271, 0.139, 0.0, 0.208]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=85373)[0m top1: 0.020988805970149255
[2m[36m(func pid=85373)[0m top5: 0.6371268656716418
[2m[36m(func pid=85373)[0m f1_micro: 0.020988805970149255
[2m[36m(func pid=85373)[0m f1_macro: 0.01896413139089909
[2m[36m(func pid=85373)[0m f1_weighted: 0.023830323840171207
[2m[36m(func pid=85373)[0m f1_per_class: [0.024, 0.031, 0.016, 0.01, 0.0, 0.038, 0.031, 0.006, 0.033, 0.0]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=91054)[0m top1: 0.20102611940298507
[2m[36m(func pid=91054)[0m top5: 0.5736940298507462
[2m[36m(func pid=91054)[0m f1_micro: 0.2010261194029851
[2m[36m(func pid=91054)[0m f1_macro: 0.06291851181048612
[2m[36m(func pid=91054)[0m f1_weighted: 0.10296467790029866
[2m[36m(func pid=91054)[0m f1_per_class: [0.0, 0.0, 0.235, 0.356, 0.0, 0.0, 0.0, 0.038, 0.0, 0.0]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.3778 | Steps: 2 | Val loss: 3.8080 | Batch size: 32 | lr: 0.001 | Duration: 2.78s
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.5334 | Steps: 2 | Val loss: 6.2807 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 1.8134 | Steps: 2 | Val loss: 664.6346 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 2.8923 | Steps: 2 | Val loss: 2.3221 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 02:45:46 (running for 00:21:47.79)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.378 |      0.256 |                   57 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  0.761 |      0.181 |                   36 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  1.775 |      0.019 |                   29 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054 | 0.0001 |       0.9  |         0.0001 |  2.957 |      0.063 |                    5 |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=79460)[0m top1: 0.31529850746268656
[2m[36m(func pid=79460)[0m top5: 0.855410447761194
[2m[36m(func pid=79460)[0m f1_micro: 0.31529850746268656
[2m[36m(func pid=79460)[0m f1_macro: 0.256300057790083
[2m[36m(func pid=79460)[0m f1_weighted: 0.3305708302874192
[2m[36m(func pid=79460)[0m f1_per_class: [0.121, 0.478, 0.24, 0.215, 0.111, 0.186, 0.44, 0.423, 0.117, 0.231]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=83696)[0m top1: 0.28404850746268656
[2m[36m(func pid=83696)[0m top5: 0.8069029850746269
[2m[36m(func pid=83696)[0m f1_micro: 0.28404850746268656
[2m[36m(func pid=83696)[0m f1_macro: 0.16883582714879591
[2m[36m(func pid=83696)[0m f1_weighted: 0.26712950524990076
[2m[36m(func pid=83696)[0m f1_per_class: [0.045, 0.434, 0.0, 0.189, 0.043, 0.016, 0.408, 0.187, 0.0, 0.367]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=85373)[0m top1: 0.017723880597014924
[2m[36m(func pid=85373)[0m top5: 0.6273320895522388
[2m[36m(func pid=85373)[0m f1_micro: 0.017723880597014924
[2m[36m(func pid=85373)[0m f1_macro: 0.021631226289925923
[2m[36m(func pid=85373)[0m f1_weighted: 0.016908465162613604
[2m[36m(func pid=85373)[0m f1_per_class: [0.0, 0.0, 0.016, 0.007, 0.0, 0.057, 0.021, 0.005, 0.032, 0.078]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=91054)[0m top1: 0.20988805970149255
[2m[36m(func pid=91054)[0m top5: 0.5750932835820896
[2m[36m(func pid=91054)[0m f1_micro: 0.20988805970149255
[2m[36m(func pid=91054)[0m f1_macro: 0.07499941725347106
[2m[36m(func pid=91054)[0m f1_weighted: 0.10636744932517332
[2m[36m(func pid=91054)[0m f1_per_class: [0.0, 0.0, 0.348, 0.366, 0.0, 0.0, 0.0, 0.036, 0.0, 0.0]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.2423 | Steps: 2 | Val loss: 3.5968 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.7264 | Steps: 2 | Val loss: 6.1429 | Batch size: 32 | lr: 0.01 | Duration: 3.05s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 3.6628 | Steps: 2 | Val loss: 715.8992 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 2.8720 | Steps: 2 | Val loss: 2.3252 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
== Status ==
Current time: 2024-01-07 02:45:52 (running for 00:21:53.10)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.242 |      0.275 |                   58 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  0.533 |      0.169 |                   37 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  1.813 |      0.022 |                   30 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054 | 0.0001 |       0.9  |         0.0001 |  2.892 |      0.075 |                    6 |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=79460)[0m top1: 0.3344216417910448
[2m[36m(func pid=79460)[0m top5: 0.8591417910447762
[2m[36m(func pid=79460)[0m f1_micro: 0.3344216417910448
[2m[36m(func pid=79460)[0m f1_macro: 0.2745903746375109
[2m[36m(func pid=79460)[0m f1_weighted: 0.346701373720033
[2m[36m(func pid=79460)[0m f1_per_class: [0.139, 0.497, 0.268, 0.263, 0.112, 0.215, 0.421, 0.419, 0.151, 0.259]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=83696)[0m top1: 0.333955223880597
[2m[36m(func pid=83696)[0m top5: 0.8498134328358209
[2m[36m(func pid=83696)[0m f1_micro: 0.333955223880597
[2m[36m(func pid=83696)[0m f1_macro: 0.17297089253052494
[2m[36m(func pid=83696)[0m f1_weighted: 0.2787398300185124
[2m[36m(func pid=83696)[0m f1_per_class: [0.068, 0.44, 0.0, 0.118, 0.03, 0.016, 0.519, 0.113, 0.026, 0.4]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=85373)[0m top1: 0.01585820895522388
[2m[36m(func pid=85373)[0m top5: 0.6263992537313433
[2m[36m(func pid=85373)[0m f1_micro: 0.01585820895522388
[2m[36m(func pid=85373)[0m f1_macro: 0.03196888402854951
[2m[36m(func pid=85373)[0m f1_weighted: 0.014446410009196638
[2m[36m(func pid=85373)[0m f1_per_class: [0.0, 0.0, 0.017, 0.016, 0.171, 0.027, 0.012, 0.005, 0.032, 0.039]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=91054)[0m top1: 0.21548507462686567
[2m[36m(func pid=91054)[0m top5: 0.5699626865671642
[2m[36m(func pid=91054)[0m f1_micro: 0.21548507462686567
[2m[36m(func pid=91054)[0m f1_macro: 0.06897492512580984
[2m[36m(func pid=91054)[0m f1_weighted: 0.1076730607149937
[2m[36m(func pid=91054)[0m f1_per_class: [0.0, 0.0, 0.279, 0.372, 0.0, 0.0, 0.0, 0.039, 0.0, 0.0]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.5204 | Steps: 2 | Val loss: 3.5742 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 1.7607 | Steps: 2 | Val loss: 655.3280 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 1.7066 | Steps: 2 | Val loss: 5.9537 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 2.8103 | Steps: 2 | Val loss: 2.3266 | Batch size: 32 | lr: 0.0001 | Duration: 3.01s
== Status ==
Current time: 2024-01-07 02:45:57 (running for 00:21:58.30)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.52  |      0.298 |                   59 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  0.726 |      0.173 |                   38 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  3.663 |      0.032 |                   31 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054 | 0.0001 |       0.9  |         0.0001 |  2.872 |      0.069 |                    7 |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=79460)[0m top1: 0.3521455223880597
[2m[36m(func pid=79460)[0m top5: 0.8582089552238806
[2m[36m(func pid=79460)[0m f1_micro: 0.3521455223880597
[2m[36m(func pid=79460)[0m f1_macro: 0.29845088291977634
[2m[36m(func pid=79460)[0m f1_weighted: 0.3564275064054286
[2m[36m(func pid=79460)[0m f1_per_class: [0.155, 0.501, 0.415, 0.301, 0.12, 0.191, 0.422, 0.413, 0.13, 0.337]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=85373)[0m top1: 0.024253731343283583
[2m[36m(func pid=85373)[0m top5: 0.6590485074626866
[2m[36m(func pid=85373)[0m f1_micro: 0.024253731343283583
[2m[36m(func pid=85373)[0m f1_macro: 0.038656029130472655
[2m[36m(func pid=85373)[0m f1_weighted: 0.024264423799196008
[2m[36m(func pid=85373)[0m f1_per_class: [0.0, 0.0, 0.017, 0.016, 0.152, 0.064, 0.029, 0.006, 0.053, 0.05]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=83696)[0m top1: 0.3451492537313433
[2m[36m(func pid=83696)[0m top5: 0.8722014925373134
[2m[36m(func pid=83696)[0m f1_micro: 0.3451492537313433
[2m[36m(func pid=83696)[0m f1_macro: 0.16768058812373784
[2m[36m(func pid=83696)[0m f1_weighted: 0.2891102488164377
[2m[36m(func pid=83696)[0m f1_per_class: [0.073, 0.44, 0.0, 0.122, 0.017, 0.024, 0.555, 0.092, 0.0, 0.353]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=91054)[0m top1: 0.22014925373134328
[2m[36m(func pid=91054)[0m top5: 0.5615671641791045
[2m[36m(func pid=91054)[0m f1_micro: 0.22014925373134328
[2m[36m(func pid=91054)[0m f1_macro: 0.058325743936864516
[2m[36m(func pid=91054)[0m f1_weighted: 0.1095635807469929
[2m[36m(func pid=91054)[0m f1_per_class: [0.0, 0.005, 0.162, 0.378, 0.0, 0.0, 0.0, 0.038, 0.0, 0.0]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.2808 | Steps: 2 | Val loss: 4.4959 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 35.9330 | Steps: 2 | Val loss: 535.4566 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.9519 | Steps: 2 | Val loss: 5.1375 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 2.7522 | Steps: 2 | Val loss: 2.3251 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 02:46:02 (running for 00:22:03.59)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.281 |      0.285 |                   60 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  1.707 |      0.168 |                   39 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  1.761 |      0.039 |                   32 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054 | 0.0001 |       0.9  |         0.0001 |  2.81  |      0.058 |                    8 |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=79460)[0m top1: 0.29151119402985076
[2m[36m(func pid=79460)[0m top5: 0.8260261194029851
[2m[36m(func pid=79460)[0m f1_micro: 0.29151119402985076
[2m[36m(func pid=79460)[0m f1_macro: 0.2846964189975849
[2m[36m(func pid=79460)[0m f1_weighted: 0.2985628475207736
[2m[36m(func pid=79460)[0m f1_per_class: [0.115, 0.461, 0.667, 0.26, 0.132, 0.167, 0.321, 0.302, 0.105, 0.318]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=83696)[0m top1: 0.32649253731343286
[2m[36m(func pid=83696)[0m top5: 0.8680037313432836
[2m[36m(func pid=83696)[0m f1_micro: 0.32649253731343286
[2m[36m(func pid=83696)[0m f1_macro: 0.16735539097644417
[2m[36m(func pid=83696)[0m f1_weighted: 0.2926292333785823
[2m[36m(func pid=83696)[0m f1_per_class: [0.074, 0.452, 0.0, 0.179, 0.065, 0.024, 0.521, 0.016, 0.0, 0.343]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=85373)[0m top1: 0.03544776119402985
[2m[36m(func pid=85373)[0m top5: 0.6842350746268657
[2m[36m(func pid=85373)[0m f1_micro: 0.03544776119402985
[2m[36m(func pid=85373)[0m f1_macro: 0.04458274931391056
[2m[36m(func pid=85373)[0m f1_weighted: 0.040120000676553226
[2m[36m(func pid=85373)[0m f1_per_class: [0.0, 0.0, 0.016, 0.019, 0.15, 0.082, 0.072, 0.007, 0.046, 0.053]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=91054)[0m top1: 0.22014925373134328
[2m[36m(func pid=91054)[0m top5: 0.5578358208955224
[2m[36m(func pid=91054)[0m f1_micro: 0.22014925373134328
[2m[36m(func pid=91054)[0m f1_macro: 0.05528746947641958
[2m[36m(func pid=91054)[0m f1_weighted: 0.11083861337527166
[2m[36m(func pid=91054)[0m f1_per_class: [0.0, 0.011, 0.111, 0.377, 0.0, 0.0, 0.0, 0.054, 0.0, 0.0]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.2042 | Steps: 2 | Val loss: 5.1940 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 5.8467 | Steps: 2 | Val loss: 284.6415 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.8538 | Steps: 2 | Val loss: 4.6978 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 2.7275 | Steps: 2 | Val loss: 2.3254 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 02:46:08 (running for 00:22:08.84)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.204 |      0.272 |                   61 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  0.952 |      0.167 |                   40 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 | 35.933 |      0.045 |                   33 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054 | 0.0001 |       0.9  |         0.0001 |  2.752 |      0.055 |                    9 |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=79460)[0m top1: 0.279384328358209
[2m[36m(func pid=79460)[0m top5: 0.800839552238806
[2m[36m(func pid=79460)[0m f1_micro: 0.279384328358209
[2m[36m(func pid=79460)[0m f1_macro: 0.27192382137369464
[2m[36m(func pid=79460)[0m f1_weighted: 0.29197732893866923
[2m[36m(func pid=79460)[0m f1_per_class: [0.102, 0.436, 0.571, 0.269, 0.146, 0.172, 0.307, 0.302, 0.094, 0.319]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=83696)[0m top1: 0.3269589552238806
[2m[36m(func pid=83696)[0m top5: 0.8694029850746269
[2m[36m(func pid=83696)[0m f1_micro: 0.3269589552238806
[2m[36m(func pid=83696)[0m f1_macro: 0.24258769738913832
[2m[36m(func pid=83696)[0m f1_weighted: 0.3183523832856941
[2m[36m(func pid=83696)[0m f1_per_class: [0.08, 0.487, 0.629, 0.25, 0.085, 0.07, 0.492, 0.0, 0.0, 0.333]
[2m[36m(func pid=85373)[0m top1: 0.05083955223880597
[2m[36m(func pid=85373)[0m top5: 0.7047574626865671
[2m[36m(func pid=85373)[0m f1_micro: 0.05083955223880597
[2m[36m(func pid=85373)[0m f1_macro: 0.059681993924416886
[2m[36m(func pid=85373)[0m f1_weighted: 0.0589323296591842
[2m[36m(func pid=85373)[0m f1_per_class: [0.0, 0.005, 0.018, 0.047, 0.177, 0.098, 0.098, 0.008, 0.047, 0.098]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=91054)[0m top1: 0.21315298507462688
[2m[36m(func pid=91054)[0m top5: 0.5559701492537313
[2m[36m(func pid=91054)[0m f1_micro: 0.2131529850746269
[2m[36m(func pid=91054)[0m f1_macro: 0.05589243796396447
[2m[36m(func pid=91054)[0m f1_weighted: 0.1094721381931349
[2m[36m(func pid=91054)[0m f1_per_class: [0.0, 0.005, 0.094, 0.368, 0.0, 0.0, 0.0, 0.092, 0.0, 0.0]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.2087 | Steps: 2 | Val loss: 5.8658 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 1.6398 | Steps: 2 | Val loss: 121.1043 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.6794 | Steps: 2 | Val loss: 4.5879 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 02:46:13 (running for 00:22:13.92)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.209 |      0.243 |                   62 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  0.854 |      0.243 |                   41 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  5.847 |      0.06  |                   34 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054 | 0.0001 |       0.9  |         0.0001 |  2.727 |      0.056 |                   10 |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=79460)[0m top1: 0.261660447761194
[2m[36m(func pid=79460)[0m top5: 0.7835820895522388
[2m[36m(func pid=79460)[0m f1_micro: 0.261660447761194
[2m[36m(func pid=79460)[0m f1_macro: 0.24344761455794703
[2m[36m(func pid=79460)[0m f1_weighted: 0.2807494036094249
[2m[36m(func pid=79460)[0m f1_per_class: [0.089, 0.424, 0.375, 0.284, 0.141, 0.164, 0.275, 0.279, 0.079, 0.323]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 2.7000 | Steps: 2 | Val loss: 2.3240 | Batch size: 32 | lr: 0.0001 | Duration: 3.05s
[2m[36m(func pid=85373)[0m top1: 0.07182835820895522
[2m[36m(func pid=85373)[0m top5: 0.6809701492537313
[2m[36m(func pid=85373)[0m f1_micro: 0.07182835820895522
[2m[36m(func pid=85373)[0m f1_macro: 0.07764036581080058
[2m[36m(func pid=85373)[0m f1_weighted: 0.08416239584795256
[2m[36m(func pid=85373)[0m f1_per_class: [0.0, 0.026, 0.022, 0.063, 0.167, 0.169, 0.126, 0.007, 0.059, 0.138]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=83696)[0m top1: 0.32742537313432835
[2m[36m(func pid=83696)[0m top5: 0.8736007462686567
[2m[36m(func pid=83696)[0m f1_micro: 0.32742537313432835
[2m[36m(func pid=83696)[0m f1_macro: 0.2532920515477828
[2m[36m(func pid=83696)[0m f1_weighted: 0.34780137099799263
[2m[36m(func pid=83696)[0m f1_per_class: [0.081, 0.49, 0.364, 0.282, 0.119, 0.181, 0.462, 0.296, 0.077, 0.182]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=91054)[0m top1: 0.21222014925373134
[2m[36m(func pid=91054)[0m top5: 0.5559701492537313
[2m[36m(func pid=91054)[0m f1_micro: 0.21222014925373134
[2m[36m(func pid=91054)[0m f1_macro: 0.06600139103417964
[2m[36m(func pid=91054)[0m f1_weighted: 0.11634015593359257
[2m[36m(func pid=91054)[0m f1_per_class: [0.0, 0.01, 0.07, 0.364, 0.0, 0.0, 0.0, 0.216, 0.0, 0.0]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.4256 | Steps: 2 | Val loss: 5.7534 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 1.7414 | Steps: 2 | Val loss: 50.0587 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.9496 | Steps: 2 | Val loss: 5.1551 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
== Status ==
Current time: 2024-01-07 02:46:18 (running for 00:22:19.16)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.426 |      0.225 |                   63 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  0.679 |      0.253 |                   42 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  1.64  |      0.078 |                   35 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054 | 0.0001 |       0.9  |         0.0001 |  2.7   |      0.066 |                   11 |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=79460)[0m top1: 0.27472014925373134
[2m[36m(func pid=79460)[0m top5: 0.7952425373134329
[2m[36m(func pid=79460)[0m f1_micro: 0.27472014925373134
[2m[36m(func pid=79460)[0m f1_macro: 0.22511582066288857
[2m[36m(func pid=79460)[0m f1_weighted: 0.3038336403625515
[2m[36m(func pid=79460)[0m f1_per_class: [0.093, 0.414, 0.143, 0.336, 0.138, 0.151, 0.319, 0.299, 0.062, 0.296]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 2.6661 | Steps: 2 | Val loss: 2.3236 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=83696)[0m top1: 0.28031716417910446
[2m[36m(func pid=83696)[0m top5: 0.8596082089552238
[2m[36m(func pid=83696)[0m f1_micro: 0.28031716417910446
[2m[36m(func pid=83696)[0m f1_macro: 0.2250870842243924
[2m[36m(func pid=83696)[0m f1_weighted: 0.29150378599443477
[2m[36m(func pid=83696)[0m f1_per_class: [0.08, 0.48, 0.212, 0.314, 0.148, 0.131, 0.245, 0.405, 0.145, 0.091]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=85373)[0m top1: 0.09001865671641791
[2m[36m(func pid=85373)[0m top5: 0.6119402985074627
[2m[36m(func pid=85373)[0m f1_micro: 0.0900186567164179
[2m[36m(func pid=85373)[0m f1_macro: 0.09734228459657537
[2m[36m(func pid=85373)[0m f1_weighted: 0.10242262460736698
[2m[36m(func pid=85373)[0m f1_per_class: [0.024, 0.075, 0.028, 0.053, 0.187, 0.152, 0.168, 0.006, 0.086, 0.194]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.1921 | Steps: 2 | Val loss: 5.1011 | Batch size: 32 | lr: 0.001 | Duration: 2.75s
[2m[36m(func pid=91054)[0m top1: 0.20615671641791045
[2m[36m(func pid=91054)[0m top5: 0.5527052238805971
[2m[36m(func pid=91054)[0m f1_micro: 0.20615671641791045
[2m[36m(func pid=91054)[0m f1_macro: 0.07070379294713332
[2m[36m(func pid=91054)[0m f1_weighted: 0.11836972010531537
[2m[36m(func pid=91054)[0m f1_per_class: [0.0, 0.01, 0.057, 0.358, 0.0, 0.0, 0.0, 0.281, 0.0, 0.0]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.6517 | Steps: 2 | Val loss: 5.6846 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 1.8888 | Steps: 2 | Val loss: 24.1459 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=79460)[0m top1: 0.29990671641791045
[2m[36m(func pid=79460)[0m top5: 0.8069029850746269
[2m[36m(func pid=79460)[0m f1_micro: 0.29990671641791045
[2m[36m(func pid=79460)[0m f1_macro: 0.2873219629439889
[2m[36m(func pid=79460)[0m f1_weighted: 0.33937684217856157
[2m[36m(func pid=79460)[0m f1_per_class: [0.11, 0.359, 0.609, 0.361, 0.14, 0.205, 0.409, 0.332, 0.065, 0.283]
[2m[36m(func pid=79460)[0m 
== Status ==
Current time: 2024-01-07 02:46:23 (running for 00:22:24.38)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.192 |      0.287 |                   64 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  0.95  |      0.225 |                   43 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  1.741 |      0.097 |                   36 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054 | 0.0001 |       0.9  |         0.0001 |  2.666 |      0.071 |                   12 |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 2.6527 | Steps: 2 | Val loss: 2.3187 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=83696)[0m top1: 0.2513992537313433
[2m[36m(func pid=83696)[0m top5: 0.8549440298507462
[2m[36m(func pid=83696)[0m f1_micro: 0.2513992537313433
[2m[36m(func pid=83696)[0m f1_macro: 0.20000470581927926
[2m[36m(func pid=83696)[0m f1_weighted: 0.24373524942618358
[2m[36m(func pid=83696)[0m f1_per_class: [0.079, 0.473, 0.183, 0.294, 0.156, 0.04, 0.149, 0.367, 0.149, 0.11]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=85373)[0m top1: 0.12033582089552239
[2m[36m(func pid=85373)[0m top5: 0.6343283582089553
[2m[36m(func pid=85373)[0m f1_micro: 0.12033582089552239
[2m[36m(func pid=85373)[0m f1_macro: 0.0823343577353871
[2m[36m(func pid=85373)[0m f1_weighted: 0.1294312285999329
[2m[36m(func pid=85373)[0m f1_per_class: [0.027, 0.053, 0.043, 0.077, 0.123, 0.129, 0.263, 0.013, 0.095, 0.0]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=91054)[0m top1: 0.20522388059701493
[2m[36m(func pid=91054)[0m top5: 0.5611007462686567
[2m[36m(func pid=91054)[0m f1_micro: 0.20522388059701493
[2m[36m(func pid=91054)[0m f1_macro: 0.07732346534125158
[2m[36m(func pid=91054)[0m f1_weighted: 0.1216337928685392
[2m[36m(func pid=91054)[0m f1_per_class: [0.0, 0.01, 0.054, 0.355, 0.0, 0.0, 0.0, 0.354, 0.0, 0.0]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.6163 | Steps: 2 | Val loss: 5.1194 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.5758 | Steps: 2 | Val loss: 6.4190 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 1.6340 | Steps: 2 | Val loss: 13.5919 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 02:46:28 (running for 00:22:29.57)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.616 |      0.313 |                   65 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  0.652 |      0.2   |                   44 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  1.889 |      0.082 |                   37 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054 | 0.0001 |       0.9  |         0.0001 |  2.653 |      0.077 |                   13 |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=79460)[0m top1: 0.3292910447761194
[2m[36m(func pid=79460)[0m top5: 0.7957089552238806
[2m[36m(func pid=79460)[0m f1_micro: 0.3292910447761194
[2m[36m(func pid=79460)[0m f1_macro: 0.3134752193068321
[2m[36m(func pid=79460)[0m f1_weighted: 0.3769168408283272
[2m[36m(func pid=79460)[0m f1_per_class: [0.115, 0.351, 0.643, 0.389, 0.163, 0.248, 0.476, 0.424, 0.09, 0.235]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 2.6189 | Steps: 2 | Val loss: 2.3128 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=83696)[0m top1: 0.22807835820895522
[2m[36m(func pid=83696)[0m top5: 0.8530783582089553
[2m[36m(func pid=83696)[0m f1_micro: 0.22807835820895522
[2m[36m(func pid=83696)[0m f1_macro: 0.18039284812860606
[2m[36m(func pid=83696)[0m f1_weighted: 0.21531648958025779
[2m[36m(func pid=83696)[0m f1_per_class: [0.085, 0.468, 0.145, 0.216, 0.138, 0.016, 0.144, 0.37, 0.1, 0.123]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=85373)[0m top1: 0.1296641791044776
[2m[36m(func pid=85373)[0m top5: 0.6609141791044776
[2m[36m(func pid=85373)[0m f1_micro: 0.1296641791044776
[2m[36m(func pid=85373)[0m f1_macro: 0.09505495742806933
[2m[36m(func pid=85373)[0m f1_weighted: 0.12851953318511664
[2m[36m(func pid=85373)[0m f1_per_class: [0.055, 0.052, 0.116, 0.044, 0.131, 0.117, 0.285, 0.044, 0.106, 0.0]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.2831 | Steps: 2 | Val loss: 5.9632 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=91054)[0m top1: 0.20662313432835822
[2m[36m(func pid=91054)[0m top5: 0.5680970149253731
[2m[36m(func pid=91054)[0m f1_micro: 0.20662313432835824
[2m[36m(func pid=91054)[0m f1_macro: 0.08625560277231353
[2m[36m(func pid=91054)[0m f1_weighted: 0.12764078002573348
[2m[36m(func pid=91054)[0m f1_per_class: [0.0, 0.03, 0.055, 0.349, 0.0, 0.0, 0.0, 0.429, 0.0, 0.0]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.8013 | Steps: 2 | Val loss: 7.5335 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 2.3941 | Steps: 2 | Val loss: 9.6775 | Batch size: 32 | lr: 0.1 | Duration: 2.98s
== Status ==
Current time: 2024-01-07 02:46:34 (running for 00:22:34.89)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.283 |      0.303 |                   66 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  0.576 |      0.18  |                   45 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  1.634 |      0.095 |                   38 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054 | 0.0001 |       0.9  |         0.0001 |  2.619 |      0.086 |                   14 |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=79460)[0m top1: 0.3064365671641791
[2m[36m(func pid=79460)[0m top5: 0.7555970149253731
[2m[36m(func pid=79460)[0m f1_micro: 0.3064365671641791
[2m[36m(func pid=79460)[0m f1_macro: 0.3027363674867278
[2m[36m(func pid=79460)[0m f1_weighted: 0.361299830691662
[2m[36m(func pid=79460)[0m f1_per_class: [0.108, 0.333, 0.6, 0.284, 0.093, 0.37, 0.493, 0.389, 0.099, 0.258]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 2.6173 | Steps: 2 | Val loss: 2.3108 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=83696)[0m top1: 0.22574626865671643
[2m[36m(func pid=83696)[0m top5: 0.8563432835820896
[2m[36m(func pid=83696)[0m f1_micro: 0.22574626865671643
[2m[36m(func pid=83696)[0m f1_macro: 0.17234586643477673
[2m[36m(func pid=83696)[0m f1_weighted: 0.21325662307050158
[2m[36m(func pid=83696)[0m f1_per_class: [0.075, 0.471, 0.109, 0.179, 0.095, 0.016, 0.166, 0.403, 0.107, 0.102]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=85373)[0m top1: 0.13992537313432835
[2m[36m(func pid=85373)[0m top5: 0.6916977611940298
[2m[36m(func pid=85373)[0m f1_micro: 0.13992537313432835
[2m[36m(func pid=85373)[0m f1_macro: 0.11130734218357614
[2m[36m(func pid=85373)[0m f1_weighted: 0.13794953593066334
[2m[36m(func pid=85373)[0m f1_per_class: [0.054, 0.08, 0.209, 0.035, 0.13, 0.142, 0.294, 0.071, 0.1, 0.0]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.6814 | Steps: 2 | Val loss: 8.2309 | Batch size: 32 | lr: 0.001 | Duration: 2.76s
[2m[36m(func pid=91054)[0m top1: 0.20289179104477612
[2m[36m(func pid=91054)[0m top5: 0.570429104477612
[2m[36m(func pid=91054)[0m f1_micro: 0.20289179104477612
[2m[36m(func pid=91054)[0m f1_macro: 0.08847457179725213
[2m[36m(func pid=91054)[0m f1_weighted: 0.12910497343934355
[2m[36m(func pid=91054)[0m f1_per_class: [0.0, 0.038, 0.053, 0.345, 0.0, 0.0, 0.0, 0.448, 0.0, 0.0]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.9979 | Steps: 2 | Val loss: 7.2292 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 1.9004 | Steps: 2 | Val loss: 8.8648 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 02:46:39 (running for 00:22:40.04)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.681 |      0.262 |                   67 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  0.801 |      0.172 |                   46 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  2.394 |      0.111 |                   39 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054 | 0.0001 |       0.9  |         0.0001 |  2.617 |      0.088 |                   15 |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=79460)[0m top1: 0.23880597014925373
[2m[36m(func pid=79460)[0m top5: 0.695429104477612
[2m[36m(func pid=79460)[0m f1_micro: 0.23880597014925373
[2m[36m(func pid=79460)[0m f1_macro: 0.2616546029619017
[2m[36m(func pid=79460)[0m f1_weighted: 0.2783252943258463
[2m[36m(func pid=79460)[0m f1_per_class: [0.097, 0.288, 0.538, 0.183, 0.135, 0.386, 0.363, 0.211, 0.096, 0.32]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 2.5696 | Steps: 2 | Val loss: 2.3085 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=83696)[0m top1: 0.22294776119402984
[2m[36m(func pid=83696)[0m top5: 0.851679104477612
[2m[36m(func pid=83696)[0m f1_micro: 0.22294776119402981
[2m[36m(func pid=83696)[0m f1_macro: 0.16942307712102897
[2m[36m(func pid=83696)[0m f1_weighted: 0.2063386769753086
[2m[36m(func pid=83696)[0m f1_per_class: [0.084, 0.469, 0.124, 0.123, 0.0, 0.055, 0.174, 0.453, 0.096, 0.117]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=85373)[0m top1: 0.13899253731343283
[2m[36m(func pid=85373)[0m top5: 0.7014925373134329
[2m[36m(func pid=85373)[0m f1_micro: 0.13899253731343283
[2m[36m(func pid=85373)[0m f1_macro: 0.0949280071486483
[2m[36m(func pid=85373)[0m f1_weighted: 0.1295361978999538
[2m[36m(func pid=85373)[0m f1_per_class: [0.0, 0.045, 0.119, 0.019, 0.168, 0.085, 0.322, 0.095, 0.095, 0.0]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.2252 | Steps: 2 | Val loss: 9.8013 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=91054)[0m top1: 0.2019589552238806
[2m[36m(func pid=91054)[0m top5: 0.5708955223880597
[2m[36m(func pid=91054)[0m f1_micro: 0.2019589552238806
[2m[36m(func pid=91054)[0m f1_macro: 0.09157175137422777
[2m[36m(func pid=91054)[0m f1_weighted: 0.1306911764856747
[2m[36m(func pid=91054)[0m f1_per_class: [0.0, 0.042, 0.053, 0.342, 0.0, 0.0, 0.0, 0.478, 0.0, 0.0]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 2.5620 | Steps: 2 | Val loss: 6.3533 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 1.7137 | Steps: 2 | Val loss: 8.5016 | Batch size: 32 | lr: 0.1 | Duration: 3.03s
== Status ==
Current time: 2024-01-07 02:46:44 (running for 00:22:45.40)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.225 |      0.225 |                   68 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  0.998 |      0.169 |                   47 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  1.9   |      0.095 |                   40 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054 | 0.0001 |       0.9  |         0.0001 |  2.57  |      0.092 |                   16 |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=79460)[0m top1: 0.17397388059701493
[2m[36m(func pid=79460)[0m top5: 0.6422574626865671
[2m[36m(func pid=79460)[0m f1_micro: 0.17397388059701493
[2m[36m(func pid=79460)[0m f1_macro: 0.2246685658380802
[2m[36m(func pid=79460)[0m f1_weighted: 0.18752467019057933
[2m[36m(func pid=79460)[0m f1_per_class: [0.094, 0.315, 0.522, 0.157, 0.133, 0.391, 0.08, 0.147, 0.073, 0.333]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 2.5350 | Steps: 2 | Val loss: 2.3036 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=83696)[0m top1: 0.24253731343283583
[2m[36m(func pid=83696)[0m top5: 0.8656716417910447
[2m[36m(func pid=83696)[0m f1_micro: 0.24253731343283583
[2m[36m(func pid=83696)[0m f1_macro: 0.19468850943290836
[2m[36m(func pid=83696)[0m f1_weighted: 0.22655583976566393
[2m[36m(func pid=83696)[0m f1_per_class: [0.094, 0.472, 0.179, 0.087, 0.0, 0.134, 0.232, 0.497, 0.096, 0.156]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=85373)[0m top1: 0.15391791044776118
[2m[36m(func pid=85373)[0m top5: 0.7252798507462687
[2m[36m(func pid=85373)[0m f1_micro: 0.15391791044776118
[2m[36m(func pid=85373)[0m f1_macro: 0.10465307523812159
[2m[36m(func pid=85373)[0m f1_weighted: 0.14010475123152571
[2m[36m(func pid=85373)[0m f1_per_class: [0.0, 0.021, 0.129, 0.041, 0.165, 0.083, 0.343, 0.135, 0.09, 0.039]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.3789 | Steps: 2 | Val loss: 10.1017 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=91054)[0m top1: 0.20662313432835822
[2m[36m(func pid=91054)[0m top5: 0.5727611940298507
[2m[36m(func pid=91054)[0m f1_micro: 0.20662313432835824
[2m[36m(func pid=91054)[0m f1_macro: 0.0927272903404752
[2m[36m(func pid=91054)[0m f1_weighted: 0.13361583690330928
[2m[36m(func pid=91054)[0m f1_per_class: [0.0, 0.047, 0.054, 0.35, 0.0, 0.0, 0.0, 0.476, 0.0, 0.0]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.4995 | Steps: 2 | Val loss: 5.5756 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 1.5961 | Steps: 2 | Val loss: 9.0426 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
== Status ==
Current time: 2024-01-07 02:46:49 (running for 00:22:50.55)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.379 |      0.205 |                   69 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  2.562 |      0.195 |                   48 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  1.714 |      0.105 |                   41 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054 | 0.0001 |       0.9  |         0.0001 |  2.535 |      0.093 |                   17 |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=79460)[0m top1: 0.16138059701492538
[2m[36m(func pid=79460)[0m top5: 0.6567164179104478
[2m[36m(func pid=79460)[0m f1_micro: 0.16138059701492538
[2m[36m(func pid=79460)[0m f1_macro: 0.2054226151083415
[2m[36m(func pid=79460)[0m f1_weighted: 0.17407943328470524
[2m[36m(func pid=79460)[0m f1_per_class: [0.096, 0.342, 0.5, 0.173, 0.143, 0.363, 0.042, 0.016, 0.069, 0.31]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 2.5135 | Steps: 2 | Val loss: 2.2994 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
[2m[36m(func pid=83696)[0m top1: 0.25093283582089554
[2m[36m(func pid=83696)[0m top5: 0.8731343283582089
[2m[36m(func pid=83696)[0m f1_micro: 0.25093283582089554
[2m[36m(func pid=83696)[0m f1_macro: 0.22183941708654617
[2m[36m(func pid=83696)[0m f1_weighted: 0.23271184101125097
[2m[36m(func pid=83696)[0m f1_per_class: [0.118, 0.425, 0.367, 0.102, 0.0, 0.175, 0.238, 0.513, 0.116, 0.163]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=85373)[0m top1: 0.15578358208955223
[2m[36m(func pid=85373)[0m top5: 0.7518656716417911
[2m[36m(func pid=85373)[0m f1_micro: 0.15578358208955223
[2m[36m(func pid=85373)[0m f1_macro: 0.11897029750484453
[2m[36m(func pid=85373)[0m f1_weighted: 0.1462788158649461
[2m[36m(func pid=85373)[0m f1_per_class: [0.053, 0.032, 0.154, 0.108, 0.154, 0.045, 0.297, 0.16, 0.119, 0.069]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.2257 | Steps: 2 | Val loss: 8.7963 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=91054)[0m top1: 0.2019589552238806
[2m[36m(func pid=91054)[0m top5: 0.5844216417910447
[2m[36m(func pid=91054)[0m f1_micro: 0.2019589552238806
[2m[36m(func pid=91054)[0m f1_macro: 0.10053053850214337
[2m[36m(func pid=91054)[0m f1_weighted: 0.13436576927496346
[2m[36m(func pid=91054)[0m f1_per_class: [0.014, 0.063, 0.054, 0.341, 0.0, 0.0, 0.0, 0.468, 0.0, 0.065]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.5638 | Steps: 2 | Val loss: 6.0608 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 2.5260 | Steps: 2 | Val loss: 10.8223 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=79460)[0m top1: 0.17257462686567165
[2m[36m(func pid=79460)[0m top5: 0.7196828358208955
[2m[36m(func pid=79460)[0m f1_micro: 0.17257462686567165
[2m[36m(func pid=79460)[0m f1_macro: 0.21688974852854312
[2m[36m(func pid=79460)[0m f1_weighted: 0.1971165959012423
[2m[36m(func pid=79460)[0m f1_per_class: [0.104, 0.386, 0.545, 0.227, 0.128, 0.305, 0.062, 0.032, 0.074, 0.308]
[2m[36m(func pid=79460)[0m 
== Status ==
Current time: 2024-01-07 02:46:54 (running for 00:22:55.79)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.226 |      0.217 |                   70 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  0.499 |      0.222 |                   49 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  1.596 |      0.119 |                   42 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054 | 0.0001 |       0.9  |         0.0001 |  2.514 |      0.101 |                   18 |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 2.5358 | Steps: 2 | Val loss: 2.2947 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=83696)[0m top1: 0.23647388059701493
[2m[36m(func pid=83696)[0m top5: 0.867070895522388
[2m[36m(func pid=83696)[0m f1_micro: 0.23647388059701493
[2m[36m(func pid=83696)[0m f1_macro: 0.2358826093960673
[2m[36m(func pid=83696)[0m f1_weighted: 0.22123326251947067
[2m[36m(func pid=83696)[0m f1_per_class: [0.113, 0.412, 0.522, 0.076, 0.0, 0.085, 0.256, 0.538, 0.104, 0.252]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=85373)[0m top1: 0.14598880597014927
[2m[36m(func pid=85373)[0m top5: 0.7551305970149254
[2m[36m(func pid=85373)[0m f1_micro: 0.14598880597014927
[2m[36m(func pid=85373)[0m f1_macro: 0.09894571792838697
[2m[36m(func pid=85373)[0m f1_weighted: 0.1425457872539051
[2m[36m(func pid=85373)[0m f1_per_class: [0.044, 0.016, 0.154, 0.202, 0.136, 0.072, 0.213, 0.152, 0.0, 0.0]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.1789 | Steps: 2 | Val loss: 6.9762 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=91054)[0m top1: 0.20289179104477612
[2m[36m(func pid=91054)[0m top5: 0.5960820895522388
[2m[36m(func pid=91054)[0m f1_micro: 0.20289179104477612
[2m[36m(func pid=91054)[0m f1_macro: 0.10257323587843428
[2m[36m(func pid=91054)[0m f1_weighted: 0.14113555826473934
[2m[36m(func pid=91054)[0m f1_per_class: [0.0, 0.104, 0.056, 0.341, 0.0, 0.0, 0.0, 0.467, 0.0, 0.057]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 1.0314 | Steps: 2 | Val loss: 6.1864 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
== Status ==
Current time: 2024-01-07 02:47:00 (running for 00:23:01.12)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.179 |      0.238 |                   71 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  0.564 |      0.236 |                   50 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  2.526 |      0.099 |                   43 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054 | 0.0001 |       0.9  |         0.0001 |  2.536 |      0.103 |                   19 |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=79460)[0m top1: 0.1958955223880597
[2m[36m(func pid=79460)[0m top5: 0.7793843283582089
[2m[36m(func pid=79460)[0m f1_micro: 0.19589552238805974
[2m[36m(func pid=79460)[0m f1_macro: 0.23835932379042063
[2m[36m(func pid=79460)[0m f1_weighted: 0.22831577630747352
[2m[36m(func pid=79460)[0m f1_per_class: [0.114, 0.419, 0.615, 0.294, 0.157, 0.239, 0.106, 0.031, 0.076, 0.333]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 1.6438 | Steps: 2 | Val loss: 11.3312 | Batch size: 32 | lr: 0.1 | Duration: 2.99s
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 2.4903 | Steps: 2 | Val loss: 2.2934 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=83696)[0m top1: 0.27798507462686567
[2m[36m(func pid=83696)[0m top5: 0.8535447761194029
[2m[36m(func pid=83696)[0m f1_micro: 0.27798507462686567
[2m[36m(func pid=83696)[0m f1_macro: 0.1977137866406814
[2m[36m(func pid=83696)[0m f1_weighted: 0.25984115897444404
[2m[36m(func pid=83696)[0m f1_per_class: [0.104, 0.403, 0.0, 0.053, 0.0, 0.031, 0.444, 0.508, 0.156, 0.279]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=85373)[0m top1: 0.12080223880597014
[2m[36m(func pid=85373)[0m top5: 0.7444029850746269
[2m[36m(func pid=85373)[0m f1_micro: 0.12080223880597014
[2m[36m(func pid=85373)[0m f1_macro: 0.08541327030800944
[2m[36m(func pid=85373)[0m f1_weighted: 0.09715464576005382
[2m[36m(func pid=85373)[0m f1_per_class: [0.046, 0.011, 0.158, 0.072, 0.11, 0.053, 0.185, 0.189, 0.0, 0.031]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.2158 | Steps: 2 | Val loss: 5.3043 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=91054)[0m top1: 0.20055970149253732
[2m[36m(func pid=91054)[0m top5: 0.6040111940298507
[2m[36m(func pid=91054)[0m f1_micro: 0.20055970149253732
[2m[36m(func pid=91054)[0m f1_macro: 0.10533026901489229
[2m[36m(func pid=91054)[0m f1_weighted: 0.14272889467472505
[2m[36m(func pid=91054)[0m f1_per_class: [0.021, 0.119, 0.059, 0.337, 0.0, 0.0, 0.0, 0.462, 0.0, 0.054]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.5861 | Steps: 2 | Val loss: 6.3851 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=79460)[0m top1: 0.24953358208955223
[2m[36m(func pid=79460)[0m top5: 0.8176305970149254
[2m[36m(func pid=79460)[0m f1_micro: 0.24953358208955223
[2m[36m(func pid=79460)[0m f1_macro: 0.2587699079759918
[2m[36m(func pid=79460)[0m f1_weighted: 0.2904288784789972
[2m[36m(func pid=79460)[0m f1_per_class: [0.129, 0.439, 0.514, 0.376, 0.165, 0.218, 0.217, 0.117, 0.091, 0.323]
[2m[36m(func pid=79460)[0m 
== Status ==
Current time: 2024-01-07 02:47:05 (running for 00:23:06.35)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.216 |      0.259 |                   72 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  1.031 |      0.198 |                   51 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  1.644 |      0.085 |                   44 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054 | 0.0001 |       0.9  |         0.0001 |  2.49  |      0.105 |                   20 |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 1.9685 | Steps: 2 | Val loss: 12.8176 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 2.4722 | Steps: 2 | Val loss: 2.2910 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=83696)[0m top1: 0.3278917910447761
[2m[36m(func pid=83696)[0m top5: 0.8652052238805971
[2m[36m(func pid=83696)[0m f1_micro: 0.3278917910447761
[2m[36m(func pid=83696)[0m f1_macro: 0.2085007440714532
[2m[36m(func pid=83696)[0m f1_weighted: 0.3017423144865406
[2m[36m(func pid=83696)[0m f1_per_class: [0.101, 0.411, 0.0, 0.081, 0.0, 0.016, 0.564, 0.463, 0.208, 0.241]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=85373)[0m top1: 0.11380597014925373
[2m[36m(func pid=85373)[0m top5: 0.7094216417910447
[2m[36m(func pid=85373)[0m f1_micro: 0.11380597014925373
[2m[36m(func pid=85373)[0m f1_macro: 0.08231188189713466
[2m[36m(func pid=85373)[0m f1_weighted: 0.07175693947923513
[2m[36m(func pid=85373)[0m f1_per_class: [0.044, 0.0, 0.163, 0.01, 0.151, 0.018, 0.173, 0.204, 0.0, 0.06]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.2186 | Steps: 2 | Val loss: 3.9264 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=91054)[0m top1: 0.20055970149253732
[2m[36m(func pid=91054)[0m top5: 0.6142723880597015
[2m[36m(func pid=91054)[0m f1_micro: 0.20055970149253732
[2m[36m(func pid=91054)[0m f1_macro: 0.10829614098911304
[2m[36m(func pid=91054)[0m f1_weighted: 0.1441693044149426
[2m[36m(func pid=91054)[0m f1_per_class: [0.039, 0.121, 0.063, 0.339, 0.0, 0.0, 0.0, 0.462, 0.0, 0.057]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.5487 | Steps: 2 | Val loss: 6.2543 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
== Status ==
Current time: 2024-01-07 02:47:10 (running for 00:23:11.58)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.219 |      0.315 |                   73 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  0.586 |      0.209 |                   52 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  1.968 |      0.082 |                   45 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054 | 0.0001 |       0.9  |         0.0001 |  2.472 |      0.108 |                   21 |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=79460)[0m top1: 0.3302238805970149
[2m[36m(func pid=79460)[0m top5: 0.8521455223880597
[2m[36m(func pid=79460)[0m f1_micro: 0.3302238805970149
[2m[36m(func pid=79460)[0m f1_macro: 0.3152355494314154
[2m[36m(func pid=79460)[0m f1_weighted: 0.366741120791798
[2m[36m(func pid=79460)[0m f1_per_class: [0.176, 0.433, 0.537, 0.444, 0.178, 0.23, 0.351, 0.371, 0.132, 0.301]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 1.7683 | Steps: 2 | Val loss: 14.1771 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 2.5118 | Steps: 2 | Val loss: 2.2923 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=83696)[0m top1: 0.3255597014925373
[2m[36m(func pid=83696)[0m top5: 0.8773320895522388
[2m[36m(func pid=83696)[0m f1_micro: 0.3255597014925373
[2m[36m(func pid=83696)[0m f1_macro: 0.24300184422194918
[2m[36m(func pid=83696)[0m f1_weighted: 0.30888971935918474
[2m[36m(func pid=83696)[0m f1_per_class: [0.091, 0.398, 0.545, 0.122, 0.0, 0.032, 0.584, 0.244, 0.202, 0.211]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.2788 | Steps: 2 | Val loss: 3.4300 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=85373)[0m top1: 0.12220149253731344
[2m[36m(func pid=85373)[0m top5: 0.7112873134328358
[2m[36m(func pid=85373)[0m f1_micro: 0.12220149253731344
[2m[36m(func pid=85373)[0m f1_macro: 0.08515489824305952
[2m[36m(func pid=85373)[0m f1_weighted: 0.08040889986669897
[2m[36m(func pid=85373)[0m f1_per_class: [0.036, 0.011, 0.164, 0.003, 0.132, 0.035, 0.191, 0.225, 0.022, 0.033]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=91054)[0m top1: 0.19029850746268656
[2m[36m(func pid=91054)[0m top5: 0.6161380597014925
[2m[36m(func pid=91054)[0m f1_micro: 0.19029850746268656
[2m[36m(func pid=91054)[0m f1_macro: 0.11051561289969078
[2m[36m(func pid=91054)[0m f1_weighted: 0.14404203633245757
[2m[36m(func pid=91054)[0m f1_per_class: [0.032, 0.149, 0.058, 0.324, 0.0, 0.0, 0.0, 0.447, 0.0, 0.095]
[2m[36m(func pid=91054)[0m 
== Status ==
Current time: 2024-01-07 02:47:16 (running for 00:23:16.84)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.279 |      0.33  |                   74 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  0.549 |      0.243 |                   53 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  1.768 |      0.085 |                   46 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054 | 0.0001 |       0.9  |         0.0001 |  2.512 |      0.111 |                   22 |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=79460)[0m top1: 0.35867537313432835
[2m[36m(func pid=79460)[0m top5: 0.8652052238805971
[2m[36m(func pid=79460)[0m f1_micro: 0.35867537313432835
[2m[36m(func pid=79460)[0m f1_macro: 0.3301425160930276
[2m[36m(func pid=79460)[0m f1_weighted: 0.3788525087314185
[2m[36m(func pid=79460)[0m f1_per_class: [0.244, 0.39, 0.564, 0.472, 0.145, 0.255, 0.367, 0.399, 0.165, 0.299]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 1.0941 | Steps: 2 | Val loss: 5.8820 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 6.0800 | Steps: 2 | Val loss: 14.7013 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 2.4502 | Steps: 2 | Val loss: 2.2912 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=83696)[0m top1: 0.345615671641791
[2m[36m(func pid=83696)[0m top5: 0.8773320895522388
[2m[36m(func pid=83696)[0m f1_micro: 0.345615671641791
[2m[36m(func pid=83696)[0m f1_macro: 0.2547607461424006
[2m[36m(func pid=83696)[0m f1_weighted: 0.32868153122234406
[2m[36m(func pid=83696)[0m f1_per_class: [0.102, 0.401, 0.529, 0.16, 0.0, 0.032, 0.59, 0.38, 0.189, 0.164]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.1723 | Steps: 2 | Val loss: 3.2404 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=85373)[0m top1: 0.12033582089552239
[2m[36m(func pid=85373)[0m top5: 0.7248134328358209
[2m[36m(func pid=85373)[0m f1_micro: 0.12033582089552239
[2m[36m(func pid=85373)[0m f1_macro: 0.0902101470568351
[2m[36m(func pid=85373)[0m f1_weighted: 0.08480203295732683
[2m[36m(func pid=85373)[0m f1_per_class: [0.046, 0.042, 0.14, 0.0, 0.145, 0.064, 0.177, 0.219, 0.056, 0.012]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=91054)[0m top1: 0.1814365671641791
[2m[36m(func pid=91054)[0m top5: 0.6236007462686567
[2m[36m(func pid=91054)[0m f1_micro: 0.1814365671641791
[2m[36m(func pid=91054)[0m f1_macro: 0.11046316937099995
[2m[36m(func pid=91054)[0m f1_weighted: 0.14222195759219058
[2m[36m(func pid=91054)[0m f1_per_class: [0.027, 0.151, 0.06, 0.312, 0.0, 0.024, 0.0, 0.423, 0.0, 0.108]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=79460)[0m top1: 0.38199626865671643
[2m[36m(func pid=79460)[0m top5: 0.871268656716418
[2m[36m(func pid=79460)[0m f1_micro: 0.3819962686567165
[2m[36m(func pid=79460)[0m f1_macro: 0.3455189262446617
[2m[36m(func pid=79460)[0m f1_weighted: 0.3924285678919552
[2m[36m(func pid=79460)[0m f1_per_class: [0.28, 0.32, 0.611, 0.521, 0.134, 0.225, 0.402, 0.433, 0.217, 0.311]
== Status ==
Current time: 2024-01-07 02:47:21 (running for 00:23:22.20)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: 0.32525000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.172 |      0.346 |                   75 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  1.094 |      0.255 |                   54 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  6.08  |      0.09  |                   47 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054 | 0.0001 |       0.9  |         0.0001 |  2.45  |      0.11  |                   23 |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.3666 | Steps: 2 | Val loss: 7.0419 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 1.6962 | Steps: 2 | Val loss: 12.7945 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 2.4397 | Steps: 2 | Val loss: 2.2844 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=83696)[0m top1: 0.35261194029850745
[2m[36m(func pid=83696)[0m top5: 0.8558768656716418
[2m[36m(func pid=83696)[0m f1_micro: 0.35261194029850745
[2m[36m(func pid=83696)[0m f1_macro: 0.23609204892086083
[2m[36m(func pid=83696)[0m f1_weighted: 0.31039636721314295
[2m[36m(func pid=83696)[0m f1_per_class: [0.062, 0.4, 0.312, 0.133, 0.0, 0.008, 0.551, 0.484, 0.169, 0.243]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 75] | Train loss: 0.1785 | Steps: 2 | Val loss: 3.3339 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
[2m[36m(func pid=85373)[0m top1: 0.10494402985074627
[2m[36m(func pid=85373)[0m top5: 0.7318097014925373
[2m[36m(func pid=85373)[0m f1_micro: 0.10494402985074627
[2m[36m(func pid=85373)[0m f1_macro: 0.08433887844124195
[2m[36m(func pid=85373)[0m f1_weighted: 0.06558537231468498
[2m[36m(func pid=85373)[0m f1_per_class: [0.045, 0.026, 0.171, 0.0, 0.133, 0.085, 0.117, 0.206, 0.046, 0.013]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=91054)[0m top1: 0.18423507462686567
[2m[36m(func pid=91054)[0m top5: 0.6315298507462687
[2m[36m(func pid=91054)[0m f1_micro: 0.1842350746268657
[2m[36m(func pid=91054)[0m f1_macro: 0.11616420141543533
[2m[36m(func pid=91054)[0m f1_weighted: 0.1480294735439879
[2m[36m(func pid=91054)[0m f1_per_class: [0.024, 0.173, 0.066, 0.31, 0.0, 0.039, 0.0, 0.436, 0.0, 0.114]
[2m[36m(func pid=91054)[0m 
== Status ==
Current time: 2024-01-07 02:47:26 (running for 00:23:27.46)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: 0.32525000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.178 |      0.337 |                   76 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  0.367 |      0.236 |                   55 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  1.696 |      0.084 |                   48 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054 | 0.0001 |       0.9  |         0.0001 |  2.44  |      0.116 |                   24 |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=79460)[0m top1: 0.3675373134328358
[2m[36m(func pid=79460)[0m top5: 0.8745335820895522
[2m[36m(func pid=79460)[0m f1_micro: 0.36753731343283574
[2m[36m(func pid=79460)[0m f1_macro: 0.33654918261209715
[2m[36m(func pid=79460)[0m f1_weighted: 0.37089074435493713
[2m[36m(func pid=79460)[0m f1_per_class: [0.335, 0.281, 0.621, 0.53, 0.139, 0.236, 0.344, 0.4, 0.228, 0.252]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.3155 | Steps: 2 | Val loss: 9.5063 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 1.6597 | Steps: 2 | Val loss: 11.7684 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 2.4440 | Steps: 2 | Val loss: 2.2817 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=83696)[0m top1: 0.33348880597014924
[2m[36m(func pid=83696)[0m top5: 0.8236940298507462
[2m[36m(func pid=83696)[0m f1_micro: 0.33348880597014924
[2m[36m(func pid=83696)[0m f1_macro: 0.18517352396937897
[2m[36m(func pid=83696)[0m f1_weighted: 0.2873986040553307
[2m[36m(func pid=83696)[0m f1_per_class: [0.0, 0.37, 0.152, 0.088, 0.0, 0.016, 0.567, 0.404, 0.055, 0.2]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 76] | Train loss: 0.0810 | Steps: 2 | Val loss: 3.5579 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=91054)[0m top1: 0.18563432835820895
[2m[36m(func pid=91054)[0m top5: 0.636660447761194
[2m[36m(func pid=91054)[0m f1_micro: 0.18563432835820895
[2m[36m(func pid=91054)[0m f1_macro: 0.11796031512689394
[2m[36m(func pid=91054)[0m f1_weighted: 0.15324069225640338
[2m[36m(func pid=91054)[0m f1_per_class: [0.022, 0.2, 0.07, 0.3, 0.0, 0.06, 0.0, 0.459, 0.0, 0.069]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=85373)[0m top1: 0.09981343283582089
[2m[36m(func pid=85373)[0m top5: 0.7346082089552238
[2m[36m(func pid=85373)[0m f1_micro: 0.0998134328358209
[2m[36m(func pid=85373)[0m f1_macro: 0.07995143783817002
[2m[36m(func pid=85373)[0m f1_weighted: 0.057527206256256784
[2m[36m(func pid=85373)[0m f1_per_class: [0.014, 0.026, 0.183, 0.0, 0.109, 0.076, 0.092, 0.211, 0.066, 0.022]
[2m[36m(func pid=85373)[0m 
== Status ==
Current time: 2024-01-07 02:47:31 (running for 00:23:32.58)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: 0.32525000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.081 |      0.303 |                   77 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  0.315 |      0.185 |                   56 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  1.66  |      0.08  |                   49 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054 | 0.0001 |       0.9  |         0.0001 |  2.444 |      0.118 |                   25 |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=79460)[0m top1: 0.33722014925373134
[2m[36m(func pid=79460)[0m top5: 0.8754664179104478
[2m[36m(func pid=79460)[0m f1_micro: 0.33722014925373134
[2m[36m(func pid=79460)[0m f1_macro: 0.3031970740262483
[2m[36m(func pid=79460)[0m f1_weighted: 0.3291226661958255
[2m[36m(func pid=79460)[0m f1_per_class: [0.393, 0.257, 0.444, 0.523, 0.121, 0.227, 0.234, 0.371, 0.233, 0.229]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.6165 | Steps: 2 | Val loss: 12.2921 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 2.3953 | Steps: 2 | Val loss: 2.2778 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 2.2055 | Steps: 2 | Val loss: 10.1378 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=83696)[0m top1: 0.3003731343283582
[2m[36m(func pid=83696)[0m top5: 0.8041044776119403
[2m[36m(func pid=83696)[0m f1_micro: 0.3003731343283582
[2m[36m(func pid=83696)[0m f1_macro: 0.1301579634892544
[2m[36m(func pid=83696)[0m f1_weighted: 0.25264453402566706
[2m[36m(func pid=83696)[0m f1_per_class: [0.0, 0.353, 0.082, 0.083, 0.0, 0.0, 0.548, 0.032, 0.022, 0.18]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 77] | Train loss: 0.1329 | Steps: 2 | Val loss: 3.7173 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=91054)[0m top1: 0.18330223880597016
[2m[36m(func pid=91054)[0m top5: 0.644589552238806
[2m[36m(func pid=91054)[0m f1_micro: 0.18330223880597016
[2m[36m(func pid=91054)[0m f1_macro: 0.1288920459513722
[2m[36m(func pid=91054)[0m f1_weighted: 0.15474535844295007
[2m[36m(func pid=91054)[0m f1_per_class: [0.034, 0.218, 0.077, 0.285, 0.0, 0.073, 0.0, 0.459, 0.0, 0.143]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=85373)[0m top1: 0.10401119402985075
[2m[36m(func pid=85373)[0m top5: 0.746268656716418
[2m[36m(func pid=85373)[0m f1_micro: 0.10401119402985075
[2m[36m(func pid=85373)[0m f1_macro: 0.08614444171132621
[2m[36m(func pid=85373)[0m f1_weighted: 0.06408619237639789
[2m[36m(func pid=85373)[0m f1_per_class: [0.0, 0.051, 0.212, 0.0, 0.111, 0.08, 0.096, 0.22, 0.073, 0.018]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=79460)[0m top1: 0.3302238805970149
[2m[36m(func pid=79460)[0m top5: 0.8703358208955224
[2m[36m(func pid=79460)[0m f1_micro: 0.3302238805970149
[2m[36m(func pid=79460)[0m f1_macro: 0.27074915237992936
[2m[36m(func pid=79460)[0m f1_weighted: 0.32026131571815963
[2m[36m(func pid=79460)[0m f1_per_class: [0.386, 0.256, 0.143, 0.518, 0.121, 0.258, 0.205, 0.373, 0.224, 0.224]
[2m[36m(func pid=79460)[0m 
== Status ==
Current time: 2024-01-07 02:47:37 (running for 00:23:37.96)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: 0.32525000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.133 |      0.271 |                   78 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  0.617 |      0.13  |                   57 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  2.206 |      0.086 |                   50 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054 | 0.0001 |       0.9  |         0.0001 |  2.395 |      0.129 |                   26 |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.3590 | Steps: 2 | Val loss: 14.5701 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 2.3763 | Steps: 2 | Val loss: 2.2737 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 1.7992 | Steps: 2 | Val loss: 8.4957 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 78] | Train loss: 0.2605 | Steps: 2 | Val loss: 3.9470 | Batch size: 32 | lr: 0.001 | Duration: 2.71s
[2m[36m(func pid=83696)[0m top1: 0.26865671641791045
[2m[36m(func pid=83696)[0m top5: 0.808768656716418
[2m[36m(func pid=83696)[0m f1_micro: 0.26865671641791045
[2m[36m(func pid=83696)[0m f1_macro: 0.12049986088112515
[2m[36m(func pid=83696)[0m f1_weighted: 0.24291286004436038
[2m[36m(func pid=83696)[0m f1_per_class: [0.0, 0.305, 0.054, 0.079, 0.0, 0.04, 0.538, 0.0, 0.051, 0.138]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=91054)[0m top1: 0.18190298507462688
[2m[36m(func pid=91054)[0m top5: 0.6515858208955224
[2m[36m(func pid=91054)[0m f1_micro: 0.1819029850746269
[2m[36m(func pid=91054)[0m f1_macro: 0.1313865468448984
[2m[36m(func pid=91054)[0m f1_weighted: 0.1567720449945503
[2m[36m(func pid=91054)[0m f1_per_class: [0.034, 0.245, 0.084, 0.274, 0.0, 0.079, 0.0, 0.455, 0.0, 0.143]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=85373)[0m top1: 0.11520522388059702
[2m[36m(func pid=85373)[0m top5: 0.7677238805970149
[2m[36m(func pid=85373)[0m f1_micro: 0.11520522388059702
[2m[36m(func pid=85373)[0m f1_macro: 0.10206472915485634
[2m[36m(func pid=85373)[0m f1_weighted: 0.07943027375939424
[2m[36m(func pid=85373)[0m f1_per_class: [0.035, 0.096, 0.235, 0.0, 0.122, 0.05, 0.125, 0.231, 0.095, 0.031]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=79460)[0m top1: 0.31716417910447764
[2m[36m(func pid=79460)[0m top5: 0.8666044776119403
[2m[36m(func pid=79460)[0m f1_micro: 0.31716417910447764
[2m[36m(func pid=79460)[0m f1_macro: 0.2558212969490528
[2m[36m(func pid=79460)[0m f1_weighted: 0.3118316383971764
[2m[36m(func pid=79460)[0m f1_per_class: [0.242, 0.276, 0.111, 0.471, 0.125, 0.29, 0.205, 0.393, 0.203, 0.242]
== Status ==
Current time: 2024-01-07 02:47:42 (running for 00:23:43.05)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: 0.32525000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.26  |      0.256 |                   79 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  0.359 |      0.12  |                   58 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  1.799 |      0.102 |                   51 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054 | 0.0001 |       0.9  |         0.0001 |  2.376 |      0.131 |                   27 |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.9346 | Steps: 2 | Val loss: 14.6754 | Batch size: 32 | lr: 0.01 | Duration: 3.05s
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 2.3706 | Steps: 2 | Val loss: 2.2698 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 1.7142 | Steps: 2 | Val loss: 7.6957 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 79] | Train loss: 0.0846 | Steps: 2 | Val loss: 4.1657 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=91054)[0m top1: 0.18563432835820895
[2m[36m(func pid=91054)[0m top5: 0.6529850746268657
[2m[36m(func pid=91054)[0m f1_micro: 0.18563432835820895
[2m[36m(func pid=91054)[0m f1_macro: 0.13828484728284163
[2m[36m(func pid=91054)[0m f1_weighted: 0.16575193447597492
[2m[36m(func pid=91054)[0m f1_per_class: [0.035, 0.259, 0.093, 0.274, 0.0, 0.14, 0.0, 0.443, 0.0, 0.138]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=83696)[0m top1: 0.2621268656716418
[2m[36m(func pid=83696)[0m top5: 0.8264925373134329
[2m[36m(func pid=83696)[0m f1_micro: 0.2621268656716418
[2m[36m(func pid=83696)[0m f1_macro: 0.13055432835047148
[2m[36m(func pid=83696)[0m f1_weighted: 0.2517302061721003
[2m[36m(func pid=83696)[0m f1_per_class: [0.0, 0.276, 0.05, 0.1, 0.0, 0.078, 0.533, 0.089, 0.052, 0.128]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=85373)[0m top1: 0.134794776119403
[2m[36m(func pid=85373)[0m top5: 0.784981343283582
[2m[36m(func pid=85373)[0m f1_micro: 0.134794776119403
[2m[36m(func pid=85373)[0m f1_macro: 0.12247090533521358
[2m[36m(func pid=85373)[0m f1_weighted: 0.10759708492963282
[2m[36m(func pid=85373)[0m f1_per_class: [0.056, 0.122, 0.242, 0.016, 0.138, 0.086, 0.171, 0.239, 0.09, 0.063]
[2m[36m(func pid=85373)[0m 
== Status ==
Current time: 2024-01-07 02:47:47 (running for 00:23:48.42)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: 0.32525000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.085 |      0.254 |                   80 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  0.935 |      0.131 |                   59 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  1.714 |      0.122 |                   52 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054 | 0.0001 |       0.9  |         0.0001 |  2.371 |      0.138 |                   28 |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=79460)[0m top1: 0.3218283582089552
[2m[36m(func pid=79460)[0m top5: 0.8614738805970149
[2m[36m(func pid=79460)[0m f1_micro: 0.3218283582089552
[2m[36m(func pid=79460)[0m f1_macro: 0.2544129724203965
[2m[36m(func pid=79460)[0m f1_weighted: 0.3284304447386853
[2m[36m(func pid=79460)[0m f1_per_class: [0.152, 0.293, 0.051, 0.446, 0.138, 0.323, 0.262, 0.427, 0.194, 0.258]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 2.3573 | Steps: 2 | Val loss: 2.2670 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.7421 | Steps: 2 | Val loss: 14.9841 | Batch size: 32 | lr: 0.01 | Duration: 3.03s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 1.7704 | Steps: 2 | Val loss: 7.0934 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 80] | Train loss: 0.5599 | Steps: 2 | Val loss: 5.4089 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=91054)[0m top1: 0.1921641791044776
[2m[36m(func pid=91054)[0m top5: 0.6567164179104478
[2m[36m(func pid=91054)[0m f1_micro: 0.1921641791044776
[2m[36m(func pid=91054)[0m f1_macro: 0.14561119810228199
[2m[36m(func pid=91054)[0m f1_weighted: 0.17788134325603422
[2m[36m(func pid=91054)[0m f1_per_class: [0.036, 0.299, 0.1, 0.267, 0.0, 0.222, 0.0, 0.415, 0.0, 0.118]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=83696)[0m top1: 0.2537313432835821
[2m[36m(func pid=83696)[0m top5: 0.8017723880597015
[2m[36m(func pid=83696)[0m f1_micro: 0.2537313432835821
[2m[36m(func pid=83696)[0m f1_macro: 0.15672058164669705
[2m[36m(func pid=83696)[0m f1_weighted: 0.25841699650982475
[2m[36m(func pid=83696)[0m f1_per_class: [0.028, 0.272, 0.047, 0.136, 0.0, 0.024, 0.477, 0.46, 0.0, 0.123]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=85373)[0m top1: 0.14085820895522388
[2m[36m(func pid=85373)[0m top5: 0.7915111940298507
[2m[36m(func pid=85373)[0m f1_micro: 0.14085820895522388
[2m[36m(func pid=85373)[0m f1_macro: 0.1249394894616243
[2m[36m(func pid=85373)[0m f1_weighted: 0.11548029766757134
[2m[36m(func pid=85373)[0m f1_per_class: [0.051, 0.106, 0.264, 0.052, 0.168, 0.043, 0.191, 0.239, 0.071, 0.065]
[2m[36m(func pid=85373)[0m 
== Status ==
Current time: 2024-01-07 02:47:52 (running for 00:23:53.68)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: 0.32525000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.56  |      0.223 |                   81 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  0.742 |      0.157 |                   60 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  1.77  |      0.125 |                   53 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054 | 0.0001 |       0.9  |         0.0001 |  2.357 |      0.146 |                   29 |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=79460)[0m top1: 0.2658582089552239
[2m[36m(func pid=79460)[0m top5: 0.8101679104477612
[2m[36m(func pid=79460)[0m f1_micro: 0.2658582089552239
[2m[36m(func pid=79460)[0m f1_macro: 0.22321367788611468
[2m[36m(func pid=79460)[0m f1_weighted: 0.2705549460965772
[2m[36m(func pid=79460)[0m f1_per_class: [0.122, 0.291, 0.065, 0.345, 0.155, 0.282, 0.188, 0.409, 0.186, 0.19]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 2.3668 | Steps: 2 | Val loss: 2.2659 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.1852 | Steps: 2 | Val loss: 16.3850 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 6.6345 | Steps: 2 | Val loss: 7.8944 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 81] | Train loss: 0.3168 | Steps: 2 | Val loss: 9.1268 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=91054)[0m top1: 0.19682835820895522
[2m[36m(func pid=91054)[0m top5: 0.6609141791044776
[2m[36m(func pid=91054)[0m f1_micro: 0.1968283582089552
[2m[36m(func pid=91054)[0m f1_macro: 0.1522527306400499
[2m[36m(func pid=91054)[0m f1_weighted: 0.1875253354841915
[2m[36m(func pid=91054)[0m f1_per_class: [0.037, 0.324, 0.106, 0.272, 0.0, 0.264, 0.0, 0.394, 0.0, 0.125]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=83696)[0m top1: 0.20475746268656717
[2m[36m(func pid=83696)[0m top5: 0.7513992537313433
[2m[36m(func pid=83696)[0m f1_micro: 0.20475746268656717
[2m[36m(func pid=83696)[0m f1_macro: 0.13592594224079363
[2m[36m(func pid=83696)[0m f1_weighted: 0.20277205187807598
[2m[36m(func pid=83696)[0m f1_per_class: [0.018, 0.258, 0.046, 0.144, 0.0, 0.0, 0.303, 0.441, 0.0, 0.149]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=85373)[0m top1: 0.1478544776119403
[2m[36m(func pid=85373)[0m top5: 0.7742537313432836
[2m[36m(func pid=85373)[0m f1_micro: 0.1478544776119403
[2m[36m(func pid=85373)[0m f1_macro: 0.11591062949839115
[2m[36m(func pid=85373)[0m f1_weighted: 0.12393121355318945
[2m[36m(func pid=85373)[0m f1_per_class: [0.043, 0.026, 0.247, 0.149, 0.182, 0.029, 0.191, 0.227, 0.0, 0.065]
[2m[36m(func pid=85373)[0m 
== Status ==
Current time: 2024-01-07 02:47:58 (running for 00:23:58.93)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: 0.32525000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.317 |      0.175 |                   82 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  0.185 |      0.136 |                   61 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  6.635 |      0.116 |                   54 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054 | 0.0001 |       0.9  |         0.0001 |  2.367 |      0.152 |                   30 |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=79460)[0m top1: 0.17397388059701493
[2m[36m(func pid=79460)[0m top5: 0.6338619402985075
[2m[36m(func pid=79460)[0m f1_micro: 0.17397388059701493
[2m[36m(func pid=79460)[0m f1_macro: 0.17497406667290613
[2m[36m(func pid=79460)[0m f1_weighted: 0.1912064088578719
[2m[36m(func pid=79460)[0m f1_per_class: [0.058, 0.272, 0.07, 0.167, 0.189, 0.192, 0.142, 0.435, 0.118, 0.106]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 2.3600 | Steps: 2 | Val loss: 2.2669 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.3218 | Steps: 2 | Val loss: 16.0153 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 1.5896 | Steps: 2 | Val loss: 7.7716 | Batch size: 32 | lr: 0.1 | Duration: 3.04s
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 82] | Train loss: 0.2957 | Steps: 2 | Val loss: 12.7093 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=83696)[0m top1: 0.18236940298507462
[2m[36m(func pid=83696)[0m top5: 0.7644589552238806
[2m[36m(func pid=83696)[0m f1_micro: 0.18236940298507462
[2m[36m(func pid=83696)[0m f1_macro: 0.11653752874325587
[2m[36m(func pid=83696)[0m f1_weighted: 0.15434791845047235
[2m[36m(func pid=83696)[0m f1_per_class: [0.011, 0.291, 0.048, 0.14, 0.0, 0.008, 0.131, 0.402, 0.0, 0.135]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=91054)[0m top1: 0.19402985074626866
[2m[36m(func pid=91054)[0m top5: 0.6665111940298507
[2m[36m(func pid=91054)[0m f1_micro: 0.19402985074626866
[2m[36m(func pid=91054)[0m f1_macro: 0.14984652879770052
[2m[36m(func pid=91054)[0m f1_weighted: 0.18714199529482997
[2m[36m(func pid=91054)[0m f1_per_class: [0.041, 0.328, 0.111, 0.256, 0.0, 0.3, 0.0, 0.394, 0.0, 0.07]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=85373)[0m top1: 0.1837686567164179
[2m[36m(func pid=85373)[0m top5: 0.773320895522388
[2m[36m(func pid=85373)[0m f1_micro: 0.18376865671641787
[2m[36m(func pid=85373)[0m f1_macro: 0.13652733942766687
[2m[36m(func pid=85373)[0m f1_weighted: 0.1695358687454346
[2m[36m(func pid=85373)[0m f1_per_class: [0.042, 0.026, 0.286, 0.318, 0.183, 0.035, 0.183, 0.221, 0.0, 0.07]
[2m[36m(func pid=85373)[0m 
== Status ==
Current time: 2024-01-07 02:48:03 (running for 00:24:04.21)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: 0.32525000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.296 |      0.15  |                   83 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  0.322 |      0.117 |                   62 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  1.59  |      0.137 |                   55 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054 | 0.0001 |       0.9  |         0.0001 |  2.36  |      0.15  |                   31 |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=79460)[0m top1: 0.12220149253731344
[2m[36m(func pid=79460)[0m top5: 0.5289179104477612
[2m[36m(func pid=79460)[0m f1_micro: 0.12220149253731344
[2m[36m(func pid=79460)[0m f1_macro: 0.1503746600082034
[2m[36m(func pid=79460)[0m f1_weighted: 0.14182088615059962
[2m[36m(func pid=79460)[0m f1_per_class: [0.044, 0.2, 0.072, 0.099, 0.224, 0.13, 0.108, 0.437, 0.109, 0.081]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 2.4369 | Steps: 2 | Val loss: 2.2667 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.3765 | Steps: 2 | Val loss: 15.2125 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 1.7479 | Steps: 2 | Val loss: 7.1922 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 83] | Train loss: 0.2579 | Steps: 2 | Val loss: 15.5059 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=91054)[0m top1: 0.18983208955223882
[2m[36m(func pid=91054)[0m top5: 0.6693097014925373
[2m[36m(func pid=91054)[0m f1_micro: 0.18983208955223882
[2m[36m(func pid=91054)[0m f1_macro: 0.14730683879919476
[2m[36m(func pid=91054)[0m f1_weighted: 0.18744709545213395
[2m[36m(func pid=91054)[0m f1_per_class: [0.04, 0.329, 0.115, 0.261, 0.0, 0.296, 0.0, 0.385, 0.0, 0.047]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=83696)[0m top1: 0.19309701492537312
[2m[36m(func pid=83696)[0m top5: 0.8013059701492538
[2m[36m(func pid=83696)[0m f1_micro: 0.19309701492537315
[2m[36m(func pid=83696)[0m f1_macro: 0.13643166570015805
[2m[36m(func pid=83696)[0m f1_weighted: 0.1816424802899169
[2m[36m(func pid=83696)[0m f1_per_class: [0.036, 0.354, 0.047, 0.144, 0.0, 0.129, 0.139, 0.349, 0.048, 0.117]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=85373)[0m top1: 0.18796641791044777
[2m[36m(func pid=85373)[0m top5: 0.792910447761194
[2m[36m(func pid=85373)[0m f1_micro: 0.18796641791044777
[2m[36m(func pid=85373)[0m f1_macro: 0.1506033065600252
[2m[36m(func pid=85373)[0m f1_weighted: 0.18212293806777918
[2m[36m(func pid=85373)[0m f1_per_class: [0.047, 0.089, 0.324, 0.328, 0.153, 0.102, 0.155, 0.218, 0.0, 0.091]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=79460)[0m top1: 0.10354477611940298
[2m[36m(func pid=79460)[0m top5: 0.47574626865671643
[2m[36m(func pid=79460)[0m f1_micro: 0.10354477611940298
[2m[36m(func pid=79460)[0m f1_macro: 0.13833615376120414
[2m[36m(func pid=79460)[0m f1_weighted: 0.11782726004640912
[2m[36m(func pid=79460)[0m f1_per_class: [0.046, 0.167, 0.081, 0.101, 0.293, 0.05, 0.082, 0.408, 0.093, 0.064]
[2m[36m(func pid=79460)[0m 
== Status ==
Current time: 2024-01-07 02:48:08 (running for 00:24:09.38)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: 0.32525000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.258 |      0.138 |                   84 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  0.376 |      0.136 |                   63 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  1.748 |      0.151 |                   56 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054 | 0.0001 |       0.9  |         0.0001 |  2.437 |      0.147 |                   32 |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 2.3597 | Steps: 2 | Val loss: 2.2648 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.2206 | Steps: 2 | Val loss: 14.5558 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 1.6317 | Steps: 2 | Val loss: 6.5134 | Batch size: 32 | lr: 0.1 | Duration: 3.01s
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 84] | Train loss: 0.4148 | Steps: 2 | Val loss: 15.1674 | Batch size: 32 | lr: 0.001 | Duration: 2.72s
[2m[36m(func pid=91054)[0m top1: 0.18936567164179105
[2m[36m(func pid=91054)[0m top5: 0.6842350746268657
[2m[36m(func pid=91054)[0m f1_micro: 0.18936567164179105
[2m[36m(func pid=91054)[0m f1_macro: 0.15018147668556578
[2m[36m(func pid=91054)[0m f1_weighted: 0.18669859014696308
[2m[36m(func pid=91054)[0m f1_per_class: [0.041, 0.34, 0.128, 0.245, 0.0, 0.308, 0.0, 0.388, 0.0, 0.052]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=83696)[0m top1: 0.22761194029850745
[2m[36m(func pid=83696)[0m top5: 0.792910447761194
[2m[36m(func pid=83696)[0m f1_micro: 0.22761194029850745
[2m[36m(func pid=83696)[0m f1_macro: 0.1610523966821236
[2m[36m(func pid=83696)[0m f1_weighted: 0.24880607743608607
[2m[36m(func pid=83696)[0m f1_per_class: [0.034, 0.388, 0.049, 0.151, 0.0, 0.058, 0.369, 0.311, 0.062, 0.189]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=85373)[0m top1: 0.16511194029850745
[2m[36m(func pid=85373)[0m top5: 0.8115671641791045
[2m[36m(func pid=85373)[0m f1_micro: 0.16511194029850745
[2m[36m(func pid=85373)[0m f1_macro: 0.14546047800391484
[2m[36m(func pid=85373)[0m f1_weighted: 0.15833424773287808
[2m[36m(func pid=85373)[0m f1_per_class: [0.057, 0.157, 0.338, 0.243, 0.154, 0.079, 0.122, 0.222, 0.0, 0.082]
[2m[36m(func pid=85373)[0m 
== Status ==
Current time: 2024-01-07 02:48:13 (running for 00:24:14.40)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: 0.32525000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.415 |      0.157 |                   85 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  0.221 |      0.161 |                   64 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  1.632 |      0.145 |                   57 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054 | 0.0001 |       0.9  |         0.0001 |  2.36  |      0.15  |                   33 |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=79460)[0m top1: 0.13292910447761194
[2m[36m(func pid=79460)[0m top5: 0.5298507462686567
[2m[36m(func pid=79460)[0m f1_micro: 0.13292910447761194
[2m[36m(func pid=79460)[0m f1_macro: 0.157346067725811
[2m[36m(func pid=79460)[0m f1_weighted: 0.14369357125494647
[2m[36m(func pid=79460)[0m f1_per_class: [0.053, 0.227, 0.091, 0.087, 0.254, 0.1, 0.117, 0.444, 0.118, 0.083]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 2.3564 | Steps: 2 | Val loss: 2.2545 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.7147 | Steps: 2 | Val loss: 14.2362 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 1.5812 | Steps: 2 | Val loss: 5.5285 | Batch size: 32 | lr: 0.1 | Duration: 2.99s
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 85] | Train loss: 0.4024 | Steps: 2 | Val loss: 13.9225 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=91054)[0m top1: 0.20009328358208955
[2m[36m(func pid=91054)[0m top5: 0.7052238805970149
[2m[36m(func pid=91054)[0m f1_micro: 0.20009328358208955
[2m[36m(func pid=91054)[0m f1_macro: 0.1678144676066693
[2m[36m(func pid=91054)[0m f1_weighted: 0.19465732623228163
[2m[36m(func pid=91054)[0m f1_per_class: [0.045, 0.368, 0.151, 0.237, 0.053, 0.341, 0.0, 0.397, 0.0, 0.086]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=83696)[0m top1: 0.19962686567164178
[2m[36m(func pid=83696)[0m top5: 0.8078358208955224
[2m[36m(func pid=83696)[0m f1_micro: 0.1996268656716418
[2m[36m(func pid=83696)[0m f1_macro: 0.1526934518573034
[2m[36m(func pid=83696)[0m f1_weighted: 0.21335670524590214
[2m[36m(func pid=83696)[0m f1_per_class: [0.037, 0.372, 0.055, 0.103, 0.028, 0.044, 0.31, 0.293, 0.082, 0.203]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=85373)[0m top1: 0.146455223880597
[2m[36m(func pid=85373)[0m top5: 0.8218283582089553
[2m[36m(func pid=85373)[0m f1_micro: 0.146455223880597
[2m[36m(func pid=85373)[0m f1_macro: 0.1373272988653116
[2m[36m(func pid=85373)[0m f1_weighted: 0.13364523250451601
[2m[36m(func pid=85373)[0m f1_per_class: [0.062, 0.167, 0.357, 0.162, 0.139, 0.079, 0.107, 0.231, 0.0, 0.068]
[2m[36m(func pid=85373)[0m 
== Status ==
Current time: 2024-01-07 02:48:18 (running for 00:24:19.74)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: 0.32525000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.402 |      0.187 |                   86 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  0.715 |      0.153 |                   65 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  1.581 |      0.137 |                   58 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054 | 0.0001 |       0.9  |         0.0001 |  2.356 |      0.168 |                   34 |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=79460)[0m top1: 0.17164179104477612
[2m[36m(func pid=79460)[0m top5: 0.6096082089552238
[2m[36m(func pid=79460)[0m f1_micro: 0.17164179104477612
[2m[36m(func pid=79460)[0m f1_macro: 0.18736646125648126
[2m[36m(func pid=79460)[0m f1_weighted: 0.17725389902685396
[2m[36m(func pid=79460)[0m f1_per_class: [0.053, 0.31, 0.098, 0.077, 0.231, 0.22, 0.15, 0.38, 0.144, 0.212]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 2.2753 | Steps: 2 | Val loss: 2.2463 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 1.8552 | Steps: 2 | Val loss: 14.0981 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 1.6325 | Steps: 2 | Val loss: 4.5425 | Batch size: 32 | lr: 0.1 | Duration: 3.01s
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 86] | Train loss: 0.1774 | Steps: 2 | Val loss: 12.5400 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=91054)[0m top1: 0.20615671641791045
[2m[36m(func pid=91054)[0m top5: 0.7234141791044776
[2m[36m(func pid=91054)[0m f1_micro: 0.20615671641791045
[2m[36m(func pid=91054)[0m f1_macro: 0.1768008163151741
[2m[36m(func pid=91054)[0m f1_weighted: 0.20007565943657454
[2m[36m(func pid=91054)[0m f1_per_class: [0.045, 0.368, 0.15, 0.231, 0.062, 0.376, 0.006, 0.413, 0.0, 0.118]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=83696)[0m top1: 0.14598880597014927
[2m[36m(func pid=83696)[0m top5: 0.8120335820895522
[2m[36m(func pid=83696)[0m f1_micro: 0.14598880597014927
[2m[36m(func pid=83696)[0m f1_macro: 0.11696116466192141
[2m[36m(func pid=83696)[0m f1_weighted: 0.122768160207679
[2m[36m(func pid=83696)[0m f1_per_class: [0.056, 0.324, 0.07, 0.076, 0.0, 0.045, 0.068, 0.265, 0.022, 0.244]
[2m[36m(func pid=83696)[0m 
== Status ==
Current time: 2024-01-07 02:48:23 (running for 00:24:24.78)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: 0.32525000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.402 |      0.187 |                   86 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  1.855 |      0.117 |                   66 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  1.633 |      0.124 |                   59 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054 | 0.0001 |       0.9  |         0.0001 |  2.275 |      0.177 |                   35 |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=85373)[0m top1: 0.14412313432835822
[2m[36m(func pid=85373)[0m top5: 0.8353544776119403
[2m[36m(func pid=85373)[0m f1_micro: 0.14412313432835822
[2m[36m(func pid=85373)[0m f1_macro: 0.12364251795928376
[2m[36m(func pid=85373)[0m f1_weighted: 0.13311276790359056
[2m[36m(func pid=85373)[0m f1_per_class: [0.044, 0.164, 0.25, 0.131, 0.121, 0.057, 0.143, 0.259, 0.0, 0.067]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=79460)[0m top1: 0.17537313432835822
[2m[36m(func pid=79460)[0m top5: 0.6371268656716418
[2m[36m(func pid=79460)[0m f1_micro: 0.17537313432835822
[2m[36m(func pid=79460)[0m f1_macro: 0.19220081517353976
[2m[36m(func pid=79460)[0m f1_weighted: 0.17489254980573707
[2m[36m(func pid=79460)[0m f1_per_class: [0.057, 0.354, 0.101, 0.071, 0.159, 0.227, 0.123, 0.344, 0.142, 0.344]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 2.2683 | Steps: 2 | Val loss: 2.2407 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.9655 | Steps: 2 | Val loss: 11.3018 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 1.9312 | Steps: 2 | Val loss: 3.9736 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 87] | Train loss: 0.1604 | Steps: 2 | Val loss: 10.9254 | Batch size: 32 | lr: 0.001 | Duration: 2.73s
[2m[36m(func pid=91054)[0m top1: 0.20522388059701493
[2m[36m(func pid=91054)[0m top5: 0.7341417910447762
[2m[36m(func pid=91054)[0m f1_micro: 0.20522388059701493
[2m[36m(func pid=91054)[0m f1_macro: 0.18825109948745822
[2m[36m(func pid=91054)[0m f1_weighted: 0.19838391061963284
[2m[36m(func pid=91054)[0m f1_per_class: [0.046, 0.37, 0.158, 0.219, 0.104, 0.367, 0.009, 0.417, 0.0, 0.192]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=83696)[0m top1: 0.16417910447761194
[2m[36m(func pid=83696)[0m top5: 0.8222947761194029
[2m[36m(func pid=83696)[0m f1_micro: 0.16417910447761194
[2m[36m(func pid=83696)[0m f1_macro: 0.1345794153282994
[2m[36m(func pid=83696)[0m f1_weighted: 0.1292176586998055
[2m[36m(func pid=83696)[0m f1_per_class: [0.078, 0.35, 0.182, 0.083, 0.0, 0.022, 0.073, 0.257, 0.019, 0.282]
[2m[36m(func pid=83696)[0m 
== Status ==
Current time: 2024-01-07 02:48:29 (running for 00:24:30.20)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: 0.32525000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.177 |      0.192 |                   87 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  0.966 |      0.135 |                   67 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  1.931 |      0.116 |                   60 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054 | 0.0001 |       0.9  |         0.0001 |  2.268 |      0.188 |                   36 |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=79460)[0m top1: 0.1730410447761194
[2m[36m(func pid=79460)[0m top5: 0.6609141791044776
[2m[36m(func pid=79460)[0m f1_micro: 0.1730410447761194
[2m[36m(func pid=79460)[0m f1_macro: 0.18628856618129244
[2m[36m(func pid=79460)[0m f1_weighted: 0.1713715428095238
[2m[36m(func pid=79460)[0m f1_per_class: [0.048, 0.4, 0.09, 0.088, 0.125, 0.175, 0.096, 0.314, 0.121, 0.406]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=85373)[0m top1: 0.1553171641791045
[2m[36m(func pid=85373)[0m top5: 0.8414179104477612
[2m[36m(func pid=85373)[0m f1_micro: 0.1553171641791045
[2m[36m(func pid=85373)[0m f1_macro: 0.11582231429100028
[2m[36m(func pid=85373)[0m f1_weighted: 0.14792835423349127
[2m[36m(func pid=85373)[0m f1_per_class: [0.024, 0.165, 0.103, 0.059, 0.111, 0.093, 0.241, 0.316, 0.0, 0.049]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 2.2460 | Steps: 2 | Val loss: 2.2344 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 1.5843 | Steps: 2 | Val loss: 10.1449 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 88] | Train loss: 0.3734 | Steps: 2 | Val loss: 9.2332 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 1.8157 | Steps: 2 | Val loss: 4.1460 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
[2m[36m(func pid=91054)[0m top1: 0.20708955223880596
[2m[36m(func pid=91054)[0m top5: 0.7444029850746269
[2m[36m(func pid=91054)[0m f1_micro: 0.20708955223880596
[2m[36m(func pid=91054)[0m f1_macro: 0.19055203360805606
[2m[36m(func pid=91054)[0m f1_weighted: 0.20237043965230922
[2m[36m(func pid=91054)[0m f1_per_class: [0.046, 0.381, 0.169, 0.221, 0.101, 0.362, 0.012, 0.434, 0.0, 0.179]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=83696)[0m top1: 0.1646455223880597
[2m[36m(func pid=83696)[0m top5: 0.8274253731343284
[2m[36m(func pid=83696)[0m f1_micro: 0.1646455223880597
[2m[36m(func pid=83696)[0m f1_macro: 0.10995100291486345
[2m[36m(func pid=83696)[0m f1_weighted: 0.1254134781648027
[2m[36m(func pid=83696)[0m f1_per_class: [0.075, 0.334, 0.0, 0.045, 0.0, 0.02, 0.111, 0.268, 0.015, 0.232]
[2m[36m(func pid=83696)[0m 
== Status ==
Current time: 2024-01-07 02:48:34 (running for 00:24:35.43)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: 0.32525000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.373 |      0.189 |                   89 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  1.584 |      0.11  |                   68 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  1.931 |      0.116 |                   60 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054 | 0.0001 |       0.9  |         0.0001 |  2.246 |      0.191 |                   37 |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=79460)[0m top1: 0.1828358208955224
[2m[36m(func pid=79460)[0m top5: 0.7000932835820896
[2m[36m(func pid=79460)[0m f1_micro: 0.1828358208955224
[2m[36m(func pid=79460)[0m f1_macro: 0.18871059043118846
[2m[36m(func pid=79460)[0m f1_weighted: 0.1839496792855644
[2m[36m(func pid=79460)[0m f1_per_class: [0.052, 0.423, 0.078, 0.11, 0.112, 0.13, 0.122, 0.312, 0.122, 0.426]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=85373)[0m top1: 0.16371268656716417
[2m[36m(func pid=85373)[0m top5: 0.8227611940298507
[2m[36m(func pid=85373)[0m f1_micro: 0.16371268656716417
[2m[36m(func pid=85373)[0m f1_macro: 0.11783022320331435
[2m[36m(func pid=85373)[0m f1_weighted: 0.14897626824221286
[2m[36m(func pid=85373)[0m f1_per_class: [0.068, 0.108, 0.118, 0.032, 0.114, 0.035, 0.317, 0.337, 0.0, 0.049]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 2.2843 | Steps: 2 | Val loss: 2.2337 | Batch size: 32 | lr: 0.0001 | Duration: 3.01s
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 1.4109 | Steps: 2 | Val loss: 9.4251 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 89] | Train loss: 0.2699 | Steps: 2 | Val loss: 8.2226 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 2.0925 | Steps: 2 | Val loss: 4.2879 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=91054)[0m top1: 0.20289179104477612
[2m[36m(func pid=91054)[0m top5: 0.7467350746268657
[2m[36m(func pid=91054)[0m f1_micro: 0.20289179104477612
[2m[36m(func pid=91054)[0m f1_macro: 0.19061265142148212
[2m[36m(func pid=91054)[0m f1_weighted: 0.19688085185678872
[2m[36m(func pid=91054)[0m f1_per_class: [0.046, 0.37, 0.168, 0.211, 0.105, 0.361, 0.009, 0.436, 0.0, 0.2]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=83696)[0m top1: 0.17583955223880596
[2m[36m(func pid=83696)[0m top5: 0.8414179104477612
[2m[36m(func pid=83696)[0m f1_micro: 0.17583955223880596
[2m[36m(func pid=83696)[0m f1_macro: 0.12413738347694861
[2m[36m(func pid=83696)[0m f1_weighted: 0.14174901341000576
[2m[36m(func pid=83696)[0m f1_per_class: [0.098, 0.304, 0.0, 0.038, 0.0, 0.041, 0.171, 0.295, 0.023, 0.271]
[2m[36m(func pid=83696)[0m 
== Status ==
Current time: 2024-01-07 02:48:39 (running for 00:24:40.66)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: 0.32525000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.27  |      0.185 |                   90 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  1.411 |      0.124 |                   69 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  1.816 |      0.118 |                   61 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054 | 0.0001 |       0.9  |         0.0001 |  2.284 |      0.191 |                   38 |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=79460)[0m top1: 0.18889925373134328
[2m[36m(func pid=79460)[0m top5: 0.7406716417910447
[2m[36m(func pid=79460)[0m f1_micro: 0.18889925373134325
[2m[36m(func pid=79460)[0m f1_macro: 0.1851945588935915
[2m[36m(func pid=79460)[0m f1_weighted: 0.1945431122485039
[2m[36m(func pid=79460)[0m f1_per_class: [0.056, 0.418, 0.062, 0.164, 0.06, 0.096, 0.121, 0.32, 0.141, 0.415]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=85373)[0m top1: 0.15904850746268656
[2m[36m(func pid=85373)[0m top5: 0.8036380597014925
[2m[36m(func pid=85373)[0m f1_micro: 0.15904850746268656
[2m[36m(func pid=85373)[0m f1_macro: 0.12066738605287497
[2m[36m(func pid=85373)[0m f1_weighted: 0.13800024450763676
[2m[36m(func pid=85373)[0m f1_per_class: [0.012, 0.082, 0.158, 0.023, 0.131, 0.034, 0.299, 0.324, 0.086, 0.058]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 2.2917 | Steps: 2 | Val loss: 2.2288 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.9391 | Steps: 2 | Val loss: 10.4277 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 90] | Train loss: 0.4722 | Steps: 2 | Val loss: 8.2059 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 1.5248 | Steps: 2 | Val loss: 5.4693 | Batch size: 32 | lr: 0.1 | Duration: 3.02s
[2m[36m(func pid=91054)[0m top1: 0.20569029850746268
[2m[36m(func pid=91054)[0m top5: 0.7490671641791045
[2m[36m(func pid=91054)[0m f1_micro: 0.20569029850746268
[2m[36m(func pid=91054)[0m f1_macro: 0.18970621533074178
[2m[36m(func pid=91054)[0m f1_weighted: 0.19841863130042703
[2m[36m(func pid=91054)[0m f1_per_class: [0.047, 0.379, 0.175, 0.211, 0.108, 0.361, 0.009, 0.442, 0.0, 0.165]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=83696)[0m top1: 0.20475746268656717
[2m[36m(func pid=83696)[0m top5: 0.8381529850746269
[2m[36m(func pid=83696)[0m f1_micro: 0.20475746268656717
[2m[36m(func pid=83696)[0m f1_macro: 0.15069793192318667
[2m[36m(func pid=83696)[0m f1_weighted: 0.1945490568893957
[2m[36m(func pid=83696)[0m f1_per_class: [0.101, 0.285, 0.0, 0.069, 0.0, 0.103, 0.295, 0.341, 0.056, 0.257]
[2m[36m(func pid=83696)[0m 
== Status ==
Current time: 2024-01-07 02:48:45 (running for 00:24:45.94)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: 0.32525000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.472 |      0.174 |                   91 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  0.939 |      0.151 |                   70 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  2.092 |      0.121 |                   62 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054 | 0.0001 |       0.9  |         0.0001 |  2.292 |      0.19  |                   39 |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=79460)[0m top1: 0.18423507462686567
[2m[36m(func pid=79460)[0m top5: 0.7868470149253731
[2m[36m(func pid=79460)[0m f1_micro: 0.1842350746268657
[2m[36m(func pid=79460)[0m f1_macro: 0.17413897888180035
[2m[36m(func pid=79460)[0m f1_weighted: 0.19036276149743742
[2m[36m(func pid=79460)[0m f1_per_class: [0.047, 0.367, 0.059, 0.146, 0.081, 0.074, 0.158, 0.348, 0.152, 0.308]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=85373)[0m top1: 0.14085820895522388
[2m[36m(func pid=85373)[0m top5: 0.7756529850746269
[2m[36m(func pid=85373)[0m f1_micro: 0.14085820895522388
[2m[36m(func pid=85373)[0m f1_macro: 0.14138707556328195
[2m[36m(func pid=85373)[0m f1_weighted: 0.11065381132735738
[2m[36m(func pid=85373)[0m f1_per_class: [0.058, 0.069, 0.385, 0.01, 0.148, 0.102, 0.206, 0.248, 0.081, 0.108]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 2.2713 | Steps: 2 | Val loss: 2.2305 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.9808 | Steps: 2 | Val loss: 16.8841 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 91] | Train loss: 0.3371 | Steps: 2 | Val loss: 9.2279 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 1.8516 | Steps: 2 | Val loss: 6.8607 | Batch size: 32 | lr: 0.1 | Duration: 2.78s
[2m[36m(func pid=91054)[0m top1: 0.19962686567164178
[2m[36m(func pid=91054)[0m top5: 0.7509328358208955
[2m[36m(func pid=91054)[0m f1_micro: 0.1996268656716418
[2m[36m(func pid=91054)[0m f1_macro: 0.17750288166356948
[2m[36m(func pid=91054)[0m f1_weighted: 0.19641030475133694
[2m[36m(func pid=91054)[0m f1_per_class: [0.048, 0.362, 0.163, 0.212, 0.08, 0.372, 0.012, 0.433, 0.0, 0.092]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=83696)[0m top1: 0.2271455223880597
[2m[36m(func pid=83696)[0m top5: 0.8003731343283582
[2m[36m(func pid=83696)[0m f1_micro: 0.2271455223880597
[2m[36m(func pid=83696)[0m f1_macro: 0.1620946857941371
[2m[36m(func pid=83696)[0m f1_weighted: 0.24286019016314894
[2m[36m(func pid=83696)[0m f1_per_class: [0.08, 0.231, 0.0, 0.068, 0.054, 0.174, 0.464, 0.341, 0.088, 0.122]
[2m[36m(func pid=83696)[0m 
== Status ==
Current time: 2024-01-07 02:48:50 (running for 00:24:51.29)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: 0.32525000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.337 |      0.176 |                   92 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  0.981 |      0.162 |                   71 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  1.525 |      0.141 |                   63 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054 | 0.0001 |       0.9  |         0.0001 |  2.271 |      0.178 |                   40 |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=79460)[0m top1: 0.18470149253731344
[2m[36m(func pid=79460)[0m top5: 0.7863805970149254
[2m[36m(func pid=79460)[0m f1_micro: 0.18470149253731344
[2m[36m(func pid=79460)[0m f1_macro: 0.17566980097668544
[2m[36m(func pid=79460)[0m f1_weighted: 0.19633695431057094
[2m[36m(func pid=79460)[0m f1_per_class: [0.048, 0.335, 0.06, 0.149, 0.077, 0.096, 0.185, 0.355, 0.152, 0.3]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=85373)[0m top1: 0.12406716417910447
[2m[36m(func pid=85373)[0m top5: 0.7607276119402985
[2m[36m(func pid=85373)[0m f1_micro: 0.12406716417910447
[2m[36m(func pid=85373)[0m f1_macro: 0.1374703205181606
[2m[36m(func pid=85373)[0m f1_weighted: 0.09127407152108655
[2m[36m(func pid=85373)[0m f1_per_class: [0.067, 0.088, 0.377, 0.01, 0.208, 0.125, 0.128, 0.217, 0.064, 0.091]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 2.2414 | Steps: 2 | Val loss: 2.2248 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.9401 | Steps: 2 | Val loss: 25.7545 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 92] | Train loss: 0.6815 | Steps: 2 | Val loss: 9.5975 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 1.6391 | Steps: 2 | Val loss: 7.0800 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=91054)[0m top1: 0.19916044776119404
[2m[36m(func pid=91054)[0m top5: 0.7551305970149254
[2m[36m(func pid=91054)[0m f1_micro: 0.19916044776119404
[2m[36m(func pid=91054)[0m f1_macro: 0.1765432960149323
[2m[36m(func pid=91054)[0m f1_weighted: 0.19477124173060498
[2m[36m(func pid=91054)[0m f1_per_class: [0.05, 0.36, 0.155, 0.211, 0.099, 0.355, 0.015, 0.432, 0.0, 0.088]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=83696)[0m top1: 0.22014925373134328
[2m[36m(func pid=83696)[0m top5: 0.7765858208955224
[2m[36m(func pid=83696)[0m f1_micro: 0.22014925373134328
[2m[36m(func pid=83696)[0m f1_macro: 0.17532604851042255
[2m[36m(func pid=83696)[0m f1_weighted: 0.2516060234979557
[2m[36m(func pid=83696)[0m f1_per_class: [0.072, 0.208, 0.0, 0.098, 0.118, 0.229, 0.452, 0.348, 0.112, 0.117]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=79460)[0m top1: 0.17863805970149255
[2m[36m(func pid=79460)[0m top5: 0.7854477611940298
[2m[36m(func pid=79460)[0m f1_micro: 0.17863805970149257
[2m[36m(func pid=79460)[0m f1_macro: 0.18366206633347368
[2m[36m(func pid=79460)[0m f1_weighted: 0.18476134763122123
[2m[36m(func pid=79460)[0m f1_per_class: [0.044, 0.336, 0.074, 0.146, 0.087, 0.134, 0.137, 0.332, 0.122, 0.426]
[2m[36m(func pid=79460)[0m 
== Status ==
Current time: 2024-01-07 02:48:56 (running for 00:24:56.88)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: 0.32525000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.681 |      0.184 |                   93 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  0.94  |      0.175 |                   72 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  1.639 |      0.136 |                   65 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054 | 0.0001 |       0.9  |         0.0001 |  2.241 |      0.177 |                   41 |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=85373)[0m top1: 0.1259328358208955
[2m[36m(func pid=85373)[0m top5: 0.7793843283582089
[2m[36m(func pid=85373)[0m f1_micro: 0.1259328358208955
[2m[36m(func pid=85373)[0m f1_macro: 0.13577880687107097
[2m[36m(func pid=85373)[0m f1_weighted: 0.0928820225555984
[2m[36m(func pid=85373)[0m f1_per_class: [0.068, 0.164, 0.367, 0.01, 0.23, 0.134, 0.087, 0.215, 0.082, 0.0]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 2.1662 | Steps: 2 | Val loss: 2.2181 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.4018 | Steps: 2 | Val loss: 31.7382 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 93] | Train loss: 0.9344 | Steps: 2 | Val loss: 9.5255 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 1.6540 | Steps: 2 | Val loss: 6.2055 | Batch size: 32 | lr: 0.1 | Duration: 2.78s
[2m[36m(func pid=91054)[0m top1: 0.20009328358208955
[2m[36m(func pid=91054)[0m top5: 0.7751865671641791
[2m[36m(func pid=91054)[0m f1_micro: 0.20009328358208955
[2m[36m(func pid=91054)[0m f1_macro: 0.1794064344301091
[2m[36m(func pid=91054)[0m f1_weighted: 0.19525166954968046
[2m[36m(func pid=91054)[0m f1_per_class: [0.051, 0.358, 0.153, 0.201, 0.103, 0.357, 0.027, 0.425, 0.0, 0.12]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=83696)[0m top1: 0.20055970149253732
[2m[36m(func pid=83696)[0m top5: 0.7667910447761194
[2m[36m(func pid=83696)[0m f1_micro: 0.20055970149253732
[2m[36m(func pid=83696)[0m f1_macro: 0.20022852133886904
[2m[36m(func pid=83696)[0m f1_weighted: 0.2309877844570513
[2m[36m(func pid=83696)[0m f1_per_class: [0.068, 0.21, 0.078, 0.102, 0.209, 0.293, 0.345, 0.353, 0.112, 0.234]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=79460)[0m top1: 0.19636194029850745
[2m[36m(func pid=79460)[0m top5: 0.7961753731343284
[2m[36m(func pid=79460)[0m f1_micro: 0.19636194029850748
[2m[36m(func pid=79460)[0m f1_macro: 0.18491254778698588
[2m[36m(func pid=79460)[0m f1_weighted: 0.1839667090862589
[2m[36m(func pid=79460)[0m f1_per_class: [0.068, 0.372, 0.072, 0.194, 0.101, 0.171, 0.056, 0.313, 0.132, 0.37]
[2m[36m(func pid=79460)[0m 
== Status ==
Current time: 2024-01-07 02:49:01 (running for 00:25:02.12)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: 0.32525000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.934 |      0.185 |                   94 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  0.402 |      0.2   |                   73 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  1.654 |      0.145 |                   66 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054 | 0.0001 |       0.9  |         0.0001 |  2.166 |      0.179 |                   42 |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=85373)[0m top1: 0.1357276119402985
[2m[36m(func pid=85373)[0m top5: 0.8036380597014925
[2m[36m(func pid=85373)[0m f1_micro: 0.1357276119402985
[2m[36m(func pid=85373)[0m f1_macro: 0.14518343534094097
[2m[36m(func pid=85373)[0m f1_weighted: 0.1034017926804484
[2m[36m(func pid=85373)[0m f1_per_class: [0.06, 0.247, 0.369, 0.013, 0.208, 0.167, 0.055, 0.233, 0.099, 0.0]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 2.2031 | Steps: 2 | Val loss: 2.2135 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.8688 | Steps: 2 | Val loss: 32.1316 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 94] | Train loss: 0.3183 | Steps: 2 | Val loss: 8.9652 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 1.7707 | Steps: 2 | Val loss: 4.8895 | Batch size: 32 | lr: 0.1 | Duration: 3.01s
[2m[36m(func pid=91054)[0m top1: 0.20382462686567165
[2m[36m(func pid=91054)[0m top5: 0.7877798507462687
[2m[36m(func pid=91054)[0m f1_micro: 0.20382462686567165
[2m[36m(func pid=91054)[0m f1_macro: 0.18618281588911484
[2m[36m(func pid=91054)[0m f1_weighted: 0.2012994443177052
[2m[36m(func pid=91054)[0m f1_per_class: [0.05, 0.349, 0.167, 0.21, 0.105, 0.358, 0.041, 0.43, 0.0, 0.152]
[2m[36m(func pid=83696)[0m top1: 0.1958955223880597
[2m[36m(func pid=83696)[0m top5: 0.7803171641791045
[2m[36m(func pid=83696)[0m f1_micro: 0.19589552238805974
[2m[36m(func pid=83696)[0m f1_macro: 0.20560143512010104
[2m[36m(func pid=83696)[0m f1_weighted: 0.2256694706337329
[2m[36m(func pid=83696)[0m f1_per_class: [0.072, 0.253, 0.075, 0.158, 0.216, 0.352, 0.229, 0.354, 0.071, 0.276]
[2m[36m(func pid=83696)[0m 
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=79460)[0m top1: 0.21222014925373134
[2m[36m(func pid=79460)[0m top5: 0.8041044776119403
[2m[36m(func pid=79460)[0m f1_micro: 0.21222014925373134
[2m[36m(func pid=79460)[0m f1_macro: 0.19551755453139175
[2m[36m(func pid=79460)[0m f1_weighted: 0.19900680858632067
[2m[36m(func pid=79460)[0m f1_per_class: [0.066, 0.427, 0.075, 0.23, 0.121, 0.184, 0.039, 0.311, 0.111, 0.393]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=85373)[0m top1: 0.1501865671641791
[2m[36m(func pid=85373)[0m top5: 0.8288246268656716
[2m[36m(func pid=85373)[0m f1_micro: 0.1501865671641791
[2m[36m(func pid=85373)[0m f1_macro: 0.15270875383358304
[2m[36m(func pid=85373)[0m f1_weighted: 0.12381136453898463
[2m[36m(func pid=85373)[0m f1_per_class: [0.054, 0.264, 0.343, 0.026, 0.177, 0.198, 0.083, 0.271, 0.112, 0.0]
== Status ==
Current time: 2024-01-07 02:49:06 (running for 00:25:07.56)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: 0.32525000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460 | 0.001  |       0.99 |         0.0001 |  0.318 |      0.196 |                   95 |
| train_6ed81_00010 | RUNNING    | 192.168.7.53:83696 | 0.01   |       0.99 |         0.0001 |  0.869 |      0.206 |                   74 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373 | 0.1    |       0.99 |         0.0001 |  1.771 |      0.153 |                   67 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054 | 0.0001 |       0.9  |         0.0001 |  2.203 |      0.186 |                   43 |
| train_6ed81_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305 | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679 | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098 | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517 | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782 | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934 | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121 | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614 | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 2.2014 | Steps: 2 | Val loss: 2.2097 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=83696)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 1.4502 | Steps: 2 | Val loss: 33.1475 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 95] | Train loss: 0.2753 | Steps: 2 | Val loss: 7.9449 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 1.4253 | Steps: 2 | Val loss: 4.3534 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=91054)[0m top1: 0.20335820895522388
[2m[36m(func pid=91054)[0m top5: 0.7957089552238806
[2m[36m(func pid=91054)[0m f1_micro: 0.20335820895522388
[2m[36m(func pid=91054)[0m f1_macro: 0.19147508913511174
[2m[36m(func pid=91054)[0m f1_weighted: 0.20161804699814925
[2m[36m(func pid=91054)[0m f1_per_class: [0.05, 0.348, 0.173, 0.189, 0.091, 0.35, 0.061, 0.44, 0.0, 0.212]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=83696)[0m top1: 0.19962686567164178
[2m[36m(func pid=83696)[0m top5: 0.7859141791044776
[2m[36m(func pid=83696)[0m f1_micro: 0.1996268656716418
[2m[36m(func pid=83696)[0m f1_macro: 0.1982037694061049
[2m[36m(func pid=83696)[0m f1_weighted: 0.23225903285366314
[2m[36m(func pid=83696)[0m f1_per_class: [0.073, 0.248, 0.038, 0.199, 0.205, 0.3, 0.235, 0.364, 0.074, 0.245]
[2m[36m(func pid=79460)[0m top1: 0.23227611940298507
[2m[36m(func pid=79460)[0m top5: 0.816231343283582
[2m[36m(func pid=79460)[0m f1_micro: 0.23227611940298507
[2m[36m(func pid=79460)[0m f1_macro: 0.21574396785874664
[2m[36m(func pid=79460)[0m f1_weighted: 0.22131866070228287
[2m[36m(func pid=79460)[0m f1_per_class: [0.1, 0.475, 0.079, 0.259, 0.134, 0.203, 0.045, 0.319, 0.12, 0.423]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=85373)[0m top1: 0.15485074626865672
[2m[36m(func pid=85373)[0m top5: 0.8339552238805971
[2m[36m(func pid=85373)[0m f1_micro: 0.15485074626865672
[2m[36m(func pid=85373)[0m f1_macro: 0.15991331121564084
[2m[36m(func pid=85373)[0m f1_weighted: 0.13741049410080888
[2m[36m(func pid=85373)[0m f1_per_class: [0.062, 0.181, 0.343, 0.056, 0.142, 0.197, 0.142, 0.295, 0.105, 0.077]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 2.2026 | Steps: 2 | Val loss: 2.2075 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 96] | Train loss: 0.4626 | Steps: 2 | Val loss: 7.4174 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 1.3944 | Steps: 2 | Val loss: 4.3349 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=91054)[0m top1: 0.20242537313432835
[2m[36m(func pid=91054)[0m top5: 0.7966417910447762
[2m[36m(func pid=91054)[0m f1_micro: 0.20242537313432832
[2m[36m(func pid=91054)[0m f1_macro: 0.19277974803378167
[2m[36m(func pid=91054)[0m f1_weighted: 0.20072753847042463
[2m[36m(func pid=91054)[0m f1_per_class: [0.048, 0.348, 0.158, 0.174, 0.096, 0.354, 0.07, 0.444, 0.0, 0.235]
[2m[36m(func pid=79460)[0m top1: 0.25093283582089554
[2m[36m(func pid=79460)[0m top5: 0.8129664179104478
[2m[36m(func pid=79460)[0m f1_micro: 0.25093283582089554
[2m[36m(func pid=79460)[0m f1_macro: 0.23688652984327024
[2m[36m(func pid=79460)[0m f1_weighted: 0.24673015076980845
[2m[36m(func pid=79460)[0m f1_per_class: [0.104, 0.5, 0.081, 0.267, 0.103, 0.276, 0.067, 0.363, 0.143, 0.464]
[2m[36m(func pid=85373)[0m top1: 0.15764925373134328
[2m[36m(func pid=85373)[0m top5: 0.8311567164179104
[2m[36m(func pid=85373)[0m f1_micro: 0.15764925373134328
[2m[36m(func pid=85373)[0m f1_macro: 0.16083173791882002
[2m[36m(func pid=85373)[0m f1_weighted: 0.13779824490708964
[2m[36m(func pid=85373)[0m f1_per_class: [0.057, 0.056, 0.324, 0.089, 0.109, 0.16, 0.189, 0.321, 0.128, 0.176]
== Status ==
Current time: 2024-01-07 02:49:12 (running for 00:25:13.04)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=10
Bracket: Iter 75.000: 0.3235
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (10 PENDING, 4 RUNNING, 10 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  0.275 |      0.216 |                   96 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  1.425 |      0.16  |                   68 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  2.201 |      0.191 |                   44 |
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (2 PENDING, 2 TERMINATED)


== Status ==
Current time: 2024-01-07 02:49:19 (running for 00:25:19.94)
Memory usage on this node: 23.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=10
Bracket: Iter 75.000: 0.3235
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (10 PENDING, 4 RUNNING, 10 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  0.463 |      0.237 |                   97 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  1.425 |      0.16  |                   68 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  2.201 |      0.191 |                   44 |
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (2 PENDING, 2 TERMINATED)


[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=101178)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=101178)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=101178)[0m Configuration completed!
[2m[36m(func pid=101178)[0m New optimizer parameters:
[2m[36m(func pid=101178)[0m SGD (
[2m[36m(func pid=101178)[0m Parameter Group 0
[2m[36m(func pid=101178)[0m     dampening: 0
[2m[36m(func pid=101178)[0m     differentiable: False
[2m[36m(func pid=101178)[0m     foreach: None
[2m[36m(func pid=101178)[0m     lr: 0.001
[2m[36m(func pid=101178)[0m     maximize: False
[2m[36m(func pid=101178)[0m     momentum: 0.9
[2m[36m(func pid=101178)[0m     nesterov: False
[2m[36m(func pid=101178)[0m     weight_decay: 0.0001
[2m[36m(func pid=101178)[0m )
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 97] | Train loss: 0.2917 | Steps: 2 | Val loss: 6.9527 | Batch size: 32 | lr: 0.001 | Duration: 3.03s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 1.7627 | Steps: 2 | Val loss: 4.6235 | Batch size: 32 | lr: 0.1 | Duration: 3.15s
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 2.1770 | Steps: 2 | Val loss: 2.2013 | Batch size: 32 | lr: 0.0001 | Duration: 3.17s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 3.1083 | Steps: 2 | Val loss: 2.3767 | Batch size: 32 | lr: 0.001 | Duration: 4.85s
== Status ==
Current time: 2024-01-07 02:49:24 (running for 00:25:24.97)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=10
Bracket: Iter 75.000: 0.3235
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (10 PENDING, 4 RUNNING, 10 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  0.463 |      0.237 |                   97 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  1.394 |      0.161 |                   69 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  2.203 |      0.193 |                   45 |
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (2 PENDING, 2 TERMINATED)


[2m[36m(func pid=79460)[0m top1: 0.25699626865671643
[2m[36m(func pid=79460)[0m top5: 0.8134328358208955
[2m[36m(func pid=79460)[0m f1_micro: 0.25699626865671643
[2m[36m(func pid=79460)[0m f1_macro: 0.24195174877192888
[2m[36m(func pid=79460)[0m f1_weighted: 0.2592960452757106
[2m[36m(func pid=79460)[0m f1_per_class: [0.121, 0.465, 0.092, 0.282, 0.061, 0.295, 0.102, 0.387, 0.158, 0.456]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=85373)[0m top1: 0.17444029850746268
[2m[36m(func pid=85373)[0m top5: 0.832089552238806
[2m[36m(func pid=85373)[0m f1_micro: 0.17444029850746268
[2m[36m(func pid=85373)[0m f1_macro: 0.15933503340211036
[2m[36m(func pid=85373)[0m f1_weighted: 0.16706259086317007
[2m[36m(func pid=85373)[0m f1_per_class: [0.048, 0.016, 0.303, 0.175, 0.095, 0.154, 0.234, 0.332, 0.125, 0.112]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=91054)[0m top1: 0.21082089552238806
[2m[36m(func pid=91054)[0m top5: 0.8003731343283582
[2m[36m(func pid=91054)[0m f1_micro: 0.21082089552238809
[2m[36m(func pid=91054)[0m f1_macro: 0.20028672329213992
[2m[36m(func pid=91054)[0m f1_weighted: 0.2132184969580057
[2m[36m(func pid=91054)[0m f1_per_class: [0.049, 0.35, 0.171, 0.173, 0.092, 0.367, 0.103, 0.447, 0.021, 0.23]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=101178)[0m top1: 0.07042910447761194
[2m[36m(func pid=101178)[0m top5: 0.302705223880597
[2m[36m(func pid=101178)[0m f1_micro: 0.07042910447761194
[2m[36m(func pid=101178)[0m f1_macro: 0.019750781902789748
[2m[36m(func pid=101178)[0m f1_weighted: 0.02760681379437759
[2m[36m(func pid=101178)[0m f1_per_class: [0.0, 0.0, 0.0, 0.073, 0.0, 0.0, 0.0, 0.124, 0.0, 0.0]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 98] | Train loss: 0.5773 | Steps: 2 | Val loss: 6.4565 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 1.4938 | Steps: 2 | Val loss: 5.1344 | Batch size: 32 | lr: 0.1 | Duration: 3.12s
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 2.2027 | Steps: 2 | Val loss: 2.1954 | Batch size: 32 | lr: 0.0001 | Duration: 3.10s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 2.9929 | Steps: 2 | Val loss: 2.3263 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 02:49:29 (running for 00:25:30.74)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=10
Bracket: Iter 75.000: 0.3235
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (10 PENDING, 4 RUNNING, 10 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00009 | RUNNING    | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  0.577 |      0.258 |                   99 |
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  1.763 |      0.159 |                   70 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  2.177 |      0.2   |                   46 |
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  3.108 |      0.02  |                    1 |
| train_6ed81_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (2 PENDING, 2 TERMINATED)


[2m[36m(func pid=79460)[0m top1: 0.2719216417910448
[2m[36m(func pid=79460)[0m top5: 0.8180970149253731
[2m[36m(func pid=79460)[0m f1_micro: 0.2719216417910448
[2m[36m(func pid=79460)[0m f1_macro: 0.2583419435160359
[2m[36m(func pid=79460)[0m f1_weighted: 0.27568538758808425
[2m[36m(func pid=79460)[0m f1_per_class: [0.135, 0.447, 0.117, 0.276, 0.073, 0.336, 0.151, 0.407, 0.156, 0.485]
[2m[36m(func pid=79460)[0m 
[2m[36m(func pid=91054)[0m top1: 0.2103544776119403
[2m[36m(func pid=91054)[0m top5: 0.8036380597014925
[2m[36m(func pid=91054)[0m f1_micro: 0.2103544776119403
[2m[36m(func pid=91054)[0m f1_macro: 0.19405499189280526
[2m[36m(func pid=91054)[0m f1_weighted: 0.2143046147053696
[2m[36m(func pid=91054)[0m f1_per_class: [0.05, 0.341, 0.177, 0.174, 0.092, 0.373, 0.113, 0.439, 0.019, 0.162]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=85373)[0m top1: 0.20615671641791045
[2m[36m(func pid=85373)[0m top5: 0.8376865671641791
[2m[36m(func pid=85373)[0m f1_micro: 0.20615671641791045
[2m[36m(func pid=85373)[0m f1_macro: 0.17968667878108174
[2m[36m(func pid=85373)[0m f1_weighted: 0.20470608433494694
[2m[36m(func pid=85373)[0m f1_per_class: [0.064, 0.011, 0.316, 0.283, 0.084, 0.133, 0.264, 0.34, 0.141, 0.162]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=101178)[0m top1: 0.11473880597014925
[2m[36m(func pid=101178)[0m top5: 0.5041977611940298
[2m[36m(func pid=101178)[0m f1_micro: 0.11473880597014925
[2m[36m(func pid=101178)[0m f1_macro: 0.07119289487071381
[2m[36m(func pid=101178)[0m f1_weighted: 0.09260328727216749
[2m[36m(func pid=101178)[0m f1_per_class: [0.0, 0.0, 0.021, 0.238, 0.0, 0.0, 0.0, 0.453, 0.0, 0.0]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=79460)[0m [N0-GPU0] | [Epoch: 99] | Train loss: 1.1024 | Steps: 2 | Val loss: 6.0897 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 2.1502 | Steps: 2 | Val loss: 2.1923 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 6.4505 | Steps: 2 | Val loss: 5.6534 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 2.7269 | Steps: 2 | Val loss: 2.3052 | Batch size: 32 | lr: 0.001 | Duration: 3.10s
[2m[36m(func pid=79460)[0m top1: 0.2933768656716418
[2m[36m(func pid=79460)[0m top5: 0.8222947761194029
[2m[36m(func pid=79460)[0m f1_micro: 0.2933768656716418
[2m[36m(func pid=79460)[0m f1_macro: 0.25674485966220245
[2m[36m(func pid=79460)[0m f1_weighted: 0.3200640285129321
[2m[36m(func pid=79460)[0m f1_per_class: [0.137, 0.441, 0.147, 0.295, 0.137, 0.338, 0.301, 0.368, 0.139, 0.265]
== Status ==
Current time: 2024-01-07 02:49:35 (running for 00:25:36.02)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: 0.3235
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (10 PENDING, 3 RUNNING, 11 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  1.494 |      0.18  |                   71 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  2.203 |      0.194 |                   47 |
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  2.993 |      0.071 |                    2 |
| train_6ed81_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (1 PENDING, 2 TERMINATED)


[2m[36m(func pid=91054)[0m top1: 0.2103544776119403
[2m[36m(func pid=91054)[0m top5: 0.8064365671641791
[2m[36m(func pid=91054)[0m f1_micro: 0.2103544776119403
[2m[36m(func pid=91054)[0m f1_macro: 0.19782742928424635
[2m[36m(func pid=91054)[0m f1_weighted: 0.21657462473731853
[2m[36m(func pid=91054)[0m f1_per_class: [0.051, 0.333, 0.18, 0.179, 0.085, 0.363, 0.119, 0.449, 0.053, 0.167]
[2m[36m(func pid=85373)[0m top1: 0.22621268656716417
[2m[36m(func pid=85373)[0m top5: 0.847481343283582
[2m[36m(func pid=85373)[0m f1_micro: 0.22621268656716417
[2m[36m(func pid=85373)[0m f1_macro: 0.19181602249351604
[2m[36m(func pid=85373)[0m f1_weighted: 0.22504152439868594
[2m[36m(func pid=85373)[0m f1_per_class: [0.072, 0.025, 0.25, 0.356, 0.088, 0.135, 0.25, 0.34, 0.158, 0.244]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=101178)[0m top1: 0.049906716417910446
[2m[36m(func pid=101178)[0m top5: 0.5928171641791045
[2m[36m(func pid=101178)[0m f1_micro: 0.04990671641791045
[2m[36m(func pid=101178)[0m f1_macro: 0.022345414728968283
[2m[36m(func pid=101178)[0m f1_weighted: 0.05789556573493718
[2m[36m(func pid=101178)[0m f1_per_class: [0.0, 0.005, 0.014, 0.204, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 2.2118 | Steps: 2 | Val loss: 2.1880 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 2.5615 | Steps: 2 | Val loss: 5.7084 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 2.7820 | Steps: 2 | Val loss: 2.2925 | Batch size: 32 | lr: 0.001 | Duration: 2.75s
[2m[36m(func pid=85373)[0m top1: 0.2355410447761194
[2m[36m(func pid=85373)[0m top5: 0.8535447761194029
[2m[36m(func pid=85373)[0m f1_micro: 0.2355410447761194
[2m[36m(func pid=85373)[0m f1_macro: 0.17141648022378309
[2m[36m(func pid=85373)[0m f1_weighted: 0.2289375682694733
[2m[36m(func pid=85373)[0m f1_per_class: [0.049, 0.072, 0.238, 0.408, 0.086, 0.154, 0.196, 0.334, 0.1, 0.077]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=91054)[0m top1: 0.20988805970149255
[2m[36m(func pid=91054)[0m top5: 0.8148320895522388
[2m[36m(func pid=91054)[0m f1_micro: 0.20988805970149255
[2m[36m(func pid=91054)[0m f1_macro: 0.19803338544549123
[2m[36m(func pid=91054)[0m f1_weighted: 0.21455457095181082
[2m[36m(func pid=91054)[0m f1_per_class: [0.053, 0.327, 0.175, 0.185, 0.095, 0.36, 0.113, 0.431, 0.051, 0.19]
[2m[36m(func pid=101178)[0m top1: 0.03264925373134328
[2m[36m(func pid=101178)[0m top5: 0.6063432835820896
[2m[36m(func pid=101178)[0m f1_micro: 0.03264925373134328
[2m[36m(func pid=101178)[0m f1_macro: 0.01541265160859287
[2m[36m(func pid=101178)[0m f1_weighted: 0.03872560471688543
[2m[36m(func pid=101178)[0m f1_per_class: [0.0, 0.005, 0.014, 0.135, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
== Status ==
Current time: 2024-01-07 02:49:41 (running for 00:25:42.05)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: 0.3235
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (9 PENDING, 4 RUNNING, 11 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.562 |      0.171 |                   73 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  2.15  |      0.198 |                   48 |
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  2.727 |      0.022 |                    3 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (1 PENDING, 3 TERMINATED)


[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=102297)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=102297)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=102297)[0m Configuration completed!
[2m[36m(func pid=102297)[0m New optimizer parameters:
[2m[36m(func pid=102297)[0m SGD (
[2m[36m(func pid=102297)[0m Parameter Group 0
[2m[36m(func pid=102297)[0m     dampening: 0
[2m[36m(func pid=102297)[0m     differentiable: False
[2m[36m(func pid=102297)[0m     foreach: None
[2m[36m(func pid=102297)[0m     lr: 0.01
[2m[36m(func pid=102297)[0m     maximize: False
[2m[36m(func pid=102297)[0m     momentum: 0.9
[2m[36m(func pid=102297)[0m     nesterov: False
[2m[36m(func pid=102297)[0m     weight_decay: 0.0001
[2m[36m(func pid=102297)[0m )
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 1.8168 | Steps: 2 | Val loss: 5.6075 | Batch size: 32 | lr: 0.1 | Duration: 2.98s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 2.7556 | Steps: 2 | Val loss: 2.2736 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 2.1786 | Steps: 2 | Val loss: 2.1836 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
== Status ==
Current time: 2024-01-07 02:49:46 (running for 00:25:47.64)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: 0.3235
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (9 PENDING, 4 RUNNING, 11 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00011 | RUNNING    | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  1.817 |      0.162 |                   74 |
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  2.212 |      0.198 |                   49 |
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  2.782 |      0.015 |                    4 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (1 PENDING, 3 TERMINATED)


[2m[36m(func pid=85373)[0m top1: 0.26026119402985076
[2m[36m(func pid=85373)[0m top5: 0.8572761194029851
[2m[36m(func pid=85373)[0m f1_micro: 0.26026119402985076
[2m[36m(func pid=85373)[0m f1_macro: 0.16160419993517985
[2m[36m(func pid=85373)[0m f1_weighted: 0.24626195137229398
[2m[36m(func pid=85373)[0m f1_per_class: [0.034, 0.135, 0.13, 0.459, 0.108, 0.17, 0.18, 0.324, 0.0, 0.077]
[2m[36m(func pid=85373)[0m 
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 3.0025 | Steps: 2 | Val loss: 2.8174 | Batch size: 32 | lr: 0.01 | Duration: 4.68s
[2m[36m(func pid=91054)[0m top1: 0.2080223880597015
[2m[36m(func pid=91054)[0m top5: 0.8166977611940298
[2m[36m(func pid=91054)[0m f1_micro: 0.2080223880597015
[2m[36m(func pid=91054)[0m f1_macro: 0.19583296777330797
[2m[36m(func pid=91054)[0m f1_weighted: 0.21490091246867637
[2m[36m(func pid=91054)[0m f1_per_class: [0.054, 0.314, 0.173, 0.195, 0.091, 0.342, 0.12, 0.43, 0.048, 0.19]
[2m[36m(func pid=101178)[0m top1: 0.060167910447761194
[2m[36m(func pid=101178)[0m top5: 0.6161380597014925
[2m[36m(func pid=101178)[0m f1_micro: 0.060167910447761194
[2m[36m(func pid=101178)[0m f1_macro: 0.040798040809855794
[2m[36m(func pid=101178)[0m f1_weighted: 0.07135539944011911
[2m[36m(func pid=101178)[0m f1_per_class: [0.034, 0.053, 0.016, 0.198, 0.0, 0.0, 0.0, 0.107, 0.0, 0.0]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=85373)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 2.1110 | Steps: 2 | Val loss: 5.5064 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=102297)[0m top1: 0.006063432835820896
[2m[36m(func pid=102297)[0m top5: 0.35447761194029853
[2m[36m(func pid=102297)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=102297)[0m f1_macro: 0.001205377839592026
[2m[36m(func pid=102297)[0m f1_weighted: 7.308727572153144e-05
[2m[36m(func pid=102297)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 2.4999 | Steps: 2 | Val loss: 2.2511 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 2.1053 | Steps: 2 | Val loss: 2.1820 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 02:49:52 (running for 00:25:52.94)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: 0.32175
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (9 PENDING, 3 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  2.179 |      0.196 |                   50 |
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  2.756 |      0.041 |                    5 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  3.002 |      0.001 |                    1 |
| train_6ed81_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (3 TERMINATED)


[2m[36m(func pid=85373)[0m top1: 0.283115671641791
[2m[36m(func pid=85373)[0m top5: 0.851679104477612
[2m[36m(func pid=85373)[0m f1_micro: 0.283115671641791
[2m[36m(func pid=85373)[0m f1_macro: 0.18848760540010595
[2m[36m(func pid=85373)[0m f1_weighted: 0.27062625967598913
[2m[36m(func pid=85373)[0m f1_per_class: [0.016, 0.258, 0.204, 0.458, 0.108, 0.189, 0.181, 0.322, 0.0, 0.148]
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 2.8317 | Steps: 2 | Val loss: 3.7548 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=91054)[0m top1: 0.20522388059701493
[2m[36m(func pid=91054)[0m top5: 0.8176305970149254
[2m[36m(func pid=91054)[0m f1_micro: 0.20522388059701493
[2m[36m(func pid=91054)[0m f1_macro: 0.19297700966678988
[2m[36m(func pid=91054)[0m f1_weighted: 0.21266935485774388
[2m[36m(func pid=91054)[0m f1_per_class: [0.049, 0.314, 0.172, 0.198, 0.091, 0.339, 0.112, 0.434, 0.045, 0.176]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=101178)[0m top1: 0.10727611940298508
[2m[36m(func pid=101178)[0m top5: 0.7024253731343284
[2m[36m(func pid=101178)[0m f1_micro: 0.10727611940298508
[2m[36m(func pid=101178)[0m f1_macro: 0.0882308976352603
[2m[36m(func pid=101178)[0m f1_weighted: 0.10644429613505292
[2m[36m(func pid=101178)[0m f1_per_class: [0.04, 0.207, 0.052, 0.134, 0.0, 0.081, 0.009, 0.346, 0.0, 0.012]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=102297)[0m top1: 0.0065298507462686565
[2m[36m(func pid=102297)[0m top5: 0.558768656716418
[2m[36m(func pid=102297)[0m f1_micro: 0.0065298507462686565
[2m[36m(func pid=102297)[0m f1_macro: 0.001743810307707059
[2m[36m(func pid=102297)[0m f1_weighted: 0.000996055282177478
[2m[36m(func pid=102297)[0m f1_per_class: [0.0, 0.005, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 2.1581 | Steps: 2 | Val loss: 2.1771 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 2.4091 | Steps: 2 | Val loss: 2.2262 | Batch size: 32 | lr: 0.001 | Duration: 3.04s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 2.5185 | Steps: 2 | Val loss: 3.7198 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=91054)[0m top1: 0.20522388059701493
[2m[36m(func pid=91054)[0m top5: 0.8227611940298507
[2m[36m(func pid=91054)[0m f1_micro: 0.20522388059701493
[2m[36m(func pid=91054)[0m f1_macro: 0.19040082521548604
[2m[36m(func pid=91054)[0m f1_weighted: 0.21429647779477545
[2m[36m(func pid=91054)[0m f1_per_class: [0.051, 0.305, 0.175, 0.21, 0.085, 0.335, 0.114, 0.43, 0.043, 0.156]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=101178)[0m top1: 0.17817164179104478
[2m[36m(func pid=101178)[0m top5: 0.8348880597014925
[2m[36m(func pid=101178)[0m f1_micro: 0.17817164179104475
[2m[36m(func pid=101178)[0m f1_macro: 0.1374608785517882
[2m[36m(func pid=101178)[0m f1_weighted: 0.17848323451877332
[2m[36m(func pid=101178)[0m f1_per_class: [0.073, 0.337, 0.211, 0.024, 0.0, 0.103, 0.269, 0.323, 0.0, 0.036]
== Status ==
Current time: 2024-01-07 02:49:59 (running for 00:26:00.22)
Memory usage on this node: 23.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  2.158 |      0.19  |                   52 |
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  2.5   |      0.088 |                    6 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  2.832 |      0.002 |                    2 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=103229)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=103229)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=103229)[0m Configuration completed!
[2m[36m(func pid=103229)[0m New optimizer parameters:
[2m[36m(func pid=103229)[0m SGD (
[2m[36m(func pid=103229)[0m Parameter Group 0
[2m[36m(func pid=103229)[0m     dampening: 0
[2m[36m(func pid=103229)[0m     differentiable: False
[2m[36m(func pid=103229)[0m     foreach: None
[2m[36m(func pid=103229)[0m     lr: 0.1
[2m[36m(func pid=103229)[0m     maximize: False
[2m[36m(func pid=103229)[0m     momentum: 0.9
[2m[36m(func pid=103229)[0m     nesterov: False
[2m[36m(func pid=103229)[0m     weight_decay: 0.0001
[2m[36m(func pid=103229)[0m )
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=102297)[0m top1: 0.07229477611940298
[2m[36m(func pid=102297)[0m top5: 0.7271455223880597
[2m[36m(func pid=102297)[0m f1_micro: 0.07229477611940298
[2m[36m(func pid=102297)[0m f1_macro: 0.04747154020273997
[2m[36m(func pid=102297)[0m f1_weighted: 0.070161054915708
[2m[36m(func pid=102297)[0m f1_per_class: [0.015, 0.354, 0.029, 0.0, 0.0, 0.077, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 2.0723 | Steps: 2 | Val loss: 2.1730 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 2.3460 | Steps: 2 | Val loss: 2.2052 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 2.3114 | Steps: 2 | Val loss: 4.0639 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 02:50:04 (running for 00:26:05.58)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  2.072 |      0.197 |                   53 |
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  2.409 |      0.137 |                    7 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  2.518 |      0.047 |                    3 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |        |            |                      |
| train_6ed81_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=91054)[0m top1: 0.21128731343283583
[2m[36m(func pid=91054)[0m top5: 0.8264925373134329
[2m[36m(func pid=91054)[0m f1_micro: 0.21128731343283583
[2m[36m(func pid=91054)[0m f1_macro: 0.19748867620531102
[2m[36m(func pid=91054)[0m f1_weighted: 0.22093658912962014
[2m[36m(func pid=91054)[0m f1_per_class: [0.05, 0.314, 0.18, 0.223, 0.084, 0.347, 0.113, 0.435, 0.044, 0.185]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 3.0279 | Steps: 2 | Val loss: 99.0170 | Batch size: 32 | lr: 0.1 | Duration: 4.49s
[2m[36m(func pid=101178)[0m top1: 0.21641791044776118
[2m[36m(func pid=101178)[0m top5: 0.8404850746268657
[2m[36m(func pid=101178)[0m f1_micro: 0.21641791044776118
[2m[36m(func pid=101178)[0m f1_macro: 0.18307162174130487
[2m[36m(func pid=101178)[0m f1_weighted: 0.21052443919026526
[2m[36m(func pid=101178)[0m f1_per_class: [0.08, 0.4, 0.372, 0.0, 0.083, 0.135, 0.332, 0.388, 0.0, 0.041]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=102297)[0m top1: 0.134794776119403
[2m[36m(func pid=102297)[0m top5: 0.7322761194029851
[2m[36m(func pid=102297)[0m f1_micro: 0.134794776119403
[2m[36m(func pid=102297)[0m f1_macro: 0.08587519842166065
[2m[36m(func pid=102297)[0m f1_weighted: 0.12457268482123714
[2m[36m(func pid=102297)[0m f1_per_class: [0.02, 0.356, 0.031, 0.0, 0.154, 0.096, 0.162, 0.04, 0.0, 0.0]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=103229)[0m top1: 0.020522388059701493
[2m[36m(func pid=103229)[0m top5: 0.4300373134328358
[2m[36m(func pid=103229)[0m f1_micro: 0.020522388059701493
[2m[36m(func pid=103229)[0m f1_macro: 0.0040219378427787935
[2m[36m(func pid=103229)[0m f1_weighted: 0.000825397691615051
[2m[36m(func pid=103229)[0m f1_per_class: [0.04, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 2.1024 | Steps: 2 | Val loss: 2.1701 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 2.2919 | Steps: 2 | Val loss: 2.1800 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 2.1981 | Steps: 2 | Val loss: 4.0517 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 02:50:09 (running for 00:26:10.73)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  2.102 |      0.202 |                   54 |
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  2.346 |      0.183 |                    8 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  2.311 |      0.086 |                    4 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  3.028 |      0.004 |                    1 |
| train_6ed81_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=91054)[0m top1: 0.2140858208955224
[2m[36m(func pid=91054)[0m top5: 0.8269589552238806
[2m[36m(func pid=91054)[0m f1_micro: 0.2140858208955224
[2m[36m(func pid=91054)[0m f1_macro: 0.20179664606413192
[2m[36m(func pid=91054)[0m f1_weighted: 0.22224998739157936
[2m[36m(func pid=91054)[0m f1_per_class: [0.053, 0.309, 0.188, 0.235, 0.083, 0.35, 0.105, 0.437, 0.047, 0.211]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 5.0749 | Steps: 2 | Val loss: 3034.8442 | Batch size: 32 | lr: 0.1 | Duration: 3.07s
[2m[36m(func pid=101178)[0m top1: 0.23134328358208955
[2m[36m(func pid=101178)[0m top5: 0.840018656716418
[2m[36m(func pid=101178)[0m f1_micro: 0.23134328358208955
[2m[36m(func pid=101178)[0m f1_macro: 0.1840108254011497
[2m[36m(func pid=101178)[0m f1_weighted: 0.21657817160353934
[2m[36m(func pid=101178)[0m f1_per_class: [0.099, 0.441, 0.387, 0.0, 0.051, 0.087, 0.347, 0.373, 0.019, 0.036]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=102297)[0m top1: 0.15205223880597016
[2m[36m(func pid=102297)[0m top5: 0.746268656716418
[2m[36m(func pid=102297)[0m f1_micro: 0.15205223880597016
[2m[36m(func pid=102297)[0m f1_macro: 0.10485552493338321
[2m[36m(func pid=102297)[0m f1_weighted: 0.16969314728738402
[2m[36m(func pid=102297)[0m f1_per_class: [0.022, 0.225, 0.029, 0.032, 0.148, 0.024, 0.384, 0.0, 0.041, 0.143]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 2.0919 | Steps: 2 | Val loss: 2.1669 | Batch size: 32 | lr: 0.0001 | Duration: 2.74s
[2m[36m(func pid=103229)[0m top1: 0.006063432835820896
[2m[36m(func pid=103229)[0m top5: 0.5107276119402985
[2m[36m(func pid=103229)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=103229)[0m f1_macro: 0.001205377839592026
[2m[36m(func pid=103229)[0m f1_weighted: 7.308727572153144e-05
[2m[36m(func pid=103229)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 2.2306 | Steps: 2 | Val loss: 2.1581 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 2.0109 | Steps: 2 | Val loss: 4.1595 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
== Status ==
Current time: 2024-01-07 02:50:15 (running for 00:26:15.87)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  2.092 |      0.206 |                   55 |
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  2.292 |      0.184 |                    9 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  2.198 |      0.105 |                    5 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  5.075 |      0.001 |                    2 |
| train_6ed81_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=91054)[0m top1: 0.2150186567164179
[2m[36m(func pid=91054)[0m top5: 0.8288246268656716
[2m[36m(func pid=91054)[0m f1_micro: 0.2150186567164179
[2m[36m(func pid=91054)[0m f1_macro: 0.20582252490771874
[2m[36m(func pid=91054)[0m f1_weighted: 0.2240798545998244
[2m[36m(func pid=91054)[0m f1_per_class: [0.054, 0.318, 0.185, 0.232, 0.081, 0.349, 0.108, 0.433, 0.058, 0.24]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 4.2459 | Steps: 2 | Val loss: 78340.3672 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=101178)[0m top1: 0.23973880597014927
[2m[36m(func pid=101178)[0m top5: 0.8442164179104478
[2m[36m(func pid=101178)[0m f1_micro: 0.23973880597014927
[2m[36m(func pid=101178)[0m f1_macro: 0.19535721409923018
[2m[36m(func pid=101178)[0m f1_weighted: 0.2173839298806085
[2m[36m(func pid=101178)[0m f1_per_class: [0.114, 0.445, 0.333, 0.0, 0.094, 0.092, 0.326, 0.443, 0.057, 0.05]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=102297)[0m top1: 0.1571828358208955
[2m[36m(func pid=102297)[0m top5: 0.816231343283582
[2m[36m(func pid=102297)[0m f1_micro: 0.1571828358208955
[2m[36m(func pid=102297)[0m f1_macro: 0.1173058938747312
[2m[36m(func pid=102297)[0m f1_weighted: 0.18515309771875912
[2m[36m(func pid=102297)[0m f1_per_class: [0.043, 0.103, 0.032, 0.229, 0.127, 0.055, 0.279, 0.183, 0.0, 0.122]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 2.1939 | Steps: 2 | Val loss: 2.1623 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=103229)[0m top1: 0.006063432835820896
[2m[36m(func pid=103229)[0m top5: 0.5093283582089553
[2m[36m(func pid=103229)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=103229)[0m f1_macro: 0.001205377839592026
[2m[36m(func pid=103229)[0m f1_weighted: 7.308727572153144e-05
[2m[36m(func pid=103229)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 2.1963 | Steps: 2 | Val loss: 2.1306 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 1.7333 | Steps: 2 | Val loss: 3.4137 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
== Status ==
Current time: 2024-01-07 02:50:20 (running for 00:26:21.24)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  2.194 |      0.208 |                   56 |
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  2.231 |      0.195 |                   10 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  2.011 |      0.117 |                    6 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  4.246 |      0.001 |                    3 |
| train_6ed81_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=91054)[0m top1: 0.21595149253731344
[2m[36m(func pid=91054)[0m top5: 0.8330223880597015
[2m[36m(func pid=91054)[0m f1_micro: 0.21595149253731344
[2m[36m(func pid=91054)[0m f1_macro: 0.20798581521221599
[2m[36m(func pid=91054)[0m f1_weighted: 0.2244672793886177
[2m[36m(func pid=91054)[0m f1_per_class: [0.055, 0.317, 0.191, 0.22, 0.079, 0.362, 0.116, 0.433, 0.044, 0.261]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 3.7860 | Steps: 2 | Val loss: 75706.2656 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=101178)[0m top1: 0.24813432835820895
[2m[36m(func pid=101178)[0m top5: 0.8586753731343284
[2m[36m(func pid=101178)[0m f1_micro: 0.24813432835820895
[2m[36m(func pid=101178)[0m f1_macro: 0.20810809802349012
[2m[36m(func pid=101178)[0m f1_weighted: 0.2092321962864042
[2m[36m(func pid=101178)[0m f1_per_class: [0.132, 0.428, 0.408, 0.0, 0.071, 0.15, 0.27, 0.511, 0.062, 0.049]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=102297)[0m top1: 0.1417910447761194
[2m[36m(func pid=102297)[0m top5: 0.8227611940298507
[2m[36m(func pid=102297)[0m f1_micro: 0.1417910447761194
[2m[36m(func pid=102297)[0m f1_macro: 0.11672082975632299
[2m[36m(func pid=102297)[0m f1_weighted: 0.1349460309773356
[2m[36m(func pid=102297)[0m f1_per_class: [0.051, 0.429, 0.041, 0.144, 0.189, 0.046, 0.0, 0.213, 0.0, 0.054]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 2.0875 | Steps: 2 | Val loss: 2.1639 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=103229)[0m top1: 0.006063432835820896
[2m[36m(func pid=103229)[0m top5: 0.5093283582089553
[2m[36m(func pid=103229)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=103229)[0m f1_macro: 0.001205377839592026
[2m[36m(func pid=103229)[0m f1_weighted: 7.308727572153144e-05
[2m[36m(func pid=103229)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 2.1136 | Steps: 2 | Val loss: 2.0977 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 1.7659 | Steps: 2 | Val loss: 2.8543 | Batch size: 32 | lr: 0.01 | Duration: 2.74s
== Status ==
Current time: 2024-01-07 02:50:25 (running for 00:26:26.53)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  2.088 |      0.212 |                   57 |
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  2.196 |      0.208 |                   11 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  1.733 |      0.117 |                    7 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  3.786 |      0.001 |                    4 |
| train_6ed81_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=91054)[0m top1: 0.22294776119402984
[2m[36m(func pid=91054)[0m top5: 0.8302238805970149
[2m[36m(func pid=91054)[0m f1_micro: 0.22294776119402981
[2m[36m(func pid=91054)[0m f1_macro: 0.21207096406352904
[2m[36m(func pid=91054)[0m f1_weighted: 0.23243415171996526
[2m[36m(func pid=91054)[0m f1_per_class: [0.056, 0.336, 0.179, 0.226, 0.081, 0.366, 0.121, 0.445, 0.06, 0.25]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 3.3099 | Steps: 2 | Val loss: 32609.1113 | Batch size: 32 | lr: 0.1 | Duration: 2.99s
[2m[36m(func pid=101178)[0m top1: 0.23041044776119404
[2m[36m(func pid=101178)[0m top5: 0.8754664179104478
[2m[36m(func pid=101178)[0m f1_micro: 0.23041044776119404
[2m[36m(func pid=101178)[0m f1_macro: 0.18109814592752665
[2m[36m(func pid=101178)[0m f1_weighted: 0.16802822668936587
[2m[36m(func pid=101178)[0m f1_per_class: [0.135, 0.419, 0.328, 0.0, 0.117, 0.08, 0.171, 0.506, 0.023, 0.033]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=102297)[0m top1: 0.17723880597014927
[2m[36m(func pid=102297)[0m top5: 0.8255597014925373
[2m[36m(func pid=102297)[0m f1_micro: 0.17723880597014927
[2m[36m(func pid=102297)[0m f1_macro: 0.1407550470906866
[2m[36m(func pid=102297)[0m f1_weighted: 0.147249488737299
[2m[36m(func pid=102297)[0m f1_per_class: [0.065, 0.51, 0.073, 0.062, 0.185, 0.188, 0.012, 0.22, 0.0, 0.093]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 2.0568 | Steps: 2 | Val loss: 2.1609 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=103229)[0m top1: 0.006063432835820896
[2m[36m(func pid=103229)[0m top5: 0.5093283582089553
[2m[36m(func pid=103229)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=103229)[0m f1_macro: 0.001205377839592026
[2m[36m(func pid=103229)[0m f1_weighted: 7.308727572153144e-05
[2m[36m(func pid=103229)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 1.9817 | Steps: 2 | Val loss: 2.0869 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 1.3231 | Steps: 2 | Val loss: 2.3952 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=91054)[0m top1: 0.22014925373134328
[2m[36m(func pid=91054)[0m top5: 0.8348880597014925
[2m[36m(func pid=91054)[0m f1_micro: 0.22014925373134328
[2m[36m(func pid=91054)[0m f1_macro: 0.2093523833505934
[2m[36m(func pid=91054)[0m f1_weighted: 0.23554746715147545
[2m[36m(func pid=91054)[0m f1_per_class: [0.056, 0.321, 0.18, 0.233, 0.076, 0.349, 0.141, 0.454, 0.043, 0.24]
[2m[36m(func pid=91054)[0m 
== Status ==
Current time: 2024-01-07 02:50:30 (running for 00:26:31.78)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  2.057 |      0.209 |                   58 |
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  2.114 |      0.181 |                   12 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  1.766 |      0.141 |                    8 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  3.31  |      0.001 |                    5 |
| train_6ed81_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 3.1235 | Steps: 2 | Val loss: 5201.5122 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=101178)[0m top1: 0.21128731343283583
[2m[36m(func pid=101178)[0m top5: 0.8838619402985075
[2m[36m(func pid=101178)[0m f1_micro: 0.21128731343283583
[2m[36m(func pid=101178)[0m f1_macro: 0.16655445417475245
[2m[36m(func pid=101178)[0m f1_weighted: 0.13672565007387902
[2m[36m(func pid=101178)[0m f1_per_class: [0.205, 0.415, 0.293, 0.0, 0.095, 0.023, 0.088, 0.508, 0.0, 0.038]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=102297)[0m top1: 0.27658582089552236
[2m[36m(func pid=102297)[0m top5: 0.8605410447761194
[2m[36m(func pid=102297)[0m f1_micro: 0.27658582089552236
[2m[36m(func pid=102297)[0m f1_macro: 0.2150922597548548
[2m[36m(func pid=102297)[0m f1_weighted: 0.22871706859776264
[2m[36m(func pid=102297)[0m f1_per_class: [0.083, 0.501, 0.296, 0.044, 0.107, 0.296, 0.23, 0.357, 0.0, 0.235]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 2.0232 | Steps: 2 | Val loss: 2.1551 | Batch size: 32 | lr: 0.0001 | Duration: 2.68s
[2m[36m(func pid=103229)[0m top1: 0.006063432835820896
[2m[36m(func pid=103229)[0m top5: 0.5004664179104478
[2m[36m(func pid=103229)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=103229)[0m f1_macro: 0.0012070566388115134
[2m[36m(func pid=103229)[0m f1_weighted: 7.318906858465332e-05
[2m[36m(func pid=103229)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 2.0327 | Steps: 2 | Val loss: 2.0836 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 1.3793 | Steps: 2 | Val loss: 3.0427 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=91054)[0m top1: 0.2196828358208955
[2m[36m(func pid=91054)[0m top5: 0.8414179104477612
[2m[36m(func pid=91054)[0m f1_micro: 0.2196828358208955
[2m[36m(func pid=91054)[0m f1_macro: 0.21215728111335733
[2m[36m(func pid=91054)[0m f1_weighted: 0.23865992274122916
[2m[36m(func pid=91054)[0m f1_per_class: [0.056, 0.319, 0.191, 0.238, 0.079, 0.334, 0.154, 0.444, 0.057, 0.25]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 2.4213 | Steps: 2 | Val loss: 488.7195 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
== Status ==
Current time: 2024-01-07 02:50:37 (running for 00:26:38.40)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  2.023 |      0.212 |                   59 |
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  2.033 |      0.153 |                   14 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  1.323 |      0.215 |                    9 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  3.123 |      0.001 |                    6 |
| train_6ed81_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=101178)[0m top1: 0.19076492537313433
[2m[36m(func pid=101178)[0m top5: 0.8777985074626866
[2m[36m(func pid=101178)[0m f1_micro: 0.19076492537313436
[2m[36m(func pid=101178)[0m f1_macro: 0.15310304006307957
[2m[36m(func pid=101178)[0m f1_weighted: 0.11141028233305518
[2m[36m(func pid=101178)[0m f1_per_class: [0.157, 0.403, 0.293, 0.003, 0.127, 0.0, 0.022, 0.491, 0.0, 0.035]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=102297)[0m top1: 0.2392723880597015
[2m[36m(func pid=102297)[0m top5: 0.8689365671641791
[2m[36m(func pid=102297)[0m f1_micro: 0.2392723880597015
[2m[36m(func pid=102297)[0m f1_macro: 0.20134049085691305
[2m[36m(func pid=102297)[0m f1_weighted: 0.21558559061936597
[2m[36m(func pid=102297)[0m f1_per_class: [0.061, 0.469, 0.087, 0.074, 0.073, 0.239, 0.191, 0.346, 0.09, 0.382]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 2.0382 | Steps: 2 | Val loss: 2.1533 | Batch size: 32 | lr: 0.0001 | Duration: 2.75s
[2m[36m(func pid=103229)[0m top1: 0.009794776119402986
[2m[36m(func pid=103229)[0m top5: 0.5457089552238806
[2m[36m(func pid=103229)[0m f1_micro: 0.009794776119402986
[2m[36m(func pid=103229)[0m f1_macro: 0.0040065092216009
[2m[36m(func pid=103229)[0m f1_weighted: 0.007262206400714758
[2m[36m(func pid=103229)[0m f1_per_class: [0.0, 0.005, 0.012, 0.022, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 2.0738 | Steps: 2 | Val loss: 2.0390 | Batch size: 32 | lr: 0.001 | Duration: 3.08s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 1.1105 | Steps: 2 | Val loss: 3.0870 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=91054)[0m top1: 0.22014925373134328
[2m[36m(func pid=91054)[0m top5: 0.8395522388059702
[2m[36m(func pid=91054)[0m f1_micro: 0.22014925373134328
[2m[36m(func pid=91054)[0m f1_macro: 0.21223216492468938
[2m[36m(func pid=91054)[0m f1_weighted: 0.2380816495099135
[2m[36m(func pid=91054)[0m f1_per_class: [0.057, 0.321, 0.193, 0.231, 0.08, 0.328, 0.159, 0.447, 0.057, 0.25]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 12.9400 | Steps: 2 | Val loss: 3869276.7500 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 02:50:42 (running for 00:26:43.80)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  2.038 |      0.212 |                   60 |
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  2.074 |      0.148 |                   15 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  1.379 |      0.201 |                   10 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  2.421 |      0.004 |                    7 |
| train_6ed81_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=101178)[0m top1: 0.19169776119402984
[2m[36m(func pid=101178)[0m top5: 0.8694029850746269
[2m[36m(func pid=101178)[0m f1_micro: 0.19169776119402984
[2m[36m(func pid=101178)[0m f1_macro: 0.14837779820499408
[2m[36m(func pid=101178)[0m f1_weighted: 0.10908229038748528
[2m[36m(func pid=101178)[0m f1_per_class: [0.085, 0.391, 0.364, 0.01, 0.116, 0.0, 0.025, 0.459, 0.0, 0.035]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=102297)[0m top1: 0.24207089552238806
[2m[36m(func pid=102297)[0m top5: 0.8773320895522388
[2m[36m(func pid=102297)[0m f1_micro: 0.24207089552238806
[2m[36m(func pid=102297)[0m f1_macro: 0.18558462502366757
[2m[36m(func pid=102297)[0m f1_weighted: 0.19761946669531283
[2m[36m(func pid=102297)[0m f1_per_class: [0.0, 0.472, 0.091, 0.131, 0.08, 0.206, 0.097, 0.303, 0.142, 0.333]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 2.0715 | Steps: 2 | Val loss: 2.1546 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
[2m[36m(func pid=103229)[0m top1: 0.006063432835820896
[2m[36m(func pid=103229)[0m top5: 0.5093283582089553
[2m[36m(func pid=103229)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=103229)[0m f1_macro: 0.001205377839592026
[2m[36m(func pid=103229)[0m f1_weighted: 7.308727572153144e-05
[2m[36m(func pid=103229)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 1.8453 | Steps: 2 | Val loss: 1.9741 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 1.3327 | Steps: 2 | Val loss: 2.4456 | Batch size: 32 | lr: 0.01 | Duration: 2.72s
[2m[36m(func pid=91054)[0m top1: 0.21595149253731344
[2m[36m(func pid=91054)[0m top5: 0.835820895522388
[2m[36m(func pid=91054)[0m f1_micro: 0.21595149253731344
[2m[36m(func pid=91054)[0m f1_macro: 0.21085773515472644
[2m[36m(func pid=91054)[0m f1_weighted: 0.232969554245419
[2m[36m(func pid=91054)[0m f1_per_class: [0.059, 0.321, 0.191, 0.22, 0.078, 0.326, 0.152, 0.45, 0.057, 0.255]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 2.4642 | Steps: 2 | Val loss: 312246.0938 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
== Status ==
Current time: 2024-01-07 02:50:48 (running for 00:26:49.12)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  2.071 |      0.211 |                   61 |
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  1.845 |      0.16  |                   16 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  1.11  |      0.186 |                   11 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 | 12.94  |      0.001 |                    8 |
| train_6ed81_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=101178)[0m top1: 0.20848880597014927
[2m[36m(func pid=101178)[0m top5: 0.8731343283582089
[2m[36m(func pid=101178)[0m f1_micro: 0.20848880597014927
[2m[36m(func pid=101178)[0m f1_macro: 0.160229046669312
[2m[36m(func pid=101178)[0m f1_weighted: 0.12494776221920684
[2m[36m(func pid=101178)[0m f1_per_class: [0.154, 0.393, 0.393, 0.019, 0.087, 0.039, 0.06, 0.395, 0.0, 0.063]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=102297)[0m top1: 0.31576492537313433
[2m[36m(func pid=102297)[0m top5: 0.8763992537313433
[2m[36m(func pid=102297)[0m f1_micro: 0.31576492537313433
[2m[36m(func pid=102297)[0m f1_macro: 0.24747898311824726
[2m[36m(func pid=102297)[0m f1_weighted: 0.27763324119123695
[2m[36m(func pid=102297)[0m f1_per_class: [0.0, 0.481, 0.273, 0.305, 0.14, 0.356, 0.125, 0.337, 0.202, 0.256]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 2.1686 | Steps: 2 | Val loss: 2.1562 | Batch size: 32 | lr: 0.0001 | Duration: 2.77s
[2m[36m(func pid=103229)[0m top1: 0.006063432835820896
[2m[36m(func pid=103229)[0m top5: 0.5093283582089553
[2m[36m(func pid=103229)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=103229)[0m f1_macro: 0.001205377839592026
[2m[36m(func pid=103229)[0m f1_weighted: 7.308727572153144e-05
[2m[36m(func pid=103229)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 1.7582 | Steps: 2 | Val loss: 1.9779 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 1.0515 | Steps: 2 | Val loss: 5.7341 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
[2m[36m(func pid=91054)[0m top1: 0.21315298507462688
[2m[36m(func pid=91054)[0m top5: 0.8325559701492538
[2m[36m(func pid=91054)[0m f1_micro: 0.2131529850746269
[2m[36m(func pid=91054)[0m f1_macro: 0.21097987970776325
[2m[36m(func pid=91054)[0m f1_weighted: 0.2263610398562424
[2m[36m(func pid=91054)[0m f1_per_class: [0.063, 0.329, 0.193, 0.214, 0.075, 0.328, 0.128, 0.456, 0.059, 0.264]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 9.9668 | Steps: 2 | Val loss: 70221.0000 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
== Status ==
Current time: 2024-01-07 02:50:53 (running for 00:26:54.45)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  2.169 |      0.211 |                   62 |
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  1.758 |      0.155 |                   17 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  1.333 |      0.247 |                   12 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  2.464 |      0.001 |                    9 |
| train_6ed81_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=101178)[0m top1: 0.20708955223880596
[2m[36m(func pid=101178)[0m top5: 0.8591417910447762
[2m[36m(func pid=101178)[0m f1_micro: 0.20708955223880596
[2m[36m(func pid=101178)[0m f1_macro: 0.15522575207081396
[2m[36m(func pid=101178)[0m f1_weighted: 0.11710900580537303
[2m[36m(func pid=101178)[0m f1_per_class: [0.169, 0.403, 0.355, 0.025, 0.096, 0.0, 0.034, 0.409, 0.0, 0.061]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=102297)[0m top1: 0.19449626865671643
[2m[36m(func pid=102297)[0m top5: 0.5629664179104478
[2m[36m(func pid=102297)[0m f1_micro: 0.19449626865671643
[2m[36m(func pid=102297)[0m f1_macro: 0.13150958779174493
[2m[36m(func pid=102297)[0m f1_weighted: 0.18509777258165278
[2m[36m(func pid=102297)[0m f1_per_class: [0.043, 0.371, 0.273, 0.417, 0.151, 0.0, 0.0, 0.0, 0.022, 0.039]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 2.0374 | Steps: 2 | Val loss: 2.1543 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=103229)[0m top1: 0.01166044776119403
[2m[36m(func pid=103229)[0m top5: 0.5149253731343284
[2m[36m(func pid=103229)[0m f1_micro: 0.01166044776119403
[2m[36m(func pid=103229)[0m f1_macro: 0.0023052097740894418
[2m[36m(func pid=103229)[0m f1_weighted: 0.0002687977814936383
[2m[36m(func pid=103229)[0m f1_per_class: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.023]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 1.8355 | Steps: 2 | Val loss: 1.9906 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 1.1544 | Steps: 2 | Val loss: 3.3260 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
[2m[36m(func pid=91054)[0m top1: 0.21128731343283583
[2m[36m(func pid=91054)[0m top5: 0.832089552238806
[2m[36m(func pid=91054)[0m f1_micro: 0.21128731343283583
[2m[36m(func pid=91054)[0m f1_macro: 0.20579763369962345
[2m[36m(func pid=91054)[0m f1_weighted: 0.2232697249693505
[2m[36m(func pid=91054)[0m f1_per_class: [0.063, 0.33, 0.198, 0.211, 0.074, 0.328, 0.124, 0.447, 0.047, 0.235]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 3.8480 | Steps: 2 | Val loss: 6658.1455 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 02:50:58 (running for 00:26:59.75)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  2.037 |      0.206 |                   63 |
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  1.836 |      0.174 |                   18 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  1.052 |      0.132 |                   13 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  9.967 |      0.002 |                   10 |
| train_6ed81_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=101178)[0m top1: 0.20708955223880596
[2m[36m(func pid=101178)[0m top5: 0.8596082089552238
[2m[36m(func pid=101178)[0m f1_micro: 0.20708955223880596
[2m[36m(func pid=101178)[0m f1_macro: 0.1739468966106676
[2m[36m(func pid=101178)[0m f1_weighted: 0.13102190770313166
[2m[36m(func pid=101178)[0m f1_per_class: [0.258, 0.413, 0.373, 0.07, 0.109, 0.0, 0.018, 0.446, 0.0, 0.052]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=102297)[0m top1: 0.29757462686567165
[2m[36m(func pid=102297)[0m top5: 0.8675373134328358
[2m[36m(func pid=102297)[0m f1_micro: 0.29757462686567165
[2m[36m(func pid=102297)[0m f1_macro: 0.23765925494233073
[2m[36m(func pid=102297)[0m f1_weighted: 0.30211139314161084
[2m[36m(func pid=102297)[0m f1_per_class: [0.076, 0.393, 0.139, 0.271, 0.16, 0.248, 0.323, 0.4, 0.158, 0.209]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 1.9914 | Steps: 2 | Val loss: 2.1515 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=103229)[0m top1: 0.009794776119402986
[2m[36m(func pid=103229)[0m top5: 0.523320895522388
[2m[36m(func pid=103229)[0m f1_micro: 0.009794776119402986
[2m[36m(func pid=103229)[0m f1_macro: 0.005380485527544351
[2m[36m(func pid=103229)[0m f1_weighted: 0.007244774464512173
[2m[36m(func pid=103229)[0m f1_per_class: [0.0, 0.042, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 1.7233 | Steps: 2 | Val loss: 1.9572 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 1.4030 | Steps: 2 | Val loss: 5.8734 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=91054)[0m top1: 0.2126865671641791
[2m[36m(func pid=91054)[0m top5: 0.8386194029850746
[2m[36m(func pid=91054)[0m f1_micro: 0.2126865671641791
[2m[36m(func pid=91054)[0m f1_macro: 0.20925464681725417
[2m[36m(func pid=91054)[0m f1_weighted: 0.22482483639344686
[2m[36m(func pid=91054)[0m f1_per_class: [0.061, 0.345, 0.202, 0.209, 0.073, 0.33, 0.121, 0.444, 0.047, 0.261]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 2.3593 | Steps: 2 | Val loss: 2201.3145 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 02:51:04 (running for 00:27:05.04)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.991 |      0.209 |                   64 |
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  1.836 |      0.174 |                   18 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  1.403 |      0.081 |                   15 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  3.848 |      0.005 |                   11 |
| train_6ed81_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.0914179104477612
[2m[36m(func pid=102297)[0m top5: 0.5895522388059702
[2m[36m(func pid=102297)[0m f1_micro: 0.0914179104477612
[2m[36m(func pid=102297)[0m f1_macro: 0.08068401100635167
[2m[36m(func pid=102297)[0m f1_weighted: 0.08864769912935677
[2m[36m(func pid=102297)[0m f1_per_class: [0.04, 0.397, 0.081, 0.038, 0.154, 0.0, 0.015, 0.031, 0.01, 0.04]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=101178)[0m top1: 0.22388059701492538
[2m[36m(func pid=101178)[0m top5: 0.8596082089552238
[2m[36m(func pid=101178)[0m f1_micro: 0.22388059701492538
[2m[36m(func pid=101178)[0m f1_macro: 0.18931772525361965
[2m[36m(func pid=101178)[0m f1_weighted: 0.17562050177833738
[2m[36m(func pid=101178)[0m f1_per_class: [0.251, 0.435, 0.328, 0.146, 0.073, 0.046, 0.065, 0.464, 0.0, 0.086]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 1.9745 | Steps: 2 | Val loss: 2.1491 | Batch size: 32 | lr: 0.0001 | Duration: 2.79s
[2m[36m(func pid=103229)[0m top1: 0.02332089552238806
[2m[36m(func pid=103229)[0m top5: 0.5629664179104478
[2m[36m(func pid=103229)[0m f1_micro: 0.02332089552238806
[2m[36m(func pid=103229)[0m f1_macro: 0.04128641060078804
[2m[36m(func pid=103229)[0m f1_weighted: 0.026742753800062132
[2m[36m(func pid=103229)[0m f1_per_class: [0.0, 0.144, 0.013, 0.0, 0.256, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 1.2059 | Steps: 2 | Val loss: 4.8436 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 1.6660 | Steps: 2 | Val loss: 1.9388 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=91054)[0m top1: 0.2126865671641791
[2m[36m(func pid=91054)[0m top5: 0.8386194029850746
[2m[36m(func pid=91054)[0m f1_micro: 0.2126865671641791
[2m[36m(func pid=91054)[0m f1_macro: 0.2128945416699736
[2m[36m(func pid=91054)[0m f1_weighted: 0.22585657925000677
[2m[36m(func pid=91054)[0m f1_per_class: [0.07, 0.346, 0.21, 0.206, 0.071, 0.327, 0.126, 0.448, 0.047, 0.279]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 2.1939 | Steps: 2 | Val loss: 925.2527 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
== Status ==
Current time: 2024-01-07 02:51:09 (running for 00:27:10.37)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.974 |      0.213 |                   65 |
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  1.666 |      0.209 |                   20 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  1.403 |      0.081 |                   15 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  2.359 |      0.041 |                   12 |
| train_6ed81_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=101178)[0m top1: 0.24113805970149255
[2m[36m(func pid=101178)[0m top5: 0.8591417910447762
[2m[36m(func pid=101178)[0m f1_micro: 0.24113805970149255
[2m[36m(func pid=101178)[0m f1_macro: 0.20938987230552558
[2m[36m(func pid=101178)[0m f1_weighted: 0.2117481663481714
[2m[36m(func pid=101178)[0m f1_per_class: [0.215, 0.467, 0.349, 0.238, 0.066, 0.125, 0.056, 0.41, 0.055, 0.112]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=102297)[0m top1: 0.09794776119402986
[2m[36m(func pid=102297)[0m top5: 0.769589552238806
[2m[36m(func pid=102297)[0m f1_micro: 0.09794776119402987
[2m[36m(func pid=102297)[0m f1_macro: 0.09774620245889243
[2m[36m(func pid=102297)[0m f1_weighted: 0.10733557519704233
[2m[36m(func pid=102297)[0m f1_per_class: [0.047, 0.351, 0.102, 0.023, 0.16, 0.008, 0.097, 0.104, 0.036, 0.048]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 2.0887 | Steps: 2 | Val loss: 2.1498 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=103229)[0m top1: 0.03684701492537314
[2m[36m(func pid=103229)[0m top5: 0.5970149253731343
[2m[36m(func pid=103229)[0m f1_micro: 0.03684701492537314
[2m[36m(func pid=103229)[0m f1_macro: 0.03678813622475594
[2m[36m(func pid=103229)[0m f1_weighted: 0.03751039960047738
[2m[36m(func pid=103229)[0m f1_per_class: [0.0, 0.211, 0.014, 0.0, 0.143, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 1.5518 | Steps: 2 | Val loss: 1.9307 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 1.0078 | Steps: 2 | Val loss: 3.4717 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=91054)[0m top1: 0.20755597014925373
[2m[36m(func pid=91054)[0m top5: 0.8386194029850746
[2m[36m(func pid=91054)[0m f1_micro: 0.20755597014925375
[2m[36m(func pid=91054)[0m f1_macro: 0.2090167195630081
[2m[36m(func pid=91054)[0m f1_weighted: 0.21925542967804654
[2m[36m(func pid=91054)[0m f1_per_class: [0.068, 0.337, 0.202, 0.19, 0.069, 0.314, 0.127, 0.466, 0.046, 0.273]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 2.1553 | Steps: 2 | Val loss: 415.1028 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
== Status ==
Current time: 2024-01-07 02:51:14 (running for 00:27:15.65)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  2.089 |      0.209 |                   66 |
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  1.666 |      0.209 |                   20 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  1.008 |      0.192 |                   17 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  2.194 |      0.037 |                   13 |
| train_6ed81_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.21175373134328357
[2m[36m(func pid=102297)[0m top5: 0.8558768656716418
[2m[36m(func pid=102297)[0m f1_micro: 0.21175373134328357
[2m[36m(func pid=102297)[0m f1_macro: 0.1924535932954064
[2m[36m(func pid=102297)[0m f1_weighted: 0.2090651943303798
[2m[36m(func pid=102297)[0m f1_per_class: [0.075, 0.309, 0.258, 0.088, 0.179, 0.236, 0.262, 0.31, 0.062, 0.144]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=101178)[0m top1: 0.2513992537313433
[2m[36m(func pid=101178)[0m top5: 0.8624067164179104
[2m[36m(func pid=101178)[0m f1_micro: 0.2513992537313433
[2m[36m(func pid=101178)[0m f1_macro: 0.22293326856928722
[2m[36m(func pid=101178)[0m f1_weighted: 0.242272260751263
[2m[36m(func pid=101178)[0m f1_per_class: [0.167, 0.453, 0.324, 0.277, 0.062, 0.219, 0.098, 0.404, 0.054, 0.173]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 2.0279 | Steps: 2 | Val loss: 2.1437 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=103229)[0m top1: 0.07602611940298508
[2m[36m(func pid=103229)[0m top5: 0.6026119402985075
[2m[36m(func pid=103229)[0m f1_micro: 0.07602611940298508
[2m[36m(func pid=103229)[0m f1_macro: 0.037278665979026994
[2m[36m(func pid=103229)[0m f1_weighted: 0.06156207263065795
[2m[36m(func pid=103229)[0m f1_per_class: [0.0, 0.357, 0.016, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.9379 | Steps: 2 | Val loss: 3.2845 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 1.5077 | Steps: 2 | Val loss: 1.9055 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=91054)[0m top1: 0.208955223880597
[2m[36m(func pid=91054)[0m top5: 0.8381529850746269
[2m[36m(func pid=91054)[0m f1_micro: 0.208955223880597
[2m[36m(func pid=91054)[0m f1_macro: 0.21212407995948923
[2m[36m(func pid=91054)[0m f1_weighted: 0.2211988243038532
[2m[36m(func pid=91054)[0m f1_per_class: [0.075, 0.334, 0.218, 0.195, 0.065, 0.322, 0.124, 0.465, 0.074, 0.25]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 2.3326 | Steps: 2 | Val loss: 210.0935 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
== Status ==
Current time: 2024-01-07 02:51:20 (running for 00:27:20.84)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  2.028 |      0.212 |                   67 |
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  1.552 |      0.223 |                   21 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.938 |      0.23  |                   18 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  2.155 |      0.037 |                   14 |
| train_6ed81_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.19542910447761194
[2m[36m(func pid=102297)[0m top5: 0.8432835820895522
[2m[36m(func pid=102297)[0m f1_micro: 0.19542910447761194
[2m[36m(func pid=102297)[0m f1_macro: 0.22995177371528586
[2m[36m(func pid=102297)[0m f1_weighted: 0.17251182689315647
[2m[36m(func pid=102297)[0m f1_per_class: [0.113, 0.247, 0.686, 0.191, 0.103, 0.283, 0.039, 0.301, 0.183, 0.152]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=101178)[0m top1: 0.2789179104477612
[2m[36m(func pid=101178)[0m top5: 0.8647388059701493
[2m[36m(func pid=101178)[0m f1_micro: 0.2789179104477612
[2m[36m(func pid=101178)[0m f1_macro: 0.24436193540696646
[2m[36m(func pid=101178)[0m f1_weighted: 0.28499859456859533
[2m[36m(func pid=101178)[0m f1_per_class: [0.176, 0.464, 0.338, 0.331, 0.066, 0.22, 0.175, 0.442, 0.053, 0.178]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 1.9985 | Steps: 2 | Val loss: 2.1415 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=103229)[0m top1: 0.11007462686567164
[2m[36m(func pid=103229)[0m top5: 0.5541044776119403
[2m[36m(func pid=103229)[0m f1_micro: 0.11007462686567164
[2m[36m(func pid=103229)[0m f1_macro: 0.045997943918626404
[2m[36m(func pid=103229)[0m f1_weighted: 0.07082065290236846
[2m[36m(func pid=103229)[0m f1_per_class: [0.0, 0.352, 0.019, 0.0, 0.0, 0.089, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 1.3038 | Steps: 2 | Val loss: 3.0271 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 1.4994 | Steps: 2 | Val loss: 1.8992 | Batch size: 32 | lr: 0.001 | Duration: 3.03s
[2m[36m(func pid=91054)[0m top1: 0.21455223880597016
[2m[36m(func pid=91054)[0m top5: 0.8339552238805971
[2m[36m(func pid=91054)[0m f1_micro: 0.21455223880597016
[2m[36m(func pid=91054)[0m f1_macro: 0.22123235882429962
[2m[36m(func pid=91054)[0m f1_weighted: 0.22485052923924234
[2m[36m(func pid=91054)[0m f1_per_class: [0.088, 0.327, 0.237, 0.193, 0.066, 0.332, 0.135, 0.471, 0.073, 0.292]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 1.8393 | Steps: 2 | Val loss: 92.8496 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 02:51:25 (running for 00:27:26.21)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.999 |      0.221 |                   68 |
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  1.508 |      0.244 |                   22 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  1.304 |      0.218 |                   19 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  2.333 |      0.046 |                   15 |
| train_6ed81_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.19169776119402984
[2m[36m(func pid=102297)[0m top5: 0.8278917910447762
[2m[36m(func pid=102297)[0m f1_micro: 0.19169776119402984
[2m[36m(func pid=102297)[0m f1_macro: 0.21787660340182033
[2m[36m(func pid=102297)[0m f1_weighted: 0.20359849697996205
[2m[36m(func pid=102297)[0m f1_per_class: [0.157, 0.242, 0.667, 0.36, 0.082, 0.122, 0.054, 0.354, 0.074, 0.067]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=101178)[0m top1: 0.2947761194029851
[2m[36m(func pid=101178)[0m top5: 0.8638059701492538
[2m[36m(func pid=101178)[0m f1_micro: 0.2947761194029851
[2m[36m(func pid=101178)[0m f1_macro: 0.25449604743355136
[2m[36m(func pid=101178)[0m f1_weighted: 0.31229371842148496
[2m[36m(func pid=101178)[0m f1_per_class: [0.173, 0.456, 0.333, 0.376, 0.073, 0.193, 0.228, 0.495, 0.073, 0.144]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 1.9797 | Steps: 2 | Val loss: 2.1395 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=103229)[0m top1: 0.13805970149253732
[2m[36m(func pid=103229)[0m top5: 0.5536380597014925
[2m[36m(func pid=103229)[0m f1_micro: 0.13805970149253732
[2m[36m(func pid=103229)[0m f1_macro: 0.07163531296611533
[2m[36m(func pid=103229)[0m f1_weighted: 0.09111834409757963
[2m[36m(func pid=103229)[0m f1_per_class: [0.0, 0.301, 0.033, 0.0, 0.043, 0.339, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 1.3829 | Steps: 2 | Val loss: 2.5718 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
[2m[36m(func pid=91054)[0m top1: 0.2103544776119403
[2m[36m(func pid=91054)[0m top5: 0.8316231343283582
[2m[36m(func pid=91054)[0m f1_micro: 0.2103544776119403
[2m[36m(func pid=91054)[0m f1_macro: 0.2163561307214576
[2m[36m(func pid=91054)[0m f1_weighted: 0.21435896928105894
[2m[36m(func pid=91054)[0m f1_per_class: [0.088, 0.333, 0.256, 0.181, 0.066, 0.335, 0.109, 0.454, 0.071, 0.269]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 1.4141 | Steps: 2 | Val loss: 1.8509 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 2.0521 | Steps: 2 | Val loss: 46.2349 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
== Status ==
Current time: 2024-01-07 02:51:30 (running for 00:27:31.52)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.98  |      0.216 |                   69 |
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  1.499 |      0.254 |                   23 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  1.383 |      0.211 |                   20 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.839 |      0.072 |                   16 |
| train_6ed81_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.355410447761194
[2m[36m(func pid=102297)[0m top5: 0.8614738805970149
[2m[36m(func pid=102297)[0m f1_micro: 0.355410447761194
[2m[36m(func pid=102297)[0m f1_macro: 0.21083751979286341
[2m[36m(func pid=102297)[0m f1_weighted: 0.3621263195981821
[2m[36m(func pid=102297)[0m f1_per_class: [0.278, 0.43, 0.0, 0.473, 0.03, 0.17, 0.408, 0.058, 0.143, 0.119]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=101178)[0m top1: 0.3199626865671642
[2m[36m(func pid=101178)[0m top5: 0.8731343283582089
[2m[36m(func pid=101178)[0m f1_micro: 0.3199626865671642
[2m[36m(func pid=101178)[0m f1_macro: 0.2741869411656862
[2m[36m(func pid=101178)[0m f1_weighted: 0.33764042036018693
[2m[36m(func pid=101178)[0m f1_per_class: [0.16, 0.472, 0.338, 0.397, 0.079, 0.253, 0.261, 0.481, 0.074, 0.225]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 1.9228 | Steps: 2 | Val loss: 2.1373 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=103229)[0m top1: 0.12313432835820895
[2m[36m(func pid=103229)[0m top5: 0.6660447761194029
[2m[36m(func pid=103229)[0m f1_micro: 0.12313432835820895
[2m[36m(func pid=103229)[0m f1_macro: 0.08236605273182072
[2m[36m(func pid=103229)[0m f1_weighted: 0.08726619528543471
[2m[36m(func pid=103229)[0m f1_per_class: [0.021, 0.216, 0.067, 0.0, 0.049, 0.317, 0.015, 0.138, 0.0, 0.0]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 1.2588 | Steps: 2 | Val loss: 3.4112 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=91054)[0m top1: 0.20848880597014927
[2m[36m(func pid=91054)[0m top5: 0.8334888059701493
[2m[36m(func pid=91054)[0m f1_micro: 0.20848880597014927
[2m[36m(func pid=91054)[0m f1_macro: 0.21394128654132918
[2m[36m(func pid=91054)[0m f1_weighted: 0.21232814482740903
[2m[36m(func pid=91054)[0m f1_per_class: [0.088, 0.338, 0.259, 0.192, 0.068, 0.323, 0.098, 0.436, 0.068, 0.269]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 1.4536 | Steps: 2 | Val loss: 1.8756 | Batch size: 32 | lr: 0.001 | Duration: 3.07s
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 1.9829 | Steps: 2 | Val loss: 26.2380 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 02:51:36 (running for 00:27:36.93)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.923 |      0.214 |                   70 |
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  1.414 |      0.274 |                   24 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  1.259 |      0.218 |                   21 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  2.052 |      0.082 |                   17 |
| train_6ed81_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.36240671641791045
[2m[36m(func pid=102297)[0m top5: 0.8689365671641791
[2m[36m(func pid=102297)[0m f1_micro: 0.36240671641791045
[2m[36m(func pid=102297)[0m f1_macro: 0.2184709524136657
[2m[36m(func pid=102297)[0m f1_weighted: 0.33479715578166847
[2m[36m(func pid=102297)[0m f1_per_class: [0.105, 0.434, 0.0, 0.305, 0.0, 0.067, 0.447, 0.463, 0.044, 0.32]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=101178)[0m top1: 0.32136194029850745
[2m[36m(func pid=101178)[0m top5: 0.8666044776119403
[2m[36m(func pid=101178)[0m f1_micro: 0.32136194029850745
[2m[36m(func pid=101178)[0m f1_macro: 0.27955534625422546
[2m[36m(func pid=101178)[0m f1_weighted: 0.3405781381284411
[2m[36m(func pid=101178)[0m f1_per_class: [0.146, 0.504, 0.286, 0.367, 0.085, 0.285, 0.261, 0.519, 0.073, 0.27]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 1.9557 | Steps: 2 | Val loss: 2.1338 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=103229)[0m top1: 0.13152985074626866
[2m[36m(func pid=103229)[0m top5: 0.738339552238806
[2m[36m(func pid=103229)[0m f1_micro: 0.13152985074626866
[2m[36m(func pid=103229)[0m f1_macro: 0.0873636670479664
[2m[36m(func pid=103229)[0m f1_weighted: 0.11543803421424233
[2m[36m(func pid=103229)[0m f1_per_class: [0.026, 0.241, 0.109, 0.0, 0.045, 0.297, 0.128, 0.0, 0.0, 0.028]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 1.3511 | Steps: 2 | Val loss: 5.3160 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=91054)[0m top1: 0.20662313432835822
[2m[36m(func pid=91054)[0m top5: 0.8348880597014925
[2m[36m(func pid=91054)[0m f1_micro: 0.20662313432835824
[2m[36m(func pid=91054)[0m f1_macro: 0.21024742251468945
[2m[36m(func pid=91054)[0m f1_weighted: 0.20799913174343754
[2m[36m(func pid=91054)[0m f1_per_class: [0.087, 0.328, 0.253, 0.192, 0.067, 0.324, 0.09, 0.436, 0.068, 0.259]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 1.3195 | Steps: 2 | Val loss: 1.9252 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 2.0449 | Steps: 2 | Val loss: 15.7891 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 02:51:41 (running for 00:27:42.51)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.956 |      0.21  |                   71 |
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  1.454 |      0.28  |                   25 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  1.351 |      0.15  |                   22 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.983 |      0.087 |                   18 |
| train_6ed81_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.14738805970149255
[2m[36m(func pid=102297)[0m top5: 0.851679104477612
[2m[36m(func pid=102297)[0m f1_micro: 0.14738805970149255
[2m[36m(func pid=102297)[0m f1_macro: 0.14986745417748168
[2m[36m(func pid=102297)[0m f1_weighted: 0.13927222588070637
[2m[36m(func pid=102297)[0m f1_per_class: [0.067, 0.136, 0.071, 0.124, 0.088, 0.191, 0.108, 0.299, 0.126, 0.289]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=101178)[0m top1: 0.31669776119402987
[2m[36m(func pid=101178)[0m top5: 0.8456156716417911
[2m[36m(func pid=101178)[0m f1_micro: 0.31669776119402987
[2m[36m(func pid=101178)[0m f1_macro: 0.27182682786891166
[2m[36m(func pid=101178)[0m f1_weighted: 0.34786847205999094
[2m[36m(func pid=101178)[0m f1_per_class: [0.166, 0.491, 0.282, 0.416, 0.085, 0.248, 0.259, 0.542, 0.098, 0.132]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 1.9253 | Steps: 2 | Val loss: 2.1326 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=103229)[0m top1: 0.17583955223880596
[2m[36m(func pid=103229)[0m top5: 0.753731343283582
[2m[36m(func pid=103229)[0m f1_micro: 0.17583955223880596
[2m[36m(func pid=103229)[0m f1_macro: 0.09916835633603482
[2m[36m(func pid=103229)[0m f1_weighted: 0.12618184071342908
[2m[36m(func pid=103229)[0m f1_per_class: [0.026, 0.371, 0.178, 0.01, 0.0, 0.257, 0.091, 0.016, 0.0, 0.043]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.7399 | Steps: 2 | Val loss: 6.5987 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=91054)[0m top1: 0.20475746268656717
[2m[36m(func pid=91054)[0m top5: 0.8348880597014925
[2m[36m(func pid=91054)[0m f1_micro: 0.20475746268656717
[2m[36m(func pid=91054)[0m f1_macro: 0.20978172636009945
[2m[36m(func pid=91054)[0m f1_weighted: 0.2049562877873013
[2m[36m(func pid=91054)[0m f1_per_class: [0.084, 0.333, 0.25, 0.187, 0.067, 0.328, 0.079, 0.439, 0.067, 0.264]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 1.2059 | Steps: 2 | Val loss: 1.8086 | Batch size: 32 | lr: 0.001 | Duration: 3.12s
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 1.6471 | Steps: 2 | Val loss: 9.4548 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=102297)[0m top1: 0.14085820895522388
[2m[36m(func pid=102297)[0m top5: 0.8274253731343284
[2m[36m(func pid=102297)[0m f1_micro: 0.14085820895522388
[2m[36m(func pid=102297)[0m f1_macro: 0.14758889389631072
[2m[36m(func pid=102297)[0m f1_weighted: 0.11330130099496602
[2m[36m(func pid=102297)[0m f1_per_class: [0.051, 0.016, 0.064, 0.02, 0.074, 0.352, 0.113, 0.379, 0.125, 0.283]
== Status ==
Current time: 2024-01-07 02:51:46 (running for 00:27:47.73)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.925 |      0.21  |                   72 |
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  1.32  |      0.272 |                   26 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.74  |      0.148 |                   23 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  2.045 |      0.099 |                   19 |
| train_6ed81_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=101178)[0m top1: 0.36240671641791045
[2m[36m(func pid=101178)[0m top5: 0.8782649253731343
[2m[36m(func pid=101178)[0m f1_micro: 0.36240671641791045
[2m[36m(func pid=101178)[0m f1_macro: 0.3152150195090452
[2m[36m(func pid=101178)[0m f1_weighted: 0.3931006484417914
[2m[36m(func pid=101178)[0m f1_per_class: [0.18, 0.465, 0.344, 0.46, 0.079, 0.278, 0.356, 0.569, 0.123, 0.297]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 1.9932 | Steps: 2 | Val loss: 2.1313 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=103229)[0m top1: 0.23647388059701493
[2m[36m(func pid=103229)[0m top5: 0.8148320895522388
[2m[36m(func pid=103229)[0m f1_micro: 0.23647388059701493
[2m[36m(func pid=103229)[0m f1_macro: 0.15531432846773469
[2m[36m(func pid=103229)[0m f1_weighted: 0.17453175333628343
[2m[36m(func pid=103229)[0m f1_per_class: [0.041, 0.397, 0.273, 0.041, 0.0, 0.232, 0.153, 0.332, 0.0, 0.084]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 1.2756 | Steps: 2 | Val loss: 3.8823 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=91054)[0m top1: 0.20988805970149255
[2m[36m(func pid=91054)[0m top5: 0.8311567164179104
[2m[36m(func pid=91054)[0m f1_micro: 0.20988805970149255
[2m[36m(func pid=91054)[0m f1_macro: 0.21155764092604215
[2m[36m(func pid=91054)[0m f1_weighted: 0.20959260813700947
[2m[36m(func pid=91054)[0m f1_per_class: [0.085, 0.341, 0.247, 0.194, 0.068, 0.341, 0.076, 0.457, 0.066, 0.241]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 1.1790 | Steps: 2 | Val loss: 2.0031 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 1.8608 | Steps: 2 | Val loss: 7.3983 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
== Status ==
Current time: 2024-01-07 02:51:52 (running for 00:27:53.00)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.993 |      0.212 |                   73 |
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  1.206 |      0.315 |                   27 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  1.276 |      0.152 |                   24 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.647 |      0.155 |                   20 |
| train_6ed81_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.1478544776119403
[2m[36m(func pid=102297)[0m top5: 0.7658582089552238
[2m[36m(func pid=102297)[0m f1_micro: 0.1478544776119403
[2m[36m(func pid=102297)[0m f1_macro: 0.1523667927491738
[2m[36m(func pid=102297)[0m f1_weighted: 0.1755248128972364
[2m[36m(func pid=102297)[0m f1_per_class: [0.074, 0.309, 0.111, 0.153, 0.077, 0.194, 0.109, 0.318, 0.081, 0.098]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=101178)[0m top1: 0.2775186567164179
[2m[36m(func pid=101178)[0m top5: 0.835820895522388
[2m[36m(func pid=101178)[0m f1_micro: 0.2775186567164179
[2m[36m(func pid=101178)[0m f1_macro: 0.2533858316418528
[2m[36m(func pid=101178)[0m f1_weighted: 0.30475620653833585
[2m[36m(func pid=101178)[0m f1_per_class: [0.17, 0.474, 0.328, 0.445, 0.083, 0.163, 0.129, 0.53, 0.126, 0.086]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=103229)[0m top1: 0.2178171641791045
[2m[36m(func pid=103229)[0m top5: 0.8185634328358209
[2m[36m(func pid=103229)[0m f1_micro: 0.2178171641791045
[2m[36m(func pid=103229)[0m f1_macro: 0.1801696384044706
[2m[36m(func pid=103229)[0m f1_weighted: 0.18848802228349196
[2m[36m(func pid=103229)[0m f1_per_class: [0.054, 0.322, 0.245, 0.243, 0.076, 0.265, 0.024, 0.363, 0.046, 0.163]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 2.0518 | Steps: 2 | Val loss: 2.1298 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 1.7048 | Steps: 2 | Val loss: 3.2781 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=91054)[0m top1: 0.20942164179104478
[2m[36m(func pid=91054)[0m top5: 0.8325559701492538
[2m[36m(func pid=91054)[0m f1_micro: 0.20942164179104478
[2m[36m(func pid=91054)[0m f1_macro: 0.20716648118614273
[2m[36m(func pid=91054)[0m f1_weighted: 0.21394793231900583
[2m[36m(func pid=91054)[0m f1_per_class: [0.079, 0.33, 0.214, 0.196, 0.065, 0.329, 0.099, 0.472, 0.065, 0.222]
[2m[36m(func pid=91054)[0m 
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 1.1846 | Steps: 2 | Val loss: 1.9453 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 1.7890 | Steps: 2 | Val loss: 6.4629 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
== Status ==
Current time: 2024-01-07 02:51:57 (running for 00:27:58.24)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00012 | RUNNING    | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  2.052 |      0.207 |                   74 |
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  1.179 |      0.253 |                   28 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  1.705 |      0.18  |                   25 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.861 |      0.18  |                   21 |
| train_6ed81_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.17723880597014927
[2m[36m(func pid=102297)[0m top5: 0.7882462686567164
[2m[36m(func pid=102297)[0m f1_micro: 0.17723880597014927
[2m[36m(func pid=102297)[0m f1_macro: 0.18010248028128678
[2m[36m(func pid=102297)[0m f1_weighted: 0.2053715626846167
[2m[36m(func pid=102297)[0m f1_per_class: [0.103, 0.407, 0.364, 0.169, 0.08, 0.07, 0.197, 0.218, 0.075, 0.118]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=101178)[0m top1: 0.30783582089552236
[2m[36m(func pid=101178)[0m top5: 0.8512126865671642
[2m[36m(func pid=101178)[0m f1_micro: 0.30783582089552236
[2m[36m(func pid=101178)[0m f1_macro: 0.27588163046883274
[2m[36m(func pid=101178)[0m f1_weighted: 0.34153434145586437
[2m[36m(func pid=101178)[0m f1_per_class: [0.182, 0.48, 0.333, 0.463, 0.081, 0.156, 0.222, 0.55, 0.19, 0.101]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=103229)[0m top1: 0.2140858208955224
[2m[36m(func pid=103229)[0m top5: 0.8218283582089553
[2m[36m(func pid=103229)[0m f1_micro: 0.2140858208955224
[2m[36m(func pid=103229)[0m f1_macro: 0.19459991777382185
[2m[36m(func pid=103229)[0m f1_weighted: 0.24736132519083961
[2m[36m(func pid=103229)[0m f1_per_class: [0.055, 0.199, 0.203, 0.167, 0.046, 0.265, 0.339, 0.509, 0.062, 0.101]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=91054)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 1.9767 | Steps: 2 | Val loss: 2.1210 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.7535 | Steps: 2 | Val loss: 3.4945 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=91054)[0m top1: 0.21082089552238806
[2m[36m(func pid=91054)[0m top5: 0.8395522388059702
[2m[36m(func pid=91054)[0m f1_micro: 0.21082089552238809
[2m[36m(func pid=91054)[0m f1_macro: 0.21152819555950148
[2m[36m(func pid=91054)[0m f1_weighted: 0.21512923331241735
[2m[36m(func pid=91054)[0m f1_per_class: [0.091, 0.323, 0.237, 0.207, 0.064, 0.319, 0.099, 0.463, 0.078, 0.235]
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 6.2048 | Steps: 2 | Val loss: 50.5531 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 1.0818 | Steps: 2 | Val loss: 1.7233 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=102297)[0m top1: 0.21828358208955223
[2m[36m(func pid=102297)[0m top5: 0.8390858208955224
[2m[36m(func pid=102297)[0m f1_micro: 0.21828358208955223
[2m[36m(func pid=102297)[0m f1_macro: 0.1733930422653328
[2m[36m(func pid=102297)[0m f1_weighted: 0.23991134427797592
[2m[36m(func pid=102297)[0m f1_per_class: [0.08, 0.337, 0.0, 0.038, 0.069, 0.081, 0.479, 0.133, 0.158, 0.359]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=103229)[0m top1: 0.20755597014925373
[2m[36m(func pid=103229)[0m top5: 0.7896455223880597
[2m[36m(func pid=103229)[0m f1_micro: 0.20755597014925375
[2m[36m(func pid=103229)[0m f1_macro: 0.13640093820552046
[2m[36m(func pid=103229)[0m f1_weighted: 0.1966294445139587
[2m[36m(func pid=103229)[0m f1_per_class: [0.014, 0.276, 0.0, 0.013, 0.048, 0.197, 0.328, 0.408, 0.0, 0.08]
[2m[36m(func pid=101178)[0m top1: 0.3903917910447761
[2m[36m(func pid=101178)[0m top5: 0.8959888059701493
[2m[36m(func pid=101178)[0m f1_micro: 0.39039179104477606
[2m[36m(func pid=101178)[0m f1_macro: 0.33734437997935546
[2m[36m(func pid=101178)[0m f1_weighted: 0.4156239924791872
[2m[36m(func pid=101178)[0m f1_per_class: [0.213, 0.507, 0.355, 0.459, 0.085, 0.236, 0.418, 0.529, 0.202, 0.37]
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.6897 | Steps: 2 | Val loss: 4.3702 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=102297)[0m top1: 0.17257462686567165
[2m[36m(func pid=102297)[0m top5: 0.7220149253731343
[2m[36m(func pid=102297)[0m f1_micro: 0.17257462686567165
[2m[36m(func pid=102297)[0m f1_macro: 0.20906624342323257
[2m[36m(func pid=102297)[0m f1_weighted: 0.13535282903109797
[2m[36m(func pid=102297)[0m f1_per_class: [0.256, 0.458, 0.71, 0.036, 0.086, 0.102, 0.062, 0.0, 0.084, 0.298]
== Status ==
Current time: 2024-01-07 02:52:02 (running for 00:28:03.66)
Memory usage on this node: 22.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  1.185 |      0.276 |                   29 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.753 |      0.173 |                   26 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.789 |      0.195 |                   22 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


== Status ==
Current time: 2024-01-07 02:52:09 (running for 00:28:09.87)
Memory usage on this node: 23.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  1.082 |      0.337 |                   30 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.753 |      0.173 |                   26 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.789 |      0.195 |                   22 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=108657)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=108657)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=108657)[0m Configuration completed!
[2m[36m(func pid=108657)[0m New optimizer parameters:
[2m[36m(func pid=108657)[0m SGD (
[2m[36m(func pid=108657)[0m Parameter Group 0
[2m[36m(func pid=108657)[0m     dampening: 0
[2m[36m(func pid=108657)[0m     differentiable: False
[2m[36m(func pid=108657)[0m     foreach: None
[2m[36m(func pid=108657)[0m     lr: 0.0001
[2m[36m(func pid=108657)[0m     maximize: False
[2m[36m(func pid=108657)[0m     momentum: 0.99
[2m[36m(func pid=108657)[0m     nesterov: False
[2m[36m(func pid=108657)[0m     weight_decay: 1e-05
[2m[36m(func pid=108657)[0m )
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.6850 | Steps: 2 | Val loss: 3.0829 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 3.1058 | Steps: 2 | Val loss: 112.4046 | Batch size: 32 | lr: 0.1 | Duration: 3.01s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 1.0948 | Steps: 2 | Val loss: 1.7366 | Batch size: 32 | lr: 0.001 | Duration: 3.17s
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 3.1039 | Steps: 2 | Val loss: 2.3714 | Batch size: 32 | lr: 0.0001 | Duration: 4.75s
== Status ==
Current time: 2024-01-07 02:52:14 (running for 00:28:14.89)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  1.082 |      0.337 |                   30 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.69  |      0.209 |                   27 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  6.205 |      0.136 |                   23 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.2751865671641791
[2m[36m(func pid=102297)[0m top5: 0.8731343283582089
[2m[36m(func pid=102297)[0m f1_micro: 0.2751865671641791
[2m[36m(func pid=102297)[0m f1_macro: 0.2381855597396969
[2m[36m(func pid=102297)[0m f1_weighted: 0.2582304657871013
[2m[36m(func pid=102297)[0m f1_per_class: [0.0, 0.458, 0.414, 0.059, 0.078, 0.204, 0.35, 0.428, 0.127, 0.263]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=103229)[0m top1: 0.09934701492537314
[2m[36m(func pid=103229)[0m top5: 0.7472014925373134
[2m[36m(func pid=103229)[0m f1_micro: 0.09934701492537314
[2m[36m(func pid=103229)[0m f1_macro: 0.09797336429176226
[2m[36m(func pid=103229)[0m f1_weighted: 0.11602659159394824
[2m[36m(func pid=103229)[0m f1_per_class: [0.039, 0.045, 0.037, 0.026, 0.037, 0.155, 0.19, 0.423, 0.027, 0.0]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=101178)[0m top1: 0.38013059701492535
[2m[36m(func pid=101178)[0m top5: 0.8903917910447762
[2m[36m(func pid=101178)[0m f1_micro: 0.38013059701492535
[2m[36m(func pid=101178)[0m f1_macro: 0.3265544933463494
[2m[36m(func pid=101178)[0m f1_weighted: 0.39793041848067984
[2m[36m(func pid=101178)[0m f1_per_class: [0.213, 0.521, 0.349, 0.434, 0.094, 0.251, 0.376, 0.511, 0.17, 0.347]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=108657)[0m top1: 0.06669776119402986
[2m[36m(func pid=108657)[0m top5: 0.38572761194029853
[2m[36m(func pid=108657)[0m f1_micro: 0.06669776119402986
[2m[36m(func pid=108657)[0m f1_macro: 0.017147829647829647
[2m[36m(func pid=108657)[0m f1_weighted: 0.021290621523830478
[2m[36m(func pid=108657)[0m f1_per_class: [0.0, 0.005, 0.0, 0.049, 0.0, 0.0, 0.0, 0.117, 0.0, 0.0]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.3685 | Steps: 2 | Val loss: 2.7228 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 1.8776 | Steps: 2 | Val loss: 142.3351 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.9754 | Steps: 2 | Val loss: 1.8099 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 3.0984 | Steps: 2 | Val loss: 2.3266 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
== Status ==
Current time: 2024-01-07 02:52:19 (running for 00:28:20.60)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  1.095 |      0.327 |                   31 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.369 |      0.24  |                   29 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  3.106 |      0.098 |                   24 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  3.104 |      0.017 |                    1 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.345615671641791
[2m[36m(func pid=102297)[0m top5: 0.9020522388059702
[2m[36m(func pid=102297)[0m f1_micro: 0.345615671641791
[2m[36m(func pid=102297)[0m f1_macro: 0.24013175768145517
[2m[36m(func pid=102297)[0m f1_weighted: 0.3193713089003581
[2m[36m(func pid=102297)[0m f1_per_class: [0.0, 0.433, 0.282, 0.107, 0.083, 0.194, 0.535, 0.427, 0.112, 0.228]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=103229)[0m top1: 0.12639925373134328
[2m[36m(func pid=103229)[0m top5: 0.7486007462686567
[2m[36m(func pid=103229)[0m f1_micro: 0.12639925373134328
[2m[36m(func pid=103229)[0m f1_macro: 0.09922283049368294
[2m[36m(func pid=103229)[0m f1_weighted: 0.12245989221670882
[2m[36m(func pid=103229)[0m f1_per_class: [0.04, 0.0, 0.04, 0.069, 0.05, 0.15, 0.206, 0.36, 0.078, 0.0]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=101178)[0m top1: 0.3670708955223881
[2m[36m(func pid=101178)[0m top5: 0.8777985074626866
[2m[36m(func pid=101178)[0m f1_micro: 0.3670708955223881
[2m[36m(func pid=101178)[0m f1_macro: 0.3126633313271699
[2m[36m(func pid=101178)[0m f1_weighted: 0.39060600417095526
[2m[36m(func pid=101178)[0m f1_per_class: [0.187, 0.546, 0.31, 0.414, 0.085, 0.286, 0.349, 0.525, 0.128, 0.297]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=108657)[0m top1: 0.14365671641791045
[2m[36m(func pid=108657)[0m top5: 0.5265858208955224
[2m[36m(func pid=108657)[0m f1_micro: 0.14365671641791045
[2m[36m(func pid=108657)[0m f1_macro: 0.04264130145008281
[2m[36m(func pid=108657)[0m f1_weighted: 0.08115114471316638
[2m[36m(func pid=108657)[0m f1_per_class: [0.0, 0.0, 0.0, 0.256, 0.0, 0.0, 0.0, 0.171, 0.0, 0.0]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.6275 | Steps: 2 | Val loss: 2.5941 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 1.7107 | Steps: 2 | Val loss: 124.6906 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.9623 | Steps: 2 | Val loss: 1.8207 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 3.0401 | Steps: 2 | Val loss: 2.3144 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
== Status ==
Current time: 2024-01-07 02:52:25 (running for 00:28:25.98)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.975 |      0.313 |                   32 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.369 |      0.24  |                   29 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.711 |      0.109 |                   26 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  3.098 |      0.043 |                    2 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.3414179104477612
[2m[36m(func pid=102297)[0m top5: 0.8987873134328358
[2m[36m(func pid=102297)[0m f1_micro: 0.3414179104477612
[2m[36m(func pid=102297)[0m f1_macro: 0.24428978539385696
[2m[36m(func pid=102297)[0m f1_weighted: 0.34641867931910214
[2m[36m(func pid=102297)[0m f1_per_class: [0.0, 0.443, 0.214, 0.261, 0.133, 0.251, 0.466, 0.351, 0.153, 0.17]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=103229)[0m top1: 0.13666044776119404
[2m[36m(func pid=103229)[0m top5: 0.7644589552238806
[2m[36m(func pid=103229)[0m f1_micro: 0.13666044776119404
[2m[36m(func pid=103229)[0m f1_macro: 0.10940112296969848
[2m[36m(func pid=103229)[0m f1_weighted: 0.1314950604248126
[2m[36m(func pid=103229)[0m f1_per_class: [0.03, 0.0, 0.042, 0.048, 0.045, 0.196, 0.238, 0.355, 0.063, 0.077]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=101178)[0m top1: 0.3591417910447761
[2m[36m(func pid=101178)[0m top5: 0.8763992537313433
[2m[36m(func pid=101178)[0m f1_micro: 0.3591417910447761
[2m[36m(func pid=101178)[0m f1_macro: 0.31926403637152856
[2m[36m(func pid=101178)[0m f1_weighted: 0.38607688425572145
[2m[36m(func pid=101178)[0m f1_per_class: [0.171, 0.542, 0.31, 0.388, 0.075, 0.279, 0.35, 0.564, 0.174, 0.339]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=108657)[0m top1: 0.18610074626865672
[2m[36m(func pid=108657)[0m top5: 0.566231343283582
[2m[36m(func pid=108657)[0m f1_micro: 0.1861007462686567
[2m[36m(func pid=108657)[0m f1_macro: 0.04846223368551238
[2m[36m(func pid=108657)[0m f1_weighted: 0.0993520808535348
[2m[36m(func pid=108657)[0m f1_per_class: [0.0, 0.0, 0.0, 0.323, 0.0, 0.0, 0.0, 0.162, 0.0, 0.0]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.4062 | Steps: 2 | Val loss: 3.1705 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 3.0003 | Steps: 2 | Val loss: 101.0018 | Batch size: 32 | lr: 0.1 | Duration: 3.03s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.9846 | Steps: 2 | Val loss: 1.7822 | Batch size: 32 | lr: 0.001 | Duration: 3.13s
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 2.9849 | Steps: 2 | Val loss: 2.3127 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
== Status ==
Current time: 2024-01-07 02:52:30 (running for 00:28:31.34)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.962 |      0.319 |                   33 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.406 |      0.207 |                   31 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.711 |      0.109 |                   26 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  3.04  |      0.048 |                    3 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.27798507462686567
[2m[36m(func pid=102297)[0m top5: 0.8549440298507462
[2m[36m(func pid=102297)[0m f1_micro: 0.27798507462686567
[2m[36m(func pid=102297)[0m f1_macro: 0.20708399499500413
[2m[36m(func pid=102297)[0m f1_weighted: 0.31782535692264047
[2m[36m(func pid=102297)[0m f1_per_class: [0.118, 0.44, 0.207, 0.407, 0.082, 0.136, 0.315, 0.161, 0.133, 0.07]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=103229)[0m top1: 0.12733208955223882
[2m[36m(func pid=103229)[0m top5: 0.7439365671641791
[2m[36m(func pid=103229)[0m f1_micro: 0.12733208955223882
[2m[36m(func pid=103229)[0m f1_macro: 0.10324429738854321
[2m[36m(func pid=103229)[0m f1_weighted: 0.10910279193610112
[2m[36m(func pid=103229)[0m f1_per_class: [0.022, 0.0, 0.046, 0.016, 0.051, 0.188, 0.204, 0.308, 0.049, 0.148]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=101178)[0m top1: 0.36613805970149255
[2m[36m(func pid=101178)[0m top5: 0.8847947761194029
[2m[36m(func pid=101178)[0m f1_micro: 0.36613805970149255
[2m[36m(func pid=101178)[0m f1_macro: 0.3258329136416181
[2m[36m(func pid=101178)[0m f1_weighted: 0.39515021357531843
[2m[36m(func pid=101178)[0m f1_per_class: [0.164, 0.54, 0.349, 0.391, 0.084, 0.304, 0.374, 0.545, 0.157, 0.35]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=108657)[0m top1: 0.20055970149253732
[2m[36m(func pid=108657)[0m top5: 0.5778917910447762
[2m[36m(func pid=108657)[0m f1_micro: 0.20055970149253732
[2m[36m(func pid=108657)[0m f1_macro: 0.04285216828227929
[2m[36m(func pid=108657)[0m f1_weighted: 0.10308182557761288
[2m[36m(func pid=108657)[0m f1_per_class: [0.0, 0.0, 0.0, 0.354, 0.0, 0.0, 0.0, 0.074, 0.0, 0.0]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.6286 | Steps: 2 | Val loss: 2.4463 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 2.2105 | Steps: 2 | Val loss: 59.4110 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.9289 | Steps: 2 | Val loss: 1.8082 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 2.9236 | Steps: 2 | Val loss: 2.3137 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
== Status ==
Current time: 2024-01-07 02:52:35 (running for 00:28:36.57)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.985 |      0.326 |                   34 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.629 |      0.261 |                   32 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  3     |      0.103 |                   27 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  2.985 |      0.043 |                    4 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.3306902985074627
[2m[36m(func pid=102297)[0m top5: 0.8922574626865671
[2m[36m(func pid=102297)[0m f1_micro: 0.3306902985074627
[2m[36m(func pid=102297)[0m f1_macro: 0.26127810601975643
[2m[36m(func pid=102297)[0m f1_weighted: 0.35604425267237233
[2m[36m(func pid=102297)[0m f1_per_class: [0.236, 0.451, 0.343, 0.484, 0.103, 0.094, 0.336, 0.345, 0.104, 0.118]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=103229)[0m top1: 0.16184701492537312
[2m[36m(func pid=103229)[0m top5: 0.7817164179104478
[2m[36m(func pid=103229)[0m f1_micro: 0.16184701492537312
[2m[36m(func pid=103229)[0m f1_macro: 0.14339364944611374
[2m[36m(func pid=103229)[0m f1_weighted: 0.1633174344903542
[2m[36m(func pid=103229)[0m f1_per_class: [0.0, 0.143, 0.055, 0.035, 0.054, 0.24, 0.258, 0.329, 0.041, 0.278]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=101178)[0m top1: 0.353544776119403
[2m[36m(func pid=101178)[0m top5: 0.878731343283582
[2m[36m(func pid=101178)[0m f1_micro: 0.353544776119403
[2m[36m(func pid=101178)[0m f1_macro: 0.32043810622529645
[2m[36m(func pid=101178)[0m f1_weighted: 0.3835389507721036
[2m[36m(func pid=101178)[0m f1_per_class: [0.161, 0.535, 0.328, 0.35, 0.076, 0.314, 0.369, 0.576, 0.15, 0.346]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=108657)[0m top1: 0.22014925373134328
[2m[36m(func pid=108657)[0m top5: 0.5788246268656716
[2m[36m(func pid=108657)[0m f1_micro: 0.22014925373134328
[2m[36m(func pid=108657)[0m f1_macro: 0.08261508951406651
[2m[36m(func pid=108657)[0m f1_weighted: 0.10997794356223994
[2m[36m(func pid=108657)[0m f1_per_class: [0.0, 0.0, 0.4, 0.375, 0.0, 0.0, 0.0, 0.051, 0.0, 0.0]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.3339 | Steps: 2 | Val loss: 2.3576 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 1.6848 | Steps: 2 | Val loss: 37.5904 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.9818 | Steps: 2 | Val loss: 2.0239 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 02:52:40 (running for 00:28:41.73)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.929 |      0.32  |                   35 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.334 |      0.288 |                   33 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  2.211 |      0.143 |                   28 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  2.924 |      0.083 |                    5 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.3824626865671642
[2m[36m(func pid=102297)[0m top5: 0.8978544776119403
[2m[36m(func pid=102297)[0m f1_micro: 0.38246268656716415
[2m[36m(func pid=102297)[0m f1_macro: 0.2879506130104045
[2m[36m(func pid=102297)[0m f1_weighted: 0.3826283791544739
[2m[36m(func pid=102297)[0m f1_per_class: [0.259, 0.413, 0.444, 0.539, 0.0, 0.179, 0.349, 0.38, 0.132, 0.184]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 2.8654 | Steps: 2 | Val loss: 2.3154 | Batch size: 32 | lr: 0.0001 | Duration: 3.07s
[2m[36m(func pid=103229)[0m top1: 0.17257462686567165
[2m[36m(func pid=103229)[0m top5: 0.8055037313432836
[2m[36m(func pid=103229)[0m f1_micro: 0.17257462686567165
[2m[36m(func pid=103229)[0m f1_macro: 0.1623440770849791
[2m[36m(func pid=103229)[0m f1_weighted: 0.15000670771665695
[2m[36m(func pid=103229)[0m f1_per_class: [0.015, 0.29, 0.069, 0.054, 0.067, 0.286, 0.094, 0.304, 0.026, 0.419]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=101178)[0m top1: 0.28591417910447764
[2m[36m(func pid=101178)[0m top5: 0.8386194029850746
[2m[36m(func pid=101178)[0m f1_micro: 0.28591417910447764
[2m[36m(func pid=101178)[0m f1_macro: 0.25698247543749897
[2m[36m(func pid=101178)[0m f1_weighted: 0.3059280287726253
[2m[36m(func pid=101178)[0m f1_per_class: [0.159, 0.556, 0.314, 0.358, 0.074, 0.225, 0.154, 0.466, 0.146, 0.119]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=108657)[0m top1: 0.23227611940298507
[2m[36m(func pid=108657)[0m top5: 0.5844216417910447
[2m[36m(func pid=108657)[0m f1_micro: 0.23227611940298507
[2m[36m(func pid=108657)[0m f1_macro: 0.06389901881333511
[2m[36m(func pid=108657)[0m f1_weighted: 0.11406655187378666
[2m[36m(func pid=108657)[0m f1_per_class: [0.0, 0.005, 0.177, 0.387, 0.0, 0.0, 0.0, 0.069, 0.0, 0.0]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.4815 | Steps: 2 | Val loss: 2.8730 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 2.6077 | Steps: 2 | Val loss: 8.2928 | Batch size: 32 | lr: 0.1 | Duration: 2.78s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.9093 | Steps: 2 | Val loss: 1.7220 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 02:52:46 (running for 00:28:46.93)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.982 |      0.257 |                   36 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.481 |      0.275 |                   34 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.685 |      0.162 |                   29 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  2.865 |      0.064 |                    6 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.3810634328358209
[2m[36m(func pid=102297)[0m top5: 0.8675373134328358
[2m[36m(func pid=102297)[0m f1_micro: 0.3810634328358209
[2m[36m(func pid=102297)[0m f1_macro: 0.2753203663086775
[2m[36m(func pid=102297)[0m f1_weighted: 0.38103395537763934
[2m[36m(func pid=102297)[0m f1_per_class: [0.162, 0.413, 0.453, 0.486, 0.075, 0.045, 0.443, 0.465, 0.057, 0.155]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 2.8215 | Steps: 2 | Val loss: 2.3161 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=103229)[0m top1: 0.16138059701492538
[2m[36m(func pid=103229)[0m top5: 0.8535447761194029
[2m[36m(func pid=103229)[0m f1_micro: 0.16138059701492538
[2m[36m(func pid=103229)[0m f1_macro: 0.16018733542261213
[2m[36m(func pid=103229)[0m f1_weighted: 0.126685457203013
[2m[36m(func pid=103229)[0m f1_per_class: [0.068, 0.298, 0.162, 0.075, 0.056, 0.275, 0.006, 0.229, 0.0, 0.432]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=101178)[0m top1: 0.38992537313432835
[2m[36m(func pid=101178)[0m top5: 0.8950559701492538
[2m[36m(func pid=101178)[0m f1_micro: 0.38992537313432835
[2m[36m(func pid=101178)[0m f1_macro: 0.33935061027370184
[2m[36m(func pid=101178)[0m f1_weighted: 0.4115215035715731
[2m[36m(func pid=101178)[0m f1_per_class: [0.184, 0.559, 0.333, 0.403, 0.087, 0.31, 0.403, 0.525, 0.173, 0.416]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=108657)[0m top1: 0.23087686567164178
[2m[36m(func pid=108657)[0m top5: 0.5825559701492538
[2m[36m(func pid=108657)[0m f1_micro: 0.23087686567164178
[2m[36m(func pid=108657)[0m f1_macro: 0.05580707225868516
[2m[36m(func pid=108657)[0m f1_weighted: 0.11896592336228833
[2m[36m(func pid=108657)[0m f1_per_class: [0.0, 0.01, 0.07, 0.403, 0.0, 0.0, 0.0, 0.074, 0.0, 0.0]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.6487 | Steps: 2 | Val loss: 2.9969 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 1.5154 | Steps: 2 | Val loss: 3.8171 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.9215 | Steps: 2 | Val loss: 1.7165 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 02:52:51 (running for 00:28:52.24)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.909 |      0.339 |                   37 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.649 |      0.257 |                   35 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  2.608 |      0.16  |                   30 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  2.821 |      0.056 |                    7 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.31669776119402987
[2m[36m(func pid=102297)[0m top5: 0.8689365671641791
[2m[36m(func pid=102297)[0m f1_micro: 0.31669776119402987
[2m[36m(func pid=102297)[0m f1_macro: 0.2568389175819386
[2m[36m(func pid=102297)[0m f1_weighted: 0.3360422138868059
[2m[36m(func pid=102297)[0m f1_per_class: [0.11, 0.442, 0.429, 0.288, 0.074, 0.137, 0.436, 0.453, 0.0, 0.2]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=103229)[0m top1: 0.19682835820895522
[2m[36m(func pid=103229)[0m top5: 0.8694029850746269
[2m[36m(func pid=103229)[0m f1_micro: 0.1968283582089552
[2m[36m(func pid=103229)[0m f1_macro: 0.19392502001058654
[2m[36m(func pid=103229)[0m f1_weighted: 0.19414382853384857
[2m[36m(func pid=103229)[0m f1_per_class: [0.077, 0.26, 0.226, 0.107, 0.062, 0.263, 0.222, 0.244, 0.0, 0.476]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 2.7281 | Steps: 2 | Val loss: 2.3142 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=101178)[0m top1: 0.3931902985074627
[2m[36m(func pid=101178)[0m top5: 0.8964552238805971
[2m[36m(func pid=101178)[0m f1_micro: 0.39319029850746273
[2m[36m(func pid=101178)[0m f1_macro: 0.3349256197463186
[2m[36m(func pid=101178)[0m f1_weighted: 0.41193722391682486
[2m[36m(func pid=101178)[0m f1_per_class: [0.198, 0.551, 0.31, 0.418, 0.083, 0.289, 0.404, 0.522, 0.174, 0.4]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=108657)[0m top1: 0.19916044776119404
[2m[36m(func pid=108657)[0m top5: 0.5867537313432836
[2m[36m(func pid=108657)[0m f1_micro: 0.19916044776119404
[2m[36m(func pid=108657)[0m f1_macro: 0.05679990939657052
[2m[36m(func pid=108657)[0m f1_weighted: 0.11992833286799336
[2m[36m(func pid=108657)[0m f1_per_class: [0.0, 0.0, 0.035, 0.402, 0.0, 0.0, 0.0, 0.131, 0.0, 0.0]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.3708 | Steps: 2 | Val loss: 2.5852 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 1.5257 | Steps: 2 | Val loss: 2.6906 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 1.0430 | Steps: 2 | Val loss: 2.0956 | Batch size: 32 | lr: 0.001 | Duration: 3.11s
== Status ==
Current time: 2024-01-07 02:52:56 (running for 00:28:57.50)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.922 |      0.335 |                   38 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.371 |      0.277 |                   36 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.515 |      0.194 |                   31 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  2.728 |      0.057 |                    8 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.3306902985074627
[2m[36m(func pid=102297)[0m top5: 0.8610074626865671
[2m[36m(func pid=102297)[0m f1_micro: 0.3306902985074627
[2m[36m(func pid=102297)[0m f1_macro: 0.27687889089210055
[2m[36m(func pid=102297)[0m f1_weighted: 0.3699433228386165
[2m[36m(func pid=102297)[0m f1_per_class: [0.104, 0.448, 0.293, 0.315, 0.082, 0.323, 0.449, 0.442, 0.028, 0.286]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=103229)[0m top1: 0.2826492537313433
[2m[36m(func pid=103229)[0m top5: 0.8880597014925373
[2m[36m(func pid=103229)[0m f1_micro: 0.2826492537313433
[2m[36m(func pid=103229)[0m f1_macro: 0.2388235848276036
[2m[36m(func pid=103229)[0m f1_weighted: 0.2846782221086389
[2m[36m(func pid=103229)[0m f1_per_class: [0.093, 0.276, 0.274, 0.119, 0.066, 0.237, 0.489, 0.353, 0.05, 0.431]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 2.6753 | Steps: 2 | Val loss: 2.3137 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=101178)[0m top1: 0.2989738805970149
[2m[36m(func pid=101178)[0m top5: 0.855410447761194
[2m[36m(func pid=101178)[0m f1_micro: 0.2989738805970149
[2m[36m(func pid=101178)[0m f1_macro: 0.2529598295585438
[2m[36m(func pid=101178)[0m f1_weighted: 0.3247691655105544
[2m[36m(func pid=101178)[0m f1_per_class: [0.142, 0.56, 0.216, 0.402, 0.073, 0.189, 0.181, 0.52, 0.142, 0.106]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=108657)[0m top1: 0.14272388059701493
[2m[36m(func pid=108657)[0m top5: 0.5904850746268657
[2m[36m(func pid=108657)[0m f1_micro: 0.14272388059701493
[2m[36m(func pid=108657)[0m f1_macro: 0.05417809960410138
[2m[36m(func pid=108657)[0m f1_weighted: 0.10857748270422761
[2m[36m(func pid=108657)[0m f1_per_class: [0.0, 0.005, 0.024, 0.353, 0.0, 0.0, 0.0, 0.161, 0.0, 0.0]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.5884 | Steps: 2 | Val loss: 2.4017 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 1.4917 | Steps: 2 | Val loss: 2.3345 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.8851 | Steps: 2 | Val loss: 1.7023 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 02:53:02 (running for 00:29:03.06)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  1.043 |      0.253 |                   39 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.588 |      0.314 |                   37 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.526 |      0.239 |                   32 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  2.675 |      0.054 |                    9 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.37033582089552236
[2m[36m(func pid=102297)[0m top5: 0.8819962686567164
[2m[36m(func pid=102297)[0m f1_micro: 0.37033582089552236
[2m[36m(func pid=102297)[0m f1_macro: 0.3141574874986991
[2m[36m(func pid=102297)[0m f1_weighted: 0.41522221265062736
[2m[36m(func pid=102297)[0m f1_per_class: [0.168, 0.43, 0.333, 0.447, 0.065, 0.271, 0.492, 0.409, 0.158, 0.369]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=103229)[0m top1: 0.30783582089552236
[2m[36m(func pid=103229)[0m top5: 0.898320895522388
[2m[36m(func pid=103229)[0m f1_micro: 0.30783582089552236
[2m[36m(func pid=103229)[0m f1_macro: 0.2619131460285212
[2m[36m(func pid=103229)[0m f1_weighted: 0.32127766701869315
[2m[36m(func pid=103229)[0m f1_per_class: [0.11, 0.305, 0.257, 0.157, 0.079, 0.245, 0.545, 0.364, 0.128, 0.429]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 2.5885 | Steps: 2 | Val loss: 2.3112 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=101178)[0m top1: 0.42677238805970147
[2m[36m(func pid=101178)[0m top5: 0.8992537313432836
[2m[36m(func pid=101178)[0m f1_micro: 0.42677238805970147
[2m[36m(func pid=101178)[0m f1_macro: 0.35199072062708525
[2m[36m(func pid=101178)[0m f1_weighted: 0.454164795283838
[2m[36m(func pid=101178)[0m f1_per_class: [0.192, 0.574, 0.25, 0.441, 0.08, 0.314, 0.494, 0.556, 0.171, 0.447]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=108657)[0m top1: 0.1044776119402985
[2m[36m(func pid=108657)[0m top5: 0.5946828358208955
[2m[36m(func pid=108657)[0m f1_micro: 0.1044776119402985
[2m[36m(func pid=108657)[0m f1_macro: 0.05276982798992661
[2m[36m(func pid=108657)[0m f1_weighted: 0.09950960571345524
[2m[36m(func pid=108657)[0m f1_per_class: [0.0, 0.037, 0.019, 0.298, 0.0, 0.0, 0.0, 0.174, 0.0, 0.0]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 1.4944 | Steps: 2 | Val loss: 2.2789 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.7189 | Steps: 2 | Val loss: 2.7827 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 1.0578 | Steps: 2 | Val loss: 1.6738 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
== Status ==
Current time: 2024-01-07 02:53:07 (running for 00:29:08.56)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.885 |      0.352 |                   40 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.588 |      0.314 |                   37 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.494 |      0.269 |                   34 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  2.588 |      0.053 |                   10 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=103229)[0m top1: 0.29197761194029853
[2m[36m(func pid=103229)[0m top5: 0.8955223880597015
[2m[36m(func pid=103229)[0m f1_micro: 0.29197761194029853
[2m[36m(func pid=103229)[0m f1_macro: 0.26857060771008934
[2m[36m(func pid=103229)[0m f1_weighted: 0.3173690035357569
[2m[36m(func pid=103229)[0m f1_per_class: [0.102, 0.301, 0.25, 0.161, 0.079, 0.249, 0.524, 0.349, 0.17, 0.5]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 2.6163 | Steps: 2 | Val loss: 2.3088 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=102297)[0m top1: 0.28777985074626866
[2m[36m(func pid=102297)[0m top5: 0.8852611940298507
[2m[36m(func pid=102297)[0m f1_micro: 0.28777985074626866
[2m[36m(func pid=102297)[0m f1_macro: 0.22934081757058583
[2m[36m(func pid=102297)[0m f1_weighted: 0.30704895392674636
[2m[36m(func pid=102297)[0m f1_per_class: [0.2, 0.218, 0.444, 0.431, 0.054, 0.024, 0.41, 0.178, 0.145, 0.19]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=101178)[0m top1: 0.43843283582089554
[2m[36m(func pid=101178)[0m top5: 0.9081156716417911
[2m[36m(func pid=101178)[0m f1_micro: 0.43843283582089554
[2m[36m(func pid=101178)[0m f1_macro: 0.3608153433378899
[2m[36m(func pid=101178)[0m f1_weighted: 0.4541676940007271
[2m[36m(func pid=101178)[0m f1_per_class: [0.212, 0.588, 0.242, 0.436, 0.078, 0.246, 0.508, 0.575, 0.182, 0.542]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=108657)[0m top1: 0.07835820895522388
[2m[36m(func pid=108657)[0m top5: 0.597481343283582
[2m[36m(func pid=108657)[0m f1_micro: 0.07835820895522388
[2m[36m(func pid=108657)[0m f1_macro: 0.0564871922315614
[2m[36m(func pid=108657)[0m f1_weighted: 0.09176592270736604
[2m[36m(func pid=108657)[0m f1_per_class: [0.0, 0.129, 0.017, 0.205, 0.0, 0.0, 0.0, 0.214, 0.0, 0.0]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 1.6145 | Steps: 2 | Val loss: 2.1691 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.2694 | Steps: 2 | Val loss: 2.6537 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.8088 | Steps: 2 | Val loss: 1.8091 | Batch size: 32 | lr: 0.001 | Duration: 3.06s
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 2.5732 | Steps: 2 | Val loss: 2.3070 | Batch size: 32 | lr: 0.0001 | Duration: 2.79s
== Status ==
Current time: 2024-01-07 02:53:13 (running for 00:29:13.96)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  1.058 |      0.361 |                   41 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.719 |      0.229 |                   38 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.614 |      0.329 |                   35 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  2.616 |      0.056 |                   11 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.3381529850746269
[2m[36m(func pid=102297)[0m top5: 0.9193097014925373
[2m[36m(func pid=102297)[0m f1_micro: 0.3381529850746269
[2m[36m(func pid=102297)[0m f1_macro: 0.2802951986217538
[2m[36m(func pid=102297)[0m f1_weighted: 0.3549773634882203
[2m[36m(func pid=102297)[0m f1_per_class: [0.172, 0.209, 0.579, 0.448, 0.054, 0.139, 0.471, 0.411, 0.121, 0.197]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=103229)[0m top1: 0.31203358208955223
[2m[36m(func pid=103229)[0m top5: 0.8899253731343284
[2m[36m(func pid=103229)[0m f1_micro: 0.31203358208955223
[2m[36m(func pid=103229)[0m f1_macro: 0.32864594327015945
[2m[36m(func pid=103229)[0m f1_weighted: 0.3420307338990826
[2m[36m(func pid=103229)[0m f1_per_class: [0.097, 0.257, 0.6, 0.2, 0.093, 0.298, 0.536, 0.526, 0.171, 0.508]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=101178)[0m top1: 0.40158582089552236
[2m[36m(func pid=101178)[0m top5: 0.8847947761194029
[2m[36m(func pid=101178)[0m f1_micro: 0.40158582089552236
[2m[36m(func pid=101178)[0m f1_macro: 0.31754771196754533
[2m[36m(func pid=101178)[0m f1_weighted: 0.4354085161945378
[2m[36m(func pid=101178)[0m f1_per_class: [0.148, 0.587, 0.204, 0.447, 0.073, 0.307, 0.442, 0.49, 0.194, 0.284]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=108657)[0m top1: 0.06716417910447761
[2m[36m(func pid=108657)[0m top5: 0.5909514925373134
[2m[36m(func pid=108657)[0m f1_micro: 0.06716417910447761
[2m[36m(func pid=108657)[0m f1_macro: 0.052195379787903076
[2m[36m(func pid=108657)[0m f1_weighted: 0.08036479001354556
[2m[36m(func pid=108657)[0m f1_per_class: [0.0, 0.204, 0.016, 0.125, 0.0, 0.0, 0.0, 0.176, 0.0, 0.0]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 1.4823 | Steps: 2 | Val loss: 2.3835 | Batch size: 32 | lr: 0.1 | Duration: 3.29s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.1994 | Steps: 2 | Val loss: 2.8143 | Batch size: 32 | lr: 0.01 | Duration: 3.29s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.8743 | Steps: 2 | Val loss: 1.8834 | Batch size: 32 | lr: 0.001 | Duration: 3.23s
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 2.5362 | Steps: 2 | Val loss: 2.3082 | Batch size: 32 | lr: 0.0001 | Duration: 3.30s
== Status ==
Current time: 2024-01-07 02:53:18 (running for 00:29:19.74)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.809 |      0.318 |                   42 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.269 |      0.28  |                   39 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.482 |      0.289 |                   36 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  2.573 |      0.052 |                   12 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.37220149253731344
[2m[36m(func pid=102297)[0m top5: 0.8973880597014925
[2m[36m(func pid=102297)[0m f1_micro: 0.3722014925373134
[2m[36m(func pid=102297)[0m f1_macro: 0.2860732708316899
[2m[36m(func pid=102297)[0m f1_weighted: 0.3782480478675338
[2m[36m(func pid=102297)[0m f1_per_class: [0.118, 0.407, 0.562, 0.448, 0.085, 0.205, 0.415, 0.477, 0.015, 0.128]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=103229)[0m top1: 0.2737873134328358
[2m[36m(func pid=103229)[0m top5: 0.8857276119402985
[2m[36m(func pid=103229)[0m f1_micro: 0.2737873134328358
[2m[36m(func pid=103229)[0m f1_macro: 0.2891631981106349
[2m[36m(func pid=103229)[0m f1_weighted: 0.29257699850748164
[2m[36m(func pid=103229)[0m f1_per_class: [0.089, 0.283, 0.529, 0.162, 0.133, 0.305, 0.4, 0.523, 0.131, 0.337]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=101178)[0m top1: 0.37220149253731344
[2m[36m(func pid=101178)[0m top5: 0.8773320895522388
[2m[36m(func pid=101178)[0m f1_micro: 0.3722014925373134
[2m[36m(func pid=101178)[0m f1_macro: 0.306641079240504
[2m[36m(func pid=101178)[0m f1_weighted: 0.41454131819980766
[2m[36m(func pid=101178)[0m f1_per_class: [0.099, 0.595, 0.186, 0.404, 0.068, 0.29, 0.408, 0.546, 0.184, 0.286]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=108657)[0m top1: 0.0708955223880597
[2m[36m(func pid=108657)[0m top5: 0.5960820895522388
[2m[36m(func pid=108657)[0m f1_micro: 0.0708955223880597
[2m[36m(func pid=108657)[0m f1_macro: 0.0491822351207617
[2m[36m(func pid=108657)[0m f1_weighted: 0.07714773465099715
[2m[36m(func pid=108657)[0m f1_per_class: [0.0, 0.27, 0.016, 0.085, 0.0, 0.0, 0.0, 0.121, 0.0, 0.0]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.7401 | Steps: 2 | Val loss: 2.6671 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 37.0188 | Steps: 2 | Val loss: 19.5483 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.7750 | Steps: 2 | Val loss: 1.7809 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 2.4961 | Steps: 2 | Val loss: 2.3099 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 02:53:24 (running for 00:29:25.07)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.874 |      0.307 |                   43 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.199 |      0.286 |                   40 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 | 37.019 |      0.075 |                   37 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  2.536 |      0.049 |                   13 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.40578358208955223
[2m[36m(func pid=102297)[0m top5: 0.9011194029850746
[2m[36m(func pid=102297)[0m f1_micro: 0.40578358208955223
[2m[36m(func pid=102297)[0m f1_macro: 0.3466792571008467
[2m[36m(func pid=102297)[0m f1_weighted: 0.3856115761629316
[2m[36m(func pid=102297)[0m f1_per_class: [0.412, 0.421, 0.632, 0.51, 0.102, 0.253, 0.319, 0.489, 0.079, 0.25]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=103229)[0m top1: 0.057369402985074626
[2m[36m(func pid=103229)[0m top5: 0.6469216417910447
[2m[36m(func pid=103229)[0m f1_micro: 0.057369402985074626
[2m[36m(func pid=103229)[0m f1_macro: 0.07461523615877597
[2m[36m(func pid=103229)[0m f1_weighted: 0.06268651723064922
[2m[36m(func pid=103229)[0m f1_per_class: [0.0, 0.271, 0.062, 0.041, 0.303, 0.0, 0.0, 0.0, 0.047, 0.022]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=101178)[0m top1: 0.37546641791044777
[2m[36m(func pid=101178)[0m top5: 0.9043843283582089
[2m[36m(func pid=101178)[0m f1_micro: 0.3754664179104477
[2m[36m(func pid=101178)[0m f1_macro: 0.3270346029565671
[2m[36m(func pid=101178)[0m f1_weighted: 0.4043346045573495
[2m[36m(func pid=101178)[0m f1_per_class: [0.124, 0.569, 0.224, 0.404, 0.076, 0.274, 0.391, 0.508, 0.184, 0.516]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=108657)[0m top1: 0.08348880597014925
[2m[36m(func pid=108657)[0m top5: 0.5904850746268657
[2m[36m(func pid=108657)[0m f1_micro: 0.08348880597014925
[2m[36m(func pid=108657)[0m f1_macro: 0.05683646234056551
[2m[36m(func pid=108657)[0m f1_weighted: 0.07869806121211936
[2m[36m(func pid=108657)[0m f1_per_class: [0.018, 0.321, 0.018, 0.048, 0.0, 0.0, 0.0, 0.163, 0.0, 0.0]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.2027 | Steps: 2 | Val loss: 3.0747 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 2.7756 | Steps: 2 | Val loss: 6.3637 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.7463 | Steps: 2 | Val loss: 1.9123 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 02:53:29 (running for 00:29:30.32)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.775 |      0.327 |                   44 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.203 |      0.221 |                   42 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 | 37.019 |      0.075 |                   37 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  2.496 |      0.057 |                   14 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.33302238805970147
[2m[36m(func pid=102297)[0m top5: 0.9043843283582089
[2m[36m(func pid=102297)[0m f1_micro: 0.33302238805970147
[2m[36m(func pid=102297)[0m f1_macro: 0.22129286107601714
[2m[36m(func pid=102297)[0m f1_weighted: 0.3094855840715982
[2m[36m(func pid=102297)[0m f1_per_class: [0.282, 0.421, 0.0, 0.537, 0.123, 0.182, 0.116, 0.376, 0.077, 0.1]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=103229)[0m top1: 0.09514925373134328
[2m[36m(func pid=103229)[0m top5: 0.5909514925373134
[2m[36m(func pid=103229)[0m f1_micro: 0.09514925373134328
[2m[36m(func pid=103229)[0m f1_macro: 0.10258390218881068
[2m[36m(func pid=103229)[0m f1_weighted: 0.07715515585371409
[2m[36m(func pid=103229)[0m f1_per_class: [0.088, 0.37, 0.359, 0.023, 0.146, 0.016, 0.0, 0.0, 0.0, 0.025]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 2.4942 | Steps: 2 | Val loss: 2.3095 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=101178)[0m top1: 0.3530783582089552
[2m[36m(func pid=101178)[0m top5: 0.8698694029850746
[2m[36m(func pid=101178)[0m f1_micro: 0.3530783582089552
[2m[36m(func pid=101178)[0m f1_macro: 0.3161009909539506
[2m[36m(func pid=101178)[0m f1_weighted: 0.3889414044607265
[2m[36m(func pid=101178)[0m f1_per_class: [0.109, 0.596, 0.207, 0.358, 0.069, 0.291, 0.35, 0.58, 0.19, 0.41]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=108657)[0m top1: 0.09888059701492537
[2m[36m(func pid=108657)[0m top5: 0.5979477611940298
[2m[36m(func pid=108657)[0m f1_micro: 0.09888059701492537
[2m[36m(func pid=108657)[0m f1_macro: 0.06607567117808237
[2m[36m(func pid=108657)[0m f1_weighted: 0.08251942187348446
[2m[36m(func pid=108657)[0m f1_per_class: [0.038, 0.351, 0.02, 0.03, 0.0, 0.0, 0.0, 0.221, 0.0, 0.0]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.2677 | Steps: 2 | Val loss: 3.8454 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 2.6790 | Steps: 2 | Val loss: 5.3724 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.6882 | Steps: 2 | Val loss: 1.9219 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
== Status ==
Current time: 2024-01-07 02:53:34 (running for 00:29:35.53)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.746 |      0.316 |                   45 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.268 |      0.235 |                   43 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  2.776 |      0.103 |                   38 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  2.494 |      0.066 |                   15 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.31343283582089554
[2m[36m(func pid=102297)[0m top5: 0.8521455223880597
[2m[36m(func pid=102297)[0m f1_micro: 0.31343283582089554
[2m[36m(func pid=102297)[0m f1_macro: 0.23455706367619097
[2m[36m(func pid=102297)[0m f1_weighted: 0.27047716600469873
[2m[36m(func pid=102297)[0m f1_per_class: [0.301, 0.42, 0.632, 0.573, 0.162, 0.047, 0.062, 0.0, 0.073, 0.076]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=103229)[0m top1: 0.07369402985074627
[2m[36m(func pid=103229)[0m top5: 0.5932835820895522
[2m[36m(func pid=103229)[0m f1_micro: 0.07369402985074627
[2m[36m(func pid=103229)[0m f1_macro: 0.04909355503530436
[2m[36m(func pid=103229)[0m f1_weighted: 0.06086465338068197
[2m[36m(func pid=103229)[0m f1_per_class: [0.06, 0.276, 0.0, 0.04, 0.095, 0.0, 0.0, 0.0, 0.0, 0.02]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 2.4992 | Steps: 2 | Val loss: 2.3151 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=101178)[0m top1: 0.35447761194029853
[2m[36m(func pid=101178)[0m top5: 0.8661380597014925
[2m[36m(func pid=101178)[0m f1_micro: 0.35447761194029853
[2m[36m(func pid=101178)[0m f1_macro: 0.3242648344603072
[2m[36m(func pid=101178)[0m f1_weighted: 0.3911836660642797
[2m[36m(func pid=101178)[0m f1_per_class: [0.115, 0.609, 0.233, 0.355, 0.074, 0.291, 0.351, 0.574, 0.205, 0.436]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=108657)[0m top1: 0.09701492537313433
[2m[36m(func pid=108657)[0m top5: 0.6021455223880597
[2m[36m(func pid=108657)[0m f1_micro: 0.09701492537313433
[2m[36m(func pid=108657)[0m f1_macro: 0.06492147036367638
[2m[36m(func pid=108657)[0m f1_weighted: 0.07532401763321982
[2m[36m(func pid=108657)[0m f1_per_class: [0.021, 0.331, 0.025, 0.01, 0.0, 0.0, 0.0, 0.262, 0.0, 0.0]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.5785 | Steps: 2 | Val loss: 2.8246 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 2.0370 | Steps: 2 | Val loss: 3.9297 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.8422 | Steps: 2 | Val loss: 1.9557 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 02:53:40 (running for 00:29:40.93)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.688 |      0.324 |                   46 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.578 |      0.301 |                   44 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  2.679 |      0.049 |                   39 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  2.499 |      0.065 |                   16 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.40205223880597013
[2m[36m(func pid=102297)[0m top5: 0.9249067164179104
[2m[36m(func pid=102297)[0m f1_micro: 0.4020522388059702
[2m[36m(func pid=102297)[0m f1_macro: 0.30121198069514854
[2m[36m(func pid=102297)[0m f1_weighted: 0.39194864913173133
[2m[36m(func pid=102297)[0m f1_per_class: [0.261, 0.421, 0.733, 0.59, 0.126, 0.258, 0.364, 0.016, 0.113, 0.13]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=103229)[0m top1: 0.08348880597014925
[2m[36m(func pid=103229)[0m top5: 0.597481343283582
[2m[36m(func pid=103229)[0m f1_micro: 0.08348880597014925
[2m[36m(func pid=103229)[0m f1_macro: 0.059147624366333564
[2m[36m(func pid=103229)[0m f1_weighted: 0.09565125980474874
[2m[36m(func pid=103229)[0m f1_per_class: [0.053, 0.205, 0.0, 0.184, 0.069, 0.063, 0.0, 0.0, 0.0, 0.017]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 2.4527 | Steps: 2 | Val loss: 2.3190 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=101178)[0m top1: 0.3358208955223881
[2m[36m(func pid=101178)[0m top5: 0.8614738805970149
[2m[36m(func pid=101178)[0m f1_micro: 0.3358208955223881
[2m[36m(func pid=101178)[0m f1_macro: 0.29895361614215527
[2m[36m(func pid=101178)[0m f1_weighted: 0.3716871490598957
[2m[36m(func pid=101178)[0m f1_per_class: [0.128, 0.576, 0.286, 0.36, 0.088, 0.293, 0.315, 0.555, 0.153, 0.236]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=108657)[0m top1: 0.10494402985074627
[2m[36m(func pid=108657)[0m top5: 0.6077425373134329
[2m[36m(func pid=108657)[0m f1_micro: 0.10494402985074627
[2m[36m(func pid=108657)[0m f1_macro: 0.08152621836659683
[2m[36m(func pid=108657)[0m f1_weighted: 0.08520449738809635
[2m[36m(func pid=108657)[0m f1_per_class: [0.017, 0.335, 0.035, 0.007, 0.0, 0.053, 0.0, 0.293, 0.06, 0.016]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.1946 | Steps: 2 | Val loss: 2.9150 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 2.2869 | Steps: 2 | Val loss: 2.9961 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.6000 | Steps: 2 | Val loss: 1.8091 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 02:53:45 (running for 00:29:46.25)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.842 |      0.299 |                   47 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.195 |      0.3   |                   45 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  2.037 |      0.059 |                   40 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  2.453 |      0.082 |                   17 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.41138059701492535
[2m[36m(func pid=102297)[0m top5: 0.9402985074626866
[2m[36m(func pid=102297)[0m f1_micro: 0.41138059701492535
[2m[36m(func pid=102297)[0m f1_macro: 0.30047904940275216
[2m[36m(func pid=102297)[0m f1_weighted: 0.4234394647868006
[2m[36m(func pid=102297)[0m f1_per_class: [0.0, 0.381, 0.632, 0.53, 0.083, 0.391, 0.494, 0.088, 0.175, 0.231]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=103229)[0m top1: 0.08675373134328358
[2m[36m(func pid=103229)[0m top5: 0.8017723880597015
[2m[36m(func pid=103229)[0m f1_micro: 0.08675373134328358
[2m[36m(func pid=103229)[0m f1_macro: 0.10776341020522968
[2m[36m(func pid=103229)[0m f1_weighted: 0.10165144394617937
[2m[36m(func pid=103229)[0m f1_per_class: [0.045, 0.222, 0.462, 0.188, 0.061, 0.044, 0.0, 0.015, 0.024, 0.017]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 2.4274 | Steps: 2 | Val loss: 2.3261 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=101178)[0m top1: 0.36427238805970147
[2m[36m(func pid=101178)[0m top5: 0.8903917910447762
[2m[36m(func pid=101178)[0m f1_micro: 0.3642723880597015
[2m[36m(func pid=101178)[0m f1_macro: 0.3409933278655631
[2m[36m(func pid=101178)[0m f1_weighted: 0.3937690215734851
[2m[36m(func pid=101178)[0m f1_per_class: [0.134, 0.59, 0.319, 0.348, 0.093, 0.322, 0.367, 0.551, 0.179, 0.507]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.2003 | Steps: 2 | Val loss: 3.2365 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=108657)[0m top1: 0.1044776119402985
[2m[36m(func pid=108657)[0m top5: 0.613339552238806
[2m[36m(func pid=108657)[0m f1_micro: 0.1044776119402985
[2m[36m(func pid=108657)[0m f1_macro: 0.08388612790716059
[2m[36m(func pid=108657)[0m f1_weighted: 0.08842616768737575
[2m[36m(func pid=108657)[0m f1_per_class: [0.016, 0.337, 0.043, 0.0, 0.0, 0.106, 0.003, 0.259, 0.044, 0.031]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 1.8446 | Steps: 2 | Val loss: 3.3449 | Batch size: 32 | lr: 0.1 | Duration: 2.71s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 1.0477 | Steps: 2 | Val loss: 1.8155 | Batch size: 32 | lr: 0.001 | Duration: 3.06s
== Status ==
Current time: 2024-01-07 02:53:50 (running for 00:29:51.63)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.6   |      0.341 |                   48 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.195 |      0.3   |                   45 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.845 |      0.086 |                   42 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  2.427 |      0.084 |                   18 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.38013059701492535
[2m[36m(func pid=102297)[0m top5: 0.9379664179104478
[2m[36m(func pid=102297)[0m f1_micro: 0.38013059701492535
[2m[36m(func pid=102297)[0m f1_macro: 0.2743213689280978
[2m[36m(func pid=102297)[0m f1_weighted: 0.40634027800641687
[2m[36m(func pid=102297)[0m f1_per_class: [0.0, 0.319, 0.375, 0.467, 0.063, 0.366, 0.546, 0.062, 0.184, 0.361]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=103229)[0m top1: 0.07882462686567164
[2m[36m(func pid=103229)[0m top5: 0.8017723880597015
[2m[36m(func pid=103229)[0m f1_micro: 0.07882462686567164
[2m[36m(func pid=103229)[0m f1_macro: 0.08629020519359895
[2m[36m(func pid=103229)[0m f1_weighted: 0.06903462814100274
[2m[36m(func pid=103229)[0m f1_per_class: [0.064, 0.31, 0.269, 0.023, 0.067, 0.023, 0.0, 0.0, 0.088, 0.017]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 2.4069 | Steps: 2 | Val loss: 2.3304 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=101178)[0m top1: 0.35261194029850745
[2m[36m(func pid=101178)[0m top5: 0.8978544776119403
[2m[36m(func pid=101178)[0m f1_micro: 0.35261194029850745
[2m[36m(func pid=101178)[0m f1_macro: 0.33591149393376185
[2m[36m(func pid=101178)[0m f1_weighted: 0.373179328031844
[2m[36m(func pid=101178)[0m f1_per_class: [0.138, 0.568, 0.355, 0.337, 0.093, 0.297, 0.338, 0.487, 0.194, 0.552]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=108657)[0m top1: 0.10167910447761194
[2m[36m(func pid=108657)[0m top5: 0.644589552238806
[2m[36m(func pid=108657)[0m f1_micro: 0.10167910447761194
[2m[36m(func pid=108657)[0m f1_macro: 0.08381069656388293
[2m[36m(func pid=108657)[0m f1_weighted: 0.09173234824355718
[2m[36m(func pid=108657)[0m f1_per_class: [0.026, 0.348, 0.057, 0.0, 0.0, 0.154, 0.003, 0.186, 0.045, 0.02]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.4767 | Steps: 2 | Val loss: 3.4595 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 1.8714 | Steps: 2 | Val loss: 3.1639 | Batch size: 32 | lr: 0.1 | Duration: 3.04s
== Status ==
Current time: 2024-01-07 02:53:56 (running for 00:29:57.10)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  1.048 |      0.336 |                   49 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.2   |      0.274 |                   46 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.871 |      0.179 |                   43 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  2.407 |      0.084 |                   19 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.6241 | Steps: 2 | Val loss: 2.1022 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=102297)[0m top1: 0.3045708955223881
[2m[36m(func pid=102297)[0m top5: 0.8969216417910447
[2m[36m(func pid=102297)[0m f1_micro: 0.3045708955223881
[2m[36m(func pid=102297)[0m f1_macro: 0.25031980202182014
[2m[36m(func pid=102297)[0m f1_weighted: 0.34256948188725195
[2m[36m(func pid=102297)[0m f1_per_class: [0.0, 0.424, 0.143, 0.321, 0.054, 0.294, 0.415, 0.178, 0.155, 0.52]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=103229)[0m top1: 0.1767723880597015
[2m[36m(func pid=103229)[0m top5: 0.769589552238806
[2m[36m(func pid=103229)[0m f1_micro: 0.1767723880597015
[2m[36m(func pid=103229)[0m f1_macro: 0.17860725382032414
[2m[36m(func pid=103229)[0m f1_weighted: 0.17298607522612056
[2m[36m(func pid=103229)[0m f1_per_class: [0.076, 0.433, 0.341, 0.0, 0.05, 0.235, 0.138, 0.402, 0.088, 0.023]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 2.4256 | Steps: 2 | Val loss: 2.3399 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
[2m[36m(func pid=101178)[0m top1: 0.28824626865671643
[2m[36m(func pid=101178)[0m top5: 0.855410447761194
[2m[36m(func pid=101178)[0m f1_micro: 0.28824626865671643
[2m[36m(func pid=101178)[0m f1_macro: 0.2796984728747679
[2m[36m(func pid=101178)[0m f1_weighted: 0.30777342753029424
[2m[36m(func pid=101178)[0m f1_per_class: [0.117, 0.56, 0.31, 0.286, 0.088, 0.316, 0.169, 0.56, 0.157, 0.234]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=108657)[0m top1: 0.09328358208955224
[2m[36m(func pid=108657)[0m top5: 0.695429104477612
[2m[36m(func pid=108657)[0m f1_micro: 0.09328358208955224
[2m[36m(func pid=108657)[0m f1_macro: 0.07577474389358384
[2m[36m(func pid=108657)[0m f1_weighted: 0.08983937566834703
[2m[36m(func pid=108657)[0m f1_per_class: [0.025, 0.355, 0.071, 0.0, 0.0, 0.169, 0.015, 0.032, 0.046, 0.045]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.1222 | Steps: 2 | Val loss: 3.6102 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 1.7781 | Steps: 2 | Val loss: 3.0023 | Batch size: 32 | lr: 0.1 | Duration: 3.01s
== Status ==
Current time: 2024-01-07 02:54:01 (running for 00:30:02.37)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.624 |      0.28  |                   50 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.122 |      0.265 |                   48 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.871 |      0.179 |                   43 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  2.426 |      0.076 |                   20 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.24953358208955223
[2m[36m(func pid=102297)[0m top5: 0.832089552238806
[2m[36m(func pid=102297)[0m f1_micro: 0.24953358208955223
[2m[36m(func pid=102297)[0m f1_macro: 0.2647453609078669
[2m[36m(func pid=102297)[0m f1_weighted: 0.27091240055110827
[2m[36m(func pid=102297)[0m f1_per_class: [0.074, 0.443, 0.632, 0.223, 0.066, 0.206, 0.256, 0.323, 0.152, 0.274]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.6056 | Steps: 2 | Val loss: 2.0095 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=103229)[0m top1: 0.16371268656716417
[2m[36m(func pid=103229)[0m top5: 0.7798507462686567
[2m[36m(func pid=103229)[0m f1_micro: 0.16371268656716417
[2m[36m(func pid=103229)[0m f1_macro: 0.18712422079636656
[2m[36m(func pid=103229)[0m f1_weighted: 0.14937453872370263
[2m[36m(func pid=103229)[0m f1_per_class: [0.069, 0.396, 0.378, 0.0, 0.057, 0.283, 0.037, 0.517, 0.109, 0.024]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 2.3551 | Steps: 2 | Val loss: 2.3441 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=101178)[0m top1: 0.3185634328358209
[2m[36m(func pid=101178)[0m top5: 0.8642723880597015
[2m[36m(func pid=101178)[0m f1_micro: 0.3185634328358209
[2m[36m(func pid=101178)[0m f1_macro: 0.3124922197004186
[2m[36m(func pid=101178)[0m f1_weighted: 0.35078721220291875
[2m[36m(func pid=101178)[0m f1_per_class: [0.125, 0.564, 0.375, 0.353, 0.094, 0.317, 0.243, 0.542, 0.175, 0.337]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=108657)[0m top1: 0.09328358208955224
[2m[36m(func pid=108657)[0m top5: 0.7262126865671642
[2m[36m(func pid=108657)[0m f1_micro: 0.09328358208955224
[2m[36m(func pid=108657)[0m f1_macro: 0.07576137456001608
[2m[36m(func pid=108657)[0m f1_weighted: 0.10031245710546344
[2m[36m(func pid=108657)[0m f1_per_class: [0.028, 0.347, 0.086, 0.0, 0.0, 0.203, 0.05, 0.0, 0.044, 0.0]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.4043 | Steps: 2 | Val loss: 3.0862 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 1.7971 | Steps: 2 | Val loss: 2.8988 | Batch size: 32 | lr: 0.1 | Duration: 3.12s
[2m[36m(func pid=102297)[0m top1: 0.2635261194029851
[2m[36m(func pid=102297)[0m top5: 0.804570895522388
[2m[36m(func pid=102297)[0m f1_micro: 0.2635261194029851
[2m[36m(func pid=102297)[0m f1_macro: 0.25390051150905035
[2m[36m(func pid=102297)[0m f1_weighted: 0.29420526209788506
[2m[36m(func pid=102297)[0m f1_per_class: [0.025, 0.488, 0.72, 0.263, 0.112, 0.252, 0.303, 0.102, 0.126, 0.147]
[2m[36m(func pid=102297)[0m 
== Status ==
Current time: 2024-01-07 02:54:07 (running for 00:30:07.87)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.606 |      0.312 |                   51 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.404 |      0.254 |                   49 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.778 |      0.187 |                   44 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  2.355 |      0.076 |                   21 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.5901 | Steps: 2 | Val loss: 1.8311 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 2.3166 | Steps: 2 | Val loss: 2.3445 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=103229)[0m top1: 0.09048507462686567
[2m[36m(func pid=103229)[0m top5: 0.769589552238806
[2m[36m(func pid=103229)[0m f1_micro: 0.09048507462686567
[2m[36m(func pid=103229)[0m f1_macro: 0.14629783944667116
[2m[36m(func pid=103229)[0m f1_weighted: 0.09445782689740954
[2m[36m(func pid=103229)[0m f1_per_class: [0.064, 0.232, 0.364, 0.0, 0.067, 0.204, 0.0, 0.411, 0.095, 0.026]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=101178)[0m top1: 0.36986940298507465
[2m[36m(func pid=101178)[0m top5: 0.9006529850746269
[2m[36m(func pid=101178)[0m f1_micro: 0.36986940298507465
[2m[36m(func pid=101178)[0m f1_macro: 0.35918950549486184
[2m[36m(func pid=101178)[0m f1_weighted: 0.4152226892601039
[2m[36m(func pid=101178)[0m f1_per_class: [0.132, 0.552, 0.439, 0.382, 0.096, 0.336, 0.419, 0.562, 0.182, 0.492]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.1621 | Steps: 2 | Val loss: 2.8467 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=108657)[0m top1: 0.10027985074626866
[2m[36m(func pid=108657)[0m top5: 0.7402052238805971
[2m[36m(func pid=108657)[0m f1_micro: 0.10027985074626866
[2m[36m(func pid=108657)[0m f1_macro: 0.09909061159852418
[2m[36m(func pid=108657)[0m f1_weighted: 0.11761405698487587
[2m[36m(func pid=108657)[0m f1_per_class: [0.028, 0.343, 0.102, 0.0, 0.154, 0.214, 0.101, 0.0, 0.049, 0.0]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 1.5472 | Steps: 2 | Val loss: 2.6453 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
== Status ==
Current time: 2024-01-07 02:54:12 (running for 00:30:13.14)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.59  |      0.359 |                   52 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.162 |      0.223 |                   50 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.797 |      0.146 |                   45 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  2.317 |      0.099 |                   22 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.283115671641791
[2m[36m(func pid=102297)[0m top5: 0.8111007462686567
[2m[36m(func pid=102297)[0m f1_micro: 0.283115671641791
[2m[36m(func pid=102297)[0m f1_macro: 0.22286904539004407
[2m[36m(func pid=102297)[0m f1_weighted: 0.3207776911742475
[2m[36m(func pid=102297)[0m f1_per_class: [0.033, 0.453, 0.381, 0.322, 0.107, 0.276, 0.37, 0.031, 0.123, 0.132]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.5697 | Steps: 2 | Val loss: 1.8186 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=103229)[0m top1: 0.21921641791044777
[2m[36m(func pid=103229)[0m top5: 0.792910447761194
[2m[36m(func pid=103229)[0m f1_micro: 0.21921641791044777
[2m[36m(func pid=103229)[0m f1_macro: 0.22196548588989176
[2m[36m(func pid=103229)[0m f1_weighted: 0.2296731806348983
[2m[36m(func pid=103229)[0m f1_per_class: [0.067, 0.181, 0.444, 0.003, 0.062, 0.292, 0.418, 0.522, 0.111, 0.119]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 2.2798 | Steps: 2 | Val loss: 2.3464 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=101178)[0m top1: 0.3763992537313433
[2m[36m(func pid=101178)[0m top5: 0.8992537313432836
[2m[36m(func pid=101178)[0m f1_micro: 0.3763992537313433
[2m[36m(func pid=101178)[0m f1_macro: 0.36094973974543537
[2m[36m(func pid=101178)[0m f1_weighted: 0.42067181928074143
[2m[36m(func pid=101178)[0m f1_per_class: [0.144, 0.552, 0.474, 0.41, 0.086, 0.341, 0.414, 0.543, 0.17, 0.476]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.4066 | Steps: 2 | Val loss: 2.7757 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=108657)[0m top1: 0.10914179104477612
[2m[36m(func pid=108657)[0m top5: 0.7555970149253731
[2m[36m(func pid=108657)[0m f1_micro: 0.10914179104477612
[2m[36m(func pid=108657)[0m f1_macro: 0.10859345841169472
[2m[36m(func pid=108657)[0m f1_weighted: 0.1362470770605798
[2m[36m(func pid=108657)[0m f1_per_class: [0.032, 0.33, 0.123, 0.0, 0.186, 0.197, 0.177, 0.0, 0.041, 0.0]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 1.5632 | Steps: 2 | Val loss: 2.5810 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
== Status ==
Current time: 2024-01-07 02:54:17 (running for 00:30:18.59)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.57  |      0.361 |                   53 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.407 |      0.217 |                   51 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.547 |      0.222 |                   46 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  2.28  |      0.109 |                   23 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.26632462686567165
[2m[36m(func pid=102297)[0m top5: 0.78125
[2m[36m(func pid=102297)[0m f1_micro: 0.26632462686567165
[2m[36m(func pid=102297)[0m f1_macro: 0.21650571052106632
[2m[36m(func pid=102297)[0m f1_weighted: 0.29152606001398096
[2m[36m(func pid=102297)[0m f1_per_class: [0.081, 0.166, 0.229, 0.207, 0.167, 0.327, 0.49, 0.206, 0.107, 0.186]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.6079 | Steps: 2 | Val loss: 1.9317 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=103229)[0m top1: 0.2248134328358209
[2m[36m(func pid=103229)[0m top5: 0.8097014925373134
[2m[36m(func pid=103229)[0m f1_micro: 0.2248134328358209
[2m[36m(func pid=103229)[0m f1_macro: 0.178157295196882
[2m[36m(func pid=103229)[0m f1_weighted: 0.24532824931459757
[2m[36m(func pid=103229)[0m f1_per_class: [0.071, 0.178, 0.0, 0.044, 0.061, 0.278, 0.449, 0.529, 0.102, 0.069]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 2.2545 | Steps: 2 | Val loss: 2.3461 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=101178)[0m top1: 0.3521455223880597
[2m[36m(func pid=101178)[0m top5: 0.8740671641791045
[2m[36m(func pid=101178)[0m f1_micro: 0.3521455223880597
[2m[36m(func pid=101178)[0m f1_macro: 0.33545010788332164
[2m[36m(func pid=101178)[0m f1_weighted: 0.3897058459974367
[2m[36m(func pid=101178)[0m f1_per_class: [0.15, 0.582, 0.4, 0.412, 0.081, 0.307, 0.319, 0.46, 0.203, 0.441]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.1879 | Steps: 2 | Val loss: 3.3092 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=108657)[0m top1: 0.11380597014925373
[2m[36m(func pid=108657)[0m top5: 0.7597947761194029
[2m[36m(func pid=108657)[0m f1_micro: 0.11380597014925373
[2m[36m(func pid=108657)[0m f1_macro: 0.11131805230042906
[2m[36m(func pid=108657)[0m f1_weighted: 0.14109589833918854
[2m[36m(func pid=108657)[0m f1_per_class: [0.037, 0.316, 0.145, 0.0, 0.21, 0.139, 0.222, 0.0, 0.045, 0.0]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 6.3828 | Steps: 2 | Val loss: 2.6702 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
== Status ==
Current time: 2024-01-07 02:54:23 (running for 00:30:23.83)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.608 |      0.335 |                   54 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.188 |      0.263 |                   52 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.563 |      0.178 |                   47 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  2.254 |      0.111 |                   24 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.2737873134328358
[2m[36m(func pid=102297)[0m top5: 0.7887126865671642
[2m[36m(func pid=102297)[0m f1_micro: 0.2737873134328358
[2m[36m(func pid=102297)[0m f1_macro: 0.2632718084785095
[2m[36m(func pid=102297)[0m f1_weighted: 0.2774996364668688
[2m[36m(func pid=102297)[0m f1_per_class: [0.095, 0.036, 0.595, 0.097, 0.079, 0.267, 0.571, 0.518, 0.131, 0.243]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=103229)[0m top1: 0.25466417910447764
[2m[36m(func pid=103229)[0m top5: 0.8218283582089553
[2m[36m(func pid=103229)[0m f1_micro: 0.25466417910447764
[2m[36m(func pid=103229)[0m f1_macro: 0.18509000940232628
[2m[36m(func pid=103229)[0m f1_weighted: 0.29185725382964584
[2m[36m(func pid=103229)[0m f1_per_class: [0.068, 0.164, 0.0, 0.263, 0.068, 0.307, 0.425, 0.391, 0.098, 0.067]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.6827 | Steps: 2 | Val loss: 1.8856 | Batch size: 32 | lr: 0.001 | Duration: 3.10s
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 2.2252 | Steps: 2 | Val loss: 2.3404 | Batch size: 32 | lr: 0.0001 | Duration: 3.03s
[2m[36m(func pid=101178)[0m top1: 0.37406716417910446
[2m[36m(func pid=101178)[0m top5: 0.8763992537313433
[2m[36m(func pid=101178)[0m f1_micro: 0.37406716417910446
[2m[36m(func pid=101178)[0m f1_macro: 0.3421987474550459
[2m[36m(func pid=101178)[0m f1_weighted: 0.40887077401396854
[2m[36m(func pid=101178)[0m f1_per_class: [0.161, 0.589, 0.327, 0.446, 0.087, 0.316, 0.337, 0.48, 0.227, 0.451]
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.2493 | Steps: 2 | Val loss: 4.0369 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=108657)[0m top1: 0.12453358208955224
[2m[36m(func pid=108657)[0m top5: 0.7597947761194029
[2m[36m(func pid=108657)[0m f1_micro: 0.12453358208955224
[2m[36m(func pid=108657)[0m f1_macro: 0.11705820070348301
[2m[36m(func pid=108657)[0m f1_weighted: 0.155351147969429
[2m[36m(func pid=108657)[0m f1_per_class: [0.039, 0.28, 0.192, 0.0, 0.186, 0.139, 0.29, 0.0, 0.043, 0.0]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 1.8913 | Steps: 2 | Val loss: 2.6918 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
== Status ==
Current time: 2024-01-07 02:54:28 (running for 00:30:29.10)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.683 |      0.342 |                   55 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.249 |      0.235 |                   53 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  6.383 |      0.185 |                   48 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  2.225 |      0.117 |                   25 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.2416044776119403
[2m[36m(func pid=102297)[0m top5: 0.8036380597014925
[2m[36m(func pid=102297)[0m f1_micro: 0.2416044776119403
[2m[36m(func pid=102297)[0m f1_macro: 0.23544366744231954
[2m[36m(func pid=102297)[0m f1_weighted: 0.25573064520657174
[2m[36m(func pid=102297)[0m f1_per_class: [0.091, 0.113, 0.632, 0.087, 0.072, 0.145, 0.556, 0.314, 0.059, 0.286]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=103229)[0m top1: 0.20522388059701493
[2m[36m(func pid=103229)[0m top5: 0.8381529850746269
[2m[36m(func pid=103229)[0m f1_micro: 0.20522388059701493
[2m[36m(func pid=103229)[0m f1_macro: 0.19375299945091953
[2m[36m(func pid=103229)[0m f1_weighted: 0.21093858660409864
[2m[36m(func pid=103229)[0m f1_per_class: [0.093, 0.061, 0.253, 0.309, 0.061, 0.313, 0.146, 0.465, 0.06, 0.175]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.4732 | Steps: 2 | Val loss: 1.7183 | Batch size: 32 | lr: 0.001 | Duration: 3.10s
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 2.2376 | Steps: 2 | Val loss: 2.3413 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.1314 | Steps: 2 | Val loss: 4.4270 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=108657)[0m top1: 0.13619402985074627
[2m[36m(func pid=108657)[0m top5: 0.7588619402985075
[2m[36m(func pid=108657)[0m f1_micro: 0.13619402985074627
[2m[36m(func pid=108657)[0m f1_macro: 0.12391541424148725
[2m[36m(func pid=108657)[0m f1_weighted: 0.16792659797077766
[2m[36m(func pid=108657)[0m f1_per_class: [0.043, 0.266, 0.214, 0.0, 0.168, 0.177, 0.325, 0.0, 0.045, 0.0]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=101178)[0m top1: 0.42350746268656714
[2m[36m(func pid=101178)[0m top5: 0.9039179104477612
[2m[36m(func pid=101178)[0m f1_micro: 0.42350746268656714
[2m[36m(func pid=101178)[0m f1_macro: 0.36330612709847926
[2m[36m(func pid=101178)[0m f1_weighted: 0.4537930950253356
[2m[36m(func pid=101178)[0m f1_per_class: [0.215, 0.559, 0.333, 0.483, 0.092, 0.333, 0.462, 0.502, 0.152, 0.5]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 1.5966 | Steps: 2 | Val loss: 2.7835 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
== Status ==
Current time: 2024-01-07 02:54:33 (running for 00:30:34.54)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.473 |      0.363 |                   56 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.131 |      0.169 |                   54 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.891 |      0.194 |                   49 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  2.238 |      0.124 |                   26 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.2234141791044776
[2m[36m(func pid=102297)[0m top5: 0.8218283582089553
[2m[36m(func pid=102297)[0m f1_micro: 0.2234141791044776
[2m[36m(func pid=102297)[0m f1_macro: 0.16924178397228115
[2m[36m(func pid=102297)[0m f1_weighted: 0.25207686237419613
[2m[36m(func pid=102297)[0m f1_per_class: [0.087, 0.249, 0.0, 0.089, 0.069, 0.186, 0.505, 0.062, 0.082, 0.364]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=103229)[0m top1: 0.17583955223880596
[2m[36m(func pid=103229)[0m top5: 0.8362873134328358
[2m[36m(func pid=103229)[0m f1_micro: 0.17583955223880596
[2m[36m(func pid=103229)[0m f1_macro: 0.1699608927826889
[2m[36m(func pid=103229)[0m f1_weighted: 0.19633678729356951
[2m[36m(func pid=103229)[0m f1_per_class: [0.096, 0.09, 0.301, 0.17, 0.048, 0.285, 0.25, 0.344, 0.037, 0.077]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 2.1850 | Steps: 2 | Val loss: 2.3393 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.9830 | Steps: 2 | Val loss: 1.9060 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.2643 | Steps: 2 | Val loss: 4.2868 | Batch size: 32 | lr: 0.01 | Duration: 2.72s
[2m[36m(func pid=108657)[0m top1: 0.14319029850746268
[2m[36m(func pid=108657)[0m top5: 0.7658582089552238
[2m[36m(func pid=108657)[0m f1_micro: 0.14319029850746268
[2m[36m(func pid=108657)[0m f1_macro: 0.1257775819922849
[2m[36m(func pid=108657)[0m f1_weighted: 0.17101422884484174
[2m[36m(func pid=108657)[0m f1_per_class: [0.05, 0.228, 0.234, 0.0, 0.162, 0.186, 0.353, 0.0, 0.043, 0.0]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=101178)[0m top1: 0.37919776119402987
[2m[36m(func pid=101178)[0m top5: 0.8675373134328358
[2m[36m(func pid=101178)[0m f1_micro: 0.37919776119402987
[2m[36m(func pid=101178)[0m f1_macro: 0.32895987561490353
[2m[36m(func pid=101178)[0m f1_weighted: 0.4007174730521096
[2m[36m(func pid=101178)[0m f1_per_class: [0.201, 0.582, 0.293, 0.488, 0.079, 0.312, 0.287, 0.443, 0.2, 0.405]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 1.4379 | Steps: 2 | Val loss: 2.7064 | Batch size: 32 | lr: 0.1 | Duration: 3.05s
[2m[36m(func pid=102297)[0m top1: 0.25699626865671643
[2m[36m(func pid=102297)[0m top5: 0.8148320895522388
[2m[36m(func pid=102297)[0m f1_micro: 0.25699626865671643
[2m[36m(func pid=102297)[0m f1_macro: 0.2012912092464493
[2m[36m(func pid=102297)[0m f1_weighted: 0.27856826269292934
[2m[36m(func pid=102297)[0m f1_per_class: [0.108, 0.426, 0.0, 0.082, 0.051, 0.231, 0.459, 0.125, 0.14, 0.39]
[2m[36m(func pid=102297)[0m 
== Status ==
Current time: 2024-01-07 02:54:38 (running for 00:30:39.68)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.983 |      0.329 |                   57 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.264 |      0.201 |                   55 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.597 |      0.17  |                   50 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  2.185 |      0.126 |                   27 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=103229)[0m top1: 0.2019589552238806
[2m[36m(func pid=103229)[0m top5: 0.8563432835820896
[2m[36m(func pid=103229)[0m f1_micro: 0.2019589552238806
[2m[36m(func pid=103229)[0m f1_macro: 0.17661515031956415
[2m[36m(func pid=103229)[0m f1_weighted: 0.23328775591640502
[2m[36m(func pid=103229)[0m f1_per_class: [0.092, 0.146, 0.327, 0.158, 0.052, 0.295, 0.357, 0.339, 0.0, 0.0]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 2.1310 | Steps: 2 | Val loss: 2.3250 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.4508 | Steps: 2 | Val loss: 2.0706 | Batch size: 32 | lr: 0.001 | Duration: 3.05s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.4338 | Steps: 2 | Val loss: 4.2296 | Batch size: 32 | lr: 0.01 | Duration: 3.08s
[2m[36m(func pid=108657)[0m top1: 0.15298507462686567
[2m[36m(func pid=108657)[0m top5: 0.7747201492537313
[2m[36m(func pid=108657)[0m f1_micro: 0.15298507462686567
[2m[36m(func pid=108657)[0m f1_macro: 0.13391396878495673
[2m[36m(func pid=108657)[0m f1_weighted: 0.1765960465845958
[2m[36m(func pid=108657)[0m f1_per_class: [0.057, 0.214, 0.293, 0.0, 0.141, 0.203, 0.371, 0.0, 0.059, 0.0]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=101178)[0m top1: 0.3414179104477612
[2m[36m(func pid=101178)[0m top5: 0.8362873134328358
[2m[36m(func pid=101178)[0m f1_micro: 0.3414179104477612
[2m[36m(func pid=101178)[0m f1_macro: 0.27481098746859683
[2m[36m(func pid=101178)[0m f1_weighted: 0.35677317772994904
[2m[36m(func pid=101178)[0m f1_per_class: [0.176, 0.581, 0.191, 0.474, 0.071, 0.264, 0.196, 0.393, 0.152, 0.25]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 1.4299 | Steps: 2 | Val loss: 2.5387 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 02:54:44 (running for 00:30:45.21)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.451 |      0.275 |                   58 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.434 |      0.204 |                   56 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.438 |      0.177 |                   51 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  2.131 |      0.134 |                   28 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.3111007462686567
[2m[36m(func pid=102297)[0m top5: 0.8036380597014925
[2m[36m(func pid=102297)[0m f1_micro: 0.3111007462686567
[2m[36m(func pid=102297)[0m f1_macro: 0.20395665899241266
[2m[36m(func pid=102297)[0m f1_weighted: 0.2861519223646993
[2m[36m(func pid=102297)[0m f1_per_class: [0.129, 0.425, 0.375, 0.098, 0.044, 0.062, 0.543, 0.135, 0.04, 0.188]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=103229)[0m top1: 0.24486940298507462
[2m[36m(func pid=103229)[0m top5: 0.8568097014925373
[2m[36m(func pid=103229)[0m f1_micro: 0.24486940298507462
[2m[36m(func pid=103229)[0m f1_macro: 0.22076154132201126
[2m[36m(func pid=103229)[0m f1_weighted: 0.2841828472776218
[2m[36m(func pid=103229)[0m f1_per_class: [0.093, 0.194, 0.383, 0.224, 0.06, 0.314, 0.406, 0.436, 0.021, 0.077]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 2.1360 | Steps: 2 | Val loss: 2.3143 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.5531 | Steps: 2 | Val loss: 1.7597 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.0550 | Steps: 2 | Val loss: 4.8666 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=108657)[0m top1: 0.16324626865671643
[2m[36m(func pid=108657)[0m top5: 0.7845149253731343
[2m[36m(func pid=108657)[0m f1_micro: 0.16324626865671643
[2m[36m(func pid=108657)[0m f1_macro: 0.14622761003318085
[2m[36m(func pid=108657)[0m f1_weighted: 0.1881813230186801
[2m[36m(func pid=108657)[0m f1_per_class: [0.063, 0.243, 0.324, 0.0, 0.157, 0.208, 0.385, 0.032, 0.052, 0.0]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=101178)[0m top1: 0.42024253731343286
[2m[36m(func pid=101178)[0m top5: 0.8936567164179104
[2m[36m(func pid=101178)[0m f1_micro: 0.42024253731343286
[2m[36m(func pid=101178)[0m f1_macro: 0.3551144102100424
[2m[36m(func pid=101178)[0m f1_weighted: 0.44261022079943607
[2m[36m(func pid=101178)[0m f1_per_class: [0.226, 0.591, 0.202, 0.483, 0.084, 0.338, 0.389, 0.573, 0.205, 0.462]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 5.6958 | Steps: 2 | Val loss: 2.1826 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
== Status ==
Current time: 2024-01-07 02:54:49 (running for 00:30:50.62)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.553 |      0.355 |                   59 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.055 |      0.194 |                   57 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.43  |      0.221 |                   52 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  2.136 |      0.146 |                   29 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.29990671641791045
[2m[36m(func pid=102297)[0m top5: 0.7854477611940298
[2m[36m(func pid=102297)[0m f1_micro: 0.29990671641791045
[2m[36m(func pid=102297)[0m f1_macro: 0.19402913734340205
[2m[36m(func pid=102297)[0m f1_weighted: 0.2614668084824282
[2m[36m(func pid=102297)[0m f1_per_class: [0.06, 0.387, 0.556, 0.085, 0.067, 0.016, 0.541, 0.0, 0.019, 0.211]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 2.2252 | Steps: 2 | Val loss: 2.3092 | Batch size: 32 | lr: 0.0001 | Duration: 2.78s
[2m[36m(func pid=103229)[0m top1: 0.36800373134328357
[2m[36m(func pid=103229)[0m top5: 0.8717350746268657
[2m[36m(func pid=103229)[0m f1_micro: 0.3680037313432836
[2m[36m(func pid=103229)[0m f1_macro: 0.2881058461268813
[2m[36m(func pid=103229)[0m f1_weighted: 0.40507533743800783
[2m[36m(func pid=103229)[0m f1_per_class: [0.063, 0.44, 0.327, 0.464, 0.066, 0.33, 0.416, 0.495, 0.133, 0.148]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.4245 | Steps: 2 | Val loss: 1.7467 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.0241 | Steps: 2 | Val loss: 5.0332 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=108657)[0m top1: 0.1814365671641791
[2m[36m(func pid=108657)[0m top5: 0.784981343283582
[2m[36m(func pid=108657)[0m f1_micro: 0.1814365671641791
[2m[36m(func pid=108657)[0m f1_macro: 0.15486202547951183
[2m[36m(func pid=108657)[0m f1_weighted: 0.20436095295168985
[2m[36m(func pid=108657)[0m f1_per_class: [0.067, 0.261, 0.338, 0.0, 0.139, 0.214, 0.424, 0.031, 0.074, 0.0]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=101178)[0m top1: 0.43097014925373134
[2m[36m(func pid=101178)[0m top5: 0.9006529850746269
[2m[36m(func pid=101178)[0m f1_micro: 0.43097014925373134
[2m[36m(func pid=101178)[0m f1_macro: 0.3594456022755671
[2m[36m(func pid=101178)[0m f1_weighted: 0.45718216265654393
[2m[36m(func pid=101178)[0m f1_per_class: [0.222, 0.613, 0.182, 0.475, 0.09, 0.346, 0.439, 0.522, 0.197, 0.508]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 4.0302 | Steps: 2 | Val loss: 2.0579 | Batch size: 32 | lr: 0.1 | Duration: 3.02s
== Status ==
Current time: 2024-01-07 02:54:55 (running for 00:30:55.92)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.424 |      0.359 |                   60 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.024 |      0.211 |                   58 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  5.696 |      0.288 |                   53 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  2.225 |      0.155 |                   30 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.32136194029850745
[2m[36m(func pid=102297)[0m top5: 0.7821828358208955
[2m[36m(func pid=102297)[0m f1_micro: 0.32136194029850745
[2m[36m(func pid=102297)[0m f1_macro: 0.21094774297446617
[2m[36m(func pid=102297)[0m f1_weighted: 0.2790401976766919
[2m[36m(func pid=102297)[0m f1_per_class: [0.059, 0.364, 0.69, 0.13, 0.095, 0.008, 0.572, 0.0, 0.018, 0.174]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=103229)[0m top1: 0.3199626865671642
[2m[36m(func pid=103229)[0m top5: 0.8759328358208955
[2m[36m(func pid=103229)[0m f1_micro: 0.3199626865671642
[2m[36m(func pid=103229)[0m f1_macro: 0.23241523319047305
[2m[36m(func pid=103229)[0m f1_weighted: 0.3599237471287989
[2m[36m(func pid=103229)[0m f1_per_class: [0.0, 0.31, 0.265, 0.308, 0.0, 0.335, 0.512, 0.411, 0.105, 0.077]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 2.0718 | Steps: 2 | Val loss: 2.2914 | Batch size: 32 | lr: 0.0001 | Duration: 3.11s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.4250 | Steps: 2 | Val loss: 1.9169 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.1022 | Steps: 2 | Val loss: 4.5296 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=108657)[0m top1: 0.19029850746268656
[2m[36m(func pid=108657)[0m top5: 0.7924440298507462
[2m[36m(func pid=108657)[0m f1_micro: 0.19029850746268656
[2m[36m(func pid=108657)[0m f1_macro: 0.16405501190228516
[2m[36m(func pid=108657)[0m f1_weighted: 0.21023538569725636
[2m[36m(func pid=108657)[0m f1_per_class: [0.073, 0.279, 0.392, 0.0, 0.13, 0.196, 0.434, 0.047, 0.09, 0.0]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=101178)[0m top1: 0.37919776119402987
[2m[36m(func pid=101178)[0m top5: 0.878731343283582
[2m[36m(func pid=101178)[0m f1_micro: 0.37919776119402987
[2m[36m(func pid=101178)[0m f1_macro: 0.3171878713130191
[2m[36m(func pid=101178)[0m f1_weighted: 0.40462702910469184
[2m[36m(func pid=101178)[0m f1_per_class: [0.168, 0.598, 0.168, 0.497, 0.093, 0.302, 0.282, 0.519, 0.141, 0.404]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 1.8690 | Steps: 2 | Val loss: 2.2152 | Batch size: 32 | lr: 0.1 | Duration: 2.76s
== Status ==
Current time: 2024-01-07 02:55:00 (running for 00:31:01.44)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.425 |      0.317 |                   61 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.102 |      0.183 |                   59 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  4.03  |      0.232 |                   54 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  2.072 |      0.164 |                   31 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.32369402985074625
[2m[36m(func pid=102297)[0m top5: 0.8111007462686567
[2m[36m(func pid=102297)[0m f1_micro: 0.32369402985074625
[2m[36m(func pid=102297)[0m f1_macro: 0.18298459714143842
[2m[36m(func pid=102297)[0m f1_weighted: 0.289934950872826
[2m[36m(func pid=102297)[0m f1_per_class: [0.071, 0.336, 0.344, 0.18, 0.083, 0.023, 0.577, 0.0, 0.034, 0.182]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=103229)[0m top1: 0.22294776119402984
[2m[36m(func pid=103229)[0m top5: 0.8456156716417911
[2m[36m(func pid=103229)[0m f1_micro: 0.22294776119402981
[2m[36m(func pid=103229)[0m f1_macro: 0.14723240591465694
[2m[36m(func pid=103229)[0m f1_weighted: 0.21970804039733022
[2m[36m(func pid=103229)[0m f1_per_class: [0.0, 0.016, 0.187, 0.052, 0.0, 0.031, 0.562, 0.461, 0.09, 0.074]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 2.0633 | Steps: 2 | Val loss: 2.2642 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.4571 | Steps: 2 | Val loss: 1.7846 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.3477 | Steps: 2 | Val loss: 6.0485 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=108657)[0m top1: 0.20009328358208955
[2m[36m(func pid=108657)[0m top5: 0.8036380597014925
[2m[36m(func pid=108657)[0m f1_micro: 0.20009328358208955
[2m[36m(func pid=108657)[0m f1_macro: 0.17579647904005938
[2m[36m(func pid=108657)[0m f1_weighted: 0.21828915938371016
[2m[36m(func pid=108657)[0m f1_per_class: [0.08, 0.269, 0.409, 0.0, 0.115, 0.201, 0.458, 0.062, 0.089, 0.074]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=101178)[0m top1: 0.43097014925373134
[2m[36m(func pid=101178)[0m top5: 0.8936567164179104
[2m[36m(func pid=101178)[0m f1_micro: 0.43097014925373134
[2m[36m(func pid=101178)[0m f1_macro: 0.3649788635904127
[2m[36m(func pid=101178)[0m f1_weighted: 0.46158130814779086
[2m[36m(func pid=101178)[0m f1_per_class: [0.191, 0.595, 0.163, 0.505, 0.092, 0.338, 0.43, 0.561, 0.214, 0.56]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 1.7628 | Steps: 2 | Val loss: 2.1130 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 02:55:05 (running for 00:31:06.66)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.457 |      0.365 |                   62 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.348 |      0.172 |                   60 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.869 |      0.147 |                   55 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  2.063 |      0.176 |                   32 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.310634328358209
[2m[36m(func pid=102297)[0m top5: 0.8540111940298507
[2m[36m(func pid=102297)[0m f1_micro: 0.310634328358209
[2m[36m(func pid=102297)[0m f1_macro: 0.17177868792393436
[2m[36m(func pid=102297)[0m f1_weighted: 0.2981926777040176
[2m[36m(func pid=102297)[0m f1_per_class: [0.0, 0.341, 0.0, 0.176, 0.082, 0.185, 0.527, 0.103, 0.093, 0.211]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=103229)[0m top1: 0.21548507462686567
[2m[36m(func pid=103229)[0m top5: 0.8852611940298507
[2m[36m(func pid=103229)[0m f1_micro: 0.21548507462686567
[2m[36m(func pid=103229)[0m f1_macro: 0.2068840860914381
[2m[36m(func pid=103229)[0m f1_weighted: 0.23638163552853156
[2m[36m(func pid=103229)[0m f1_per_class: [0.0, 0.239, 0.082, 0.081, 0.162, 0.353, 0.326, 0.465, 0.107, 0.255]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.5226 | Steps: 2 | Val loss: 1.7249 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 2.0021 | Steps: 2 | Val loss: 2.2399 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.1224 | Steps: 2 | Val loss: 8.6887 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=101178)[0m top1: 0.4361007462686567
[2m[36m(func pid=101178)[0m top5: 0.9067164179104478
[2m[36m(func pid=101178)[0m f1_micro: 0.4361007462686567
[2m[36m(func pid=101178)[0m f1_macro: 0.36290813021539475
[2m[36m(func pid=101178)[0m f1_weighted: 0.464608607636125
[2m[36m(func pid=101178)[0m f1_per_class: [0.19, 0.588, 0.175, 0.501, 0.087, 0.327, 0.459, 0.548, 0.158, 0.596]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=108657)[0m top1: 0.21315298507462688
[2m[36m(func pid=108657)[0m top5: 0.8092350746268657
[2m[36m(func pid=108657)[0m f1_micro: 0.2131529850746269
[2m[36m(func pid=108657)[0m f1_macro: 0.19723934484639324
[2m[36m(func pid=108657)[0m f1_weighted: 0.2292154460936624
[2m[36m(func pid=108657)[0m f1_per_class: [0.087, 0.298, 0.45, 0.0, 0.106, 0.19, 0.475, 0.062, 0.097, 0.207]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 1.5344 | Steps: 2 | Val loss: 2.2680 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 02:55:11 (running for 00:31:12.08)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.523 |      0.363 |                   63 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.122 |      0.226 |                   61 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.763 |      0.207 |                   56 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  2.002 |      0.197 |                   33 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.30970149253731344
[2m[36m(func pid=102297)[0m top5: 0.8726679104477612
[2m[36m(func pid=102297)[0m f1_micro: 0.30970149253731344
[2m[36m(func pid=102297)[0m f1_macro: 0.2260481063886862
[2m[36m(func pid=102297)[0m f1_weighted: 0.3039709086935485
[2m[36m(func pid=102297)[0m f1_per_class: [0.0, 0.352, 0.0, 0.182, 0.101, 0.371, 0.403, 0.346, 0.164, 0.341]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=103229)[0m top1: 0.16417910447761194
[2m[36m(func pid=103229)[0m top5: 0.8936567164179104
[2m[36m(func pid=103229)[0m f1_micro: 0.16417910447761194
[2m[36m(func pid=103229)[0m f1_macro: 0.17794753900220694
[2m[36m(func pid=103229)[0m f1_weighted: 0.15312349081988863
[2m[36m(func pid=103229)[0m f1_per_class: [0.077, 0.239, 0.183, 0.106, 0.094, 0.259, 0.07, 0.384, 0.082, 0.283]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.3757 | Steps: 2 | Val loss: 1.8475 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 1.9724 | Steps: 2 | Val loss: 2.2177 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.4409 | Steps: 2 | Val loss: 4.2094 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=101178)[0m top1: 0.39925373134328357
[2m[36m(func pid=101178)[0m top5: 0.8894589552238806
[2m[36m(func pid=101178)[0m f1_micro: 0.3992537313432836
[2m[36m(func pid=101178)[0m f1_macro: 0.34554648544435296
[2m[36m(func pid=101178)[0m f1_weighted: 0.42462983918882785
[2m[36m(func pid=101178)[0m f1_per_class: [0.217, 0.577, 0.22, 0.511, 0.079, 0.301, 0.338, 0.483, 0.23, 0.5]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=108657)[0m top1: 0.22388059701492538
[2m[36m(func pid=108657)[0m top5: 0.8101679104477612
[2m[36m(func pid=108657)[0m f1_micro: 0.22388059701492538
[2m[36m(func pid=108657)[0m f1_macro: 0.20649740524324295
[2m[36m(func pid=108657)[0m f1_weighted: 0.2360465833355752
[2m[36m(func pid=108657)[0m f1_per_class: [0.09, 0.321, 0.5, 0.0, 0.103, 0.163, 0.498, 0.031, 0.091, 0.267]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 1.8503 | Steps: 2 | Val loss: 2.3819 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 02:55:16 (running for 00:31:17.39)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.376 |      0.346 |                   64 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.441 |      0.212 |                   62 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.534 |      0.178 |                   57 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.972 |      0.206 |                   34 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.29850746268656714
[2m[36m(func pid=102297)[0m top5: 0.867070895522388
[2m[36m(func pid=102297)[0m f1_micro: 0.29850746268656714
[2m[36m(func pid=102297)[0m f1_macro: 0.21155223008925708
[2m[36m(func pid=102297)[0m f1_weighted: 0.3003019050917921
[2m[36m(func pid=102297)[0m f1_per_class: [0.042, 0.386, 0.0, 0.309, 0.09, 0.31, 0.293, 0.24, 0.205, 0.241]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=103229)[0m top1: 0.23600746268656717
[2m[36m(func pid=103229)[0m top5: 0.8810634328358209
[2m[36m(func pid=103229)[0m f1_micro: 0.23600746268656717
[2m[36m(func pid=103229)[0m f1_macro: 0.20496290739619308
[2m[36m(func pid=103229)[0m f1_weighted: 0.23546154153286336
[2m[36m(func pid=103229)[0m f1_per_class: [0.083, 0.17, 0.245, 0.078, 0.077, 0.249, 0.407, 0.435, 0.106, 0.2]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 2.0013 | Steps: 2 | Val loss: 2.1952 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.3602 | Steps: 2 | Val loss: 1.9334 | Batch size: 32 | lr: 0.001 | Duration: 3.06s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.0700 | Steps: 2 | Val loss: 3.8389 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=108657)[0m top1: 0.2392723880597015
[2m[36m(func pid=108657)[0m top5: 0.8166977611940298
[2m[36m(func pid=108657)[0m f1_micro: 0.2392723880597015
[2m[36m(func pid=108657)[0m f1_macro: 0.21184771151018716
[2m[36m(func pid=108657)[0m f1_weighted: 0.24635499797861912
[2m[36m(func pid=108657)[0m f1_per_class: [0.095, 0.359, 0.514, 0.0, 0.097, 0.154, 0.514, 0.031, 0.096, 0.258]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=101178)[0m top1: 0.363339552238806
[2m[36m(func pid=101178)[0m top5: 0.878731343283582
[2m[36m(func pid=101178)[0m f1_micro: 0.363339552238806
[2m[36m(func pid=101178)[0m f1_macro: 0.30681106011122666
[2m[36m(func pid=101178)[0m f1_weighted: 0.38802208616290523
[2m[36m(func pid=101178)[0m f1_per_class: [0.182, 0.544, 0.229, 0.487, 0.08, 0.289, 0.277, 0.478, 0.172, 0.33]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 1.7551 | Steps: 2 | Val loss: 2.7740 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=102297)[0m top1: 0.2537313432835821
[2m[36m(func pid=102297)[0m top5: 0.8404850746268657
[2m[36m(func pid=102297)[0m f1_micro: 0.2537313432835821
[2m[36m(func pid=102297)[0m f1_macro: 0.20661491901501772
[2m[36m(func pid=102297)[0m f1_weighted: 0.2954219613613753
[2m[36m(func pid=102297)[0m f1_per_class: [0.036, 0.383, 0.055, 0.344, 0.075, 0.283, 0.254, 0.281, 0.167, 0.19]
[2m[36m(func pid=102297)[0m 
== Status ==
Current time: 2024-01-07 02:55:22 (running for 00:31:22.84)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.36  |      0.307 |                   65 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.07  |      0.207 |                   63 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.85  |      0.205 |                   58 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  2.001 |      0.212 |                   35 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=103229)[0m top1: 0.1767723880597015
[2m[36m(func pid=103229)[0m top5: 0.8605410447761194
[2m[36m(func pid=103229)[0m f1_micro: 0.1767723880597015
[2m[36m(func pid=103229)[0m f1_macro: 0.15131909473370958
[2m[36m(func pid=103229)[0m f1_weighted: 0.1549406247954577
[2m[36m(func pid=103229)[0m f1_per_class: [0.084, 0.01, 0.321, 0.057, 0.086, 0.194, 0.297, 0.329, 0.072, 0.062]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 1.9442 | Steps: 2 | Val loss: 2.1663 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.4084 | Steps: 2 | Val loss: 1.8707 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.4768 | Steps: 2 | Val loss: 3.9218 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 1.8119 | Steps: 2 | Val loss: 2.8663 | Batch size: 32 | lr: 0.1 | Duration: 2.78s
[2m[36m(func pid=108657)[0m top1: 0.2462686567164179
[2m[36m(func pid=108657)[0m top5: 0.8297574626865671
[2m[36m(func pid=108657)[0m f1_micro: 0.2462686567164179
[2m[36m(func pid=108657)[0m f1_macro: 0.2082521830145593
[2m[36m(func pid=108657)[0m f1_weighted: 0.24608621916272688
[2m[36m(func pid=108657)[0m f1_per_class: [0.103, 0.366, 0.514, 0.0, 0.089, 0.135, 0.522, 0.0, 0.095, 0.258]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=101178)[0m top1: 0.39132462686567165
[2m[36m(func pid=101178)[0m top5: 0.8861940298507462
[2m[36m(func pid=101178)[0m f1_micro: 0.39132462686567165
[2m[36m(func pid=101178)[0m f1_macro: 0.33090074569423505
[2m[36m(func pid=101178)[0m f1_weighted: 0.4186937374303148
[2m[36m(func pid=101178)[0m f1_per_class: [0.19, 0.556, 0.242, 0.503, 0.081, 0.307, 0.342, 0.49, 0.202, 0.396]
[2m[36m(func pid=101178)[0m 
== Status ==
Current time: 2024-01-07 02:55:27 (running for 00:31:28.20)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.408 |      0.331 |                   66 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.477 |      0.182 |                   64 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.755 |      0.151 |                   59 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.944 |      0.208 |                   36 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.24067164179104478
[2m[36m(func pid=102297)[0m top5: 0.8260261194029851
[2m[36m(func pid=102297)[0m f1_micro: 0.24067164179104478
[2m[36m(func pid=102297)[0m f1_macro: 0.18195125845925117
[2m[36m(func pid=102297)[0m f1_weighted: 0.2674487921872444
[2m[36m(func pid=102297)[0m f1_per_class: [0.065, 0.258, 0.07, 0.322, 0.075, 0.076, 0.314, 0.393, 0.136, 0.111]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=103229)[0m top1: 0.23367537313432835
[2m[36m(func pid=103229)[0m top5: 0.832089552238806
[2m[36m(func pid=103229)[0m f1_micro: 0.23367537313432835
[2m[36m(func pid=103229)[0m f1_macro: 0.2034029562799781
[2m[36m(func pid=103229)[0m f1_weighted: 0.21572855975352823
[2m[36m(func pid=103229)[0m f1_per_class: [0.082, 0.039, 0.343, 0.026, 0.167, 0.271, 0.453, 0.448, 0.104, 0.101]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 1.8786 | Steps: 2 | Val loss: 2.1402 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.5990 | Steps: 2 | Val loss: 1.7754 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.4188 | Steps: 2 | Val loss: 3.3208 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=108657)[0m top1: 0.24673507462686567
[2m[36m(func pid=108657)[0m top5: 0.8390858208955224
[2m[36m(func pid=108657)[0m f1_micro: 0.24673507462686567
[2m[36m(func pid=108657)[0m f1_macro: 0.2075224783318567
[2m[36m(func pid=108657)[0m f1_weighted: 0.24055755152961555
[2m[36m(func pid=108657)[0m f1_per_class: [0.113, 0.367, 0.529, 0.0, 0.081, 0.089, 0.519, 0.0, 0.09, 0.286]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 1.3735 | Steps: 2 | Val loss: 3.0215 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=101178)[0m top1: 0.425839552238806
[2m[36m(func pid=101178)[0m top5: 0.8959888059701493
[2m[36m(func pid=101178)[0m f1_micro: 0.42583955223880593
[2m[36m(func pid=101178)[0m f1_macro: 0.36027974564954157
[2m[36m(func pid=101178)[0m f1_weighted: 0.45370723621052744
[2m[36m(func pid=101178)[0m f1_per_class: [0.192, 0.561, 0.272, 0.508, 0.095, 0.338, 0.422, 0.568, 0.193, 0.453]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=103229)[0m top1: 0.20149253731343283
[2m[36m(func pid=103229)[0m top5: 0.8036380597014925
[2m[36m(func pid=103229)[0m f1_micro: 0.20149253731343283
[2m[36m(func pid=103229)[0m f1_macro: 0.2086904809361219
[2m[36m(func pid=103229)[0m f1_weighted: 0.18847014697409295
[2m[36m(func pid=103229)[0m f1_per_class: [0.09, 0.044, 0.353, 0.003, 0.333, 0.212, 0.4, 0.441, 0.105, 0.106]
[2m[36m(func pid=103229)[0m 
== Status ==
Current time: 2024-01-07 02:55:32 (running for 00:31:33.76)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.599 |      0.36  |                   67 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.477 |      0.182 |                   64 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.373 |      0.209 |                   61 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.879 |      0.208 |                   37 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.261660447761194
[2m[36m(func pid=102297)[0m top5: 0.8381529850746269
[2m[36m(func pid=102297)[0m f1_micro: 0.261660447761194
[2m[36m(func pid=102297)[0m f1_macro: 0.21206223286378156
[2m[36m(func pid=102297)[0m f1_weighted: 0.2958761244444485
[2m[36m(func pid=102297)[0m f1_per_class: [0.135, 0.202, 0.12, 0.343, 0.072, 0.256, 0.344, 0.406, 0.152, 0.09]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 1.8809 | Steps: 2 | Val loss: 2.1095 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.4396 | Steps: 2 | Val loss: 1.7472 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 1.6396 | Steps: 2 | Val loss: 2.8040 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
[2m[36m(func pid=108657)[0m top1: 0.2593283582089552
[2m[36m(func pid=108657)[0m top5: 0.851679104477612
[2m[36m(func pid=108657)[0m f1_micro: 0.2593283582089552
[2m[36m(func pid=108657)[0m f1_macro: 0.20539857368059306
[2m[36m(func pid=108657)[0m f1_weighted: 0.24907993419768146
[2m[36m(func pid=108657)[0m f1_per_class: [0.115, 0.384, 0.486, 0.0, 0.077, 0.076, 0.539, 0.032, 0.088, 0.256]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.1700 | Steps: 2 | Val loss: 3.1206 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=101178)[0m top1: 0.4146455223880597
[2m[36m(func pid=101178)[0m top5: 0.9067164179104478
[2m[36m(func pid=101178)[0m f1_micro: 0.4146455223880597
[2m[36m(func pid=101178)[0m f1_macro: 0.3490004438531707
[2m[36m(func pid=101178)[0m f1_weighted: 0.4338798915166778
[2m[36m(func pid=101178)[0m f1_per_class: [0.193, 0.564, 0.3, 0.494, 0.105, 0.311, 0.394, 0.495, 0.157, 0.478]
[2m[36m(func pid=101178)[0m 
== Status ==
Current time: 2024-01-07 02:55:38 (running for 00:31:39.08)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.44  |      0.349 |                   68 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.17  |      0.236 |                   66 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.373 |      0.209 |                   61 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.881 |      0.205 |                   38 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.271455223880597
[2m[36m(func pid=102297)[0m top5: 0.8428171641791045
[2m[36m(func pid=102297)[0m f1_micro: 0.271455223880597
[2m[36m(func pid=102297)[0m f1_macro: 0.23572649722675076
[2m[36m(func pid=102297)[0m f1_weighted: 0.2950786761466251
[2m[36m(func pid=102297)[0m f1_per_class: [0.182, 0.183, 0.242, 0.357, 0.089, 0.31, 0.307, 0.424, 0.17, 0.093]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=103229)[0m top1: 0.16138059701492538
[2m[36m(func pid=103229)[0m top5: 0.8036380597014925
[2m[36m(func pid=103229)[0m f1_micro: 0.16138059701492538
[2m[36m(func pid=103229)[0m f1_macro: 0.18270619558779244
[2m[36m(func pid=103229)[0m f1_weighted: 0.14217025358052623
[2m[36m(func pid=103229)[0m f1_per_class: [0.091, 0.04, 0.4, 0.112, 0.256, 0.263, 0.152, 0.299, 0.123, 0.09]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 1.7825 | Steps: 2 | Val loss: 2.0835 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.4235 | Steps: 2 | Val loss: 1.7538 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.1647 | Steps: 2 | Val loss: 2.8137 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 1.4610 | Steps: 2 | Val loss: 2.3642 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=108657)[0m top1: 0.26632462686567165
[2m[36m(func pid=108657)[0m top5: 0.8638059701492538
[2m[36m(func pid=108657)[0m f1_micro: 0.26632462686567165
[2m[36m(func pid=108657)[0m f1_macro: 0.20523281045571026
[2m[36m(func pid=108657)[0m f1_weighted: 0.25181141638227383
[2m[36m(func pid=108657)[0m f1_per_class: [0.128, 0.378, 0.462, 0.0, 0.073, 0.054, 0.552, 0.078, 0.084, 0.244]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=101178)[0m top1: 0.4123134328358209
[2m[36m(func pid=101178)[0m top5: 0.9113805970149254
[2m[36m(func pid=101178)[0m f1_micro: 0.4123134328358209
[2m[36m(func pid=101178)[0m f1_macro: 0.3496093093831819
[2m[36m(func pid=101178)[0m f1_weighted: 0.430729781674161
[2m[36m(func pid=101178)[0m f1_per_class: [0.201, 0.559, 0.353, 0.49, 0.093, 0.316, 0.387, 0.51, 0.15, 0.438]
[2m[36m(func pid=101178)[0m 
== Status ==
Current time: 2024-01-07 02:55:43 (running for 00:31:44.51)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.424 |      0.35  |                   69 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.17  |      0.236 |                   66 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.461 |      0.201 |                   63 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.782 |      0.205 |                   39 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=103229)[0m top1: 0.251865671641791
[2m[36m(func pid=103229)[0m top5: 0.8386194029850746
[2m[36m(func pid=103229)[0m f1_micro: 0.251865671641791
[2m[36m(func pid=103229)[0m f1_macro: 0.2006624537521708
[2m[36m(func pid=103229)[0m f1_weighted: 0.25469561568971977
[2m[36m(func pid=103229)[0m f1_per_class: [0.093, 0.035, 0.16, 0.342, 0.117, 0.265, 0.304, 0.374, 0.16, 0.157]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=102297)[0m top1: 0.30550373134328357
[2m[36m(func pid=102297)[0m top5: 0.8722014925373134
[2m[36m(func pid=102297)[0m f1_micro: 0.30550373134328357
[2m[36m(func pid=102297)[0m f1_macro: 0.3128400451172378
[2m[36m(func pid=102297)[0m f1_weighted: 0.3210898651407646
[2m[36m(func pid=102297)[0m f1_per_class: [0.258, 0.202, 0.818, 0.438, 0.099, 0.334, 0.282, 0.405, 0.191, 0.101]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 1.8223 | Steps: 2 | Val loss: 2.0685 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.6256 | Steps: 2 | Val loss: 1.9529 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 7.4503 | Steps: 2 | Val loss: 2.3796 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=108657)[0m top1: 0.27611940298507465
[2m[36m(func pid=108657)[0m top5: 0.8754664179104478
[2m[36m(func pid=108657)[0m f1_micro: 0.27611940298507465
[2m[36m(func pid=108657)[0m f1_macro: 0.2259594182076571
[2m[36m(func pid=108657)[0m f1_weighted: 0.26150859504894963
[2m[36m(func pid=108657)[0m f1_per_class: [0.139, 0.39, 0.45, 0.0, 0.073, 0.094, 0.55, 0.106, 0.094, 0.364]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.0824 | Steps: 2 | Val loss: 2.8246 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=101178)[0m top1: 0.3694029850746269
[2m[36m(func pid=101178)[0m top5: 0.8740671641791045
[2m[36m(func pid=101178)[0m f1_micro: 0.3694029850746269
[2m[36m(func pid=101178)[0m f1_macro: 0.3242495607143324
[2m[36m(func pid=101178)[0m f1_weighted: 0.38708301014596347
[2m[36m(func pid=101178)[0m f1_per_class: [0.207, 0.579, 0.364, 0.468, 0.063, 0.291, 0.267, 0.477, 0.16, 0.367]
[2m[36m(func pid=101178)[0m 
== Status ==
Current time: 2024-01-07 02:55:49 (running for 00:31:49.82)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.626 |      0.324 |                   70 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.165 |      0.313 |                   67 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  7.45  |      0.193 |                   64 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.822 |      0.226 |                   40 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=103229)[0m top1: 0.365205223880597
[2m[36m(func pid=103229)[0m top5: 0.8628731343283582
[2m[36m(func pid=103229)[0m f1_micro: 0.365205223880597
[2m[36m(func pid=103229)[0m f1_macro: 0.1932730195406985
[2m[36m(func pid=103229)[0m f1_weighted: 0.34397568047497135
[2m[36m(func pid=103229)[0m f1_per_class: [0.094, 0.035, 0.0, 0.422, 0.087, 0.165, 0.598, 0.244, 0.139, 0.148]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=102297)[0m top1: 0.3260261194029851
[2m[36m(func pid=102297)[0m top5: 0.8773320895522388
[2m[36m(func pid=102297)[0m f1_micro: 0.3260261194029851
[2m[36m(func pid=102297)[0m f1_macro: 0.23453010083195677
[2m[36m(func pid=102297)[0m f1_weighted: 0.33375021266198107
[2m[36m(func pid=102297)[0m f1_per_class: [0.041, 0.315, 0.0, 0.443, 0.094, 0.353, 0.264, 0.457, 0.21, 0.168]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 2.0342 | Steps: 2 | Val loss: 2.0408 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.4802 | Steps: 2 | Val loss: 1.6836 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 1.4547 | Steps: 2 | Val loss: 2.7342 | Batch size: 32 | lr: 0.1 | Duration: 2.78s
[2m[36m(func pid=108657)[0m top1: 0.283115671641791
[2m[36m(func pid=108657)[0m top5: 0.8791977611940298
[2m[36m(func pid=108657)[0m f1_micro: 0.283115671641791
[2m[36m(func pid=108657)[0m f1_macro: 0.2349435850343103
[2m[36m(func pid=108657)[0m f1_weighted: 0.2660742186613336
[2m[36m(func pid=108657)[0m f1_per_class: [0.177, 0.377, 0.439, 0.0, 0.066, 0.088, 0.552, 0.214, 0.109, 0.327]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.1170 | Steps: 2 | Val loss: 2.9801 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
[2m[36m(func pid=101178)[0m top1: 0.4468283582089552
[2m[36m(func pid=101178)[0m top5: 0.9151119402985075
[2m[36m(func pid=101178)[0m f1_micro: 0.4468283582089552
[2m[36m(func pid=101178)[0m f1_macro: 0.37121934094417364
[2m[36m(func pid=101178)[0m f1_weighted: 0.468333703323102
[2m[36m(func pid=101178)[0m f1_per_class: [0.209, 0.569, 0.389, 0.475, 0.079, 0.316, 0.53, 0.402, 0.218, 0.525]
[2m[36m(func pid=101178)[0m 
== Status ==
Current time: 2024-01-07 02:55:54 (running for 00:31:55.14)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.48  |      0.371 |                   71 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.082 |      0.235 |                   68 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.455 |      0.183 |                   65 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  2.034 |      0.235 |                   41 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=103229)[0m top1: 0.3572761194029851
[2m[36m(func pid=103229)[0m top5: 0.8176305970149254
[2m[36m(func pid=103229)[0m f1_micro: 0.35727611940298515
[2m[36m(func pid=103229)[0m f1_macro: 0.1833344473848485
[2m[36m(func pid=103229)[0m f1_weighted: 0.31288880944006553
[2m[36m(func pid=103229)[0m f1_per_class: [0.096, 0.005, 0.143, 0.41, 0.108, 0.021, 0.565, 0.348, 0.06, 0.077]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=102297)[0m top1: 0.30597014925373134
[2m[36m(func pid=102297)[0m top5: 0.8763992537313433
[2m[36m(func pid=102297)[0m f1_micro: 0.30597014925373134
[2m[36m(func pid=102297)[0m f1_macro: 0.2248987663279331
[2m[36m(func pid=102297)[0m f1_weighted: 0.32577273197063494
[2m[36m(func pid=102297)[0m f1_per_class: [0.042, 0.336, 0.0, 0.43, 0.071, 0.246, 0.284, 0.439, 0.182, 0.218]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 1.7499 | Steps: 2 | Val loss: 2.0264 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.5066 | Steps: 2 | Val loss: 1.7048 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=108657)[0m top1: 0.28824626865671643
[2m[36m(func pid=108657)[0m top5: 0.8871268656716418
[2m[36m(func pid=108657)[0m f1_micro: 0.28824626865671643
[2m[36m(func pid=108657)[0m f1_macro: 0.2492652579960383
[2m[36m(func pid=108657)[0m f1_weighted: 0.2707028360111664
[2m[36m(func pid=108657)[0m f1_per_class: [0.206, 0.378, 0.478, 0.0, 0.065, 0.108, 0.546, 0.267, 0.098, 0.345]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 1.5676 | Steps: 2 | Val loss: 2.7269 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.0790 | Steps: 2 | Val loss: 3.1737 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
[2m[36m(func pid=101178)[0m top1: 0.4398320895522388
[2m[36m(func pid=101178)[0m top5: 0.9127798507462687
[2m[36m(func pid=101178)[0m f1_micro: 0.4398320895522388
[2m[36m(func pid=101178)[0m f1_macro: 0.3680842024440538
[2m[36m(func pid=101178)[0m f1_weighted: 0.45473439269287974
[2m[36m(func pid=101178)[0m f1_per_class: [0.204, 0.552, 0.4, 0.474, 0.102, 0.236, 0.513, 0.478, 0.206, 0.517]
[2m[36m(func pid=101178)[0m 
== Status ==
Current time: 2024-01-07 02:55:59 (running for 00:32:00.40)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.507 |      0.368 |                   72 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.079 |      0.219 |                   70 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.455 |      0.183 |                   65 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.75  |      0.249 |                   42 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.27052238805970147
[2m[36m(func pid=102297)[0m top5: 0.8661380597014925
[2m[36m(func pid=102297)[0m f1_micro: 0.27052238805970147
[2m[36m(func pid=102297)[0m f1_macro: 0.2187828858507695
[2m[36m(func pid=102297)[0m f1_weighted: 0.30071342012681984
[2m[36m(func pid=102297)[0m f1_per_class: [0.145, 0.323, 0.143, 0.425, 0.058, 0.082, 0.278, 0.402, 0.14, 0.191]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=103229)[0m top1: 0.3162313432835821
[2m[36m(func pid=103229)[0m top5: 0.8059701492537313
[2m[36m(func pid=103229)[0m f1_micro: 0.3162313432835821
[2m[36m(func pid=103229)[0m f1_macro: 0.22128896610541737
[2m[36m(func pid=103229)[0m f1_weighted: 0.3026210930176238
[2m[36m(func pid=103229)[0m f1_per_class: [0.093, 0.0, 0.359, 0.332, 0.089, 0.124, 0.527, 0.516, 0.095, 0.077]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 1.7076 | Steps: 2 | Val loss: 2.0083 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.5406 | Steps: 2 | Val loss: 1.8256 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=108657)[0m top1: 0.2868470149253731
[2m[36m(func pid=108657)[0m top5: 0.8959888059701493
[2m[36m(func pid=108657)[0m f1_micro: 0.2868470149253731
[2m[36m(func pid=108657)[0m f1_macro: 0.24656876229674757
[2m[36m(func pid=108657)[0m f1_weighted: 0.2731361194269394
[2m[36m(func pid=108657)[0m f1_per_class: [0.226, 0.376, 0.423, 0.0, 0.063, 0.141, 0.536, 0.321, 0.095, 0.286]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.1019 | Steps: 2 | Val loss: 3.2535 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 1.4162 | Steps: 2 | Val loss: 2.7016 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=101178)[0m top1: 0.40531716417910446
[2m[36m(func pid=101178)[0m top5: 0.8936567164179104
[2m[36m(func pid=101178)[0m f1_micro: 0.40531716417910446
[2m[36m(func pid=101178)[0m f1_macro: 0.35799031957750077
[2m[36m(func pid=101178)[0m f1_weighted: 0.42778024251656704
[2m[36m(func pid=101178)[0m f1_per_class: [0.17, 0.565, 0.367, 0.427, 0.102, 0.345, 0.411, 0.532, 0.203, 0.457]
[2m[36m(func pid=101178)[0m 
== Status ==
Current time: 2024-01-07 02:56:04 (running for 00:32:05.60)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.541 |      0.358 |                   73 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.102 |      0.297 |                   71 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.568 |      0.221 |                   66 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.708 |      0.247 |                   43 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.2733208955223881
[2m[36m(func pid=102297)[0m top5: 0.8642723880597015
[2m[36m(func pid=102297)[0m f1_micro: 0.2733208955223881
[2m[36m(func pid=102297)[0m f1_macro: 0.2965751329201981
[2m[36m(func pid=102297)[0m f1_weighted: 0.3122013632897632
[2m[36m(func pid=102297)[0m f1_per_class: [0.215, 0.34, 0.87, 0.406, 0.059, 0.065, 0.316, 0.374, 0.154, 0.167]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=103229)[0m top1: 0.25513059701492535
[2m[36m(func pid=103229)[0m top5: 0.8260261194029851
[2m[36m(func pid=103229)[0m f1_micro: 0.25513059701492535
[2m[36m(func pid=103229)[0m f1_macro: 0.23632057724585706
[2m[36m(func pid=103229)[0m f1_weighted: 0.27191016537723023
[2m[36m(func pid=103229)[0m f1_per_class: [0.095, 0.0, 0.429, 0.289, 0.079, 0.289, 0.393, 0.53, 0.112, 0.148]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 1.7391 | Steps: 2 | Val loss: 1.9883 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.3981 | Steps: 2 | Val loss: 1.8251 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.0584 | Steps: 2 | Val loss: 3.2705 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=108657)[0m top1: 0.29151119402985076
[2m[36m(func pid=108657)[0m top5: 0.9039179104477612
[2m[36m(func pid=108657)[0m f1_micro: 0.29151119402985076
[2m[36m(func pid=108657)[0m f1_macro: 0.2627255425174121
[2m[36m(func pid=108657)[0m f1_weighted: 0.2797923708333231
[2m[36m(func pid=108657)[0m f1_per_class: [0.265, 0.369, 0.415, 0.003, 0.059, 0.136, 0.533, 0.442, 0.116, 0.29]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 1.5420 | Steps: 2 | Val loss: 2.7098 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=101178)[0m top1: 0.4314365671641791
[2m[36m(func pid=101178)[0m top5: 0.8899253731343284
[2m[36m(func pid=101178)[0m f1_micro: 0.4314365671641791
[2m[36m(func pid=101178)[0m f1_macro: 0.36731735417723604
[2m[36m(func pid=101178)[0m f1_weighted: 0.45826883326562334
[2m[36m(func pid=101178)[0m f1_per_class: [0.182, 0.588, 0.313, 0.457, 0.101, 0.366, 0.466, 0.536, 0.173, 0.492]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=102297)[0m top1: 0.2789179104477612
[2m[36m(func pid=102297)[0m top5: 0.8824626865671642
[2m[36m(func pid=102297)[0m f1_micro: 0.2789179104477612
[2m[36m(func pid=102297)[0m f1_macro: 0.3214399488570646
[2m[36m(func pid=102297)[0m f1_weighted: 0.3208011721945727
[2m[36m(func pid=102297)[0m f1_per_class: [0.239, 0.36, 0.923, 0.309, 0.062, 0.177, 0.371, 0.404, 0.148, 0.222]
== Status ==
Current time: 2024-01-07 02:56:10 (running for 00:32:10.86)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.32
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.398 |      0.367 |                   74 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.058 |      0.321 |                   72 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.416 |      0.236 |                   67 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.739 |      0.263 |                   44 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=103229)[0m top1: 0.24300373134328357
[2m[36m(func pid=103229)[0m top5: 0.8563432835820896
[2m[36m(func pid=103229)[0m f1_micro: 0.24300373134328357
[2m[36m(func pid=103229)[0m f1_macro: 0.23564592561649578
[2m[36m(func pid=103229)[0m f1_weighted: 0.2667558777587312
[2m[36m(func pid=103229)[0m f1_per_class: [0.088, 0.005, 0.4, 0.286, 0.075, 0.314, 0.362, 0.525, 0.163, 0.138]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 1.6223 | Steps: 2 | Val loss: 1.9767 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.5546 | Steps: 2 | Val loss: 1.9253 | Batch size: 32 | lr: 0.001 | Duration: 3.12s
[2m[36m(func pid=108657)[0m top1: 0.2873134328358209
[2m[36m(func pid=108657)[0m top5: 0.9053171641791045
[2m[36m(func pid=108657)[0m f1_micro: 0.2873134328358209
[2m[36m(func pid=108657)[0m f1_macro: 0.2629353082759306
[2m[36m(func pid=108657)[0m f1_weighted: 0.27977481310772784
[2m[36m(func pid=108657)[0m f1_per_class: [0.265, 0.359, 0.373, 0.007, 0.057, 0.189, 0.513, 0.449, 0.128, 0.29]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.0192 | Steps: 2 | Val loss: 3.3916 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 1.2974 | Steps: 2 | Val loss: 2.5286 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=101178)[0m top1: 0.394589552238806
[2m[36m(func pid=101178)[0m top5: 0.8782649253731343
[2m[36m(func pid=101178)[0m f1_micro: 0.394589552238806
[2m[36m(func pid=101178)[0m f1_macro: 0.3450735913221817
[2m[36m(func pid=101178)[0m f1_weighted: 0.42536226405978766
[2m[36m(func pid=101178)[0m f1_per_class: [0.181, 0.576, 0.286, 0.448, 0.081, 0.335, 0.39, 0.507, 0.182, 0.466]
[2m[36m(func pid=101178)[0m 
== Status ==
Current time: 2024-01-07 02:56:15 (running for 00:32:16.35)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.32525000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.555 |      0.345 |                   75 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.058 |      0.321 |                   72 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.297 |      0.287 |                   69 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.622 |      0.263 |                   45 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.261660447761194
[2m[36m(func pid=102297)[0m top5: 0.8908582089552238
[2m[36m(func pid=102297)[0m f1_micro: 0.261660447761194
[2m[36m(func pid=102297)[0m f1_macro: 0.3103804401888719
[2m[36m(func pid=102297)[0m f1_weighted: 0.2977722256529734
[2m[36m(func pid=102297)[0m f1_per_class: [0.235, 0.351, 0.889, 0.259, 0.063, 0.216, 0.334, 0.401, 0.133, 0.222]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=103229)[0m top1: 0.32649253731343286
[2m[36m(func pid=103229)[0m top5: 0.871268656716418
[2m[36m(func pid=103229)[0m f1_micro: 0.32649253731343286
[2m[36m(func pid=103229)[0m f1_macro: 0.286817859183663
[2m[36m(func pid=103229)[0m f1_weighted: 0.36642604021465075
[2m[36m(func pid=103229)[0m f1_per_class: [0.089, 0.226, 0.4, 0.322, 0.12, 0.333, 0.538, 0.462, 0.135, 0.242]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 1.6397 | Steps: 2 | Val loss: 1.9614 | Batch size: 32 | lr: 0.0001 | Duration: 3.07s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 75] | Train loss: 0.5863 | Steps: 2 | Val loss: 1.9337 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.0279 | Steps: 2 | Val loss: 3.4475 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 1.6183 | Steps: 2 | Val loss: 2.4641 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
[2m[36m(func pid=108657)[0m top1: 0.291044776119403
[2m[36m(func pid=108657)[0m top5: 0.9104477611940298
[2m[36m(func pid=108657)[0m f1_micro: 0.291044776119403
[2m[36m(func pid=108657)[0m f1_macro: 0.27168802321079943
[2m[36m(func pid=108657)[0m f1_weighted: 0.28763477603905635
[2m[36m(func pid=108657)[0m f1_per_class: [0.273, 0.353, 0.333, 0.023, 0.056, 0.208, 0.507, 0.513, 0.127, 0.324]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=101178)[0m top1: 0.3843283582089552
[2m[36m(func pid=101178)[0m top5: 0.8824626865671642
[2m[36m(func pid=101178)[0m f1_micro: 0.3843283582089552
[2m[36m(func pid=101178)[0m f1_macro: 0.3362752379776192
[2m[36m(func pid=101178)[0m f1_weighted: 0.41306866101365874
[2m[36m(func pid=101178)[0m f1_per_class: [0.191, 0.546, 0.272, 0.464, 0.074, 0.34, 0.355, 0.483, 0.168, 0.471]
[2m[36m(func pid=101178)[0m 
== Status ==
Current time: 2024-01-07 02:56:20 (running for 00:32:21.68)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.32525000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.586 |      0.336 |                   76 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.028 |      0.314 |                   74 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.297 |      0.287 |                   69 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.64  |      0.272 |                   46 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.26072761194029853
[2m[36m(func pid=102297)[0m top5: 0.8917910447761194
[2m[36m(func pid=102297)[0m f1_micro: 0.26072761194029853
[2m[36m(func pid=102297)[0m f1_macro: 0.3139670442610523
[2m[36m(func pid=102297)[0m f1_weighted: 0.2948422005200656
[2m[36m(func pid=102297)[0m f1_per_class: [0.242, 0.374, 0.889, 0.215, 0.055, 0.266, 0.331, 0.414, 0.124, 0.23]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=103229)[0m top1: 0.36473880597014924
[2m[36m(func pid=103229)[0m top5: 0.8675373134328358
[2m[36m(func pid=103229)[0m f1_micro: 0.36473880597014924
[2m[36m(func pid=103229)[0m f1_macro: 0.29647361255776417
[2m[36m(func pid=103229)[0m f1_weighted: 0.39274765402506323
[2m[36m(func pid=103229)[0m f1_per_class: [0.09, 0.197, 0.4, 0.394, 0.16, 0.308, 0.592, 0.386, 0.213, 0.226]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 1.5495 | Steps: 2 | Val loss: 1.9545 | Batch size: 32 | lr: 0.0001 | Duration: 3.09s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 76] | Train loss: 0.3490 | Steps: 2 | Val loss: 1.8624 | Batch size: 32 | lr: 0.001 | Duration: 3.04s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.0664 | Steps: 2 | Val loss: 3.2214 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 1.3803 | Steps: 2 | Val loss: 2.4494 | Batch size: 32 | lr: 0.1 | Duration: 2.99s
[2m[36m(func pid=108657)[0m top1: 0.2989738805970149
[2m[36m(func pid=108657)[0m top5: 0.9146455223880597
[2m[36m(func pid=108657)[0m f1_micro: 0.2989738805970149
[2m[36m(func pid=108657)[0m f1_macro: 0.28194814442042665
[2m[36m(func pid=108657)[0m f1_weighted: 0.3019927217553325
[2m[36m(func pid=108657)[0m f1_per_class: [0.272, 0.365, 0.31, 0.057, 0.057, 0.247, 0.5, 0.515, 0.132, 0.366]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=101178)[0m top1: 0.40345149253731344
[2m[36m(func pid=101178)[0m top5: 0.8917910447761194
[2m[36m(func pid=101178)[0m f1_micro: 0.40345149253731344
[2m[36m(func pid=101178)[0m f1_macro: 0.36334141586361335
[2m[36m(func pid=101178)[0m f1_weighted: 0.4288151647854495
[2m[36m(func pid=101178)[0m f1_per_class: [0.198, 0.56, 0.361, 0.482, 0.087, 0.344, 0.362, 0.557, 0.176, 0.507]
[2m[36m(func pid=101178)[0m 
== Status ==
Current time: 2024-01-07 02:56:26 (running for 00:32:27.06)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.3315
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.349 |      0.363 |                   77 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.066 |      0.336 |                   75 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.618 |      0.296 |                   70 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.55  |      0.282 |                   47 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.2905783582089552
[2m[36m(func pid=102297)[0m top5: 0.8973880597014925
[2m[36m(func pid=102297)[0m f1_micro: 0.2905783582089552
[2m[36m(func pid=102297)[0m f1_macro: 0.3355341656794609
[2m[36m(func pid=102297)[0m f1_weighted: 0.3208390654009694
[2m[36m(func pid=102297)[0m f1_per_class: [0.261, 0.413, 0.889, 0.243, 0.061, 0.325, 0.339, 0.44, 0.121, 0.264]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=103229)[0m top1: 0.34794776119402987
[2m[36m(func pid=103229)[0m top5: 0.8596082089552238
[2m[36m(func pid=103229)[0m f1_micro: 0.34794776119402987
[2m[36m(func pid=103229)[0m f1_macro: 0.2684104378965272
[2m[36m(func pid=103229)[0m f1_weighted: 0.37133822901343205
[2m[36m(func pid=103229)[0m f1_per_class: [0.067, 0.187, 0.41, 0.504, 0.167, 0.249, 0.479, 0.271, 0.115, 0.235]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 1.5555 | Steps: 2 | Val loss: 1.9528 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 77] | Train loss: 0.5573 | Steps: 2 | Val loss: 1.8640 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 75] | Train loss: 0.0252 | Steps: 2 | Val loss: 3.0577 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=108657)[0m top1: 0.30363805970149255
[2m[36m(func pid=108657)[0m top5: 0.9202425373134329
[2m[36m(func pid=108657)[0m f1_micro: 0.30363805970149255
[2m[36m(func pid=108657)[0m f1_macro: 0.28308596608819925
[2m[36m(func pid=108657)[0m f1_weighted: 0.31273851841441136
[2m[36m(func pid=108657)[0m f1_per_class: [0.282, 0.377, 0.286, 0.106, 0.059, 0.258, 0.48, 0.51, 0.127, 0.347]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 1.6311 | Steps: 2 | Val loss: 2.1913 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
[2m[36m(func pid=101178)[0m top1: 0.4099813432835821
[2m[36m(func pid=101178)[0m top5: 0.8875932835820896
[2m[36m(func pid=101178)[0m f1_micro: 0.4099813432835821
[2m[36m(func pid=101178)[0m f1_macro: 0.35696632992413074
[2m[36m(func pid=101178)[0m f1_weighted: 0.4336593185096234
[2m[36m(func pid=101178)[0m f1_per_class: [0.208, 0.575, 0.344, 0.493, 0.077, 0.337, 0.372, 0.514, 0.18, 0.471]
[2m[36m(func pid=101178)[0m 
== Status ==
Current time: 2024-01-07 02:56:31 (running for 00:32:32.50)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.3315
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.557 |      0.357 |                   78 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.025 |      0.355 |                   76 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.38  |      0.268 |                   71 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.555 |      0.283 |                   48 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.3260261194029851
[2m[36m(func pid=102297)[0m top5: 0.8964552238805971
[2m[36m(func pid=102297)[0m f1_micro: 0.3260261194029851
[2m[36m(func pid=102297)[0m f1_macro: 0.35477241311156804
[2m[36m(func pid=102297)[0m f1_weighted: 0.35297148518877786
[2m[36m(func pid=102297)[0m f1_per_class: [0.25, 0.425, 0.889, 0.3, 0.063, 0.364, 0.368, 0.444, 0.142, 0.302]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=103229)[0m top1: 0.38619402985074625
[2m[36m(func pid=103229)[0m top5: 0.8782649253731343
[2m[36m(func pid=103229)[0m f1_micro: 0.3861940298507463
[2m[36m(func pid=103229)[0m f1_macro: 0.29607782549285633
[2m[36m(func pid=103229)[0m f1_weighted: 0.38335502373480057
[2m[36m(func pid=103229)[0m f1_per_class: [0.0, 0.238, 0.41, 0.549, 0.214, 0.305, 0.383, 0.491, 0.154, 0.215]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 1.6143 | Steps: 2 | Val loss: 1.9600 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 78] | Train loss: 0.4278 | Steps: 2 | Val loss: 1.9010 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=108657)[0m top1: 0.30550373134328357
[2m[36m(func pid=108657)[0m top5: 0.9230410447761194
[2m[36m(func pid=108657)[0m f1_micro: 0.30550373134328357
[2m[36m(func pid=108657)[0m f1_macro: 0.28163675357954754
[2m[36m(func pid=108657)[0m f1_weighted: 0.32145541082544327
[2m[36m(func pid=108657)[0m f1_per_class: [0.254, 0.384, 0.237, 0.151, 0.055, 0.27, 0.458, 0.518, 0.153, 0.338]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 76] | Train loss: 0.0180 | Steps: 2 | Val loss: 2.9783 | Batch size: 32 | lr: 0.01 | Duration: 3.07s
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 1.3980 | Steps: 2 | Val loss: 2.1997 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=101178)[0m top1: 0.40531716417910446
[2m[36m(func pid=101178)[0m top5: 0.8759328358208955
[2m[36m(func pid=101178)[0m f1_micro: 0.40531716417910446
[2m[36m(func pid=101178)[0m f1_macro: 0.3492285199504583
[2m[36m(func pid=101178)[0m f1_weighted: 0.4223265954479612
[2m[36m(func pid=101178)[0m f1_per_class: [0.226, 0.591, 0.344, 0.474, 0.073, 0.343, 0.343, 0.488, 0.212, 0.4]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=102297)[0m top1: 0.3493470149253731
[2m[36m(func pid=102297)[0m top5: 0.8955223880597015
[2m[36m(func pid=102297)[0m f1_micro: 0.3493470149253731
[2m[36m(func pid=102297)[0m f1_macro: 0.36386111139657773
[2m[36m(func pid=102297)[0m f1_weighted: 0.37016723202491264
[2m[36m(func pid=102297)[0m f1_per_class: [0.275, 0.435, 0.889, 0.327, 0.074, 0.421, 0.378, 0.4, 0.168, 0.273]
[2m[36m(func pid=102297)[0m 
== Status ==
Current time: 2024-01-07 02:56:37 (running for 00:32:38.10)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.3315
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.428 |      0.349 |                   79 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.018 |      0.364 |                   77 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.631 |      0.296 |                   72 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.614 |      0.282 |                   49 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=103229)[0m top1: 0.3694029850746269
[2m[36m(func pid=103229)[0m top5: 0.8903917910447762
[2m[36m(func pid=103229)[0m f1_micro: 0.3694029850746269
[2m[36m(func pid=103229)[0m f1_macro: 0.2940523559168081
[2m[36m(func pid=103229)[0m f1_weighted: 0.3782599922848759
[2m[36m(func pid=103229)[0m f1_per_class: [0.026, 0.223, 0.41, 0.546, 0.074, 0.329, 0.358, 0.52, 0.196, 0.257]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 1.6320 | Steps: 2 | Val loss: 1.9463 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 79] | Train loss: 0.3232 | Steps: 2 | Val loss: 1.8797 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=108657)[0m top1: 0.3069029850746269
[2m[36m(func pid=108657)[0m top5: 0.9216417910447762
[2m[36m(func pid=108657)[0m f1_micro: 0.3069029850746269
[2m[36m(func pid=108657)[0m f1_macro: 0.2834976553770662
[2m[36m(func pid=108657)[0m f1_weighted: 0.3301289065792598
[2m[36m(func pid=108657)[0m f1_per_class: [0.26, 0.384, 0.232, 0.216, 0.054, 0.282, 0.423, 0.507, 0.155, 0.322]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 77] | Train loss: 0.0327 | Steps: 2 | Val loss: 2.9155 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 1.1948 | Steps: 2 | Val loss: 2.2708 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
[2m[36m(func pid=101178)[0m top1: 0.41138059701492535
[2m[36m(func pid=101178)[0m top5: 0.8796641791044776
[2m[36m(func pid=101178)[0m f1_micro: 0.41138059701492535
[2m[36m(func pid=101178)[0m f1_macro: 0.3578089841191316
[2m[36m(func pid=101178)[0m f1_weighted: 0.4234584008452896
[2m[36m(func pid=101178)[0m f1_per_class: [0.238, 0.606, 0.328, 0.462, 0.088, 0.347, 0.335, 0.547, 0.212, 0.416]
[2m[36m(func pid=101178)[0m 
== Status ==
Current time: 2024-01-07 02:56:42 (running for 00:32:43.41)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.3315
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.323 |      0.358 |                   80 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.033 |      0.352 |                   78 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.398 |      0.294 |                   73 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.632 |      0.283 |                   50 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.3512126865671642
[2m[36m(func pid=102297)[0m top5: 0.8950559701492538
[2m[36m(func pid=102297)[0m f1_micro: 0.3512126865671642
[2m[36m(func pid=102297)[0m f1_macro: 0.35182223153650927
[2m[36m(func pid=102297)[0m f1_weighted: 0.3744494847139383
[2m[36m(func pid=102297)[0m f1_per_class: [0.282, 0.437, 0.774, 0.343, 0.069, 0.413, 0.384, 0.381, 0.174, 0.26]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 1.5168 | Steps: 2 | Val loss: 1.9392 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=103229)[0m top1: 0.33488805970149255
[2m[36m(func pid=103229)[0m top5: 0.8819962686567164
[2m[36m(func pid=103229)[0m f1_micro: 0.33488805970149255
[2m[36m(func pid=103229)[0m f1_macro: 0.2761427559548754
[2m[36m(func pid=103229)[0m f1_weighted: 0.36668384818590166
[2m[36m(func pid=103229)[0m f1_per_class: [0.09, 0.209, 0.41, 0.516, 0.052, 0.28, 0.407, 0.352, 0.15, 0.295]
[2m[36m(func pid=103229)[0m 
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 80] | Train loss: 0.5121 | Steps: 2 | Val loss: 1.9071 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=108657)[0m top1: 0.30830223880597013
[2m[36m(func pid=108657)[0m top5: 0.9221082089552238
[2m[36m(func pid=108657)[0m f1_micro: 0.30830223880597013
[2m[36m(func pid=108657)[0m f1_macro: 0.2819853728670427
[2m[36m(func pid=108657)[0m f1_weighted: 0.332497083970715
[2m[36m(func pid=108657)[0m f1_per_class: [0.224, 0.386, 0.229, 0.273, 0.057, 0.282, 0.38, 0.496, 0.171, 0.323]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 78] | Train loss: 0.0126 | Steps: 2 | Val loss: 2.8909 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=103229)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 1.3396 | Steps: 2 | Val loss: 2.1044 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=101178)[0m top1: 0.4001865671641791
[2m[36m(func pid=101178)[0m top5: 0.8810634328358209
[2m[36m(func pid=101178)[0m f1_micro: 0.4001865671641791
[2m[36m(func pid=101178)[0m f1_macro: 0.33835312256246153
[2m[36m(func pid=101178)[0m f1_weighted: 0.4125370359515241
[2m[36m(func pid=101178)[0m f1_per_class: [0.261, 0.602, 0.272, 0.468, 0.078, 0.336, 0.334, 0.342, 0.238, 0.453]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=102297)[0m top1: 0.355410447761194
[2m[36m(func pid=102297)[0m top5: 0.8941231343283582
[2m[36m(func pid=102297)[0m f1_micro: 0.355410447761194
[2m[36m(func pid=102297)[0m f1_macro: 0.34384823959045974
[2m[36m(func pid=102297)[0m f1_weighted: 0.38343123628656367
[2m[36m(func pid=102297)[0m f1_per_class: [0.293, 0.442, 0.686, 0.387, 0.063, 0.374, 0.388, 0.372, 0.18, 0.255]
[2m[36m(func pid=102297)[0m 
== Status ==
Current time: 2024-01-07 02:56:47 (running for 00:32:48.67)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: 0.3315
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.512 |      0.338 |                   81 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.344 |                   79 |
| train_6ed81_00015 | RUNNING    | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.195 |      0.276 |                   74 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.517 |      0.282 |                   51 |
| train_6ed81_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=103229)[0m top1: 0.3670708955223881
[2m[36m(func pid=103229)[0m top5: 0.8978544776119403
[2m[36m(func pid=103229)[0m f1_micro: 0.3670708955223881
[2m[36m(func pid=103229)[0m f1_macro: 0.29942888994976624
[2m[36m(func pid=103229)[0m f1_weighted: 0.41465452303723555
[2m[36m(func pid=103229)[0m f1_per_class: [0.088, 0.359, 0.4, 0.454, 0.051, 0.334, 0.504, 0.462, 0.12, 0.222]
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 1.5712 | Steps: 2 | Val loss: 1.9379 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 81] | Train loss: 0.2712 | Steps: 2 | Val loss: 1.8681 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
[2m[36m(func pid=108657)[0m top1: 0.30736940298507465
[2m[36m(func pid=108657)[0m top5: 0.9193097014925373
[2m[36m(func pid=108657)[0m f1_micro: 0.30736940298507465
[2m[36m(func pid=108657)[0m f1_macro: 0.2738879355460858
[2m[36m(func pid=108657)[0m f1_weighted: 0.329945409587012
[2m[36m(func pid=108657)[0m f1_per_class: [0.218, 0.38, 0.212, 0.328, 0.059, 0.294, 0.324, 0.479, 0.179, 0.265]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 79] | Train loss: 0.0174 | Steps: 2 | Val loss: 2.9171 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=101178)[0m top1: 0.40531716417910446
[2m[36m(func pid=101178)[0m top5: 0.8917910447761194
[2m[36m(func pid=101178)[0m f1_micro: 0.40531716417910446
[2m[36m(func pid=101178)[0m f1_macro: 0.33611307707511723
[2m[36m(func pid=101178)[0m f1_weighted: 0.4269884700357016
[2m[36m(func pid=101178)[0m f1_per_class: [0.239, 0.583, 0.242, 0.485, 0.09, 0.349, 0.375, 0.353, 0.219, 0.427]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=102297)[0m top1: 0.34701492537313433
[2m[36m(func pid=102297)[0m top5: 0.8936567164179104
[2m[36m(func pid=102297)[0m f1_micro: 0.34701492537313433
[2m[36m(func pid=102297)[0m f1_macro: 0.32933465210495094
[2m[36m(func pid=102297)[0m f1_weighted: 0.38270119977627337
[2m[36m(func pid=102297)[0m f1_per_class: [0.26, 0.423, 0.632, 0.4, 0.062, 0.353, 0.399, 0.356, 0.185, 0.224]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 1.4010 | Steps: 2 | Val loss: 1.9300 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 82] | Train loss: 0.3497 | Steps: 2 | Val loss: 1.9009 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=108657)[0m top1: 0.30923507462686567
[2m[36m(func pid=108657)[0m top5: 0.9188432835820896
[2m[36m(func pid=108657)[0m f1_micro: 0.30923507462686567
[2m[36m(func pid=108657)[0m f1_macro: 0.2703944095206612
[2m[36m(func pid=108657)[0m f1_weighted: 0.3290310837530776
[2m[36m(func pid=108657)[0m f1_per_class: [0.213, 0.383, 0.214, 0.37, 0.061, 0.294, 0.284, 0.465, 0.17, 0.25]
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 80] | Train loss: 0.0108 | Steps: 2 | Val loss: 3.0634 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 02:56:53 (running for 00:32:54.05)
Memory usage on this node: 22.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: 0.32925000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.271 |      0.336 |                   82 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.017 |      0.329 |                   80 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.571 |      0.274 |                   52 |
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=120129)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=120129)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=120129)[0m Configuration completed!
[2m[36m(func pid=120129)[0m New optimizer parameters:
[2m[36m(func pid=120129)[0m SGD (
[2m[36m(func pid=120129)[0m Parameter Group 0
[2m[36m(func pid=120129)[0m     dampening: 0
[2m[36m(func pid=120129)[0m     differentiable: False
[2m[36m(func pid=120129)[0m     foreach: None
[2m[36m(func pid=120129)[0m     lr: 0.001
[2m[36m(func pid=120129)[0m     maximize: False
[2m[36m(func pid=120129)[0m     momentum: 0.99
[2m[36m(func pid=120129)[0m     nesterov: False
[2m[36m(func pid=120129)[0m     weight_decay: 1e-05
[2m[36m(func pid=120129)[0m )
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=101178)[0m top1: 0.38152985074626866
[2m[36m(func pid=101178)[0m top5: 0.8931902985074627
[2m[36m(func pid=101178)[0m f1_micro: 0.3815298507462687
[2m[36m(func pid=101178)[0m f1_macro: 0.3310180582770915
[2m[36m(func pid=101178)[0m f1_weighted: 0.41309686196819123
[2m[36m(func pid=101178)[0m f1_per_class: [0.168, 0.519, 0.241, 0.472, 0.108, 0.358, 0.353, 0.495, 0.209, 0.386]
[2m[36m(func pid=101178)[0m 
== Status ==
Current time: 2024-01-07 02:56:58 (running for 00:32:59.32)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: 0.32925000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.35  |      0.331 |                   83 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.011 |      0.311 |                   81 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.401 |      0.27  |                   53 |
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.32276119402985076
[2m[36m(func pid=102297)[0m top5: 0.8913246268656716
[2m[36m(func pid=102297)[0m f1_micro: 0.32276119402985076
[2m[36m(func pid=102297)[0m f1_macro: 0.3105947699186099
[2m[36m(func pid=102297)[0m f1_weighted: 0.3655200913712338
[2m[36m(func pid=102297)[0m f1_per_class: [0.263, 0.31, 0.585, 0.418, 0.059, 0.329, 0.4, 0.37, 0.174, 0.199]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 1.4870 | Steps: 2 | Val loss: 1.9117 | Batch size: 32 | lr: 0.0001 | Duration: 3.03s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 83] | Train loss: 0.2425 | Steps: 2 | Val loss: 1.8704 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 3.1020 | Steps: 2 | Val loss: 2.3729 | Batch size: 32 | lr: 0.001 | Duration: 4.53s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 81] | Train loss: 0.0039 | Steps: 2 | Val loss: 3.1956 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=108657)[0m top1: 0.3041044776119403
[2m[36m(func pid=108657)[0m top5: 0.9090485074626866
[2m[36m(func pid=108657)[0m f1_micro: 0.3041044776119403
[2m[36m(func pid=108657)[0m f1_macro: 0.26073795526782123
[2m[36m(func pid=108657)[0m f1_weighted: 0.31556346467204305
[2m[36m(func pid=108657)[0m f1_per_class: [0.21, 0.367, 0.224, 0.422, 0.062, 0.296, 0.209, 0.424, 0.158, 0.234]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=101178)[0m top1: 0.3885261194029851
[2m[36m(func pid=101178)[0m top5: 0.8997201492537313
[2m[36m(func pid=101178)[0m f1_micro: 0.3885261194029851
[2m[36m(func pid=101178)[0m f1_macro: 0.33399740108518217
[2m[36m(func pid=101178)[0m f1_weighted: 0.4229854204021903
[2m[36m(func pid=101178)[0m f1_per_class: [0.157, 0.501, 0.23, 0.471, 0.115, 0.367, 0.387, 0.55, 0.202, 0.361]
[2m[36m(func pid=101178)[0m 
== Status ==
Current time: 2024-01-07 02:57:03 (running for 00:33:04.37)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: 0.32925000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.242 |      0.334 |                   84 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.011 |      0.311 |                   81 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.487 |      0.261 |                   54 |
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  3.102 |      0.021 |                    1 |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.07182835820895522
[2m[36m(func pid=120129)[0m top5: 0.310634328358209
[2m[36m(func pid=120129)[0m f1_micro: 0.07182835820895522
[2m[36m(func pid=120129)[0m f1_macro: 0.0208705613932578
[2m[36m(func pid=120129)[0m f1_weighted: 0.029648008493330307
[2m[36m(func pid=120129)[0m f1_per_class: [0.0, 0.005, 0.0, 0.077, 0.0, 0.0, 0.0, 0.127, 0.0, 0.0]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=102297)[0m top1: 0.30223880597014924
[2m[36m(func pid=102297)[0m top5: 0.8899253731343284
[2m[36m(func pid=102297)[0m f1_micro: 0.30223880597014924
[2m[36m(func pid=102297)[0m f1_macro: 0.2997256778190476
[2m[36m(func pid=102297)[0m f1_weighted: 0.34403721311416907
[2m[36m(func pid=102297)[0m f1_per_class: [0.26, 0.207, 0.6, 0.404, 0.052, 0.315, 0.404, 0.377, 0.174, 0.204]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 84] | Train loss: 0.3067 | Steps: 2 | Val loss: 1.7925 | Batch size: 32 | lr: 0.001 | Duration: 2.78s
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 1.5453 | Steps: 2 | Val loss: 1.9064 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 2.9162 | Steps: 2 | Val loss: 2.3364 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 82] | Train loss: 0.0060 | Steps: 2 | Val loss: 3.3028 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
[2m[36m(func pid=108657)[0m top1: 0.30223880597014924
[2m[36m(func pid=108657)[0m top5: 0.9011194029850746
[2m[36m(func pid=108657)[0m f1_micro: 0.30223880597014924
[2m[36m(func pid=108657)[0m f1_macro: 0.2526615952674155
[2m[36m(func pid=108657)[0m f1_weighted: 0.3064831820548921
[2m[36m(func pid=108657)[0m f1_per_class: [0.198, 0.351, 0.22, 0.461, 0.062, 0.289, 0.157, 0.419, 0.157, 0.213]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=101178)[0m top1: 0.41511194029850745
[2m[36m(func pid=101178)[0m top5: 0.9081156716417911
[2m[36m(func pid=101178)[0m f1_micro: 0.4151119402985075
[2m[36m(func pid=101178)[0m f1_macro: 0.34544731815479707
[2m[36m(func pid=101178)[0m f1_weighted: 0.44317254808879675
[2m[36m(func pid=101178)[0m f1_per_class: [0.181, 0.502, 0.224, 0.497, 0.128, 0.383, 0.421, 0.556, 0.19, 0.37]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=120129)[0m top1: 0.0708955223880597
[2m[36m(func pid=120129)[0m top5: 0.4878731343283582
[2m[36m(func pid=120129)[0m f1_micro: 0.0708955223880597
[2m[36m(func pid=120129)[0m f1_macro: 0.042531087312394036
[2m[36m(func pid=120129)[0m f1_weighted: 0.060663004205208905
[2m[36m(func pid=120129)[0m f1_per_class: [0.0, 0.0, 0.02, 0.168, 0.0, 0.0, 0.0, 0.237, 0.0, 0.0]
[2m[36m(func pid=120129)[0m 
== Status ==
Current time: 2024-01-07 02:57:08 (running for 00:33:09.53)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: 0.32925000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.307 |      0.345 |                   85 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.004 |      0.3   |                   82 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.545 |      0.253 |                   55 |
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  2.916 |      0.043 |                    2 |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.29524253731343286
[2m[36m(func pid=102297)[0m top5: 0.8880597014925373
[2m[36m(func pid=102297)[0m f1_micro: 0.29524253731343286
[2m[36m(func pid=102297)[0m f1_macro: 0.296232977000399
[2m[36m(func pid=102297)[0m f1_weighted: 0.3370042622355751
[2m[36m(func pid=102297)[0m f1_per_class: [0.25, 0.162, 0.585, 0.403, 0.048, 0.293, 0.408, 0.402, 0.21, 0.201]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 1.4097 | Steps: 2 | Val loss: 1.8994 | Batch size: 32 | lr: 0.0001 | Duration: 3.11s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 85] | Train loss: 0.2429 | Steps: 2 | Val loss: 1.7784 | Batch size: 32 | lr: 0.001 | Duration: 3.10s
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 2.6954 | Steps: 2 | Val loss: 2.3291 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 83] | Train loss: 0.0174 | Steps: 2 | Val loss: 3.3875 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=108657)[0m top1: 0.3041044776119403
[2m[36m(func pid=108657)[0m top5: 0.8992537313432836
[2m[36m(func pid=108657)[0m f1_micro: 0.3041044776119403
[2m[36m(func pid=108657)[0m f1_macro: 0.2485973025266429
[2m[36m(func pid=108657)[0m f1_weighted: 0.29705683656819837
[2m[36m(func pid=108657)[0m f1_per_class: [0.22, 0.348, 0.22, 0.486, 0.065, 0.283, 0.106, 0.418, 0.161, 0.18]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=101178)[0m top1: 0.4123134328358209
[2m[36m(func pid=101178)[0m top5: 0.9071828358208955
[2m[36m(func pid=101178)[0m f1_micro: 0.4123134328358209
[2m[36m(func pid=101178)[0m f1_macro: 0.3383083993472649
[2m[36m(func pid=101178)[0m f1_weighted: 0.43170748729066777
[2m[36m(func pid=101178)[0m f1_per_class: [0.202, 0.495, 0.229, 0.51, 0.136, 0.361, 0.397, 0.48, 0.173, 0.4]
[2m[36m(func pid=101178)[0m 
== Status ==
Current time: 2024-01-07 02:57:13 (running for 00:33:14.66)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: 0.32925000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.243 |      0.338 |                   86 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.006 |      0.296 |                   83 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.41  |      0.249 |                   56 |
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  2.695 |      0.004 |                    3 |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.010261194029850746
[2m[36m(func pid=120129)[0m top5: 0.5657649253731343
[2m[36m(func pid=120129)[0m f1_micro: 0.010261194029850746
[2m[36m(func pid=120129)[0m f1_macro: 0.004041814420803783
[2m[36m(func pid=120129)[0m f1_weighted: 0.007919104885589782
[2m[36m(func pid=120129)[0m f1_per_class: [0.0, 0.0, 0.012, 0.028, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=102297)[0m top1: 0.2826492537313433
[2m[36m(func pid=102297)[0m top5: 0.8768656716417911
[2m[36m(func pid=102297)[0m f1_micro: 0.2826492537313433
[2m[36m(func pid=102297)[0m f1_macro: 0.2914398432351022
[2m[36m(func pid=102297)[0m f1_weighted: 0.3223071577194473
[2m[36m(func pid=102297)[0m f1_per_class: [0.247, 0.13, 0.585, 0.392, 0.047, 0.296, 0.381, 0.445, 0.188, 0.203]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 1.7974 | Steps: 2 | Val loss: 1.9023 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 86] | Train loss: 0.2255 | Steps: 2 | Val loss: 1.8102 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 2.6158 | Steps: 2 | Val loss: 2.3278 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 84] | Train loss: 0.0077 | Steps: 2 | Val loss: 3.4046 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=108657)[0m top1: 0.30363805970149255
[2m[36m(func pid=108657)[0m top5: 0.8927238805970149
[2m[36m(func pid=108657)[0m f1_micro: 0.30363805970149255
[2m[36m(func pid=108657)[0m f1_macro: 0.24036627633388585
[2m[36m(func pid=108657)[0m f1_weighted: 0.2870731367330344
[2m[36m(func pid=108657)[0m f1_per_class: [0.203, 0.335, 0.231, 0.503, 0.067, 0.277, 0.07, 0.423, 0.118, 0.176]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=101178)[0m top1: 0.40111940298507465
[2m[36m(func pid=101178)[0m top5: 0.9071828358208955
[2m[36m(func pid=101178)[0m f1_micro: 0.40111940298507465
[2m[36m(func pid=101178)[0m f1_macro: 0.33171837809601945
[2m[36m(func pid=101178)[0m f1_weighted: 0.4178363254437267
[2m[36m(func pid=101178)[0m f1_per_class: [0.199, 0.494, 0.231, 0.513, 0.143, 0.354, 0.356, 0.457, 0.165, 0.405]
[2m[36m(func pid=101178)[0m 
== Status ==
Current time: 2024-01-07 02:57:19 (running for 00:33:20.11)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: 0.32925000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.226 |      0.332 |                   87 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.017 |      0.291 |                   84 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.797 |      0.24  |                   57 |
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  2.616 |      0.001 |                    4 |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.006063432835820896
[2m[36m(func pid=120129)[0m top5: 0.5541044776119403
[2m[36m(func pid=120129)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=120129)[0m f1_macro: 0.0012081784386617103
[2m[36m(func pid=120129)[0m f1_weighted: 7.325708816512236e-05
[2m[36m(func pid=120129)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=102297)[0m top1: 0.2658582089552239
[2m[36m(func pid=102297)[0m top5: 0.8736007462686567
[2m[36m(func pid=102297)[0m f1_micro: 0.2658582089552239
[2m[36m(func pid=102297)[0m f1_macro: 0.2818824070476734
[2m[36m(func pid=102297)[0m f1_weighted: 0.3003280217588829
[2m[36m(func pid=102297)[0m f1_per_class: [0.24, 0.126, 0.545, 0.374, 0.048, 0.263, 0.338, 0.433, 0.215, 0.236]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 87] | Train loss: 0.2347 | Steps: 2 | Val loss: 1.8155 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 1.4540 | Steps: 2 | Val loss: 1.8887 | Batch size: 32 | lr: 0.0001 | Duration: 3.04s
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 2.5464 | Steps: 2 | Val loss: 2.3150 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 85] | Train loss: 0.0104 | Steps: 2 | Val loss: 3.4036 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=108657)[0m top1: 0.3050373134328358
[2m[36m(func pid=108657)[0m top5: 0.8838619402985075
[2m[36m(func pid=108657)[0m f1_micro: 0.3050373134328358
[2m[36m(func pid=108657)[0m f1_macro: 0.23648373882400286
[2m[36m(func pid=108657)[0m f1_weighted: 0.279858833293274
[2m[36m(func pid=108657)[0m f1_per_class: [0.222, 0.343, 0.229, 0.517, 0.071, 0.262, 0.036, 0.418, 0.103, 0.163]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=101178)[0m top1: 0.4025186567164179
[2m[36m(func pid=101178)[0m top5: 0.9006529850746269
[2m[36m(func pid=101178)[0m f1_micro: 0.4025186567164179
[2m[36m(func pid=101178)[0m f1_macro: 0.33271414806335614
[2m[36m(func pid=101178)[0m f1_weighted: 0.4205825811559677
[2m[36m(func pid=101178)[0m f1_per_class: [0.192, 0.512, 0.264, 0.515, 0.133, 0.348, 0.354, 0.471, 0.162, 0.376]
[2m[36m(func pid=101178)[0m 
== Status ==
Current time: 2024-01-07 02:57:24 (running for 00:33:25.26)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: 0.32925000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.235 |      0.333 |                   88 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.008 |      0.282 |                   85 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.454 |      0.236 |                   58 |
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  2.546 |      0.005 |                    5 |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.009794776119402986
[2m[36m(func pid=120129)[0m top5: 0.5550373134328358
[2m[36m(func pid=120129)[0m f1_micro: 0.009794776119402986
[2m[36m(func pid=120129)[0m f1_macro: 0.005214550389067783
[2m[36m(func pid=120129)[0m f1_weighted: 0.0072602361851054195
[2m[36m(func pid=120129)[0m f1_per_class: [0.0, 0.037, 0.012, 0.003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=102297)[0m top1: 0.2593283582089552
[2m[36m(func pid=102297)[0m top5: 0.8689365671641791
[2m[36m(func pid=102297)[0m f1_micro: 0.2593283582089552
[2m[36m(func pid=102297)[0m f1_macro: 0.2855133807388003
[2m[36m(func pid=102297)[0m f1_weighted: 0.29012909911572765
[2m[36m(func pid=102297)[0m f1_per_class: [0.275, 0.126, 0.6, 0.377, 0.049, 0.246, 0.307, 0.415, 0.212, 0.248]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 1.2857 | Steps: 2 | Val loss: 1.8671 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 88] | Train loss: 0.2041 | Steps: 2 | Val loss: 1.7830 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 2.4647 | Steps: 2 | Val loss: 2.2931 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 86] | Train loss: 0.0099 | Steps: 2 | Val loss: 3.3435 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=108657)[0m top1: 0.31529850746268656
[2m[36m(func pid=108657)[0m top5: 0.8815298507462687
[2m[36m(func pid=108657)[0m f1_micro: 0.31529850746268656
[2m[36m(func pid=108657)[0m f1_macro: 0.24451267799461798
[2m[36m(func pid=108657)[0m f1_weighted: 0.2838977791776168
[2m[36m(func pid=108657)[0m f1_per_class: [0.27, 0.352, 0.256, 0.529, 0.069, 0.271, 0.027, 0.416, 0.087, 0.168]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=101178)[0m top1: 0.42117537313432835
[2m[36m(func pid=101178)[0m top5: 0.9001865671641791
[2m[36m(func pid=101178)[0m f1_micro: 0.42117537313432835
[2m[36m(func pid=101178)[0m f1_macro: 0.3493669717821664
[2m[36m(func pid=101178)[0m f1_weighted: 0.4434499115880313
[2m[36m(func pid=101178)[0m f1_per_class: [0.198, 0.53, 0.259, 0.516, 0.142, 0.353, 0.403, 0.51, 0.214, 0.368]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=120129)[0m top1: 0.05783582089552239
[2m[36m(func pid=120129)[0m top5: 0.6217350746268657
[2m[36m(func pid=120129)[0m f1_micro: 0.05783582089552239
[2m[36m(func pid=120129)[0m f1_macro: 0.05356822076969374
[2m[36m(func pid=120129)[0m f1_weighted: 0.05766976080810656
[2m[36m(func pid=120129)[0m f1_per_class: [0.033, 0.302, 0.021, 0.006, 0.127, 0.008, 0.0, 0.0, 0.038, 0.0]
[2m[36m(func pid=120129)[0m 
== Status ==
Current time: 2024-01-07 02:57:29 (running for 00:33:30.57)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: 0.32925000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.204 |      0.349 |                   89 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.01  |      0.286 |                   86 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.286 |      0.245 |                   59 |
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  2.465 |      0.054 |                    6 |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m top1: 0.2579291044776119
[2m[36m(func pid=102297)[0m top5: 0.8675373134328358
[2m[36m(func pid=102297)[0m f1_micro: 0.2579291044776119
[2m[36m(func pid=102297)[0m f1_macro: 0.29705727263483445
[2m[36m(func pid=102297)[0m f1_weighted: 0.2860582942856936
[2m[36m(func pid=102297)[0m f1_per_class: [0.288, 0.164, 0.686, 0.37, 0.051, 0.237, 0.279, 0.405, 0.221, 0.269]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 1.2304 | Steps: 2 | Val loss: 1.8473 | Batch size: 32 | lr: 0.0001 | Duration: 3.01s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 89] | Train loss: 0.3784 | Steps: 2 | Val loss: 1.8487 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 2.4784 | Steps: 2 | Val loss: 2.2722 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 87] | Train loss: 0.0472 | Steps: 2 | Val loss: 3.2447 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
[2m[36m(func pid=101178)[0m top1: 0.41511194029850745
[2m[36m(func pid=101178)[0m top5: 0.8908582089552238
[2m[36m(func pid=101178)[0m f1_micro: 0.4151119402985075
[2m[36m(func pid=101178)[0m f1_macro: 0.34527842346449417
[2m[36m(func pid=101178)[0m f1_weighted: 0.44941039077567135
[2m[36m(func pid=101178)[0m f1_per_class: [0.192, 0.536, 0.267, 0.497, 0.118, 0.348, 0.445, 0.497, 0.201, 0.351]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=108657)[0m top1: 0.324160447761194
[2m[36m(func pid=108657)[0m top5: 0.8763992537313433
[2m[36m(func pid=108657)[0m f1_micro: 0.324160447761194
[2m[36m(func pid=108657)[0m f1_macro: 0.24934217421872953
[2m[36m(func pid=108657)[0m f1_weighted: 0.2875733144004841
[2m[36m(func pid=108657)[0m f1_per_class: [0.26, 0.356, 0.282, 0.538, 0.07, 0.288, 0.025, 0.415, 0.073, 0.187]
[2m[36m(func pid=108657)[0m 
== Status ==
Current time: 2024-01-07 02:57:34 (running for 00:33:35.70)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: 0.32925000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.378 |      0.345 |                   90 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.01  |      0.297 |                   87 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.23  |      0.249 |                   60 |
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  2.478 |      0.07  |                    7 |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.07602611940298508
[2m[36m(func pid=120129)[0m top5: 0.667910447761194
[2m[36m(func pid=120129)[0m f1_micro: 0.07602611940298508
[2m[36m(func pid=120129)[0m f1_macro: 0.06973875909926228
[2m[36m(func pid=120129)[0m f1_weighted: 0.07493387388386058
[2m[36m(func pid=120129)[0m f1_per_class: [0.053, 0.275, 0.056, 0.0, 0.149, 0.04, 0.062, 0.0, 0.063, 0.0]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=102297)[0m top1: 0.279384328358209
[2m[36m(func pid=102297)[0m top5: 0.8689365671641791
[2m[36m(func pid=102297)[0m f1_micro: 0.279384328358209
[2m[36m(func pid=102297)[0m f1_macro: 0.2901533020875594
[2m[36m(func pid=102297)[0m f1_weighted: 0.3206479631967787
[2m[36m(func pid=102297)[0m f1_per_class: [0.236, 0.221, 0.667, 0.353, 0.056, 0.251, 0.406, 0.269, 0.205, 0.238]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 1.2052 | Steps: 2 | Val loss: 1.8391 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 90] | Train loss: 0.2613 | Steps: 2 | Val loss: 1.9058 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 2.2639 | Steps: 2 | Val loss: 2.2422 | Batch size: 32 | lr: 0.001 | Duration: 2.74s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 88] | Train loss: 0.0047 | Steps: 2 | Val loss: 3.1385 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
[2m[36m(func pid=101178)[0m top1: 0.40158582089552236
[2m[36m(func pid=101178)[0m top5: 0.8894589552238806
[2m[36m(func pid=101178)[0m f1_micro: 0.40158582089552236
[2m[36m(func pid=101178)[0m f1_macro: 0.3346885957635634
[2m[36m(func pid=101178)[0m f1_weighted: 0.4381530195782777
[2m[36m(func pid=101178)[0m f1_per_class: [0.185, 0.538, 0.231, 0.483, 0.113, 0.341, 0.426, 0.492, 0.19, 0.348]
[2m[36m(func pid=101178)[0m 
== Status ==
Current time: 2024-01-07 02:57:39 (running for 00:33:40.81)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: 0.32925000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.261 |      0.335 |                   91 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.047 |      0.29  |                   88 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.23  |      0.249 |                   60 |
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  2.264 |      0.084 |                    8 |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=108657)[0m top1: 0.32509328358208955
[2m[36m(func pid=108657)[0m top5: 0.875
[2m[36m(func pid=108657)[0m f1_micro: 0.32509328358208955
[2m[36m(func pid=108657)[0m f1_macro: 0.24547325321778515
[2m[36m(func pid=108657)[0m f1_weighted: 0.2846532040592961
[2m[36m(func pid=108657)[0m f1_per_class: [0.255, 0.361, 0.293, 0.541, 0.07, 0.275, 0.018, 0.415, 0.026, 0.2]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=120129)[0m top1: 0.09281716417910447
[2m[36m(func pid=120129)[0m top5: 0.6753731343283582
[2m[36m(func pid=120129)[0m f1_micro: 0.09281716417910447
[2m[36m(func pid=120129)[0m f1_macro: 0.08411701331847574
[2m[36m(func pid=120129)[0m f1_weighted: 0.09191730689312652
[2m[36m(func pid=120129)[0m f1_per_class: [0.071, 0.268, 0.179, 0.0, 0.117, 0.024, 0.127, 0.0, 0.056, 0.0]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=102297)[0m top1: 0.2980410447761194
[2m[36m(func pid=102297)[0m top5: 0.8763992537313433
[2m[36m(func pid=102297)[0m f1_micro: 0.2980410447761194
[2m[36m(func pid=102297)[0m f1_macro: 0.2828570680656179
[2m[36m(func pid=102297)[0m f1_weighted: 0.33401942161827725
[2m[36m(func pid=102297)[0m f1_per_class: [0.218, 0.235, 0.727, 0.363, 0.063, 0.283, 0.464, 0.06, 0.185, 0.23]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 91] | Train loss: 0.2454 | Steps: 2 | Val loss: 1.8562 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 2.2416 | Steps: 2 | Val loss: 2.2053 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 1.1739 | Steps: 2 | Val loss: 1.8319 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 89] | Train loss: 0.0044 | Steps: 2 | Val loss: 3.1237 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 02:57:45 (running for 00:33:46.11)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: 0.32925000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.245 |      0.339 |                   92 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.005 |      0.283 |                   89 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.245 |                   61 |
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  2.264 |      0.084 |                    8 |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=101178)[0m top1: 0.40671641791044777
[2m[36m(func pid=101178)[0m top5: 0.8969216417910447
[2m[36m(func pid=101178)[0m f1_micro: 0.40671641791044777
[2m[36m(func pid=101178)[0m f1_macro: 0.33858160680500765
[2m[36m(func pid=101178)[0m f1_weighted: 0.4406541186629508
[2m[36m(func pid=101178)[0m f1_per_class: [0.168, 0.54, 0.24, 0.474, 0.106, 0.323, 0.445, 0.517, 0.178, 0.395]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=108657)[0m top1: 0.3246268656716418
[2m[36m(func pid=108657)[0m top5: 0.8740671641791045
[2m[36m(func pid=108657)[0m f1_micro: 0.3246268656716418
[2m[36m(func pid=108657)[0m f1_macro: 0.24793617790279526
[2m[36m(func pid=108657)[0m f1_weighted: 0.2827105594880395
[2m[36m(func pid=108657)[0m f1_per_class: [0.248, 0.365, 0.301, 0.537, 0.068, 0.266, 0.012, 0.435, 0.026, 0.221]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=120129)[0m top1: 0.12826492537313433
[2m[36m(func pid=120129)[0m top5: 0.7112873134328358
[2m[36m(func pid=120129)[0m f1_micro: 0.12826492537313433
[2m[36m(func pid=120129)[0m f1_macro: 0.11895709404554625
[2m[36m(func pid=120129)[0m f1_weighted: 0.13304755607830948
[2m[36m(func pid=120129)[0m f1_per_class: [0.079, 0.276, 0.417, 0.0, 0.096, 0.0, 0.264, 0.0, 0.058, 0.0]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=102297)[0m top1: 0.31203358208955223
[2m[36m(func pid=102297)[0m top5: 0.8801305970149254
[2m[36m(func pid=102297)[0m f1_micro: 0.31203358208955223
[2m[36m(func pid=102297)[0m f1_macro: 0.2890197536507164
[2m[36m(func pid=102297)[0m f1_weighted: 0.34645408060574734
[2m[36m(func pid=102297)[0m f1_per_class: [0.214, 0.246, 0.75, 0.368, 0.068, 0.295, 0.493, 0.052, 0.176, 0.228]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 2.1447 | Steps: 2 | Val loss: 2.1496 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 92] | Train loss: 0.2862 | Steps: 2 | Val loss: 1.8709 | Batch size: 32 | lr: 0.001 | Duration: 3.04s
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 1.2308 | Steps: 2 | Val loss: 1.8337 | Batch size: 32 | lr: 0.0001 | Duration: 3.05s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 90] | Train loss: 0.0050 | Steps: 2 | Val loss: 3.1309 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=120129)[0m top1: 0.2513992537313433
[2m[36m(func pid=120129)[0m top5: 0.7378731343283582
[2m[36m(func pid=120129)[0m f1_micro: 0.2513992537313433
[2m[36m(func pid=120129)[0m f1_macro: 0.15658099949524998
[2m[36m(func pid=120129)[0m f1_weighted: 0.23184762283558094
[2m[36m(func pid=120129)[0m f1_per_class: [0.097, 0.308, 0.353, 0.0, 0.078, 0.0, 0.554, 0.129, 0.047, 0.0]
[2m[36m(func pid=120129)[0m 
== Status ==
Current time: 2024-01-07 02:57:50 (running for 00:33:51.39)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: 0.32925000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.245 |      0.339 |                   92 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.004 |      0.289 |                   90 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.174 |      0.248 |                   62 |
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  2.145 |      0.157 |                   10 |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=101178)[0m top1: 0.4076492537313433
[2m[36m(func pid=101178)[0m top5: 0.9001865671641791
[2m[36m(func pid=101178)[0m f1_micro: 0.4076492537313433
[2m[36m(func pid=101178)[0m f1_macro: 0.33696628916702276
[2m[36m(func pid=101178)[0m f1_weighted: 0.4350168559964063
[2m[36m(func pid=101178)[0m f1_per_class: [0.166, 0.56, 0.264, 0.472, 0.091, 0.316, 0.424, 0.494, 0.154, 0.429]
[2m[36m(func pid=108657)[0m top1: 0.32882462686567165
[2m[36m(func pid=108657)[0m top5: 0.871268656716418
[2m[36m(func pid=108657)[0m f1_micro: 0.32882462686567165
[2m[36m(func pid=108657)[0m f1_macro: 0.25229675927692574
[2m[36m(func pid=108657)[0m f1_weighted: 0.28531376154135485
[2m[36m(func pid=108657)[0m f1_per_class: [0.253, 0.36, 0.301, 0.537, 0.069, 0.283, 0.012, 0.46, 0.026, 0.221]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=102297)[0m top1: 0.31949626865671643
[2m[36m(func pid=102297)[0m top5: 0.8796641791044776
[2m[36m(func pid=102297)[0m f1_micro: 0.31949626865671643
[2m[36m(func pid=102297)[0m f1_macro: 0.2924650773118119
[2m[36m(func pid=102297)[0m f1_weighted: 0.3521735231113895
[2m[36m(func pid=102297)[0m f1_per_class: [0.218, 0.265, 0.774, 0.358, 0.067, 0.304, 0.512, 0.028, 0.169, 0.23]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 2.0141 | Steps: 2 | Val loss: 2.1053 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 1.3007 | Steps: 2 | Val loss: 1.8381 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 93] | Train loss: 0.1708 | Steps: 2 | Val loss: 1.8636 | Batch size: 32 | lr: 0.001 | Duration: 3.08s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 91] | Train loss: 0.0054 | Steps: 2 | Val loss: 3.1310 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
== Status ==
Current time: 2024-01-07 02:57:55 (running for 00:33:56.80)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: 0.32925000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.286 |      0.337 |                   93 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.005 |      0.292 |                   91 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.231 |      0.252 |                   63 |
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  2.014 |      0.173 |                   11 |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=101178)[0m top1: 0.41697761194029853
[2m[36m(func pid=101178)[0m top5: 0.8955223880597015
[2m[36m(func pid=101178)[0m f1_micro: 0.41697761194029853
[2m[36m(func pid=101178)[0m f1_macro: 0.3528293194251806
[2m[36m(func pid=101178)[0m f1_weighted: 0.4460234688961349
[2m[36m(func pid=101178)[0m f1_per_class: [0.163, 0.574, 0.261, 0.473, 0.089, 0.342, 0.428, 0.545, 0.186, 0.469]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=108657)[0m top1: 0.332089552238806
[2m[36m(func pid=108657)[0m top5: 0.8666044776119403
[2m[36m(func pid=108657)[0m f1_micro: 0.332089552238806
[2m[36m(func pid=108657)[0m f1_macro: 0.25287578698969604
[2m[36m(func pid=108657)[0m f1_weighted: 0.29090658440590905
[2m[36m(func pid=108657)[0m f1_per_class: [0.257, 0.353, 0.306, 0.542, 0.063, 0.279, 0.031, 0.48, 0.0, 0.218]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=120129)[0m top1: 0.2891791044776119
[2m[36m(func pid=120129)[0m top5: 0.7555970149253731
[2m[36m(func pid=120129)[0m f1_micro: 0.2891791044776119
[2m[36m(func pid=120129)[0m f1_macro: 0.17251067345718266
[2m[36m(func pid=120129)[0m f1_weighted: 0.24280201694885167
[2m[36m(func pid=120129)[0m f1_per_class: [0.128, 0.335, 0.375, 0.0, 0.085, 0.0, 0.573, 0.112, 0.039, 0.077]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=102297)[0m top1: 0.3283582089552239
[2m[36m(func pid=102297)[0m top5: 0.8777985074626866
[2m[36m(func pid=102297)[0m f1_micro: 0.3283582089552239
[2m[36m(func pid=102297)[0m f1_macro: 0.29523875727267324
[2m[36m(func pid=102297)[0m f1_weighted: 0.36151242289069907
[2m[36m(func pid=102297)[0m f1_per_class: [0.216, 0.275, 0.774, 0.38, 0.071, 0.3, 0.518, 0.028, 0.174, 0.217]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 94] | Train loss: 0.1903 | Steps: 2 | Val loss: 1.8495 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 1.9028 | Steps: 2 | Val loss: 2.0586 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 1.2022 | Steps: 2 | Val loss: 1.8349 | Batch size: 32 | lr: 0.0001 | Duration: 3.03s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 92] | Train loss: 0.0234 | Steps: 2 | Val loss: 3.0773 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
== Status ==
Current time: 2024-01-07 02:58:01 (running for 00:34:02.16)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: 0.32925000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.171 |      0.353 |                   94 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.005 |      0.295 |                   92 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.301 |      0.253 |                   64 |
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  1.903 |      0.199 |                   12 |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.300839552238806
[2m[36m(func pid=120129)[0m top5: 0.7821828358208955
[2m[36m(func pid=120129)[0m f1_micro: 0.300839552238806
[2m[36m(func pid=120129)[0m f1_macro: 0.1989105535954153
[2m[36m(func pid=120129)[0m f1_weighted: 0.24400078917701076
[2m[36m(func pid=120129)[0m f1_per_class: [0.171, 0.347, 0.387, 0.0, 0.093, 0.0, 0.545, 0.21, 0.025, 0.211]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=101178)[0m top1: 0.43236940298507465
[2m[36m(func pid=101178)[0m top5: 0.8936567164179104
[2m[36m(func pid=101178)[0m f1_micro: 0.43236940298507465
[2m[36m(func pid=101178)[0m f1_macro: 0.3647745211510214
[2m[36m(func pid=101178)[0m f1_weighted: 0.45816840137007014
[2m[36m(func pid=101178)[0m f1_per_class: [0.185, 0.582, 0.27, 0.495, 0.088, 0.367, 0.427, 0.557, 0.2, 0.476]
[2m[36m(func pid=108657)[0m top1: 0.33908582089552236
[2m[36m(func pid=108657)[0m top5: 0.8698694029850746
[2m[36m(func pid=108657)[0m f1_micro: 0.33908582089552236
[2m[36m(func pid=108657)[0m f1_macro: 0.264187802404919
[2m[36m(func pid=108657)[0m f1_weighted: 0.30321613955452853
[2m[36m(func pid=108657)[0m f1_per_class: [0.264, 0.357, 0.328, 0.547, 0.062, 0.278, 0.06, 0.497, 0.0, 0.248]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=102297)[0m top1: 0.3148320895522388
[2m[36m(func pid=102297)[0m top5: 0.8763992537313433
[2m[36m(func pid=102297)[0m f1_micro: 0.3148320895522388
[2m[36m(func pid=102297)[0m f1_macro: 0.29025753114380487
[2m[36m(func pid=102297)[0m f1_weighted: 0.3507823046443028
[2m[36m(func pid=102297)[0m f1_per_class: [0.204, 0.289, 0.727, 0.361, 0.066, 0.292, 0.488, 0.062, 0.181, 0.232]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 1.8649 | Steps: 2 | Val loss: 2.0118 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 95] | Train loss: 0.2241 | Steps: 2 | Val loss: 1.8532 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 1.2587 | Steps: 2 | Val loss: 1.8264 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 93] | Train loss: 0.0048 | Steps: 2 | Val loss: 3.0542 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 02:58:06 (running for 00:34:07.53)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: 0.32925000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.19  |      0.365 |                   95 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.023 |      0.29  |                   93 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.202 |      0.264 |                   65 |
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  1.865 |      0.21  |                   13 |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=101178)[0m top1: 0.43050373134328357
[2m[36m(func pid=101178)[0m top5: 0.8894589552238806
[2m[36m(func pid=101178)[0m f1_micro: 0.43050373134328357
[2m[36m(func pid=101178)[0m f1_macro: 0.35939887437883733
[2m[36m(func pid=101178)[0m f1_weighted: 0.45329917640059475
[2m[36m(func pid=101178)[0m f1_per_class: [0.214, 0.584, 0.279, 0.501, 0.092, 0.354, 0.416, 0.516, 0.206, 0.431]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=108657)[0m top1: 0.34421641791044777
[2m[36m(func pid=108657)[0m top5: 0.8745335820895522
[2m[36m(func pid=108657)[0m f1_micro: 0.34421641791044777
[2m[36m(func pid=108657)[0m f1_macro: 0.26937698962491907
[2m[36m(func pid=108657)[0m f1_weighted: 0.3109879799319309
[2m[36m(func pid=108657)[0m f1_per_class: [0.254, 0.366, 0.349, 0.551, 0.065, 0.29, 0.074, 0.49, 0.0, 0.255]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=120129)[0m top1: 0.28591417910447764
[2m[36m(func pid=120129)[0m top5: 0.8535447761194029
[2m[36m(func pid=120129)[0m f1_micro: 0.28591417910447764
[2m[36m(func pid=120129)[0m f1_macro: 0.2102969007915972
[2m[36m(func pid=120129)[0m f1_weighted: 0.22768363373404282
[2m[36m(func pid=120129)[0m f1_per_class: [0.233, 0.381, 0.471, 0.0, 0.103, 0.0, 0.451, 0.29, 0.026, 0.149]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=102297)[0m top1: 0.29244402985074625
[2m[36m(func pid=102297)[0m top5: 0.8708022388059702
[2m[36m(func pid=102297)[0m f1_micro: 0.29244402985074625
[2m[36m(func pid=102297)[0m f1_macro: 0.30020505441862244
[2m[36m(func pid=102297)[0m f1_weighted: 0.3329851315830139
[2m[36m(func pid=102297)[0m f1_per_class: [0.212, 0.286, 0.774, 0.343, 0.067, 0.267, 0.427, 0.211, 0.175, 0.239]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 1.7751 | Steps: 2 | Val loss: 1.9910 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 1.1612 | Steps: 2 | Val loss: 1.8313 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 96] | Train loss: 0.1403 | Steps: 2 | Val loss: 1.8462 | Batch size: 32 | lr: 0.001 | Duration: 3.03s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 94] | Train loss: 0.0032 | Steps: 2 | Val loss: 3.0546 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
== Status ==
Current time: 2024-01-07 02:58:11 (running for 00:34:12.76)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: 0.32925000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.224 |      0.359 |                   96 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.005 |      0.3   |                   94 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.259 |      0.269 |                   66 |
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  1.775 |      0.206 |                   14 |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.27238805970149255
[2m[36m(func pid=120129)[0m top5: 0.9006529850746269
[2m[36m(func pid=120129)[0m f1_micro: 0.27238805970149255
[2m[36m(func pid=120129)[0m f1_macro: 0.20638486917685656
[2m[36m(func pid=120129)[0m f1_weighted: 0.2047182844463209
[2m[36m(func pid=120129)[0m f1_per_class: [0.312, 0.398, 0.439, 0.0, 0.09, 0.016, 0.347, 0.343, 0.0, 0.118]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=108657)[0m top1: 0.34701492537313433
[2m[36m(func pid=108657)[0m top5: 0.8759328358208955
[2m[36m(func pid=108657)[0m f1_micro: 0.34701492537313433
[2m[36m(func pid=108657)[0m f1_macro: 0.2740701417069154
[2m[36m(func pid=108657)[0m f1_weighted: 0.31723170413150437
[2m[36m(func pid=108657)[0m f1_per_class: [0.247, 0.39, 0.355, 0.551, 0.064, 0.28, 0.08, 0.513, 0.0, 0.259]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=101178)[0m top1: 0.42350746268656714
[2m[36m(func pid=101178)[0m top5: 0.8885261194029851
[2m[36m(func pid=101178)[0m f1_micro: 0.42350746268656714
[2m[36m(func pid=101178)[0m f1_macro: 0.3533274345457385
[2m[36m(func pid=101178)[0m f1_weighted: 0.4452672520972882
[2m[36m(func pid=101178)[0m f1_per_class: [0.229, 0.561, 0.286, 0.492, 0.101, 0.354, 0.416, 0.487, 0.222, 0.386]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=102297)[0m top1: 0.2826492537313433
[2m[36m(func pid=102297)[0m top5: 0.8736007462686567
[2m[36m(func pid=102297)[0m f1_micro: 0.2826492537313433
[2m[36m(func pid=102297)[0m f1_macro: 0.30598607912987463
[2m[36m(func pid=102297)[0m f1_weighted: 0.3168815155445852
[2m[36m(func pid=102297)[0m f1_per_class: [0.218, 0.293, 0.759, 0.338, 0.072, 0.272, 0.343, 0.363, 0.167, 0.235]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 1.6605 | Steps: 2 | Val loss: 1.9755 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 1.2034 | Steps: 2 | Val loss: 1.8337 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 97] | Train loss: 0.5847 | Steps: 2 | Val loss: 2.3668 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 95] | Train loss: 0.0019 | Steps: 2 | Val loss: 3.0834 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=120129)[0m top1: 0.25279850746268656
[2m[36m(func pid=120129)[0m top5: 0.9095149253731343
[2m[36m(func pid=120129)[0m f1_micro: 0.25279850746268656
[2m[36m(func pid=120129)[0m f1_macro: 0.2097294624510037
[2m[36m(func pid=120129)[0m f1_weighted: 0.1755177284819274
[2m[36m(func pid=120129)[0m f1_per_class: [0.339, 0.398, 0.458, 0.0, 0.072, 0.008, 0.247, 0.335, 0.0, 0.24]
== Status ==
Current time: 2024-01-07 02:58:17 (running for 00:34:18.10)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: 0.32925000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.14  |      0.353 |                   97 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.003 |      0.306 |                   95 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.161 |      0.274 |                   67 |
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  1.66  |      0.21  |                   15 |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=108657)[0m top1: 0.353544776119403
[2m[36m(func pid=108657)[0m top5: 0.8759328358208955
[2m[36m(func pid=108657)[0m f1_micro: 0.353544776119403
[2m[36m(func pid=108657)[0m f1_macro: 0.27931409082378156
[2m[36m(func pid=108657)[0m f1_weighted: 0.3285069954803597
[2m[36m(func pid=108657)[0m f1_per_class: [0.236, 0.394, 0.355, 0.549, 0.068, 0.286, 0.114, 0.529, 0.0, 0.263]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=101178)[0m top1: 0.31296641791044777
[2m[36m(func pid=101178)[0m top5: 0.800839552238806
[2m[36m(func pid=101178)[0m f1_micro: 0.31296641791044777
[2m[36m(func pid=101178)[0m f1_macro: 0.21997365548112832
[2m[36m(func pid=101178)[0m f1_weighted: 0.3009510116768733
[2m[36m(func pid=101178)[0m f1_per_class: [0.24, 0.567, 0.273, 0.468, 0.075, 0.222, 0.118, 0.0, 0.116, 0.121]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=102297)[0m top1: 0.27238805970149255
[2m[36m(func pid=102297)[0m top5: 0.871268656716418
[2m[36m(func pid=102297)[0m f1_micro: 0.27238805970149255
[2m[36m(func pid=102297)[0m f1_macro: 0.29846508842459246
[2m[36m(func pid=102297)[0m f1_weighted: 0.29986376626557565
[2m[36m(func pid=102297)[0m f1_per_class: [0.216, 0.307, 0.759, 0.338, 0.08, 0.251, 0.288, 0.353, 0.166, 0.228]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 1.5801 | Steps: 2 | Val loss: 1.9619 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 98] | Train loss: 0.2718 | Steps: 2 | Val loss: 2.1250 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 1.0422 | Steps: 2 | Val loss: 1.8282 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 96] | Train loss: 0.0050 | Steps: 2 | Val loss: 3.0946 | Batch size: 32 | lr: 0.01 | Duration: 2.73s
== Status ==
Current time: 2024-01-07 02:58:22 (running for 00:34:23.22)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: 0.32925000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.585 |      0.22  |                   98 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.002 |      0.298 |                   96 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.203 |      0.279 |                   68 |
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  1.58  |      0.167 |                   16 |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.23367537313432835
[2m[36m(func pid=120129)[0m top5: 0.9113805970149254
[2m[36m(func pid=120129)[0m f1_micro: 0.23367537313432835
[2m[36m(func pid=120129)[0m f1_macro: 0.16744031471777282
[2m[36m(func pid=120129)[0m f1_weighted: 0.14277351606374838
[2m[36m(func pid=120129)[0m f1_per_class: [0.125, 0.403, 0.431, 0.003, 0.07, 0.0, 0.151, 0.349, 0.0, 0.142]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=101178)[0m top1: 0.3521455223880597
[2m[36m(func pid=101178)[0m top5: 0.8652052238805971
[2m[36m(func pid=101178)[0m f1_micro: 0.3521455223880597
[2m[36m(func pid=101178)[0m f1_macro: 0.2931268370209412
[2m[36m(func pid=101178)[0m f1_weighted: 0.3657674661520519
[2m[36m(func pid=101178)[0m f1_per_class: [0.231, 0.571, 0.301, 0.47, 0.08, 0.276, 0.222, 0.424, 0.135, 0.221]
[2m[36m(func pid=101178)[0m 
[2m[36m(func pid=108657)[0m top1: 0.3614738805970149
[2m[36m(func pid=108657)[0m top5: 0.8791977611940298
[2m[36m(func pid=108657)[0m f1_micro: 0.3614738805970149
[2m[36m(func pid=108657)[0m f1_macro: 0.2869749309149098
[2m[36m(func pid=108657)[0m f1_weighted: 0.3413282588398631
[2m[36m(func pid=108657)[0m f1_per_class: [0.231, 0.405, 0.344, 0.542, 0.076, 0.315, 0.145, 0.518, 0.026, 0.269]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=102297)[0m top1: 0.2653917910447761
[2m[36m(func pid=102297)[0m top5: 0.8708022388059702
[2m[36m(func pid=102297)[0m f1_micro: 0.2653917910447761
[2m[36m(func pid=102297)[0m f1_macro: 0.2912050827288218
[2m[36m(func pid=102297)[0m f1_weighted: 0.2891617884720356
[2m[36m(func pid=102297)[0m f1_per_class: [0.203, 0.294, 0.759, 0.342, 0.076, 0.25, 0.26, 0.341, 0.166, 0.22]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 1.7898 | Steps: 2 | Val loss: 2.0114 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=101178)[0m [N0-GPU0] | [Epoch: 99] | Train loss: 0.1465 | Steps: 2 | Val loss: 1.8296 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 1.2005 | Steps: 2 | Val loss: 1.8271 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 97] | Train loss: 0.0028 | Steps: 2 | Val loss: 3.1223 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
== Status ==
Current time: 2024-01-07 02:58:27 (running for 00:34:28.56)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: 0.32925000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00013 | RUNNING    | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.272 |      0.293 |                   99 |
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.005 |      0.291 |                   97 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.042 |      0.287 |                   69 |
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  1.79  |      0.155 |                   17 |
| train_6ed81_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.22061567164179105
[2m[36m(func pid=120129)[0m top5: 0.9043843283582089
[2m[36m(func pid=120129)[0m f1_micro: 0.22061567164179105
[2m[36m(func pid=120129)[0m f1_macro: 0.15533249079904307
[2m[36m(func pid=120129)[0m f1_weighted: 0.12444819302203852
[2m[36m(func pid=120129)[0m f1_per_class: [0.087, 0.418, 0.4, 0.029, 0.085, 0.008, 0.054, 0.361, 0.021, 0.091]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=101178)[0m top1: 0.41138059701492535
[2m[36m(func pid=101178)[0m top5: 0.909981343283582
[2m[36m(func pid=101178)[0m f1_micro: 0.41138059701492535
[2m[36m(func pid=101178)[0m f1_macro: 0.3463366214851583
[2m[36m(func pid=101178)[0m f1_weighted: 0.4315017066477588
[2m[36m(func pid=101178)[0m f1_per_class: [0.217, 0.564, 0.282, 0.494, 0.11, 0.347, 0.374, 0.48, 0.185, 0.411]
[2m[36m(func pid=108657)[0m top1: 0.3694029850746269
[2m[36m(func pid=108657)[0m top5: 0.8801305970149254
[2m[36m(func pid=108657)[0m f1_micro: 0.3694029850746269
[2m[36m(func pid=108657)[0m f1_macro: 0.2924649523942355
[2m[36m(func pid=108657)[0m f1_weighted: 0.35915624986243405
[2m[36m(func pid=108657)[0m f1_per_class: [0.226, 0.43, 0.319, 0.538, 0.061, 0.324, 0.189, 0.514, 0.05, 0.274]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=102297)[0m top1: 0.269589552238806
[2m[36m(func pid=102297)[0m top5: 0.8684701492537313
[2m[36m(func pid=102297)[0m f1_micro: 0.269589552238806
[2m[36m(func pid=102297)[0m f1_macro: 0.2953050177090109
[2m[36m(func pid=102297)[0m f1_weighted: 0.28815226297637714
[2m[36m(func pid=102297)[0m f1_per_class: [0.207, 0.307, 0.759, 0.35, 0.078, 0.274, 0.229, 0.351, 0.175, 0.224]
[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 1.4513 | Steps: 2 | Val loss: 2.0622 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 1.1269 | Steps: 2 | Val loss: 1.8139 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 98] | Train loss: 0.0038 | Steps: 2 | Val loss: 3.1048 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=120129)[0m top1: 0.23740671641791045
[2m[36m(func pid=120129)[0m top5: 0.8927238805970149
[2m[36m(func pid=120129)[0m f1_micro: 0.23740671641791045
[2m[36m(func pid=120129)[0m f1_macro: 0.17411876418772312
[2m[36m(func pid=120129)[0m f1_weighted: 0.15664976288564064
[2m[36m(func pid=120129)[0m f1_per_class: [0.087, 0.453, 0.407, 0.172, 0.101, 0.0, 0.006, 0.348, 0.082, 0.085]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=108657)[0m top1: 0.3605410447761194
[2m[36m(func pid=108657)[0m top5: 0.8847947761194029
[2m[36m(func pid=108657)[0m f1_micro: 0.3605410447761194
[2m[36m(func pid=108657)[0m f1_macro: 0.2882832892322852
[2m[36m(func pid=108657)[0m f1_weighted: 0.34869275080452977
[2m[36m(func pid=108657)[0m f1_per_class: [0.216, 0.429, 0.319, 0.532, 0.068, 0.327, 0.164, 0.468, 0.093, 0.266]
[2m[36m(func pid=102297)[0m top1: 0.27425373134328357
[2m[36m(func pid=102297)[0m top5: 0.8698694029850746
[2m[36m(func pid=102297)[0m f1_micro: 0.27425373134328357
[2m[36m(func pid=102297)[0m f1_macro: 0.30168260786219925
[2m[36m(func pid=102297)[0m f1_weighted: 0.29098650359290135
[2m[36m(func pid=102297)[0m f1_per_class: [0.202, 0.32, 0.786, 0.353, 0.08, 0.276, 0.225, 0.359, 0.177, 0.24]
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 1.4952 | Steps: 2 | Val loss: 2.0760 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
== Status ==
Current time: 2024-01-07 02:58:32 (running for 00:34:33.63)
Memory usage on this node: 22.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: 0.32925000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (5 PENDING, 4 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.003 |      0.295 |                   98 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.2   |      0.292 |                   70 |
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  1.451 |      0.174 |                   18 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=102297)[0m 
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=124580)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=124580)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=124580)[0m Configuration completed!
[2m[36m(func pid=124580)[0m New optimizer parameters:
[2m[36m(func pid=124580)[0m SGD (
[2m[36m(func pid=124580)[0m Parameter Group 0
[2m[36m(func pid=124580)[0m     dampening: 0
[2m[36m(func pid=124580)[0m     differentiable: False
[2m[36m(func pid=124580)[0m     foreach: None
[2m[36m(func pid=124580)[0m     lr: 0.01
[2m[36m(func pid=124580)[0m     maximize: False
[2m[36m(func pid=124580)[0m     momentum: 0.99
[2m[36m(func pid=124580)[0m     nesterov: False
[2m[36m(func pid=124580)[0m     weight_decay: 1e-05
[2m[36m(func pid=124580)[0m )
[2m[36m(func pid=124580)[0m 
== Status ==
Current time: 2024-01-07 02:58:38 (running for 00:34:38.96)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: 0.32925000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (5 PENDING, 4 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00014 | RUNNING    | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.004 |      0.302 |                   99 |
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.127 |      0.288 |                   71 |
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  1.495 |      0.202 |                   19 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.2733208955223881
[2m[36m(func pid=120129)[0m top5: 0.8815298507462687
[2m[36m(func pid=120129)[0m f1_micro: 0.2733208955223881
[2m[36m(func pid=120129)[0m f1_macro: 0.20238381295967867
[2m[36m(func pid=120129)[0m f1_weighted: 0.21885292747991186
[2m[36m(func pid=120129)[0m f1_per_class: [0.154, 0.479, 0.338, 0.367, 0.123, 0.016, 0.003, 0.367, 0.093, 0.084]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=102297)[0m [N0-GPU0] | [Epoch: 99] | Train loss: 0.0125 | Steps: 2 | Val loss: 3.0653 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.9721 | Steps: 2 | Val loss: 1.8163 | Batch size: 32 | lr: 0.0001 | Duration: 3.05s
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 1.3877 | Steps: 2 | Val loss: 1.9605 | Batch size: 32 | lr: 0.001 | Duration: 3.08s
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 3.0010 | Steps: 2 | Val loss: 2.7768 | Batch size: 32 | lr: 0.01 | Duration: 4.65s
[2m[36m(func pid=102297)[0m top1: 0.2789179104477612
[2m[36m(func pid=102297)[0m top5: 0.871268656716418
[2m[36m(func pid=102297)[0m f1_micro: 0.2789179104477612
[2m[36m(func pid=102297)[0m f1_macro: 0.3070102565194629
[2m[36m(func pid=102297)[0m f1_weighted: 0.2972350932180071
[2m[36m(func pid=102297)[0m f1_per_class: [0.217, 0.325, 0.815, 0.363, 0.086, 0.28, 0.23, 0.365, 0.176, 0.214]
[2m[36m(func pid=108657)[0m top1: 0.3596082089552239
[2m[36m(func pid=108657)[0m top5: 0.8838619402985075
[2m[36m(func pid=108657)[0m f1_micro: 0.35960820895522383
[2m[36m(func pid=108657)[0m f1_macro: 0.2871253706267603
[2m[36m(func pid=108657)[0m f1_weighted: 0.34124570644170926
[2m[36m(func pid=108657)[0m f1_per_class: [0.212, 0.435, 0.338, 0.534, 0.078, 0.343, 0.131, 0.456, 0.091, 0.254]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=120129)[0m top1: 0.31343283582089554
[2m[36m(func pid=120129)[0m top5: 0.9001865671641791
[2m[36m(func pid=120129)[0m f1_micro: 0.31343283582089554
[2m[36m(func pid=120129)[0m f1_macro: 0.2463754409052213
[2m[36m(func pid=120129)[0m f1_weighted: 0.28101861454172233
[2m[36m(func pid=120129)[0m f1_per_class: [0.254, 0.496, 0.328, 0.488, 0.099, 0.082, 0.039, 0.406, 0.175, 0.096]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=124580)[0m top1: 0.006063432835820896
[2m[36m(func pid=124580)[0m top5: 0.3260261194029851
[2m[36m(func pid=124580)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=124580)[0m f1_macro: 0.001205377839592026
[2m[36m(func pid=124580)[0m f1_weighted: 7.308727572153144e-05
[2m[36m(func pid=124580)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 1.2850 | Steps: 2 | Val loss: 1.8124 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 1.2978 | Steps: 2 | Val loss: 1.8359 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=108657)[0m top1: 0.35401119402985076
[2m[36m(func pid=108657)[0m top5: 0.8871268656716418
[2m[36m(func pid=108657)[0m f1_micro: 0.35401119402985076
[2m[36m(func pid=108657)[0m f1_macro: 0.2857223783627927
[2m[36m(func pid=108657)[0m f1_weighted: 0.3362826612466911
[2m[36m(func pid=108657)[0m f1_per_class: [0.208, 0.445, 0.344, 0.531, 0.087, 0.345, 0.114, 0.411, 0.146, 0.227]
[2m[36m(func pid=120129)[0m top1: 0.3423507462686567
[2m[36m(func pid=120129)[0m top5: 0.9053171641791045
[2m[36m(func pid=120129)[0m f1_micro: 0.3423507462686567
[2m[36m(func pid=120129)[0m f1_macro: 0.2788236171196228
[2m[36m(func pid=120129)[0m f1_weighted: 0.32528288914046893
[2m[36m(func pid=120129)[0m f1_per_class: [0.356, 0.466, 0.313, 0.531, 0.097, 0.235, 0.102, 0.394, 0.156, 0.137]
== Status ==
Current time: 2024-01-07 02:58:43 (running for 00:34:44.46)
Memory usage on this node: 22.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=16
Bracket: Iter 75.000: 0.32925000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 PENDING, 4 RUNNING, 16 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  0.972 |      0.287 |                   72 |
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  1.388 |      0.246 |                   20 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


== Status ==
Current time: 2024-01-07 02:58:50 (running for 00:34:51.27)
Memory usage on this node: 23.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=16
Bracket: Iter 75.000: 0.32925000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 PENDING, 4 RUNNING, 16 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  0.972 |      0.287 |                   72 |
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  1.388 |      0.246 |                   20 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  3.001 |      0.001 |                    1 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=125328)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=125328)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=125328)[0m Configuration completed!
[2m[36m(func pid=125328)[0m New optimizer parameters:
[2m[36m(func pid=125328)[0m SGD (
[2m[36m(func pid=125328)[0m Parameter Group 0
[2m[36m(func pid=125328)[0m     dampening: 0
[2m[36m(func pid=125328)[0m     differentiable: False
[2m[36m(func pid=125328)[0m     foreach: None
[2m[36m(func pid=125328)[0m     lr: 0.1
[2m[36m(func pid=125328)[0m     maximize: False
[2m[36m(func pid=125328)[0m     momentum: 0.99
[2m[36m(func pid=125328)[0m     nesterov: False
[2m[36m(func pid=125328)[0m     weight_decay: 1e-05
[2m[36m(func pid=125328)[0m )
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 1.3048 | Steps: 2 | Val loss: 1.7916 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 2.6051 | Steps: 2 | Val loss: 4.0653 | Batch size: 32 | lr: 0.01 | Duration: 3.11s
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 1.0304 | Steps: 2 | Val loss: 1.8369 | Batch size: 32 | lr: 0.0001 | Duration: 3.15s
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 3.5665 | Steps: 2 | Val loss: 290.2241 | Batch size: 32 | lr: 0.1 | Duration: 4.61s
== Status ==
Current time: 2024-01-07 02:58:55 (running for 00:34:56.30)
Memory usage on this node: 25.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=16
Bracket: Iter 75.000: 0.32925000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 PENDING, 4 RUNNING, 16 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.285 |      0.286 |                   73 |
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  1.298 |      0.279 |                   21 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  3.001 |      0.001 |                    1 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |        |            |                      |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.3712686567164179
[2m[36m(func pid=120129)[0m top5: 0.9048507462686567
[2m[36m(func pid=120129)[0m f1_micro: 0.3712686567164179
[2m[36m(func pid=120129)[0m f1_macro: 0.2986532081664211
[2m[36m(func pid=120129)[0m f1_weighted: 0.37124352079445216
[2m[36m(func pid=120129)[0m f1_per_class: [0.327, 0.421, 0.306, 0.544, 0.109, 0.26, 0.258, 0.431, 0.108, 0.224]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=124580)[0m top1: 0.006063432835820896
[2m[36m(func pid=124580)[0m top5: 0.590018656716418
[2m[36m(func pid=124580)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=124580)[0m f1_macro: 0.001231060606060606
[2m[36m(func pid=124580)[0m f1_weighted: 7.464453301673451e-05
[2m[36m(func pid=124580)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=108657)[0m top1: 0.35027985074626866
[2m[36m(func pid=108657)[0m top5: 0.8843283582089553
[2m[36m(func pid=108657)[0m f1_micro: 0.35027985074626866
[2m[36m(func pid=108657)[0m f1_macro: 0.2800685345862498
[2m[36m(func pid=108657)[0m f1_weighted: 0.33375315343777184
[2m[36m(func pid=108657)[0m f1_per_class: [0.199, 0.472, 0.338, 0.534, 0.093, 0.325, 0.098, 0.411, 0.136, 0.196]
[2m[36m(func pid=108657)[0m 
[2m[36m(func pid=125328)[0m top1: 0.006063432835820896
[2m[36m(func pid=125328)[0m top5: 0.279384328358209
[2m[36m(func pid=125328)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=125328)[0m f1_macro: 0.001205377839592026
[2m[36m(func pid=125328)[0m f1_weighted: 7.308727572153144e-05
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 1.3464 | Steps: 2 | Val loss: 1.8555 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 2.5124 | Steps: 2 | Val loss: 5.7529 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=108657)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 1.2045 | Steps: 2 | Val loss: 1.8715 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 4.8015 | Steps: 2 | Val loss: 12133.7139 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
== Status ==
Current time: 2024-01-07 02:59:01 (running for 00:35:01.94)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=16
Bracket: Iter 75.000: 0.32925000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 PENDING, 4 RUNNING, 16 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00016 | RUNNING    | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.03  |      0.28  |                   74 |
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  1.346 |      0.295 |                   23 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  2.605 |      0.001 |                    2 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  3.567 |      0.001 |                    1 |
| train_6ed81_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.3810634328358209
[2m[36m(func pid=120129)[0m top5: 0.9034514925373134
[2m[36m(func pid=120129)[0m f1_micro: 0.3810634328358209
[2m[36m(func pid=120129)[0m f1_macro: 0.29493360843644434
[2m[36m(func pid=120129)[0m f1_weighted: 0.39772420591735413
[2m[36m(func pid=120129)[0m f1_per_class: [0.186, 0.426, 0.237, 0.523, 0.125, 0.261, 0.362, 0.487, 0.11, 0.233]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=108657)[0m top1: 0.34095149253731344
[2m[36m(func pid=108657)[0m top5: 0.8805970149253731
[2m[36m(func pid=108657)[0m f1_micro: 0.34095149253731344
[2m[36m(func pid=108657)[0m f1_macro: 0.27289590884270465
[2m[36m(func pid=108657)[0m f1_weighted: 0.3263728100711913
[2m[36m(func pid=108657)[0m f1_per_class: [0.19, 0.483, 0.324, 0.523, 0.085, 0.308, 0.081, 0.431, 0.14, 0.164]
[2m[36m(func pid=124580)[0m top1: 0.008395522388059701
[2m[36m(func pid=124580)[0m top5: 0.5475746268656716
[2m[36m(func pid=124580)[0m f1_micro: 0.008395522388059701
[2m[36m(func pid=124580)[0m f1_macro: 0.003241019687127801
[2m[36m(func pid=124580)[0m f1_weighted: 0.0004085251930373455
[2m[36m(func pid=124580)[0m f1_per_class: [0.015, 0.0, 0.018, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=125328)[0m top1: 0.17210820895522388
[2m[36m(func pid=125328)[0m top5: 0.5708955223880597
[2m[36m(func pid=125328)[0m f1_micro: 0.17210820895522388
[2m[36m(func pid=125328)[0m f1_macro: 0.029367290091524074
[2m[36m(func pid=125328)[0m f1_weighted: 0.05054351699520701
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.294, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 1.2358 | Steps: 2 | Val loss: 2.0024 | Batch size: 32 | lr: 0.001 | Duration: 2.78s
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 2.3860 | Steps: 2 | Val loss: 7.5395 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 3.5863 | Steps: 2 | Val loss: 322042.4375 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=120129)[0m top1: 0.37220149253731344
[2m[36m(func pid=120129)[0m top5: 0.9006529850746269
[2m[36m(func pid=120129)[0m f1_micro: 0.3722014925373134
[2m[36m(func pid=120129)[0m f1_macro: 0.2963838191169693
[2m[36m(func pid=120129)[0m f1_weighted: 0.4163235999065217
[2m[36m(func pid=120129)[0m f1_per_class: [0.09, 0.451, 0.224, 0.461, 0.126, 0.299, 0.453, 0.538, 0.1, 0.222]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=124580)[0m top1: 0.04197761194029851
[2m[36m(func pid=124580)[0m top5: 0.6091417910447762
[2m[36m(func pid=124580)[0m f1_micro: 0.04197761194029851
[2m[36m(func pid=124580)[0m f1_macro: 0.03272166428292492
[2m[36m(func pid=124580)[0m f1_weighted: 0.05069975547734003
[2m[36m(func pid=124580)[0m f1_per_class: [0.015, 0.292, 0.02, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=125328)[0m top1: 0.006063432835820896
[2m[36m(func pid=125328)[0m top5: 0.5093283582089553
[2m[36m(func pid=125328)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=125328)[0m f1_macro: 0.001205377839592026
[2m[36m(func pid=125328)[0m f1_weighted: 7.308727572153144e-05
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 1.0938 | Steps: 2 | Val loss: 2.2120 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 02:59:06 (running for 00:35:07.12)
Memory usage on this node: 22.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  1.236 |      0.296 |                   24 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  2.512 |      0.003 |                    3 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  4.802 |      0.029 |                    2 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=126248)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=126248)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=126248)[0m Configuration completed!
[2m[36m(func pid=126248)[0m New optimizer parameters:
[2m[36m(func pid=126248)[0m SGD (
[2m[36m(func pid=126248)[0m Parameter Group 0
[2m[36m(func pid=126248)[0m     dampening: 0
[2m[36m(func pid=126248)[0m     differentiable: False
[2m[36m(func pid=126248)[0m     foreach: None
[2m[36m(func pid=126248)[0m     lr: 0.0001
[2m[36m(func pid=126248)[0m     maximize: False
[2m[36m(func pid=126248)[0m     momentum: 0.9
[2m[36m(func pid=126248)[0m     nesterov: False
[2m[36m(func pid=126248)[0m     weight_decay: 1e-05
[2m[36m(func pid=126248)[0m )
[2m[36m(func pid=126248)[0m 
== Status ==
Current time: 2024-01-07 02:59:11 (running for 00:35:12.57)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  1.094 |      0.294 |                   25 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  2.386 |      0.033 |                    4 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  3.586 |      0.001 |                    3 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.34888059701492535
[2m[36m(func pid=120129)[0m top5: 0.8922574626865671
[2m[36m(func pid=120129)[0m f1_micro: 0.34888059701492535
[2m[36m(func pid=120129)[0m f1_macro: 0.2944176983330615
[2m[36m(func pid=120129)[0m f1_weighted: 0.4000568477740929
[2m[36m(func pid=120129)[0m f1_per_class: [0.07, 0.473, 0.22, 0.37, 0.136, 0.283, 0.47, 0.567, 0.111, 0.245]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 2.1744 | Steps: 2 | Val loss: 10.3068 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 19.1035 | Steps: 2 | Val loss: 169895.9219 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 3.1106 | Steps: 2 | Val loss: 2.3728 | Batch size: 32 | lr: 0.0001 | Duration: 4.64s
[2m[36m(func pid=125328)[0m top1: 0.006063432835820896
[2m[36m(func pid=125328)[0m top5: 0.5093283582089553
[2m[36m(func pid=125328)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=125328)[0m f1_macro: 0.001205377839592026
[2m[36m(func pid=125328)[0m f1_weighted: 7.308727572153144e-05
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 1.1164 | Steps: 2 | Val loss: 2.2454 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=124580)[0m top1: 0.11380597014925373
[2m[36m(func pid=124580)[0m top5: 0.5620335820895522
[2m[36m(func pid=124580)[0m f1_micro: 0.11380597014925373
[2m[36m(func pid=124580)[0m f1_macro: 0.061288401125746364
[2m[36m(func pid=124580)[0m f1_weighted: 0.0717806564369463
[2m[36m(func pid=124580)[0m f1_per_class: [0.0, 0.388, 0.019, 0.0, 0.174, 0.032, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=126248)[0m top1: 0.06623134328358209
[2m[36m(func pid=126248)[0m top5: 0.3787313432835821
[2m[36m(func pid=126248)[0m f1_micro: 0.06623134328358209
[2m[36m(func pid=126248)[0m f1_macro: 0.016628171361550648
[2m[36m(func pid=126248)[0m f1_weighted: 0.0204308372654004
[2m[36m(func pid=126248)[0m f1_per_class: [0.0, 0.0, 0.0, 0.049, 0.0, 0.0, 0.0, 0.117, 0.0, 0.0]
[2m[36m(func pid=126248)[0m 
== Status ==
Current time: 2024-01-07 02:59:17 (running for 00:35:17.85)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  1.116 |      0.305 |                   26 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  2.174 |      0.061 |                    5 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  | 19.104 |      0.001 |                    4 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  3.111 |      0.017 |                    1 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.3568097014925373
[2m[36m(func pid=120129)[0m top5: 0.8964552238805971
[2m[36m(func pid=120129)[0m f1_micro: 0.3568097014925374
[2m[36m(func pid=120129)[0m f1_macro: 0.30476717804821296
[2m[36m(func pid=120129)[0m f1_weighted: 0.40331045853211467
[2m[36m(func pid=120129)[0m f1_per_class: [0.07, 0.509, 0.242, 0.361, 0.113, 0.282, 0.465, 0.562, 0.132, 0.312]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 6.0831 | Steps: 2 | Val loss: 6622247.5000 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 2.3201 | Steps: 2 | Val loss: 9.6860 | Batch size: 32 | lr: 0.01 | Duration: 3.12s
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 3.0781 | Steps: 2 | Val loss: 2.3258 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=125328)[0m top1: 0.01166044776119403
[2m[36m(func pid=125328)[0m top5: 0.5149253731343284
[2m[36m(func pid=125328)[0m f1_micro: 0.01166044776119403
[2m[36m(func pid=125328)[0m f1_macro: 0.0023052097740894418
[2m[36m(func pid=125328)[0m f1_weighted: 0.0002687977814936383
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.023]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 1.2036 | Steps: 2 | Val loss: 2.4504 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=124580)[0m top1: 0.10401119402985075
[2m[36m(func pid=124580)[0m top5: 0.5811567164179104
[2m[36m(func pid=124580)[0m f1_micro: 0.10401119402985075
[2m[36m(func pid=124580)[0m f1_macro: 0.06752154275896573
[2m[36m(func pid=124580)[0m f1_weighted: 0.09324206287124277
[2m[36m(func pid=124580)[0m f1_per_class: [0.0, 0.257, 0.023, 0.125, 0.229, 0.0, 0.041, 0.0, 0.0, 0.0]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=126248)[0m top1: 0.14878731343283583
[2m[36m(func pid=126248)[0m top5: 0.5354477611940298
[2m[36m(func pid=126248)[0m f1_micro: 0.14878731343283583
[2m[36m(func pid=126248)[0m f1_macro: 0.04398513136363129
[2m[36m(func pid=126248)[0m f1_weighted: 0.0842642827236488
[2m[36m(func pid=126248)[0m f1_per_class: [0.0, 0.0, 0.0, 0.266, 0.0, 0.0, 0.0, 0.174, 0.0, 0.0]
== Status ==
Current time: 2024-01-07 02:59:22 (running for 00:35:22.93)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  1.116 |      0.305 |                   26 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  2.32  |      0.068 |                    6 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  6.083 |      0.002 |                    5 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  3.078 |      0.044 |                    2 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=120129)[0m top1: 0.3218283582089552
[2m[36m(func pid=120129)[0m top5: 0.8913246268656716
[2m[36m(func pid=120129)[0m f1_micro: 0.3218283582089552
[2m[36m(func pid=120129)[0m f1_macro: 0.2802783346147952
[2m[36m(func pid=120129)[0m f1_weighted: 0.35324056354590583
[2m[36m(func pid=120129)[0m f1_per_class: [0.075, 0.535, 0.232, 0.295, 0.103, 0.22, 0.379, 0.508, 0.116, 0.341]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 8.1773 | Steps: 2 | Val loss: 1478754.5000 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 1.8314 | Steps: 2 | Val loss: 7.0260 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 3.0634 | Steps: 2 | Val loss: 2.3154 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 1.4873 | Steps: 2 | Val loss: 2.9062 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=125328)[0m top1: 0.05783582089552239
[2m[36m(func pid=125328)[0m top5: 0.5149253731343284
[2m[36m(func pid=125328)[0m f1_micro: 0.05783582089552239
[2m[36m(func pid=125328)[0m f1_macro: 0.010934744268077601
[2m[36m(func pid=125328)[0m f1_weighted: 0.006324199110268762
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.109, 0.0, 0.0]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=124580)[0m top1: 0.1166044776119403
[2m[36m(func pid=124580)[0m top5: 0.683768656716418
[2m[36m(func pid=124580)[0m f1_micro: 0.1166044776119403
[2m[36m(func pid=124580)[0m f1_macro: 0.08124558752642339
[2m[36m(func pid=124580)[0m f1_weighted: 0.09262094924317862
[2m[36m(func pid=124580)[0m f1_per_class: [0.036, 0.232, 0.049, 0.168, 0.2, 0.008, 0.0, 0.021, 0.0, 0.098]
[2m[36m(func pid=124580)[0m 
== Status ==
Current time: 2024-01-07 02:59:27 (running for 00:35:28.49)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  1.487 |      0.256 |                   28 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  1.831 |      0.081 |                    7 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  8.177 |      0.011 |                    6 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  3.078 |      0.044 |                    2 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.28125
[2m[36m(func pid=120129)[0m top5: 0.8847947761194029
[2m[36m(func pid=120129)[0m f1_micro: 0.28125
[2m[36m(func pid=120129)[0m f1_macro: 0.255770636971311
[2m[36m(func pid=120129)[0m f1_weighted: 0.2983246809567434
[2m[36m(func pid=120129)[0m f1_per_class: [0.057, 0.556, 0.182, 0.168, 0.129, 0.24, 0.304, 0.451, 0.134, 0.337]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=126248)[0m top1: 0.18703358208955223
[2m[36m(func pid=126248)[0m top5: 0.566231343283582
[2m[36m(func pid=126248)[0m f1_micro: 0.18703358208955223
[2m[36m(func pid=126248)[0m f1_macro: 0.04807590214748032
[2m[36m(func pid=126248)[0m f1_weighted: 0.09973709929342249
[2m[36m(func pid=126248)[0m f1_per_class: [0.0, 0.0, 0.0, 0.325, 0.0, 0.0, 0.0, 0.155, 0.0, 0.0]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 3.0677 | Steps: 2 | Val loss: 891034.8750 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 1.8242 | Steps: 2 | Val loss: 7.0399 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.7902 | Steps: 2 | Val loss: 3.3566 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=125328)[0m top1: 0.006063432835820896
[2m[36m(func pid=125328)[0m top5: 0.5093283582089553
[2m[36m(func pid=125328)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=125328)[0m f1_macro: 0.001205377839592026
[2m[36m(func pid=125328)[0m f1_weighted: 7.308727572153144e-05
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=124580)[0m top1: 0.0960820895522388
[2m[36m(func pid=124580)[0m top5: 0.7271455223880597
[2m[36m(func pid=124580)[0m f1_micro: 0.0960820895522388
[2m[36m(func pid=124580)[0m f1_macro: 0.07895520369676824
[2m[36m(func pid=124580)[0m f1_weighted: 0.08334058042284054
[2m[36m(func pid=124580)[0m f1_per_class: [0.015, 0.279, 0.044, 0.084, 0.098, 0.047, 0.0, 0.059, 0.0, 0.165]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 2.9812 | Steps: 2 | Val loss: 2.3138 | Batch size: 32 | lr: 0.0001 | Duration: 3.22s
== Status ==
Current time: 2024-01-07 02:59:32 (running for 00:35:33.77)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.79  |      0.256 |                   29 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  1.824 |      0.079 |                    8 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  3.068 |      0.001 |                    7 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  3.063 |      0.048 |                    3 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.27798507462686567
[2m[36m(func pid=120129)[0m top5: 0.8754664179104478
[2m[36m(func pid=120129)[0m f1_micro: 0.27798507462686567
[2m[36m(func pid=120129)[0m f1_macro: 0.2555321528428107
[2m[36m(func pid=120129)[0m f1_weighted: 0.2941020467643233
[2m[36m(func pid=120129)[0m f1_per_class: [0.047, 0.565, 0.145, 0.121, 0.118, 0.309, 0.297, 0.479, 0.157, 0.318]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 2.6750 | Steps: 2 | Val loss: 753452.3125 | Batch size: 32 | lr: 0.1 | Duration: 2.67s
[2m[36m(func pid=126248)[0m top1: 0.19636194029850745
[2m[36m(func pid=126248)[0m top5: 0.5769589552238806
[2m[36m(func pid=126248)[0m f1_micro: 0.19636194029850748
[2m[36m(func pid=126248)[0m f1_macro: 0.04113458972040917
[2m[36m(func pid=126248)[0m f1_weighted: 0.10117881308940252
[2m[36m(func pid=126248)[0m f1_per_class: [0.0, 0.0, 0.0, 0.35, 0.0, 0.0, 0.0, 0.061, 0.0, 0.0]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 1.4898 | Steps: 2 | Val loss: 8.4213 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=125328)[0m top1: 0.006063432835820896
[2m[36m(func pid=125328)[0m top5: 0.5093283582089553
[2m[36m(func pid=125328)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=125328)[0m f1_macro: 0.001205377839592026
[2m[36m(func pid=125328)[0m f1_weighted: 7.308727572153144e-05
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.7691 | Steps: 2 | Val loss: 3.4824 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
[2m[36m(func pid=124580)[0m top1: 0.10307835820895522
[2m[36m(func pid=124580)[0m top5: 0.6907649253731343
[2m[36m(func pid=124580)[0m f1_micro: 0.10307835820895522
[2m[36m(func pid=124580)[0m f1_macro: 0.07599919769580835
[2m[36m(func pid=124580)[0m f1_weighted: 0.08045598642994349
[2m[36m(func pid=124580)[0m f1_per_class: [0.0, 0.362, 0.036, 0.01, 0.056, 0.061, 0.0, 0.08, 0.062, 0.093]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 2.9471 | Steps: 2 | Val loss: 2.3160 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 02:59:38 (running for 00:35:39.06)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.769 |      0.255 |                   30 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  1.49  |      0.076 |                    9 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  2.675 |      0.001 |                    8 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.981 |      0.041 |                    4 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.27798507462686567
[2m[36m(func pid=120129)[0m top5: 0.8680037313432836
[2m[36m(func pid=120129)[0m f1_micro: 0.27798507462686567
[2m[36m(func pid=120129)[0m f1_macro: 0.25514124014428663
[2m[36m(func pid=120129)[0m f1_weighted: 0.29184748125887516
[2m[36m(func pid=120129)[0m f1_per_class: [0.042, 0.569, 0.134, 0.113, 0.119, 0.316, 0.293, 0.468, 0.154, 0.343]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 2.1467 | Steps: 2 | Val loss: 595141.5625 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 1.5759 | Steps: 2 | Val loss: 13.6536 | Batch size: 32 | lr: 0.01 | Duration: 2.72s
[2m[36m(func pid=126248)[0m top1: 0.20615671641791045
[2m[36m(func pid=126248)[0m top5: 0.5806902985074627
[2m[36m(func pid=126248)[0m f1_micro: 0.20615671641791045
[2m[36m(func pid=126248)[0m f1_macro: 0.06471704529482623
[2m[36m(func pid=126248)[0m f1_weighted: 0.1043089048679458
[2m[36m(func pid=126248)[0m f1_per_class: [0.0, 0.0, 0.25, 0.361, 0.0, 0.0, 0.0, 0.036, 0.0, 0.0]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=125328)[0m top1: 0.006063432835820896
[2m[36m(func pid=125328)[0m top5: 0.5093283582089553
[2m[36m(func pid=125328)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=125328)[0m f1_macro: 0.001205377839592026
[2m[36m(func pid=125328)[0m f1_weighted: 7.308727572153144e-05
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.6750 | Steps: 2 | Val loss: 3.7005 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=124580)[0m top1: 0.06996268656716417
[2m[36m(func pid=124580)[0m top5: 0.7159514925373134
[2m[36m(func pid=124580)[0m f1_micro: 0.06996268656716417
[2m[36m(func pid=124580)[0m f1_macro: 0.07421305757051641
[2m[36m(func pid=124580)[0m f1_weighted: 0.066574214959154
[2m[36m(func pid=124580)[0m f1_per_class: [0.0, 0.293, 0.028, 0.0, 0.13, 0.054, 0.003, 0.09, 0.053, 0.092]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 2.9221 | Steps: 2 | Val loss: 2.3194 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 02:59:43 (running for 00:35:44.21)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.675 |      0.24  |                   31 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  1.576 |      0.074 |                   10 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  2.147 |      0.001 |                    9 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.947 |      0.065 |                    5 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.2653917910447761
[2m[36m(func pid=120129)[0m top5: 0.8563432835820896
[2m[36m(func pid=120129)[0m f1_micro: 0.2653917910447761
[2m[36m(func pid=120129)[0m f1_macro: 0.24047719199651008
[2m[36m(func pid=120129)[0m f1_weighted: 0.27431316089381685
[2m[36m(func pid=120129)[0m f1_per_class: [0.038, 0.574, 0.118, 0.11, 0.114, 0.236, 0.274, 0.431, 0.135, 0.375]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 2.3805 | Steps: 2 | Val loss: 549496.7500 | Batch size: 32 | lr: 0.1 | Duration: 2.74s
[2m[36m(func pid=126248)[0m top1: 0.2150186567164179
[2m[36m(func pid=126248)[0m top5: 0.5755597014925373
[2m[36m(func pid=126248)[0m f1_micro: 0.2150186567164179
[2m[36m(func pid=126248)[0m f1_macro: 0.061276218082334556
[2m[36m(func pid=126248)[0m f1_weighted: 0.1069005044191821
[2m[36m(func pid=126248)[0m f1_per_class: [0.0, 0.0, 0.211, 0.373, 0.0, 0.0, 0.0, 0.03, 0.0, 0.0]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 1.8250 | Steps: 2 | Val loss: 13.8826 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=125328)[0m top1: 0.006063432835820896
[2m[36m(func pid=125328)[0m top5: 0.5093283582089553
[2m[36m(func pid=125328)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=125328)[0m f1_macro: 0.001205377839592026
[2m[36m(func pid=125328)[0m f1_weighted: 7.308727572153144e-05
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.7939 | Steps: 2 | Val loss: 3.6472 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=124580)[0m top1: 0.08768656716417911
[2m[36m(func pid=124580)[0m top5: 0.7089552238805971
[2m[36m(func pid=124580)[0m f1_micro: 0.08768656716417911
[2m[36m(func pid=124580)[0m f1_macro: 0.08010882882178706
[2m[36m(func pid=124580)[0m f1_weighted: 0.0738542097449778
[2m[36m(func pid=124580)[0m f1_per_class: [0.0, 0.314, 0.033, 0.0, 0.143, 0.09, 0.0, 0.124, 0.0, 0.097]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 2.8621 | Steps: 2 | Val loss: 2.3224 | Batch size: 32 | lr: 0.0001 | Duration: 3.06s
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 2.4280 | Steps: 2 | Val loss: 410389.0000 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 02:59:48 (running for 00:35:49.45)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.794 |      0.219 |                   32 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  1.825 |      0.08  |                   11 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  2.381 |      0.001 |                   10 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.922 |      0.061 |                    6 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.25093283582089554
[2m[36m(func pid=120129)[0m top5: 0.8530783582089553
[2m[36m(func pid=120129)[0m f1_micro: 0.25093283582089554
[2m[36m(func pid=120129)[0m f1_macro: 0.21947407766843438
[2m[36m(func pid=120129)[0m f1_weighted: 0.2445833445354195
[2m[36m(func pid=120129)[0m f1_per_class: [0.039, 0.572, 0.126, 0.151, 0.102, 0.143, 0.187, 0.371, 0.11, 0.394]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=126248)[0m top1: 0.22154850746268656
[2m[36m(func pid=126248)[0m top5: 0.5746268656716418
[2m[36m(func pid=126248)[0m f1_micro: 0.22154850746268656
[2m[36m(func pid=126248)[0m f1_macro: 0.06914970423232909
[2m[36m(func pid=126248)[0m f1_weighted: 0.10898535418262276
[2m[36m(func pid=126248)[0m f1_per_class: [0.0, 0.0, 0.286, 0.379, 0.0, 0.0, 0.0, 0.027, 0.0, 0.0]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 2.1411 | Steps: 2 | Val loss: 10.3129 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=125328)[0m top1: 0.006063432835820896
[2m[36m(func pid=125328)[0m top5: 0.5093283582089553
[2m[36m(func pid=125328)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=125328)[0m f1_macro: 0.001205377839592026
[2m[36m(func pid=125328)[0m f1_weighted: 7.308727572153144e-05
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.7469 | Steps: 2 | Val loss: 3.6854 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=124580)[0m top1: 0.1394589552238806
[2m[36m(func pid=124580)[0m top5: 0.777518656716418
[2m[36m(func pid=124580)[0m f1_micro: 0.1394589552238806
[2m[36m(func pid=124580)[0m f1_macro: 0.09401343668500256
[2m[36m(func pid=124580)[0m f1_weighted: 0.08104812861468738
[2m[36m(func pid=124580)[0m f1_per_class: [0.0, 0.307, 0.183, 0.02, 0.083, 0.082, 0.0, 0.182, 0.0, 0.082]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 2.8436 | Steps: 2 | Val loss: 2.3227 | Batch size: 32 | lr: 0.0001 | Duration: 3.18s
== Status ==
Current time: 2024-01-07 02:59:53 (running for 00:35:54.76)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.747 |      0.218 |                   33 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  2.141 |      0.094 |                   12 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  2.428 |      0.001 |                   11 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.862 |      0.069 |                    7 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.25466417910447764
[2m[36m(func pid=120129)[0m top5: 0.8493470149253731
[2m[36m(func pid=120129)[0m f1_micro: 0.25466417910447764
[2m[36m(func pid=120129)[0m f1_macro: 0.2183472678951414
[2m[36m(func pid=120129)[0m f1_weighted: 0.2430859957418893
[2m[36m(func pid=120129)[0m f1_per_class: [0.047, 0.573, 0.127, 0.211, 0.11, 0.112, 0.143, 0.331, 0.107, 0.423]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 11.3295 | Steps: 2 | Val loss: 66988.3750 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 1.5206 | Steps: 2 | Val loss: 18.1193 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=126248)[0m top1: 0.22994402985074627
[2m[36m(func pid=126248)[0m top5: 0.5750932835820896
[2m[36m(func pid=126248)[0m f1_micro: 0.22994402985074627
[2m[36m(func pid=126248)[0m f1_macro: 0.06241760185530946
[2m[36m(func pid=126248)[0m f1_weighted: 0.11143460619408413
[2m[36m(func pid=126248)[0m f1_per_class: [0.0, 0.0, 0.2, 0.388, 0.0, 0.0, 0.0, 0.037, 0.0, 0.0]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=125328)[0m top1: 0.006063432835820896
[2m[36m(func pid=125328)[0m top5: 0.5093283582089553
[2m[36m(func pid=125328)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=125328)[0m f1_macro: 0.001205377839592026
[2m[36m(func pid=125328)[0m f1_weighted: 7.308727572153144e-05
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.7151 | Steps: 2 | Val loss: 4.4669 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=124580)[0m top1: 0.03544776119402985
[2m[36m(func pid=124580)[0m top5: 0.5555037313432836
[2m[36m(func pid=124580)[0m f1_micro: 0.03544776119402985
[2m[36m(func pid=124580)[0m f1_macro: 0.040067094233109266
[2m[36m(func pid=124580)[0m f1_weighted: 0.03701976036829117
[2m[36m(func pid=124580)[0m f1_per_class: [0.0, 0.125, 0.053, 0.029, 0.148, 0.0, 0.019, 0.0, 0.0, 0.026]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 2.7688 | Steps: 2 | Val loss: 2.3257 | Batch size: 32 | lr: 0.0001 | Duration: 3.11s
== Status ==
Current time: 2024-01-07 02:59:59 (running for 00:36:00.03)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.715 |      0.206 |                   34 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  1.521 |      0.04  |                   13 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  | 11.329 |      0.001 |                   12 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.844 |      0.062 |                    8 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.23274253731343283
[2m[36m(func pid=120129)[0m top5: 0.8302238805970149
[2m[36m(func pid=120129)[0m f1_micro: 0.23274253731343286
[2m[36m(func pid=120129)[0m f1_macro: 0.2058090013413481
[2m[36m(func pid=120129)[0m f1_weighted: 0.22421042826794832
[2m[36m(func pid=120129)[0m f1_per_class: [0.031, 0.558, 0.087, 0.171, 0.146, 0.171, 0.108, 0.317, 0.124, 0.345]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 2.9359 | Steps: 2 | Val loss: 121654.5859 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 1.8061 | Steps: 2 | Val loss: 20.7757 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
[2m[36m(func pid=126248)[0m top1: 0.2294776119402985
[2m[36m(func pid=126248)[0m top5: 0.570429104477612
[2m[36m(func pid=126248)[0m f1_micro: 0.2294776119402985
[2m[36m(func pid=126248)[0m f1_macro: 0.057923999921059954
[2m[36m(func pid=126248)[0m f1_weighted: 0.11229804254011062
[2m[36m(func pid=126248)[0m f1_per_class: [0.0, 0.011, 0.148, 0.386, 0.0, 0.0, 0.0, 0.035, 0.0, 0.0]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=125328)[0m top1: 0.006063432835820896
[2m[36m(func pid=125328)[0m top5: 0.5093283582089553
[2m[36m(func pid=125328)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=125328)[0m f1_macro: 0.001205377839592026
[2m[36m(func pid=125328)[0m f1_weighted: 7.308727572153144e-05
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.6457 | Steps: 2 | Val loss: 5.2570 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=124580)[0m top1: 0.05177238805970149
[2m[36m(func pid=124580)[0m top5: 0.6944962686567164
[2m[36m(func pid=124580)[0m f1_micro: 0.05177238805970149
[2m[36m(func pid=124580)[0m f1_macro: 0.06280594250542927
[2m[36m(func pid=124580)[0m f1_weighted: 0.043776412119206874
[2m[36m(func pid=124580)[0m f1_per_class: [0.0, 0.052, 0.028, 0.02, 0.263, 0.047, 0.05, 0.107, 0.0, 0.061]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 33.4316 | Steps: 2 | Val loss: 14704.1953 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 2.6939 | Steps: 2 | Val loss: 2.3264 | Batch size: 32 | lr: 0.0001 | Duration: 3.25s
== Status ==
Current time: 2024-01-07 03:00:04 (running for 00:36:05.43)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.646 |      0.198 |                   35 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  1.806 |      0.063 |                   14 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  2.936 |      0.001 |                   13 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.769 |      0.058 |                    9 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.21875
[2m[36m(func pid=120129)[0m top5: 0.8073694029850746
[2m[36m(func pid=120129)[0m f1_micro: 0.21875
[2m[36m(func pid=120129)[0m f1_macro: 0.19757091604831598
[2m[36m(func pid=120129)[0m f1_weighted: 0.22270039292006852
[2m[36m(func pid=120129)[0m f1_per_class: [0.02, 0.505, 0.073, 0.189, 0.161, 0.201, 0.104, 0.339, 0.129, 0.254]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 1.9701 | Steps: 2 | Val loss: 32.6336 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=125328)[0m top1: 0.006063432835820896
[2m[36m(func pid=125328)[0m top5: 0.5111940298507462
[2m[36m(func pid=125328)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=125328)[0m f1_macro: 0.0012166588675713616
[2m[36m(func pid=125328)[0m f1_weighted: 7.37712932762486e-05
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=126248)[0m top1: 0.2234141791044776
[2m[36m(func pid=126248)[0m top5: 0.574160447761194
[2m[36m(func pid=126248)[0m f1_micro: 0.2234141791044776
[2m[36m(func pid=126248)[0m f1_macro: 0.05688712375167295
[2m[36m(func pid=126248)[0m f1_weighted: 0.11004673690225542
[2m[36m(func pid=126248)[0m f1_per_class: [0.041, 0.005, 0.107, 0.378, 0.0, 0.0, 0.0, 0.037, 0.0, 0.0]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.6416 | Steps: 2 | Val loss: 5.2123 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=124580)[0m top1: 0.027985074626865673
[2m[36m(func pid=124580)[0m top5: 0.5685634328358209
[2m[36m(func pid=124580)[0m f1_micro: 0.027985074626865673
[2m[36m(func pid=124580)[0m f1_macro: 0.053272761994601625
[2m[36m(func pid=124580)[0m f1_weighted: 0.019050910923286927
[2m[36m(func pid=124580)[0m f1_per_class: [0.0, 0.027, 0.023, 0.01, 0.333, 0.047, 0.0, 0.057, 0.0, 0.036]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=120129)[0m top1: 0.22294776119402984
[2m[36m(func pid=120129)[0m top5: 0.8050373134328358
[2m[36m(func pid=120129)[0m f1_micro: 0.22294776119402981
[2m[36m(func pid=120129)[0m f1_macro: 0.20329816633875364
[2m[36m(func pid=120129)[0m f1_weighted: 0.23205645395004185
[2m[36m(func pid=120129)[0m f1_per_class: [0.024, 0.493, 0.076, 0.22, 0.165, 0.217, 0.109, 0.326, 0.124, 0.279]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 3.0193 | Steps: 2 | Val loss: 7961.3638 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 03:00:09 (running for 00:36:10.68)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.642 |      0.203 |                   36 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  1.97  |      0.053 |                   15 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  | 33.432 |      0.001 |                   14 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.694 |      0.057 |                   10 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 2.6861 | Steps: 2 | Val loss: 2.3261 | Batch size: 32 | lr: 0.0001 | Duration: 3.04s
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 1.5407 | Steps: 2 | Val loss: 27.7189 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=125328)[0m top1: 0.006063432835820896
[2m[36m(func pid=125328)[0m top5: 0.5107276119402985
[2m[36m(func pid=125328)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=125328)[0m f1_macro: 0.0012974051896207585
[2m[36m(func pid=125328)[0m f1_weighted: 7.866729228110941e-05
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.0, 0.013, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=126248)[0m top1: 0.2150186567164179
[2m[36m(func pid=126248)[0m top5: 0.5746268656716418
[2m[36m(func pid=126248)[0m f1_micro: 0.2150186567164179
[2m[36m(func pid=126248)[0m f1_macro: 0.05537533513851892
[2m[36m(func pid=126248)[0m f1_weighted: 0.10936113254880886
[2m[36m(func pid=126248)[0m f1_per_class: [0.0, 0.0, 0.078, 0.368, 0.0, 0.0, 0.0, 0.108, 0.0, 0.0]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.6747 | Steps: 2 | Val loss: 5.0379 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=124580)[0m top1: 0.036380597014925374
[2m[36m(func pid=124580)[0m top5: 0.6702425373134329
[2m[36m(func pid=124580)[0m f1_micro: 0.036380597014925374
[2m[36m(func pid=124580)[0m f1_macro: 0.045754216398047644
[2m[36m(func pid=124580)[0m f1_weighted: 0.019767698962183125
[2m[36m(func pid=124580)[0m f1_per_class: [0.0, 0.021, 0.028, 0.003, 0.179, 0.077, 0.0, 0.068, 0.0, 0.081]
[2m[36m(func pid=124580)[0m 
== Status ==
Current time: 2024-01-07 03:00:15 (running for 00:36:15.91)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.675 |      0.207 |                   37 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  1.541 |      0.046 |                   16 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  3.019 |      0.001 |                   15 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.686 |      0.055 |                   11 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.228544776119403
[2m[36m(func pid=120129)[0m top5: 0.8092350746268657
[2m[36m(func pid=120129)[0m f1_micro: 0.228544776119403
[2m[36m(func pid=120129)[0m f1_macro: 0.20672467892175778
[2m[36m(func pid=120129)[0m f1_weighted: 0.2444291978402042
[2m[36m(func pid=120129)[0m f1_per_class: [0.028, 0.481, 0.082, 0.245, 0.136, 0.185, 0.147, 0.31, 0.136, 0.317]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 2.6887 | Steps: 2 | Val loss: 6619.2358 | Batch size: 32 | lr: 0.1 | Duration: 3.03s
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 2.6565 | Steps: 2 | Val loss: 2.3257 | Batch size: 32 | lr: 0.0001 | Duration: 3.04s
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 1.6356 | Steps: 2 | Val loss: 21.4020 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=125328)[0m top1: 0.014458955223880597
[2m[36m(func pid=125328)[0m top5: 0.5111940298507462
[2m[36m(func pid=125328)[0m f1_micro: 0.014458955223880597
[2m[36m(func pid=125328)[0m f1_macro: 0.007521347976005036
[2m[36m(func pid=125328)[0m f1_weighted: 0.015204863898180331
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.02, 0.013, 0.042, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.4713 | Steps: 2 | Val loss: 4.5135 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=126248)[0m top1: 0.20382462686567165
[2m[36m(func pid=126248)[0m top5: 0.5755597014925373
[2m[36m(func pid=126248)[0m f1_micro: 0.20382462686567165
[2m[36m(func pid=126248)[0m f1_macro: 0.05841244091740831
[2m[36m(func pid=126248)[0m f1_weighted: 0.1097396409459641
[2m[36m(func pid=126248)[0m f1_per_class: [0.0, 0.005, 0.062, 0.355, 0.0, 0.0, 0.0, 0.161, 0.0, 0.0]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=124580)[0m top1: 0.054104477611940295
[2m[36m(func pid=124580)[0m top5: 0.7215485074626866
[2m[36m(func pid=124580)[0m f1_micro: 0.054104477611940295
[2m[36m(func pid=124580)[0m f1_macro: 0.054632757834743195
[2m[36m(func pid=124580)[0m f1_weighted: 0.04556800403223636
[2m[36m(func pid=124580)[0m f1_per_class: [0.0, 0.15, 0.035, 0.01, 0.118, 0.081, 0.003, 0.084, 0.0, 0.065]
[2m[36m(func pid=124580)[0m 
== Status ==
Current time: 2024-01-07 03:00:20 (running for 00:36:21.12)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.471 |      0.213 |                   38 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  1.636 |      0.055 |                   17 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  2.689 |      0.008 |                   16 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.656 |      0.058 |                   12 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.24813432835820895
[2m[36m(func pid=120129)[0m top5: 0.8152985074626866
[2m[36m(func pid=120129)[0m f1_micro: 0.24813432835820895
[2m[36m(func pid=120129)[0m f1_macro: 0.2126044151726536
[2m[36m(func pid=120129)[0m f1_weighted: 0.27426915714290256
[2m[36m(func pid=120129)[0m f1_per_class: [0.027, 0.453, 0.091, 0.28, 0.113, 0.172, 0.233, 0.344, 0.12, 0.294]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 2.5841 | Steps: 2 | Val loss: 3907.9883 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 1.1957 | Steps: 2 | Val loss: 11.5032 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 2.6240 | Steps: 2 | Val loss: 2.3246 | Batch size: 32 | lr: 0.0001 | Duration: 3.26s
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.4858 | Steps: 2 | Val loss: 3.9799 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=125328)[0m top1: 0.03871268656716418
[2m[36m(func pid=125328)[0m top5: 0.4925373134328358
[2m[36m(func pid=125328)[0m f1_micro: 0.03871268656716418
[2m[36m(func pid=125328)[0m f1_macro: 0.019378015933142957
[2m[36m(func pid=125328)[0m f1_weighted: 0.04669148551656721
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.033, 0.014, 0.144, 0.0, 0.0, 0.003, 0.0, 0.0, 0.0]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=124580)[0m top1: 0.18983208955223882
[2m[36m(func pid=124580)[0m top5: 0.8148320895522388
[2m[36m(func pid=124580)[0m f1_micro: 0.18983208955223882
[2m[36m(func pid=124580)[0m f1_macro: 0.09659215457092406
[2m[36m(func pid=124580)[0m f1_weighted: 0.14814953298804465
[2m[36m(func pid=124580)[0m f1_per_class: [0.0, 0.383, 0.0, 0.007, 0.0, 0.079, 0.192, 0.23, 0.0, 0.075]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=126248)[0m top1: 0.19402985074626866
[2m[36m(func pid=126248)[0m top5: 0.5816231343283582
[2m[36m(func pid=126248)[0m f1_micro: 0.19402985074626866
[2m[36m(func pid=126248)[0m f1_macro: 0.06841664663247189
[2m[36m(func pid=126248)[0m f1_weighted: 0.11202534910668992
[2m[36m(func pid=126248)[0m f1_per_class: [0.0, 0.0, 0.056, 0.341, 0.0, 0.0, 0.0, 0.287, 0.0, 0.0]
[2m[36m(func pid=126248)[0m 
== Status ==
Current time: 2024-01-07 03:00:25 (running for 00:36:26.51)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.486 |      0.248 |                   39 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  1.196 |      0.097 |                   18 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  2.584 |      0.019 |                   17 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.624 |      0.068 |                   13 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.30223880597014924
[2m[36m(func pid=120129)[0m top5: 0.8199626865671642
[2m[36m(func pid=120129)[0m f1_micro: 0.30223880597014924
[2m[36m(func pid=120129)[0m f1_macro: 0.24817950122057292
[2m[36m(func pid=120129)[0m f1_weighted: 0.3437222083201771
[2m[36m(func pid=120129)[0m f1_per_class: [0.037, 0.458, 0.106, 0.314, 0.109, 0.247, 0.384, 0.443, 0.108, 0.276]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 2.3482 | Steps: 2 | Val loss: 2494.2927 | Batch size: 32 | lr: 0.1 | Duration: 2.73s
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 1.7218 | Steps: 2 | Val loss: 13.0489 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 2.6301 | Steps: 2 | Val loss: 2.3241 | Batch size: 32 | lr: 0.0001 | Duration: 3.10s
[2m[36m(func pid=125328)[0m top1: 0.06063432835820896
[2m[36m(func pid=125328)[0m top5: 0.47761194029850745
[2m[36m(func pid=125328)[0m f1_micro: 0.06063432835820896
[2m[36m(func pid=125328)[0m f1_macro: 0.0324247887768213
[2m[36m(func pid=125328)[0m f1_weighted: 0.07543313767041343
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.105, 0.016, 0.18, 0.0, 0.0, 0.024, 0.0, 0.0, 0.0]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.5058 | Steps: 2 | Val loss: 3.7780 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=124580)[0m top1: 0.2103544776119403
[2m[36m(func pid=124580)[0m top5: 0.773320895522388
[2m[36m(func pid=124580)[0m f1_micro: 0.2103544776119403
[2m[36m(func pid=124580)[0m f1_macro: 0.10908652008010619
[2m[36m(func pid=124580)[0m f1_weighted: 0.15290169034788187
[2m[36m(func pid=124580)[0m f1_per_class: [0.0, 0.356, 0.0, 0.02, 0.0, 0.233, 0.163, 0.157, 0.0, 0.162]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=126248)[0m top1: 0.1837686567164179
[2m[36m(func pid=126248)[0m top5: 0.5876865671641791
[2m[36m(func pid=126248)[0m f1_micro: 0.18376865671641787
[2m[36m(func pid=126248)[0m f1_macro: 0.07483277085989389
[2m[36m(func pid=126248)[0m f1_weighted: 0.1145942331233405
[2m[36m(func pid=126248)[0m f1_per_class: [0.0, 0.01, 0.047, 0.328, 0.0, 0.0, 0.0, 0.363, 0.0, 0.0]
[2m[36m(func pid=126248)[0m 
== Status ==
Current time: 2024-01-07 03:00:30 (running for 00:36:31.79)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.506 |      0.264 |                   40 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  1.722 |      0.109 |                   19 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  2.348 |      0.032 |                   18 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.63  |      0.075 |                   14 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.32369402985074625
[2m[36m(func pid=120129)[0m top5: 0.8227611940298507
[2m[36m(func pid=120129)[0m f1_micro: 0.32369402985074625
[2m[36m(func pid=120129)[0m f1_macro: 0.26430682846901815
[2m[36m(func pid=120129)[0m f1_weighted: 0.3672526550007495
[2m[36m(func pid=120129)[0m f1_per_class: [0.051, 0.482, 0.124, 0.345, 0.101, 0.28, 0.396, 0.493, 0.123, 0.248]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 2.3402 | Steps: 2 | Val loss: 1435.5031 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 1.0812 | Steps: 2 | Val loss: 16.1210 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 2.5993 | Steps: 2 | Val loss: 2.3200 | Batch size: 32 | lr: 0.0001 | Duration: 3.01s
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.5211 | Steps: 2 | Val loss: 3.4417 | Batch size: 32 | lr: 0.001 | Duration: 2.72s
[2m[36m(func pid=125328)[0m top1: 0.06996268656716417
[2m[36m(func pid=125328)[0m top5: 0.4743470149253731
[2m[36m(func pid=125328)[0m f1_micro: 0.06996268656716417
[2m[36m(func pid=125328)[0m f1_macro: 0.033319748847603595
[2m[36m(func pid=125328)[0m f1_weighted: 0.07521501859522532
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.121, 0.018, 0.195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=124580)[0m top1: 0.13712686567164178
[2m[36m(func pid=124580)[0m top5: 0.7145522388059702
[2m[36m(func pid=124580)[0m f1_micro: 0.13712686567164178
[2m[36m(func pid=124580)[0m f1_macro: 0.08632535215418716
[2m[36m(func pid=124580)[0m f1_weighted: 0.0848310846554812
[2m[36m(func pid=124580)[0m f1_per_class: [0.0, 0.266, 0.0, 0.039, 0.118, 0.068, 0.043, 0.062, 0.0, 0.267]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=126248)[0m top1: 0.18423507462686567
[2m[36m(func pid=126248)[0m top5: 0.5923507462686567
[2m[36m(func pid=126248)[0m f1_micro: 0.1842350746268657
[2m[36m(func pid=126248)[0m f1_macro: 0.08189087362986397
[2m[36m(func pid=126248)[0m f1_weighted: 0.11785711987988114
[2m[36m(func pid=126248)[0m f1_per_class: [0.0, 0.005, 0.046, 0.327, 0.0, 0.0, 0.0, 0.441, 0.0, 0.0]
[2m[36m(func pid=126248)[0m 
== Status ==
Current time: 2024-01-07 03:00:35 (running for 00:36:36.80)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.521 |      0.276 |                   41 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  1.081 |      0.086 |                   20 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  2.34  |      0.033 |                   19 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.599 |      0.082 |                   15 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.34701492537313433
[2m[36m(func pid=120129)[0m top5: 0.8381529850746269
[2m[36m(func pid=120129)[0m f1_micro: 0.34701492537313433
[2m[36m(func pid=120129)[0m f1_macro: 0.2757411761137231
[2m[36m(func pid=120129)[0m f1_weighted: 0.38113752880405
[2m[36m(func pid=120129)[0m f1_per_class: [0.074, 0.516, 0.162, 0.387, 0.102, 0.268, 0.392, 0.455, 0.122, 0.278]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 2.4157 | Steps: 2 | Val loss: 858.0176 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 1.0272 | Steps: 2 | Val loss: 22.4347 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 2.5618 | Steps: 2 | Val loss: 2.3186 | Batch size: 32 | lr: 0.0001 | Duration: 3.22s
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.5169 | Steps: 2 | Val loss: 3.4743 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=125328)[0m top1: 0.08395522388059702
[2m[36m(func pid=125328)[0m top5: 0.42024253731343286
[2m[36m(func pid=125328)[0m f1_micro: 0.08395522388059702
[2m[36m(func pid=125328)[0m f1_macro: 0.0380689639775628
[2m[36m(func pid=125328)[0m f1_weighted: 0.08592422548557481
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.14, 0.019, 0.221, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=124580)[0m top1: 0.12033582089552239
[2m[36m(func pid=124580)[0m top5: 0.6291977611940298
[2m[36m(func pid=124580)[0m f1_micro: 0.12033582089552239
[2m[36m(func pid=124580)[0m f1_macro: 0.057103859473112896
[2m[36m(func pid=124580)[0m f1_weighted: 0.060633113376064716
[2m[36m(func pid=124580)[0m f1_per_class: [0.0, 0.246, 0.0, 0.032, 0.15, 0.024, 0.009, 0.032, 0.0, 0.078]
[2m[36m(func pid=124580)[0m 
== Status ==
Current time: 2024-01-07 03:00:41 (running for 00:36:42.04)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.521 |      0.276 |                   41 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  1.027 |      0.057 |                   21 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  2.416 |      0.038 |                   20 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.562 |      0.083 |                   16 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=126248)[0m top1: 0.17957089552238806
[2m[36m(func pid=126248)[0m top5: 0.5923507462686567
[2m[36m(func pid=126248)[0m f1_micro: 0.17957089552238806
[2m[36m(func pid=126248)[0m f1_macro: 0.08334786774604068
[2m[36m(func pid=126248)[0m f1_weighted: 0.11887337776452658
[2m[36m(func pid=126248)[0m f1_per_class: [0.0, 0.024, 0.045, 0.318, 0.0, 0.0, 0.0, 0.447, 0.0, 0.0]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=120129)[0m top1: 0.3283582089552239
[2m[36m(func pid=120129)[0m top5: 0.8493470149253731
[2m[36m(func pid=120129)[0m f1_micro: 0.3283582089552239
[2m[36m(func pid=120129)[0m f1_macro: 0.2629705256978787
[2m[36m(func pid=120129)[0m f1_weighted: 0.34201183566381305
[2m[36m(func pid=120129)[0m f1_per_class: [0.104, 0.53, 0.216, 0.41, 0.112, 0.155, 0.287, 0.35, 0.149, 0.316]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 2.3849 | Steps: 2 | Val loss: 573.8872 | Batch size: 32 | lr: 0.1 | Duration: 2.74s
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 1.8663 | Steps: 2 | Val loss: 37.4722 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 2.5624 | Steps: 2 | Val loss: 2.3160 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 1.2157 | Steps: 2 | Val loss: 3.8053 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=125328)[0m top1: 0.09701492537313433
[2m[36m(func pid=125328)[0m top5: 0.408115671641791
[2m[36m(func pid=125328)[0m f1_micro: 0.09701492537313433
[2m[36m(func pid=125328)[0m f1_macro: 0.04322471995401076
[2m[36m(func pid=125328)[0m f1_weighted: 0.09736708306883114
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.166, 0.02, 0.246, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=124580)[0m top1: 0.10727611940298508
[2m[36m(func pid=124580)[0m top5: 0.5555037313432836
[2m[36m(func pid=124580)[0m f1_micro: 0.10727611940298508
[2m[36m(func pid=124580)[0m f1_macro: 0.08110376098351157
[2m[36m(func pid=124580)[0m f1_weighted: 0.07748898924768385
[2m[36m(func pid=124580)[0m f1_per_class: [0.041, 0.35, 0.023, 0.02, 0.208, 0.055, 0.003, 0.015, 0.0, 0.096]
[2m[36m(func pid=124580)[0m 
== Status ==
Current time: 2024-01-07 03:00:46 (running for 00:36:47.48)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  1.216 |      0.259 |                   43 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  1.866 |      0.081 |                   22 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  2.385 |      0.043 |                   21 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.562 |      0.083 |                   16 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.3204291044776119
[2m[36m(func pid=120129)[0m top5: 0.84375
[2m[36m(func pid=120129)[0m f1_micro: 0.3204291044776119
[2m[36m(func pid=120129)[0m f1_macro: 0.25949033225495416
[2m[36m(func pid=120129)[0m f1_weighted: 0.3305810141187958
[2m[36m(func pid=120129)[0m f1_per_class: [0.118, 0.551, 0.214, 0.355, 0.112, 0.15, 0.288, 0.357, 0.157, 0.293]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=126248)[0m top1: 0.1828358208955224
[2m[36m(func pid=126248)[0m top5: 0.5970149253731343
[2m[36m(func pid=126248)[0m f1_micro: 0.1828358208955224
[2m[36m(func pid=126248)[0m f1_macro: 0.0916258020255912
[2m[36m(func pid=126248)[0m f1_weighted: 0.12251642662634309
[2m[36m(func pid=126248)[0m f1_per_class: [0.0, 0.028, 0.045, 0.322, 0.0, 0.0, 0.0, 0.465, 0.0, 0.056]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 2.3343 | Steps: 2 | Val loss: 425.1585 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 1.3180 | Steps: 2 | Val loss: 45.9888 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=125328)[0m top1: 0.09514925373134328
[2m[36m(func pid=125328)[0m top5: 0.41138059701492535
[2m[36m(func pid=125328)[0m f1_micro: 0.09514925373134328
[2m[36m(func pid=125328)[0m f1_macro: 0.04386241778156665
[2m[36m(func pid=125328)[0m f1_weighted: 0.10041026712145254
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.159, 0.018, 0.262, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.4985 | Steps: 2 | Val loss: 3.8608 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 2.5076 | Steps: 2 | Val loss: 2.3116 | Batch size: 32 | lr: 0.0001 | Duration: 3.28s
[2m[36m(func pid=124580)[0m top1: 0.08488805970149253
[2m[36m(func pid=124580)[0m top5: 0.5018656716417911
[2m[36m(func pid=124580)[0m f1_micro: 0.08488805970149253
[2m[36m(func pid=124580)[0m f1_macro: 0.04957785332439276
[2m[36m(func pid=124580)[0m f1_weighted: 0.07015129895214152
[2m[36m(func pid=124580)[0m f1_per_class: [0.051, 0.35, 0.0, 0.026, 0.0, 0.008, 0.0, 0.0, 0.0, 0.061]
[2m[36m(func pid=124580)[0m 
== Status ==
Current time: 2024-01-07 03:00:51 (running for 00:36:52.71)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.499 |      0.258 |                   44 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  1.318 |      0.05  |                   23 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  2.334 |      0.044 |                   22 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.562 |      0.092 |                   17 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.31716417910447764
[2m[36m(func pid=120129)[0m top5: 0.8460820895522388
[2m[36m(func pid=120129)[0m f1_micro: 0.31716417910447764
[2m[36m(func pid=120129)[0m f1_macro: 0.258371844646345
[2m[36m(func pid=120129)[0m f1_weighted: 0.3268409550895198
[2m[36m(func pid=120129)[0m f1_per_class: [0.136, 0.549, 0.272, 0.347, 0.109, 0.138, 0.288, 0.355, 0.175, 0.216]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 1.9875 | Steps: 2 | Val loss: 324.2794 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
[2m[36m(func pid=126248)[0m top1: 0.19076492537313433
[2m[36m(func pid=126248)[0m top5: 0.6030783582089553
[2m[36m(func pid=126248)[0m f1_micro: 0.19076492537313436
[2m[36m(func pid=126248)[0m f1_macro: 0.09646558530017232
[2m[36m(func pid=126248)[0m f1_weighted: 0.12972934868133199
[2m[36m(func pid=126248)[0m f1_per_class: [0.0, 0.049, 0.047, 0.33, 0.0, 0.0, 0.0, 0.488, 0.0, 0.05]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 1.3518 | Steps: 2 | Val loss: 40.6782 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.7610 | Steps: 2 | Val loss: 3.8598 | Batch size: 32 | lr: 0.001 | Duration: 2.76s
[2m[36m(func pid=125328)[0m top1: 0.08675373134328358
[2m[36m(func pid=125328)[0m top5: 0.4193097014925373
[2m[36m(func pid=125328)[0m f1_micro: 0.08675373134328358
[2m[36m(func pid=125328)[0m f1_macro: 0.03863141695519172
[2m[36m(func pid=125328)[0m f1_weighted: 0.09358331418287517
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.091, 0.016, 0.279, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 2.5642 | Steps: 2 | Val loss: 2.3092 | Batch size: 32 | lr: 0.0001 | Duration: 3.15s
[2m[36m(func pid=124580)[0m top1: 0.06203358208955224
[2m[36m(func pid=124580)[0m top5: 0.5121268656716418
[2m[36m(func pid=124580)[0m f1_micro: 0.06203358208955224
[2m[36m(func pid=124580)[0m f1_macro: 0.03940472716914731
[2m[36m(func pid=124580)[0m f1_weighted: 0.0560393379829327
[2m[36m(func pid=124580)[0m f1_per_class: [0.053, 0.244, 0.0, 0.045, 0.0, 0.0, 0.0, 0.0, 0.0, 0.053]
[2m[36m(func pid=124580)[0m 
== Status ==
Current time: 2024-01-07 03:00:57 (running for 00:36:57.81)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.761 |      0.263 |                   45 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  1.352 |      0.039 |                   24 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  1.988 |      0.039 |                   23 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.508 |      0.096 |                   18 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.3045708955223881
[2m[36m(func pid=120129)[0m top5: 0.8526119402985075
[2m[36m(func pid=120129)[0m f1_micro: 0.3045708955223881
[2m[36m(func pid=120129)[0m f1_macro: 0.26307662245229346
[2m[36m(func pid=120129)[0m f1_weighted: 0.3166955939354447
[2m[36m(func pid=120129)[0m f1_per_class: [0.136, 0.525, 0.417, 0.34, 0.086, 0.178, 0.262, 0.34, 0.155, 0.191]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 2.1426 | Steps: 2 | Val loss: 268.0130 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=126248)[0m top1: 0.19496268656716417
[2m[36m(func pid=126248)[0m top5: 0.6105410447761194
[2m[36m(func pid=126248)[0m f1_micro: 0.19496268656716417
[2m[36m(func pid=126248)[0m f1_macro: 0.09857623755579645
[2m[36m(func pid=126248)[0m f1_weighted: 0.13374890425360153
[2m[36m(func pid=126248)[0m f1_per_class: [0.0, 0.065, 0.049, 0.336, 0.0, 0.0, 0.0, 0.485, 0.0, 0.051]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 1.0992 | Steps: 2 | Val loss: 38.6990 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.4244 | Steps: 2 | Val loss: 4.0000 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
[2m[36m(func pid=125328)[0m top1: 0.05643656716417911
[2m[36m(func pid=125328)[0m top5: 0.4216417910447761
[2m[36m(func pid=125328)[0m f1_micro: 0.05643656716417911
[2m[36m(func pid=125328)[0m f1_macro: 0.028218177127423916
[2m[36m(func pid=125328)[0m f1_weighted: 0.06999407670861689
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.041, 0.016, 0.225, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=124580)[0m top1: 0.03264925373134328
[2m[36m(func pid=124580)[0m top5: 0.5564365671641791
[2m[36m(func pid=124580)[0m f1_micro: 0.03264925373134328
[2m[36m(func pid=124580)[0m f1_macro: 0.044888244093204056
[2m[36m(func pid=124580)[0m f1_weighted: 0.020625113267710507
[2m[36m(func pid=124580)[0m f1_per_class: [0.06, 0.031, 0.0, 0.042, 0.286, 0.0, 0.0, 0.0, 0.0, 0.031]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 2.4698 | Steps: 2 | Val loss: 2.3078 | Batch size: 32 | lr: 0.0001 | Duration: 3.07s
== Status ==
Current time: 2024-01-07 03:01:02 (running for 00:37:03.03)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.424 |      0.284 |                   46 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  1.099 |      0.045 |                   25 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  2.143 |      0.028 |                   24 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.564 |      0.099 |                   19 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.30177238805970147
[2m[36m(func pid=120129)[0m top5: 0.8456156716417911
[2m[36m(func pid=120129)[0m f1_micro: 0.30177238805970147
[2m[36m(func pid=120129)[0m f1_macro: 0.2837473210254207
[2m[36m(func pid=120129)[0m f1_weighted: 0.3216879072372655
[2m[36m(func pid=120129)[0m f1_per_class: [0.121, 0.52, 0.5, 0.312, 0.105, 0.262, 0.267, 0.355, 0.195, 0.2]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 2.1018 | Steps: 2 | Val loss: 215.8130 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=126248)[0m top1: 0.19309701492537312
[2m[36m(func pid=126248)[0m top5: 0.6142723880597015
[2m[36m(func pid=126248)[0m f1_micro: 0.19309701492537315
[2m[36m(func pid=126248)[0m f1_macro: 0.10147846045820386
[2m[36m(func pid=126248)[0m f1_weighted: 0.13664051179113512
[2m[36m(func pid=126248)[0m f1_per_class: [0.0, 0.087, 0.05, 0.33, 0.0, 0.0, 0.0, 0.496, 0.0, 0.051]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.8799 | Steps: 2 | Val loss: 40.3870 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.4421 | Steps: 2 | Val loss: 4.3732 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=125328)[0m top1: 0.03264925373134328
[2m[36m(func pid=125328)[0m top5: 0.42024253731343286
[2m[36m(func pid=125328)[0m f1_micro: 0.03264925373134328
[2m[36m(func pid=125328)[0m f1_macro: 0.01874053894581182
[2m[36m(func pid=125328)[0m f1_weighted: 0.043944544847550816
[2m[36m(func pid=125328)[0m f1_per_class: [0.005, 0.026, 0.016, 0.141, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=124580)[0m top1: 0.024720149253731342
[2m[36m(func pid=124580)[0m top5: 0.5270522388059702
[2m[36m(func pid=124580)[0m f1_micro: 0.024720149253731342
[2m[36m(func pid=124580)[0m f1_macro: 0.04728435155994426
[2m[36m(func pid=124580)[0m f1_weighted: 0.013733350694756905
[2m[36m(func pid=124580)[0m f1_per_class: [0.048, 0.0, 0.0, 0.032, 0.348, 0.0, 0.0, 0.014, 0.0, 0.03]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 2.4637 | Steps: 2 | Val loss: 2.3058 | Batch size: 32 | lr: 0.0001 | Duration: 3.16s
== Status ==
Current time: 2024-01-07 03:01:07 (running for 00:37:08.30)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.442 |      0.287 |                   47 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.88  |      0.047 |                   26 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  2.102 |      0.019 |                   25 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.47  |      0.101 |                   20 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.271455223880597
[2m[36m(func pid=120129)[0m top5: 0.8498134328358209
[2m[36m(func pid=120129)[0m f1_micro: 0.271455223880597
[2m[36m(func pid=120129)[0m f1_macro: 0.2865208045220933
[2m[36m(func pid=120129)[0m f1_weighted: 0.2846844330814107
[2m[36m(func pid=120129)[0m f1_per_class: [0.114, 0.488, 0.6, 0.294, 0.154, 0.22, 0.192, 0.322, 0.242, 0.239]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 1.8900 | Steps: 2 | Val loss: 170.4569 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.7952 | Steps: 2 | Val loss: 40.1469 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=126248)[0m top1: 0.18889925373134328
[2m[36m(func pid=126248)[0m top5: 0.621268656716418
[2m[36m(func pid=126248)[0m f1_micro: 0.18889925373134325
[2m[36m(func pid=126248)[0m f1_macro: 0.10318221607575469
[2m[36m(func pid=126248)[0m f1_weighted: 0.13412835812514662
[2m[36m(func pid=126248)[0m f1_per_class: [0.023, 0.076, 0.052, 0.324, 0.0, 0.008, 0.0, 0.49, 0.0, 0.059]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.3944 | Steps: 2 | Val loss: 5.1799 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=125328)[0m top1: 0.05830223880597015
[2m[36m(func pid=125328)[0m top5: 0.4221082089552239
[2m[36m(func pid=125328)[0m f1_micro: 0.05830223880597015
[2m[36m(func pid=125328)[0m f1_macro: 0.033286363115139404
[2m[36m(func pid=125328)[0m f1_weighted: 0.06017423380381464
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.264, 0.016, 0.053, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=124580)[0m top1: 0.03731343283582089
[2m[36m(func pid=124580)[0m top5: 0.4244402985074627
[2m[36m(func pid=124580)[0m f1_micro: 0.03731343283582089
[2m[36m(func pid=124580)[0m f1_macro: 0.06497399452081859
[2m[36m(func pid=124580)[0m f1_weighted: 0.026796344697664592
[2m[36m(func pid=124580)[0m f1_per_class: [0.037, 0.085, 0.0, 0.02, 0.444, 0.008, 0.0, 0.022, 0.0, 0.033]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 2.5264 | Steps: 2 | Val loss: 2.3069 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 03:01:12 (running for 00:37:13.57)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.394 |      0.236 |                   48 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.795 |      0.065 |                   27 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  1.89  |      0.033 |                   26 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.464 |      0.103 |                   21 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)

[2m[36m(func pid=120129)[0m top1: 0.2439365671641791

[2m[36m(func pid=120129)[0m top5: 0.8498134328358209
[2m[36m(func pid=120129)[0m f1_micro: 0.2439365671641791
[2m[36m(func pid=120129)[0m f1_macro: 0.23563968871000132
[2m[36m(func pid=120129)[0m f1_weighted: 0.2545238051257965
[2m[36m(func pid=120129)[0m f1_per_class: [0.118, 0.459, 0.375, 0.306, 0.126, 0.119, 0.154, 0.275, 0.194, 0.23]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 1.9774 | Steps: 2 | Val loss: 141.9814 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 1.3728 | Steps: 2 | Val loss: 45.1900 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=126248)[0m top1: 0.18516791044776118
[2m[36m(func pid=126248)[0m top5: 0.6254664179104478
[2m[36m(func pid=126248)[0m f1_micro: 0.18516791044776118
[2m[36m(func pid=126248)[0m f1_macro: 0.10633763311934734
[2m[36m(func pid=126248)[0m f1_weighted: 0.1344316237228645
[2m[36m(func pid=126248)[0m f1_per_class: [0.033, 0.085, 0.054, 0.315, 0.0, 0.008, 0.0, 0.508, 0.0, 0.061]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=125328)[0m top1: 0.08955223880597014
[2m[36m(func pid=125328)[0m top5: 0.4197761194029851
[2m[36m(func pid=125328)[0m f1_micro: 0.08955223880597016
[2m[36m(func pid=125328)[0m f1_macro: 0.03627704748853812
[2m[36m(func pid=125328)[0m f1_weighted: 0.05952271044665017
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.345, 0.018, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.3668 | Steps: 2 | Val loss: 5.5811 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=124580)[0m top1: 0.06856343283582089
[2m[36m(func pid=124580)[0m top5: 0.3726679104477612
[2m[36m(func pid=124580)[0m f1_micro: 0.06856343283582089
[2m[36m(func pid=124580)[0m f1_macro: 0.061839532266869834
[2m[36m(func pid=124580)[0m f1_weighted: 0.042216939102685265
[2m[36m(func pid=124580)[0m f1_per_class: [0.025, 0.16, 0.0, 0.023, 0.308, 0.024, 0.003, 0.021, 0.0, 0.055]
[2m[36m(func pid=124580)[0m 
== Status ==
Current time: 2024-01-07 03:01:18 (running for 00:37:18.92)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.367 |      0.184 |                   49 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  1.373 |      0.062 |                   28 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  1.977 |      0.036 |                   27 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.526 |      0.106 |                   22 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.23740671641791045
[2m[36m(func pid=120129)[0m top5: 0.8423507462686567
[2m[36m(func pid=120129)[0m f1_micro: 0.23740671641791045
[2m[36m(func pid=120129)[0m f1_macro: 0.18370081353374113
[2m[36m(func pid=120129)[0m f1_weighted: 0.24847795219699598
[2m[36m(func pid=120129)[0m f1_per_class: [0.119, 0.447, 0.0, 0.347, 0.112, 0.074, 0.142, 0.251, 0.103, 0.242]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 2.4605 | Steps: 2 | Val loss: 2.3049 | Batch size: 32 | lr: 0.0001 | Duration: 3.11s
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 1.7597 | Steps: 2 | Val loss: 113.7552 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.8475 | Steps: 2 | Val loss: 44.7478 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=126248)[0m top1: 0.1875
[2m[36m(func pid=126248)[0m top5: 0.6268656716417911
[2m[36m(func pid=126248)[0m f1_micro: 0.1875
[2m[36m(func pid=126248)[0m f1_macro: 0.11013282308684547
[2m[36m(func pid=126248)[0m f1_weighted: 0.1387068359052105
[2m[36m(func pid=126248)[0m f1_per_class: [0.035, 0.099, 0.057, 0.312, 0.0, 0.032, 0.0, 0.507, 0.0, 0.059]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=125328)[0m top1: 0.1021455223880597
[2m[36m(func pid=125328)[0m top5: 0.4239738805970149
[2m[36m(func pid=125328)[0m f1_micro: 0.10214552238805971
[2m[36m(func pid=125328)[0m f1_macro: 0.03656250709147435
[2m[36m(func pid=125328)[0m f1_weighted: 0.05993527833634605
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.348, 0.018, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.5426 | Steps: 2 | Val loss: 5.3210 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=124580)[0m top1: 0.04151119402985075
[2m[36m(func pid=124580)[0m top5: 0.36380597014925375
[2m[36m(func pid=124580)[0m f1_micro: 0.04151119402985075
[2m[36m(func pid=124580)[0m f1_macro: 0.06031654193629168
[2m[36m(func pid=124580)[0m f1_weighted: 0.03969350843113349
[2m[36m(func pid=124580)[0m f1_per_class: [0.019, 0.093, 0.03, 0.026, 0.25, 0.039, 0.018, 0.052, 0.009, 0.067]
[2m[36m(func pid=124580)[0m 
== Status ==
Current time: 2024-01-07 03:01:23 (running for 00:37:24.28)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.543 |      0.2   |                   50 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.848 |      0.06  |                   29 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  1.76  |      0.037 |                   28 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.461 |      0.11  |                   23 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.2513992537313433
[2m[36m(func pid=120129)[0m top5: 0.8446828358208955
[2m[36m(func pid=120129)[0m f1_micro: 0.2513992537313433
[2m[36m(func pid=120129)[0m f1_macro: 0.20005720576987365
[2m[36m(func pid=120129)[0m f1_weighted: 0.2662698524419975
[2m[36m(func pid=120129)[0m f1_per_class: [0.125, 0.448, 0.0, 0.36, 0.114, 0.133, 0.158, 0.256, 0.156, 0.25]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 2.5025 | Steps: 2 | Val loss: 2.3079 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 1.8374 | Steps: 2 | Val loss: 94.1435 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.9985 | Steps: 2 | Val loss: 48.3739 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.3578 | Steps: 2 | Val loss: 4.3357 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=125328)[0m top1: 0.11147388059701492
[2m[36m(func pid=125328)[0m top5: 0.4430970149253731
[2m[36m(func pid=125328)[0m f1_micro: 0.11147388059701491
[2m[36m(func pid=125328)[0m f1_macro: 0.03617613667593483
[2m[36m(func pid=125328)[0m f1_weighted: 0.058916110451376465
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.342, 0.02, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=126248)[0m top1: 0.1791044776119403
[2m[36m(func pid=126248)[0m top5: 0.6217350746268657
[2m[36m(func pid=126248)[0m f1_micro: 0.17910447761194032
[2m[36m(func pid=126248)[0m f1_macro: 0.10848894376028399
[2m[36m(func pid=126248)[0m f1_weighted: 0.13707369336928674
[2m[36m(func pid=126248)[0m f1_per_class: [0.028, 0.111, 0.055, 0.299, 0.0, 0.032, 0.0, 0.507, 0.0, 0.053]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=124580)[0m top1: 0.051305970149253734
[2m[36m(func pid=124580)[0m top5: 0.363339552238806
[2m[36m(func pid=124580)[0m f1_micro: 0.051305970149253734
[2m[36m(func pid=124580)[0m f1_macro: 0.06644346613997122
[2m[36m(func pid=124580)[0m f1_weighted: 0.05598995004269523
[2m[36m(func pid=124580)[0m f1_per_class: [0.014, 0.151, 0.024, 0.026, 0.188, 0.032, 0.03, 0.124, 0.009, 0.067]
[2m[36m(func pid=124580)[0m 
== Status ==
Current time: 2024-01-07 03:01:28 (running for 00:37:29.61)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.358 |      0.222 |                   51 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.998 |      0.066 |                   30 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  1.837 |      0.036 |                   29 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.502 |      0.108 |                   24 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.2943097014925373
[2m[36m(func pid=120129)[0m top5: 0.8666044776119403
[2m[36m(func pid=120129)[0m f1_micro: 0.2943097014925373
[2m[36m(func pid=120129)[0m f1_macro: 0.22154488076613177
[2m[36m(func pid=120129)[0m f1_weighted: 0.3151399744902416
[2m[36m(func pid=120129)[0m f1_per_class: [0.151, 0.401, 0.0, 0.409, 0.091, 0.155, 0.281, 0.319, 0.173, 0.235]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 1.7739 | Steps: 2 | Val loss: 75.9277 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 2.4407 | Steps: 2 | Val loss: 2.3041 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 1.5042 | Steps: 2 | Val loss: 37.4294 | Batch size: 32 | lr: 0.01 | Duration: 3.10s
[2m[36m(func pid=125328)[0m top1: 0.11707089552238806
[2m[36m(func pid=125328)[0m top5: 0.47294776119402987
[2m[36m(func pid=125328)[0m f1_micro: 0.11707089552238806
[2m[36m(func pid=125328)[0m f1_macro: 0.043762319886618585
[2m[36m(func pid=125328)[0m f1_weighted: 0.05870156969483301
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.337, 0.022, 0.0, 0.078, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.4006 | Steps: 2 | Val loss: 3.6845 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=126248)[0m top1: 0.18050373134328357
[2m[36m(func pid=126248)[0m top5: 0.6198694029850746
[2m[36m(func pid=126248)[0m f1_micro: 0.18050373134328357
[2m[36m(func pid=126248)[0m f1_macro: 0.10999514481472106
[2m[36m(func pid=126248)[0m f1_weighted: 0.1396687529850536
[2m[36m(func pid=126248)[0m f1_per_class: [0.028, 0.114, 0.062, 0.302, 0.0, 0.047, 0.0, 0.503, 0.0, 0.044]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=124580)[0m top1: 0.049440298507462684
[2m[36m(func pid=124580)[0m top5: 0.3931902985074627
[2m[36m(func pid=124580)[0m f1_micro: 0.049440298507462684
[2m[36m(func pid=124580)[0m f1_macro: 0.05471765962320231
[2m[36m(func pid=124580)[0m f1_weighted: 0.05075993132258767
[2m[36m(func pid=124580)[0m f1_per_class: [0.018, 0.123, 0.033, 0.038, 0.091, 0.047, 0.012, 0.14, 0.0, 0.045]
[2m[36m(func pid=124580)[0m 
== Status ==
Current time: 2024-01-07 03:01:34 (running for 00:37:35.00)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.401 |      0.277 |                   52 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  1.504 |      0.055 |                   31 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  1.774 |      0.044 |                   30 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.441 |      0.11  |                   25 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.35447761194029853
[2m[36m(func pid=120129)[0m top5: 0.8782649253731343
[2m[36m(func pid=120129)[0m f1_micro: 0.35447761194029853
[2m[36m(func pid=120129)[0m f1_macro: 0.2769940055804014
[2m[36m(func pid=120129)[0m f1_weighted: 0.3820008333336066
[2m[36m(func pid=120129)[0m f1_per_class: [0.164, 0.354, 0.267, 0.434, 0.055, 0.157, 0.474, 0.459, 0.181, 0.224]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 1.7376 | Steps: 2 | Val loss: 64.2698 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 2.4060 | Steps: 2 | Val loss: 2.3021 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.7038 | Steps: 2 | Val loss: 36.0249 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=125328)[0m top1: 0.09981343283582089
[2m[36m(func pid=125328)[0m top5: 0.49300373134328357
[2m[36m(func pid=125328)[0m f1_micro: 0.0998134328358209
[2m[36m(func pid=125328)[0m f1_macro: 0.03995081441566077
[2m[36m(func pid=125328)[0m f1_weighted: 0.0487800456905318
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.278, 0.026, 0.0, 0.095, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.3498 | Steps: 2 | Val loss: 3.5338 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=126248)[0m top1: 0.177705223880597
[2m[36m(func pid=126248)[0m top5: 0.6217350746268657
[2m[36m(func pid=126248)[0m f1_micro: 0.177705223880597
[2m[36m(func pid=126248)[0m f1_macro: 0.11169450113442354
[2m[36m(func pid=126248)[0m f1_weighted: 0.1394790282512058
[2m[36m(func pid=126248)[0m f1_per_class: [0.036, 0.127, 0.07, 0.292, 0.0, 0.054, 0.0, 0.491, 0.0, 0.048]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=124580)[0m top1: 0.09095149253731344
[2m[36m(func pid=124580)[0m top5: 0.5289179104477612
[2m[36m(func pid=124580)[0m f1_micro: 0.09095149253731345
[2m[36m(func pid=124580)[0m f1_macro: 0.11180529057410038
[2m[36m(func pid=124580)[0m f1_weighted: 0.08703770147253621
[2m[36m(func pid=124580)[0m f1_per_class: [0.049, 0.206, 0.114, 0.032, 0.148, 0.096, 0.012, 0.426, 0.0, 0.034]
[2m[36m(func pid=124580)[0m 
== Status ==
Current time: 2024-01-07 03:01:39 (running for 00:37:40.28)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.35  |      0.272 |                   53 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.704 |      0.112 |                   32 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  1.738 |      0.04  |                   31 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.406 |      0.112 |                   26 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.3670708955223881
[2m[36m(func pid=120129)[0m top5: 0.8773320895522388
[2m[36m(func pid=120129)[0m f1_micro: 0.3670708955223881
[2m[36m(func pid=120129)[0m f1_macro: 0.27201587909159075
[2m[36m(func pid=120129)[0m f1_weighted: 0.3897669773347692
[2m[36m(func pid=120129)[0m f1_per_class: [0.19, 0.321, 0.211, 0.461, 0.052, 0.147, 0.498, 0.469, 0.171, 0.2]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 1.6337 | Steps: 2 | Val loss: 58.6714 | Batch size: 32 | lr: 0.1 | Duration: 2.72s
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 2.3888 | Steps: 2 | Val loss: 2.2985 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.5145 | Steps: 2 | Val loss: 35.6784 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=125328)[0m top1: 0.0853544776119403
[2m[36m(func pid=125328)[0m top5: 0.4986007462686567
[2m[36m(func pid=125328)[0m f1_micro: 0.0853544776119403
[2m[36m(func pid=125328)[0m f1_macro: 0.03242319717523373
[2m[36m(func pid=125328)[0m f1_weighted: 0.04035819906561546
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.225, 0.036, 0.003, 0.06, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.4638 | Steps: 2 | Val loss: 3.6098 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=126248)[0m top1: 0.17583955223880596
[2m[36m(func pid=126248)[0m top5: 0.6231343283582089
[2m[36m(func pid=126248)[0m f1_micro: 0.17583955223880596
[2m[36m(func pid=126248)[0m f1_macro: 0.11377886909533545
[2m[36m(func pid=126248)[0m f1_weighted: 0.14026467599137446
[2m[36m(func pid=126248)[0m f1_per_class: [0.032, 0.127, 0.079, 0.29, 0.0, 0.068, 0.0, 0.483, 0.0, 0.059]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=124580)[0m top1: 0.14505597014925373
[2m[36m(func pid=124580)[0m top5: 0.7159514925373134
[2m[36m(func pid=124580)[0m f1_micro: 0.14505597014925373
[2m[36m(func pid=124580)[0m f1_macro: 0.12229479122422145
[2m[36m(func pid=124580)[0m f1_weighted: 0.12646580879528685
[2m[36m(func pid=124580)[0m f1_per_class: [0.028, 0.211, 0.0, 0.051, 0.151, 0.229, 0.077, 0.428, 0.0, 0.049]
[2m[36m(func pid=124580)[0m 
== Status ==
Current time: 2024-01-07 03:01:44 (running for 00:37:45.58)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.464 |      0.277 |                   54 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.514 |      0.122 |                   33 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  1.634 |      0.032 |                   32 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.389 |      0.114 |                   27 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.3572761194029851
[2m[36m(func pid=120129)[0m top5: 0.8810634328358209
[2m[36m(func pid=120129)[0m f1_micro: 0.35727611940298515
[2m[36m(func pid=120129)[0m f1_macro: 0.27722669796672317
[2m[36m(func pid=120129)[0m f1_weighted: 0.3744201556855267
[2m[36m(func pid=120129)[0m f1_per_class: [0.192, 0.318, 0.387, 0.466, 0.059, 0.121, 0.462, 0.409, 0.169, 0.189]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 1.7522 | Steps: 2 | Val loss: 55.7650 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 2.3918 | Steps: 2 | Val loss: 2.2928 | Batch size: 32 | lr: 0.0001 | Duration: 3.12s
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 1.2873 | Steps: 2 | Val loss: 39.1741 | Batch size: 32 | lr: 0.01 | Duration: 2.65s
[2m[36m(func pid=125328)[0m top1: 0.0830223880597015
[2m[36m(func pid=125328)[0m top5: 0.49113805970149255
[2m[36m(func pid=125328)[0m f1_micro: 0.0830223880597015
[2m[36m(func pid=125328)[0m f1_macro: 0.03114731244791974
[2m[36m(func pid=125328)[0m f1_weighted: 0.037623017149725706
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.215, 0.047, 0.0, 0.049, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.2142 | Steps: 2 | Val loss: 3.9774 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=126248)[0m top1: 0.17490671641791045
[2m[36m(func pid=126248)[0m top5: 0.6245335820895522
[2m[36m(func pid=126248)[0m f1_micro: 0.17490671641791045
[2m[36m(func pid=126248)[0m f1_macro: 0.11250576079052901
[2m[36m(func pid=126248)[0m f1_weighted: 0.13768469766901859
[2m[36m(func pid=126248)[0m f1_per_class: [0.034, 0.108, 0.086, 0.292, 0.0, 0.075, 0.0, 0.471, 0.0, 0.061]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=124580)[0m top1: 0.21361940298507462
[2m[36m(func pid=124580)[0m top5: 0.7406716417910447
[2m[36m(func pid=124580)[0m f1_micro: 0.21361940298507465
[2m[36m(func pid=124580)[0m f1_macro: 0.1439668839255161
[2m[36m(func pid=124580)[0m f1_weighted: 0.20144076130248495
[2m[36m(func pid=124580)[0m f1_per_class: [0.022, 0.252, 0.0, 0.057, 0.095, 0.21, 0.306, 0.432, 0.0, 0.066]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 2.0057 | Steps: 2 | Val loss: 51.1357 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
== Status ==
Current time: 2024-01-07 03:01:50 (running for 00:37:50.89)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.214 |      0.266 |                   55 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  1.287 |      0.144 |                   34 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  1.752 |      0.031 |                   33 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.392 |      0.113 |                   28 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.34375
[2m[36m(func pid=120129)[0m top5: 0.8740671641791045
[2m[36m(func pid=120129)[0m f1_micro: 0.34375
[2m[36m(func pid=120129)[0m f1_macro: 0.2657710702331001
[2m[36m(func pid=120129)[0m f1_weighted: 0.3646583008647865
[2m[36m(func pid=120129)[0m f1_per_class: [0.13, 0.322, 0.39, 0.473, 0.094, 0.115, 0.443, 0.317, 0.176, 0.197]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 2.4410 | Steps: 2 | Val loss: 2.2912 | Batch size: 32 | lr: 0.0001 | Duration: 3.07s
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 1.2781 | Steps: 2 | Val loss: 34.5709 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=125328)[0m top1: 0.09654850746268656
[2m[36m(func pid=125328)[0m top5: 0.49300373134328357
[2m[36m(func pid=125328)[0m f1_micro: 0.09654850746268658
[2m[36m(func pid=125328)[0m f1_macro: 0.04214387811539632
[2m[36m(func pid=125328)[0m f1_weighted: 0.043229841044719206
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.242, 0.062, 0.0, 0.043, 0.0, 0.0, 0.0, 0.0, 0.074]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.6536 | Steps: 2 | Val loss: 3.9487 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=126248)[0m top1: 0.17350746268656717
[2m[36m(func pid=126248)[0m top5: 0.632929104477612
[2m[36m(func pid=126248)[0m f1_micro: 0.17350746268656717
[2m[36m(func pid=126248)[0m f1_macro: 0.11439747727584741
[2m[36m(func pid=126248)[0m f1_weighted: 0.14189479554913104
[2m[36m(func pid=126248)[0m f1_per_class: [0.032, 0.103, 0.089, 0.292, 0.0, 0.135, 0.0, 0.439, 0.0, 0.054]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=124580)[0m top1: 0.19916044776119404
[2m[36m(func pid=124580)[0m top5: 0.7565298507462687
[2m[36m(func pid=124580)[0m f1_micro: 0.19916044776119404
[2m[36m(func pid=124580)[0m f1_macro: 0.1448400896225313
[2m[36m(func pid=124580)[0m f1_weighted: 0.20707696221330743
[2m[36m(func pid=124580)[0m f1_per_class: [0.061, 0.194, 0.0, 0.045, 0.151, 0.089, 0.41, 0.445, 0.0, 0.054]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 2.0173 | Steps: 2 | Val loss: 49.0370 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
== Status ==
Current time: 2024-01-07 03:01:55 (running for 00:37:56.23)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.654 |      0.259 |                   56 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  1.278 |      0.145 |                   35 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  2.006 |      0.042 |                   34 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.441 |      0.114 |                   29 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.3344216417910448
[2m[36m(func pid=120129)[0m top5: 0.8754664179104478
[2m[36m(func pid=120129)[0m f1_micro: 0.3344216417910448
[2m[36m(func pid=120129)[0m f1_macro: 0.2594784100484894
[2m[36m(func pid=120129)[0m f1_weighted: 0.3584683802904427
[2m[36m(func pid=120129)[0m f1_per_class: [0.119, 0.33, 0.368, 0.465, 0.069, 0.137, 0.422, 0.289, 0.193, 0.203]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 2.3599 | Steps: 2 | Val loss: 2.2853 | Batch size: 32 | lr: 0.0001 | Duration: 3.15s
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 1.3865 | Steps: 2 | Val loss: 24.4112 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=125328)[0m top1: 0.09375
[2m[36m(func pid=125328)[0m top5: 0.5424440298507462
[2m[36m(func pid=125328)[0m f1_micro: 0.09375
[2m[36m(func pid=125328)[0m f1_macro: 0.03862539915934135
[2m[36m(func pid=125328)[0m f1_weighted: 0.04485382644352691
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.246, 0.074, 0.0, 0.038, 0.0, 0.003, 0.0, 0.025, 0.0]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.2238 | Steps: 2 | Val loss: 3.6636 | Batch size: 32 | lr: 0.001 | Duration: 2.72s
[2m[36m(func pid=126248)[0m top1: 0.17397388059701493
[2m[36m(func pid=126248)[0m top5: 0.6413246268656716
[2m[36m(func pid=126248)[0m f1_micro: 0.17397388059701493
[2m[36m(func pid=126248)[0m f1_macro: 0.12118649524545295
[2m[36m(func pid=126248)[0m f1_weighted: 0.14739960902074478
[2m[36m(func pid=126248)[0m f1_per_class: [0.036, 0.11, 0.094, 0.286, 0.0, 0.185, 0.0, 0.445, 0.0, 0.056]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=124580)[0m top1: 0.11940298507462686
[2m[36m(func pid=124580)[0m top5: 0.7262126865671642
[2m[36m(func pid=124580)[0m f1_micro: 0.11940298507462686
[2m[36m(func pid=124580)[0m f1_macro: 0.11713800856960344
[2m[36m(func pid=124580)[0m f1_weighted: 0.12820769393996082
[2m[36m(func pid=124580)[0m f1_per_class: [0.044, 0.12, 0.0, 0.035, 0.152, 0.214, 0.158, 0.407, 0.0, 0.04]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 1.7666 | Steps: 2 | Val loss: 47.5415 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
== Status ==
Current time: 2024-01-07 03:02:00 (running for 00:38:01.39)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.224 |      0.277 |                   57 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  1.387 |      0.117 |                   36 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  2.017 |      0.039 |                   35 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.36  |      0.121 |                   30 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.34468283582089554
[2m[36m(func pid=120129)[0m top5: 0.8903917910447762
[2m[36m(func pid=120129)[0m f1_micro: 0.34468283582089554
[2m[36m(func pid=120129)[0m f1_macro: 0.27713138875284876
[2m[36m(func pid=120129)[0m f1_weighted: 0.3620632132375051
[2m[36m(func pid=120129)[0m f1_per_class: [0.176, 0.333, 0.353, 0.479, 0.074, 0.185, 0.384, 0.344, 0.194, 0.25]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 2.4095 | Steps: 2 | Val loss: 2.2835 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=125328)[0m top1: 0.09468283582089553
[2m[36m(func pid=125328)[0m top5: 0.5475746268656716
[2m[36m(func pid=125328)[0m f1_micro: 0.09468283582089553
[2m[36m(func pid=125328)[0m f1_macro: 0.054797549412118916
[2m[36m(func pid=125328)[0m f1_weighted: 0.046571309191786446
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.249, 0.085, 0.003, 0.035, 0.0, 0.0, 0.0, 0.0, 0.176]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.4098 | Steps: 2 | Val loss: 23.2472 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.2531 | Steps: 2 | Val loss: 3.4754 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=124580)[0m top1: 0.048507462686567165
[2m[36m(func pid=124580)[0m top5: 0.5485074626865671
[2m[36m(func pid=124580)[0m f1_micro: 0.048507462686567165
[2m[36m(func pid=124580)[0m f1_macro: 0.0681864511473822
[2m[36m(func pid=124580)[0m f1_weighted: 0.051481674556192916
[2m[36m(func pid=124580)[0m f1_per_class: [0.047, 0.152, 0.0, 0.016, 0.2, 0.008, 0.016, 0.215, 0.0, 0.028]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=126248)[0m top1: 0.1767723880597015
[2m[36m(func pid=126248)[0m top5: 0.6492537313432836
[2m[36m(func pid=126248)[0m f1_micro: 0.1767723880597015
[2m[36m(func pid=126248)[0m f1_macro: 0.13179930305931256
[2m[36m(func pid=126248)[0m f1_weighted: 0.15425864277852466
[2m[36m(func pid=126248)[0m f1_per_class: [0.035, 0.118, 0.098, 0.284, 0.043, 0.232, 0.0, 0.452, 0.0, 0.057]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 1.5204 | Steps: 2 | Val loss: 45.7770 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
== Status ==
Current time: 2024-01-07 03:02:05 (running for 00:38:06.76)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.253 |      0.278 |                   58 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.41  |      0.068 |                   37 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  1.767 |      0.055 |                   36 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.41  |      0.132 |                   31 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.34841417910447764
[2m[36m(func pid=120129)[0m top5: 0.8992537313432836
[2m[36m(func pid=120129)[0m f1_micro: 0.34841417910447764
[2m[36m(func pid=120129)[0m f1_macro: 0.277966314907421
[2m[36m(func pid=120129)[0m f1_weighted: 0.36383083755567913
[2m[36m(func pid=120129)[0m f1_per_class: [0.21, 0.348, 0.214, 0.48, 0.074, 0.196, 0.368, 0.36, 0.215, 0.314]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=125328)[0m top1: 0.10307835820895522
[2m[36m(func pid=125328)[0m top5: 0.5494402985074627
[2m[36m(func pid=125328)[0m f1_micro: 0.10307835820895522
[2m[36m(func pid=125328)[0m f1_macro: 0.06684974438043564
[2m[36m(func pid=125328)[0m f1_weighted: 0.05036798009539443
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.259, 0.094, 0.003, 0.034, 0.008, 0.0, 0.0, 0.0, 0.27]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 1.2271 | Steps: 2 | Val loss: 23.4688 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 2.3209 | Steps: 2 | Val loss: 2.2749 | Batch size: 32 | lr: 0.0001 | Duration: 3.05s
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.3198 | Steps: 2 | Val loss: 3.4145 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=124580)[0m top1: 0.049906716417910446
[2m[36m(func pid=124580)[0m top5: 0.5261194029850746
[2m[36m(func pid=124580)[0m f1_micro: 0.04990671641791045
[2m[36m(func pid=124580)[0m f1_macro: 0.06633002156682388
[2m[36m(func pid=124580)[0m f1_weighted: 0.05379236840592792
[2m[36m(func pid=124580)[0m f1_per_class: [0.044, 0.227, 0.025, 0.003, 0.216, 0.016, 0.012, 0.092, 0.0, 0.028]
[2m[36m(func pid=124580)[0m 
== Status ==
Current time: 2024-01-07 03:02:11 (running for 00:38:11.89)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.253 |      0.278 |                   58 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  1.227 |      0.066 |                   38 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  1.52  |      0.067 |                   37 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.321 |      0.145 |                   32 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.3474813432835821
[2m[36m(func pid=120129)[0m top5: 0.8987873134328358
[2m[36m(func pid=120129)[0m f1_micro: 0.3474813432835821
[2m[36m(func pid=120129)[0m f1_macro: 0.28181157251063194
[2m[36m(func pid=120129)[0m f1_weighted: 0.36541182990281806
[2m[36m(func pid=120129)[0m f1_per_class: [0.218, 0.37, 0.214, 0.473, 0.081, 0.189, 0.369, 0.361, 0.213, 0.33]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 1.6938 | Steps: 2 | Val loss: 44.2118 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=126248)[0m top1: 0.18796641791044777
[2m[36m(func pid=126248)[0m top5: 0.6576492537313433
[2m[36m(func pid=126248)[0m f1_micro: 0.18796641791044777
[2m[36m(func pid=126248)[0m f1_macro: 0.1448667726288558
[2m[36m(func pid=126248)[0m f1_weighted: 0.16581229219649063
[2m[36m(func pid=126248)[0m f1_per_class: [0.039, 0.112, 0.113, 0.299, 0.075, 0.298, 0.0, 0.455, 0.0, 0.057]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=125328)[0m top1: 0.10774253731343283
[2m[36m(func pid=125328)[0m top5: 0.5480410447761194
[2m[36m(func pid=125328)[0m f1_micro: 0.10774253731343283
[2m[36m(func pid=125328)[0m f1_macro: 0.07277645179393714
[2m[36m(func pid=125328)[0m f1_weighted: 0.0515399233902012
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.273, 0.097, 0.0, 0.034, 0.0, 0.0, 0.0, 0.0, 0.324]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 1.5699 | Steps: 2 | Val loss: 23.1435 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.1991 | Steps: 2 | Val loss: 3.2953 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 2.2985 | Steps: 2 | Val loss: 2.2681 | Batch size: 32 | lr: 0.0001 | Duration: 3.25s
== Status ==
Current time: 2024-01-07 03:02:16 (running for 00:38:17.03)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.32  |      0.282 |                   59 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  1.57  |      0.095 |                   39 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  1.694 |      0.073 |                   38 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.321 |      0.145 |                   32 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=124580)[0m top1: 0.09375
[2m[36m(func pid=124580)[0m top5: 0.5802238805970149
[2m[36m(func pid=124580)[0m f1_micro: 0.09375
[2m[36m(func pid=124580)[0m f1_macro: 0.0946810405844513
[2m[36m(func pid=124580)[0m f1_weighted: 0.08400324960771134
[2m[36m(func pid=124580)[0m f1_per_class: [0.058, 0.267, 0.0, 0.007, 0.225, 0.038, 0.042, 0.276, 0.0, 0.033]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=120129)[0m top1: 0.3498134328358209
[2m[36m(func pid=120129)[0m top5: 0.8978544776119403
[2m[36m(func pid=120129)[0m f1_micro: 0.3498134328358209
[2m[36m(func pid=120129)[0m f1_macro: 0.2843961427056836
[2m[36m(func pid=120129)[0m f1_weighted: 0.3694600324460844
[2m[36m(func pid=120129)[0m f1_per_class: [0.246, 0.385, 0.182, 0.472, 0.071, 0.197, 0.367, 0.388, 0.195, 0.341]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 1.5754 | Steps: 2 | Val loss: 40.9323 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
[2m[36m(func pid=126248)[0m top1: 0.19449626865671643
[2m[36m(func pid=126248)[0m top5: 0.6609141791044776
[2m[36m(func pid=126248)[0m f1_micro: 0.19449626865671643
[2m[36m(func pid=126248)[0m f1_macro: 0.15145928396906394
[2m[36m(func pid=126248)[0m f1_weighted: 0.17369707978327492
[2m[36m(func pid=126248)[0m f1_per_class: [0.039, 0.13, 0.121, 0.306, 0.094, 0.315, 0.003, 0.454, 0.0, 0.053]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=125328)[0m top1: 0.1044776119402985
[2m[36m(func pid=125328)[0m top5: 0.5475746268656716
[2m[36m(func pid=125328)[0m f1_micro: 0.1044776119402985
[2m[36m(func pid=125328)[0m f1_macro: 0.07499639055094448
[2m[36m(func pid=125328)[0m f1_weighted: 0.052847605739334724
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.279, 0.097, 0.0, 0.031, 0.0, 0.0, 0.0, 0.0, 0.343]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 1.0753 | Steps: 2 | Val loss: 25.9377 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.7431 | Steps: 2 | Val loss: 3.1020 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 2.3135 | Steps: 2 | Val loss: 2.2632 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
== Status ==
Current time: 2024-01-07 03:02:21 (running for 00:38:22.44)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.199 |      0.284 |                   60 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  1.075 |      0.117 |                   40 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  1.575 |      0.075 |                   39 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.298 |      0.151 |                   33 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=124580)[0m top1: 0.146455223880597
[2m[36m(func pid=124580)[0m top5: 0.7140858208955224
[2m[36m(func pid=124580)[0m f1_micro: 0.146455223880597
[2m[36m(func pid=124580)[0m f1_macro: 0.11707428825083468
[2m[36m(func pid=124580)[0m f1_weighted: 0.1204555559818886
[2m[36m(func pid=124580)[0m f1_per_class: [0.0, 0.258, 0.0, 0.016, 0.24, 0.153, 0.106, 0.348, 0.0, 0.05]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=120129)[0m top1: 0.3675373134328358
[2m[36m(func pid=120129)[0m top5: 0.8969216417910447
[2m[36m(func pid=120129)[0m f1_micro: 0.36753731343283574
[2m[36m(func pid=120129)[0m f1_macro: 0.31651310639052416
[2m[36m(func pid=120129)[0m f1_weighted: 0.3911972231388899
[2m[36m(func pid=120129)[0m f1_per_class: [0.25, 0.399, 0.353, 0.465, 0.069, 0.244, 0.407, 0.444, 0.181, 0.353]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 2.0777 | Steps: 2 | Val loss: 40.6517 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=126248)[0m top1: 0.197294776119403
[2m[36m(func pid=126248)[0m top5: 0.6707089552238806
[2m[36m(func pid=126248)[0m f1_micro: 0.197294776119403
[2m[36m(func pid=126248)[0m f1_macro: 0.15789366893734408
[2m[36m(func pid=126248)[0m f1_weighted: 0.1774390710960484
[2m[36m(func pid=126248)[0m f1_per_class: [0.044, 0.139, 0.13, 0.311, 0.076, 0.322, 0.003, 0.442, 0.0, 0.111]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=125328)[0m top1: 0.08162313432835822
[2m[36m(func pid=125328)[0m top5: 0.585820895522388
[2m[36m(func pid=125328)[0m f1_micro: 0.08162313432835822
[2m[36m(func pid=125328)[0m f1_macro: 0.07305748038295423
[2m[36m(func pid=125328)[0m f1_weighted: 0.051150797162435806
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.27, 0.092, 0.0, 0.026, 0.0, 0.0, 0.0, 0.0, 0.343]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 1.2811 | Steps: 2 | Val loss: 30.2467 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.3853 | Steps: 2 | Val loss: 3.1306 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 2.2719 | Steps: 2 | Val loss: 2.2541 | Batch size: 32 | lr: 0.0001 | Duration: 3.03s
== Status ==
Current time: 2024-01-07 03:02:27 (running for 00:38:27.88)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.743 |      0.317 |                   61 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  1.281 |      0.114 |                   41 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  2.078 |      0.073 |                   40 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.313 |      0.158 |                   34 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=124580)[0m top1: 0.15205223880597016
[2m[36m(func pid=124580)[0m top5: 0.7117537313432836
[2m[36m(func pid=124580)[0m f1_micro: 0.15205223880597016
[2m[36m(func pid=124580)[0m f1_macro: 0.11427895006522648
[2m[36m(func pid=124580)[0m f1_weighted: 0.12536394258384467
[2m[36m(func pid=124580)[0m f1_per_class: [0.0, 0.265, 0.0, 0.06, 0.27, 0.194, 0.09, 0.189, 0.018, 0.057]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=120129)[0m top1: 0.38013059701492535
[2m[36m(func pid=120129)[0m top5: 0.8913246268656716
[2m[36m(func pid=120129)[0m f1_micro: 0.38013059701492535
[2m[36m(func pid=120129)[0m f1_macro: 0.3323968971971374
[2m[36m(func pid=120129)[0m f1_weighted: 0.41267338148276944
[2m[36m(func pid=120129)[0m f1_per_class: [0.239, 0.351, 0.4, 0.47, 0.05, 0.291, 0.469, 0.516, 0.201, 0.337]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 1.6977 | Steps: 2 | Val loss: 38.4566 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
[2m[36m(func pid=126248)[0m top1: 0.20335820895522388
[2m[36m(func pid=126248)[0m top5: 0.6791044776119403
[2m[36m(func pid=126248)[0m f1_micro: 0.20335820895522388
[2m[36m(func pid=126248)[0m f1_macro: 0.16493809044167632
[2m[36m(func pid=126248)[0m f1_weighted: 0.18367706015038274
[2m[36m(func pid=126248)[0m f1_per_class: [0.045, 0.149, 0.137, 0.318, 0.102, 0.344, 0.003, 0.437, 0.0, 0.114]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=125328)[0m top1: 0.07136194029850747
[2m[36m(func pid=125328)[0m top5: 0.6147388059701493
[2m[36m(func pid=125328)[0m f1_micro: 0.07136194029850747
[2m[36m(func pid=125328)[0m f1_macro: 0.07875642244245636
[2m[36m(func pid=125328)[0m f1_weighted: 0.05147530053839249
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.268, 0.097, 0.0, 0.023, 0.0, 0.0, 0.0, 0.0, 0.4]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.9008 | Steps: 2 | Val loss: 33.3724 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.3316 | Steps: 2 | Val loss: 3.3865 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 2.2747 | Steps: 2 | Val loss: 2.2500 | Batch size: 32 | lr: 0.0001 | Duration: 2.76s
== Status ==
Current time: 2024-01-07 03:02:32 (running for 00:38:33.22)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.385 |      0.332 |                   62 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.901 |      0.098 |                   42 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  1.698 |      0.079 |                   41 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.272 |      0.165 |                   35 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=124580)[0m top1: 0.14132462686567165
[2m[36m(func pid=124580)[0m top5: 0.632929104477612
[2m[36m(func pid=124580)[0m f1_micro: 0.14132462686567165
[2m[36m(func pid=124580)[0m f1_macro: 0.09835255813009564
[2m[36m(func pid=124580)[0m f1_weighted: 0.10873701096771367
[2m[36m(func pid=124580)[0m f1_per_class: [0.0, 0.28, 0.0, 0.077, 0.222, 0.178, 0.03, 0.112, 0.028, 0.056]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=120129)[0m top1: 0.37593283582089554
[2m[36m(func pid=120129)[0m top5: 0.8694029850746269
[2m[36m(func pid=120129)[0m f1_micro: 0.37593283582089554
[2m[36m(func pid=120129)[0m f1_macro: 0.33496862305947
[2m[36m(func pid=120129)[0m f1_weighted: 0.41602897369513275
[2m[36m(func pid=120129)[0m f1_per_class: [0.23, 0.339, 0.48, 0.468, 0.044, 0.29, 0.499, 0.468, 0.191, 0.341]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 1.6628 | Steps: 2 | Val loss: 38.2310 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=126248)[0m top1: 0.20755597014925373
[2m[36m(func pid=126248)[0m top5: 0.6847014925373134
[2m[36m(func pid=126248)[0m f1_micro: 0.20755597014925375
[2m[36m(func pid=126248)[0m f1_macro: 0.17155858521712608
[2m[36m(func pid=126248)[0m f1_weighted: 0.18935080285266206
[2m[36m(func pid=126248)[0m f1_per_class: [0.044, 0.161, 0.143, 0.317, 0.124, 0.374, 0.003, 0.441, 0.0, 0.108]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=125328)[0m top1: 0.07835820895522388
[2m[36m(func pid=125328)[0m top5: 0.6501865671641791
[2m[36m(func pid=125328)[0m f1_micro: 0.07835820895522388
[2m[36m(func pid=125328)[0m f1_macro: 0.08138505034083456
[2m[36m(func pid=125328)[0m f1_weighted: 0.054738173443820946
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.287, 0.115, 0.0, 0.023, 0.0, 0.0, 0.0, 0.0, 0.389]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 1.0454 | Steps: 2 | Val loss: 34.2883 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.1454 | Steps: 2 | Val loss: 3.6087 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 2.2517 | Steps: 2 | Val loss: 2.2434 | Batch size: 32 | lr: 0.0001 | Duration: 3.08s
== Status ==
Current time: 2024-01-07 03:02:37 (running for 00:38:38.58)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.145 |      0.32  |                   64 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.901 |      0.098 |                   42 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  1.663 |      0.081 |                   42 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.275 |      0.172 |                   36 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.36380597014925375
[2m[36m(func pid=120129)[0m top5: 0.8652052238805971
[2m[36m(func pid=120129)[0m f1_micro: 0.3638059701492538
[2m[36m(func pid=120129)[0m f1_macro: 0.3202758508321796
[2m[36m(func pid=120129)[0m f1_weighted: 0.4033246513459378
[2m[36m(func pid=120129)[0m f1_per_class: [0.214, 0.336, 0.545, 0.468, 0.048, 0.311, 0.483, 0.318, 0.161, 0.319]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=124580)[0m top1: 0.14692164179104478
[2m[36m(func pid=124580)[0m top5: 0.6180037313432836
[2m[36m(func pid=124580)[0m f1_micro: 0.14692164179104478
[2m[36m(func pid=124580)[0m f1_macro: 0.08601953967991365
[2m[36m(func pid=124580)[0m f1_weighted: 0.09372720058273436
[2m[36m(func pid=124580)[0m f1_per_class: [0.034, 0.317, 0.0, 0.044, 0.167, 0.115, 0.018, 0.092, 0.012, 0.062]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 1.7622 | Steps: 2 | Val loss: 31.9551 | Batch size: 32 | lr: 0.1 | Duration: 2.70s
[2m[36m(func pid=126248)[0m top1: 0.2103544776119403
[2m[36m(func pid=126248)[0m top5: 0.691231343283582
[2m[36m(func pid=126248)[0m f1_micro: 0.2103544776119403
[2m[36m(func pid=126248)[0m f1_macro: 0.1754742550292672
[2m[36m(func pid=126248)[0m f1_weighted: 0.19279185535806603
[2m[36m(func pid=126248)[0m f1_per_class: [0.041, 0.167, 0.155, 0.317, 0.123, 0.394, 0.003, 0.443, 0.0, 0.111]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=125328)[0m top1: 0.09281716417910447
[2m[36m(func pid=125328)[0m top5: 0.6935634328358209
[2m[36m(func pid=125328)[0m f1_micro: 0.09281716417910447
[2m[36m(func pid=125328)[0m f1_macro: 0.07867212649119974
[2m[36m(func pid=125328)[0m f1_weighted: 0.05973197132396511
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.301, 0.126, 0.0, 0.027, 0.03, 0.0, 0.0, 0.0, 0.303]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.1848 | Steps: 2 | Val loss: 3.7573 | Batch size: 32 | lr: 0.001 | Duration: 2.78s
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.9443 | Steps: 2 | Val loss: 36.6952 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 2.2809 | Steps: 2 | Val loss: 2.2389 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 03:02:42 (running for 00:38:43.78)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.185 |      0.29  |                   65 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  1.045 |      0.086 |                   43 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  1.762 |      0.079 |                   43 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.252 |      0.175 |                   37 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.34794776119402987
[2m[36m(func pid=120129)[0m top5: 0.8624067164179104
[2m[36m(func pid=120129)[0m f1_micro: 0.34794776119402987
[2m[36m(func pid=120129)[0m f1_macro: 0.289500383605304
[2m[36m(func pid=120129)[0m f1_weighted: 0.37939746926576157
[2m[36m(func pid=120129)[0m f1_per_class: [0.198, 0.314, 0.545, 0.471, 0.054, 0.301, 0.46, 0.106, 0.151, 0.294]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=124580)[0m top1: 0.1515858208955224
[2m[36m(func pid=124580)[0m top5: 0.6110074626865671
[2m[36m(func pid=124580)[0m f1_micro: 0.1515858208955224
[2m[36m(func pid=124580)[0m f1_macro: 0.09214504625856908
[2m[36m(func pid=124580)[0m f1_weighted: 0.08848761306761349
[2m[36m(func pid=124580)[0m f1_per_class: [0.023, 0.314, 0.0, 0.023, 0.24, 0.137, 0.015, 0.078, 0.0, 0.091]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 2.1361 | Steps: 2 | Val loss: 27.3055 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=126248)[0m top1: 0.20848880597014927
[2m[36m(func pid=126248)[0m top5: 0.7024253731343284
[2m[36m(func pid=126248)[0m f1_micro: 0.20848880597014927
[2m[36m(func pid=126248)[0m f1_macro: 0.17353903902687154
[2m[36m(func pid=126248)[0m f1_weighted: 0.19116607913062197
[2m[36m(func pid=126248)[0m f1_per_class: [0.042, 0.157, 0.159, 0.324, 0.111, 0.374, 0.003, 0.439, 0.026, 0.1]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=125328)[0m top1: 0.11520522388059702
[2m[36m(func pid=125328)[0m top5: 0.7453358208955224
[2m[36m(func pid=125328)[0m f1_micro: 0.11520522388059702
[2m[36m(func pid=125328)[0m f1_macro: 0.10345897988596695
[2m[36m(func pid=125328)[0m f1_weighted: 0.07976625704003448
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.29, 0.133, 0.0, 0.034, 0.214, 0.0, 0.0, 0.0, 0.364]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.2237 | Steps: 2 | Val loss: 3.8011 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 2.8342 | Steps: 2 | Val loss: 41.3214 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=124580)[0m top1: 0.16184701492537312
[2m[36m(func pid=124580)[0m top5: 0.5825559701492538
[2m[36m(func pid=124580)[0m f1_micro: 0.16184701492537312
[2m[36m(func pid=124580)[0m f1_macro: 0.09150528853897887
[2m[36m(func pid=124580)[0m f1_weighted: 0.09823296932351708
[2m[36m(func pid=124580)[0m f1_per_class: [0.017, 0.327, 0.0, 0.007, 0.19, 0.069, 0.077, 0.095, 0.018, 0.115]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 2.2488 | Steps: 2 | Val loss: 2.2352 | Batch size: 32 | lr: 0.0001 | Duration: 3.12s
== Status ==
Current time: 2024-01-07 03:02:48 (running for 00:38:49.14)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.185 |      0.29  |                   65 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  2.834 |      0.092 |                   45 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  2.136 |      0.103 |                   44 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.281 |      0.174 |                   38 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.3512126865671642
[2m[36m(func pid=120129)[0m top5: 0.8596082089552238
[2m[36m(func pid=120129)[0m f1_micro: 0.3512126865671642
[2m[36m(func pid=120129)[0m f1_macro: 0.29221586227235
[2m[36m(func pid=120129)[0m f1_weighted: 0.38406891464364434
[2m[36m(func pid=120129)[0m f1_per_class: [0.179, 0.324, 0.526, 0.455, 0.064, 0.318, 0.473, 0.145, 0.155, 0.283]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 1.6452 | Steps: 2 | Val loss: 29.8353 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=125328)[0m top1: 0.10167910447761194
[2m[36m(func pid=125328)[0m top5: 0.7765858208955224
[2m[36m(func pid=125328)[0m f1_micro: 0.10167910447761194
[2m[36m(func pid=125328)[0m f1_macro: 0.07228412897476448
[2m[36m(func pid=125328)[0m f1_weighted: 0.07005083550111173
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.266, 0.157, 0.0, 0.031, 0.195, 0.0, 0.0, 0.0, 0.074]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=126248)[0m top1: 0.20848880597014927
[2m[36m(func pid=126248)[0m top5: 0.7122201492537313
[2m[36m(func pid=126248)[0m f1_micro: 0.20848880597014927
[2m[36m(func pid=126248)[0m f1_macro: 0.18027543347345648
[2m[36m(func pid=126248)[0m f1_weighted: 0.19315381285897437
[2m[36m(func pid=126248)[0m f1_per_class: [0.043, 0.169, 0.159, 0.319, 0.127, 0.377, 0.006, 0.427, 0.026, 0.15]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.4985 | Steps: 2 | Val loss: 3.6678 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.9087 | Steps: 2 | Val loss: 41.8061 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 03:02:53 (running for 00:38:54.49)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.224 |      0.292 |                   66 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.909 |      0.079 |                   46 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  1.645 |      0.072 |                   45 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.249 |      0.18  |                   39 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.3787313432835821
[2m[36m(func pid=120129)[0m top5: 0.8605410447761194
[2m[36m(func pid=120129)[0m f1_micro: 0.3787313432835821
[2m[36m(func pid=120129)[0m f1_macro: 0.33675695415591395
[2m[36m(func pid=120129)[0m f1_weighted: 0.41556253694108347
[2m[36m(func pid=120129)[0m f1_per_class: [0.18, 0.384, 0.526, 0.43, 0.083, 0.331, 0.488, 0.495, 0.219, 0.232]
[2m[36m(func pid=124580)[0m top1: 0.13619402985074627
[2m[36m(func pid=124580)[0m top5: 0.5186567164179104
[2m[36m(func pid=124580)[0m f1_micro: 0.13619402985074627
[2m[36m(func pid=124580)[0m f1_macro: 0.07909725373255393
[2m[36m(func pid=124580)[0m f1_weighted: 0.0946521463895497
[2m[36m(func pid=124580)[0m f1_per_class: [0.028, 0.286, 0.0, 0.007, 0.168, 0.024, 0.12, 0.015, 0.031, 0.112]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 2.2334 | Steps: 2 | Val loss: 30.6212 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 2.2150 | Steps: 2 | Val loss: 2.2332 | Batch size: 32 | lr: 0.0001 | Duration: 3.25s
[2m[36m(func pid=125328)[0m top1: 0.10121268656716417
[2m[36m(func pid=125328)[0m top5: 0.7989738805970149
[2m[36m(func pid=125328)[0m f1_micro: 0.10121268656716416
[2m[36m(func pid=125328)[0m f1_macro: 0.0669676846789645
[2m[36m(func pid=125328)[0m f1_weighted: 0.06865351975875403
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.257, 0.179, 0.0, 0.031, 0.202, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 1.0671 | Steps: 2 | Val loss: 37.5184 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.5294 | Steps: 2 | Val loss: 4.6997 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=126248)[0m top1: 0.20988805970149255
[2m[36m(func pid=126248)[0m top5: 0.7192164179104478
[2m[36m(func pid=126248)[0m f1_micro: 0.20988805970149255
[2m[36m(func pid=126248)[0m f1_macro: 0.18185177986972148
[2m[36m(func pid=126248)[0m f1_weighted: 0.19518322208692732
[2m[36m(func pid=126248)[0m f1_per_class: [0.043, 0.177, 0.155, 0.326, 0.123, 0.378, 0.003, 0.417, 0.025, 0.171]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 1.7263 | Steps: 2 | Val loss: 28.4229 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=124580)[0m top1: 0.11473880597014925
[2m[36m(func pid=124580)[0m top5: 0.5004664179104478
[2m[36m(func pid=124580)[0m f1_micro: 0.11473880597014925
[2m[36m(func pid=124580)[0m f1_macro: 0.07095091563631448
[2m[36m(func pid=124580)[0m f1_weighted: 0.08315506984795418
[2m[36m(func pid=124580)[0m f1_per_class: [0.028, 0.259, 0.0, 0.01, 0.157, 0.008, 0.102, 0.0, 0.043, 0.102]
[2m[36m(func pid=124580)[0m 
== Status ==
Current time: 2024-01-07 03:02:58 (running for 00:38:59.75)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.499 |      0.337 |                   67 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  1.067 |      0.071 |                   47 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  2.233 |      0.067 |                   46 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.215 |      0.182 |                   40 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.29850746268656714
[2m[36m(func pid=120129)[0m top5: 0.8540111940298507
[2m[36m(func pid=120129)[0m f1_micro: 0.29850746268656714
[2m[36m(func pid=120129)[0m f1_macro: 0.3061551796536919
[2m[36m(func pid=120129)[0m f1_weighted: 0.3088396461137079
[2m[36m(func pid=120129)[0m f1_per_class: [0.164, 0.417, 0.667, 0.275, 0.168, 0.338, 0.281, 0.349, 0.201, 0.2]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 2.2075 | Steps: 2 | Val loss: 2.2313 | Batch size: 32 | lr: 0.0001 | Duration: 3.11s
[2m[36m(func pid=125328)[0m top1: 0.11194029850746269
[2m[36m(func pid=125328)[0m top5: 0.8190298507462687
[2m[36m(func pid=125328)[0m f1_micro: 0.11194029850746269
[2m[36m(func pid=125328)[0m f1_macro: 0.10558336738022303
[2m[36m(func pid=125328)[0m f1_weighted: 0.08671160217867145
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.208, 0.197, 0.0, 0.031, 0.241, 0.0, 0.378, 0.0, 0.0]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 1.0542 | Steps: 2 | Val loss: 29.9335 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.2737 | Steps: 2 | Val loss: 5.5928 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=126248)[0m top1: 0.21222014925373134
[2m[36m(func pid=126248)[0m top5: 0.7178171641791045
[2m[36m(func pid=126248)[0m f1_micro: 0.21222014925373134
[2m[36m(func pid=126248)[0m f1_macro: 0.1843178392034651
[2m[36m(func pid=126248)[0m f1_weighted: 0.1981589350610868
[2m[36m(func pid=126248)[0m f1_per_class: [0.044, 0.192, 0.154, 0.325, 0.133, 0.381, 0.003, 0.425, 0.024, 0.162]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 2.9933 | Steps: 2 | Val loss: 26.8978 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
== Status ==
Current time: 2024-01-07 03:03:04 (running for 00:39:05.10)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.529 |      0.306 |                   68 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  1.054 |      0.087 |                   48 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  1.726 |      0.106 |                   47 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.208 |      0.184 |                   41 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.2737873134328358
[2m[36m(func pid=120129)[0m top5: 0.8526119402985075
[2m[36m(func pid=120129)[0m f1_micro: 0.2737873134328358
[2m[36m(func pid=120129)[0m f1_macro: 0.2765034671803476
[2m[36m(func pid=120129)[0m f1_weighted: 0.2615969871316916
[2m[36m(func pid=120129)[0m f1_per_class: [0.231, 0.411, 0.545, 0.22, 0.173, 0.349, 0.188, 0.273, 0.194, 0.182]
[2m[36m(func pid=124580)[0m top1: 0.12313432835820895
[2m[36m(func pid=124580)[0m top5: 0.5774253731343284
[2m[36m(func pid=124580)[0m f1_micro: 0.12313432835820895
[2m[36m(func pid=124580)[0m f1_macro: 0.08656438335405545
[2m[36m(func pid=124580)[0m f1_weighted: 0.11219726586077546
[2m[36m(func pid=124580)[0m f1_per_class: [0.029, 0.251, 0.0, 0.06, 0.2, 0.061, 0.138, 0.0, 0.038, 0.09]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 2.2372 | Steps: 2 | Val loss: 2.2251 | Batch size: 32 | lr: 0.0001 | Duration: 3.31s
[2m[36m(func pid=125328)[0m top1: 0.11380597014925373
[2m[36m(func pid=125328)[0m top5: 0.8097014925373134
[2m[36m(func pid=125328)[0m f1_micro: 0.11380597014925373
[2m[36m(func pid=125328)[0m f1_macro: 0.10421476990794303
[2m[36m(func pid=125328)[0m f1_weighted: 0.08586125630005514
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.209, 0.212, 0.0, 0.032, 0.254, 0.0, 0.335, 0.0, 0.0]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.1813 | Steps: 2 | Val loss: 5.9508 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.6974 | Steps: 2 | Val loss: 23.3463 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=126248)[0m top1: 0.20755597014925373
[2m[36m(func pid=126248)[0m top5: 0.7234141791044776
[2m[36m(func pid=126248)[0m f1_micro: 0.20755597014925375
[2m[36m(func pid=126248)[0m f1_macro: 0.17781829348165706
[2m[36m(func pid=126248)[0m f1_weighted: 0.1939512894693171
[2m[36m(func pid=126248)[0m f1_per_class: [0.045, 0.173, 0.162, 0.325, 0.104, 0.378, 0.003, 0.418, 0.024, 0.146]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 1.6576 | Steps: 2 | Val loss: 28.4458 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=120129)[0m top1: 0.27611940298507465
[2m[36m(func pid=120129)[0m top5: 0.8619402985074627
[2m[36m(func pid=120129)[0m f1_micro: 0.27611940298507465
[2m[36m(func pid=120129)[0m f1_macro: 0.2645989953711233
[2m[36m(func pid=120129)[0m f1_weighted: 0.25124053566404364
[2m[36m(func pid=120129)[0m f1_per_class: [0.331, 0.422, 0.387, 0.228, 0.17, 0.274, 0.168, 0.271, 0.133, 0.261]
[2m[36m(func pid=124580)[0m top1: 0.1333955223880597
[2m[36m(func pid=124580)[0m top5: 0.6138059701492538
[2m[36m(func pid=124580)[0m f1_micro: 0.1333955223880597
[2m[36m(func pid=124580)[0m f1_macro: 0.09715617792728577
[2m[36m(func pid=124580)[0m f1_weighted: 0.13588767663970594
[2m[36m(func pid=124580)[0m f1_per_class: [0.028, 0.277, 0.0, 0.116, 0.16, 0.136, 0.119, 0.015, 0.042, 0.079]
[2m[36m(func pid=124580)[0m 
== Status ==
Current time: 2024-01-07 03:03:09 (running for 00:39:10.50)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.274 |      0.277 |                   69 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.697 |      0.097 |                   49 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  2.993 |      0.104 |                   48 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.237 |      0.178 |                   42 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 2.2669 | Steps: 2 | Val loss: 2.2233 | Batch size: 32 | lr: 0.0001 | Duration: 3.15s
[2m[36m(func pid=125328)[0m top1: 0.07835820895522388
[2m[36m(func pid=125328)[0m top5: 0.7747201492537313
[2m[36m(func pid=125328)[0m f1_micro: 0.07835820895522388
[2m[36m(func pid=125328)[0m f1_macro: 0.07259489274102712
[2m[36m(func pid=125328)[0m f1_weighted: 0.0588801865621972
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.198, 0.233, 0.0, 0.026, 0.195, 0.0, 0.0, 0.0, 0.074]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.0948 | Steps: 2 | Val loss: 6.0033 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 1.0404 | Steps: 2 | Val loss: 18.9405 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=126248)[0m top1: 0.20569029850746268
[2m[36m(func pid=126248)[0m top5: 0.7322761194029851
[2m[36m(func pid=126248)[0m f1_micro: 0.20569029850746268
[2m[36m(func pid=126248)[0m f1_macro: 0.17778474649913095
[2m[36m(func pid=126248)[0m f1_weighted: 0.1943121196484871
[2m[36m(func pid=126248)[0m f1_per_class: [0.045, 0.185, 0.161, 0.315, 0.093, 0.382, 0.003, 0.421, 0.047, 0.125]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 1.8639 | Steps: 2 | Val loss: 30.4761 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 03:03:14 (running for 00:39:15.80)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.095 |      0.26  |                   71 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.697 |      0.097 |                   49 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  1.658 |      0.073 |                   49 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.267 |      0.178 |                   43 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.28824626865671643
[2m[36m(func pid=120129)[0m top5: 0.8698694029850746
[2m[36m(func pid=120129)[0m f1_micro: 0.28824626865671643
[2m[36m(func pid=120129)[0m f1_macro: 0.25992169869047876
[2m[36m(func pid=120129)[0m f1_weighted: 0.2643422183942325
[2m[36m(func pid=120129)[0m f1_per_class: [0.341, 0.424, 0.2, 0.247, 0.176, 0.268, 0.197, 0.279, 0.088, 0.378]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=124580)[0m top1: 0.13526119402985073
[2m[36m(func pid=124580)[0m top5: 0.6254664179104478
[2m[36m(func pid=124580)[0m f1_micro: 0.13526119402985073
[2m[36m(func pid=124580)[0m f1_macro: 0.11134111105416344
[2m[36m(func pid=124580)[0m f1_weighted: 0.14401201989622694
[2m[36m(func pid=124580)[0m f1_per_class: [0.047, 0.293, 0.144, 0.168, 0.0, 0.202, 0.051, 0.063, 0.06, 0.085]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=125328)[0m top1: 0.06063432835820896
[2m[36m(func pid=125328)[0m top5: 0.7038246268656716
[2m[36m(func pid=125328)[0m f1_micro: 0.06063432835820896
[2m[36m(func pid=125328)[0m f1_macro: 0.0633198289340969
[2m[36m(func pid=125328)[0m f1_weighted: 0.048822790849927154
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.224, 0.245, 0.0, 0.022, 0.068, 0.0, 0.0, 0.0, 0.074]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 2.1532 | Steps: 2 | Val loss: 2.2205 | Batch size: 32 | lr: 0.0001 | Duration: 3.26s
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.4762 | Steps: 2 | Val loss: 4.9791 | Batch size: 32 | lr: 0.001 | Duration: 3.11s
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 1.0271 | Steps: 2 | Val loss: 16.6587 | Batch size: 32 | lr: 0.01 | Duration: 3.14s
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 1.9414 | Steps: 2 | Val loss: 29.4488 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
[2m[36m(func pid=126248)[0m top1: 0.20569029850746268
[2m[36m(func pid=126248)[0m top5: 0.7374067164179104
[2m[36m(func pid=126248)[0m f1_micro: 0.20569029850746268
[2m[36m(func pid=126248)[0m f1_macro: 0.17776589396327375
[2m[36m(func pid=126248)[0m f1_weighted: 0.19304988475189458
[2m[36m(func pid=126248)[0m f1_per_class: [0.045, 0.167, 0.164, 0.316, 0.091, 0.393, 0.003, 0.428, 0.048, 0.122]
[2m[36m(func pid=126248)[0m 
== Status ==
Current time: 2024-01-07 03:03:20 (running for 00:39:21.04)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.095 |      0.26  |                   71 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  1.04  |      0.111 |                   50 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  1.864 |      0.063 |                   50 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.153 |      0.178 |                   44 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.32136194029850745
[2m[36m(func pid=120129)[0m top5: 0.8847947761194029
[2m[36m(func pid=120129)[0m f1_micro: 0.32136194029850745
[2m[36m(func pid=120129)[0m f1_macro: 0.2698202174221038
[2m[36m(func pid=120129)[0m f1_weighted: 0.3045707261656225
[2m[36m(func pid=120129)[0m f1_per_class: [0.297, 0.442, 0.174, 0.279, 0.119, 0.22, 0.301, 0.324, 0.118, 0.423]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=124580)[0m top1: 0.13805970149253732
[2m[36m(func pid=124580)[0m top5: 0.621268656716418
[2m[36m(func pid=124580)[0m f1_micro: 0.13805970149253732
[2m[36m(func pid=124580)[0m f1_macro: 0.11700355969395007
[2m[36m(func pid=124580)[0m f1_weighted: 0.15497868112552118
[2m[36m(func pid=124580)[0m f1_per_class: [0.04, 0.291, 0.083, 0.204, 0.0, 0.269, 0.024, 0.085, 0.088, 0.086]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=125328)[0m top1: 0.09375
[2m[36m(func pid=125328)[0m top5: 0.683768656716418
[2m[36m(func pid=125328)[0m f1_micro: 0.09375
[2m[36m(func pid=125328)[0m f1_macro: 0.07029012386068165
[2m[36m(func pid=125328)[0m f1_weighted: 0.0577047277103518
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.307, 0.276, 0.0, 0.027, 0.019, 0.0, 0.0, 0.0, 0.074]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 2.2020 | Steps: 2 | Val loss: 2.2174 | Batch size: 32 | lr: 0.0001 | Duration: 3.05s
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.2222 | Steps: 2 | Val loss: 4.2815 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 1.0673 | Steps: 2 | Val loss: 13.7748 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 2.1560 | Steps: 2 | Val loss: 29.5758 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
== Status ==
Current time: 2024-01-07 03:03:25 (running for 00:39:26.49)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.222 |      0.29  |                   73 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  1.027 |      0.117 |                   51 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  1.941 |      0.07  |                   51 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.153 |      0.178 |                   44 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.38152985074626866
[2m[36m(func pid=120129)[0m top5: 0.8917910447761194
[2m[36m(func pid=120129)[0m f1_micro: 0.3815298507462687
[2m[36m(func pid=120129)[0m f1_macro: 0.28983594796874346
[2m[36m(func pid=120129)[0m f1_weighted: 0.36583483102976155
[2m[36m(func pid=120129)[0m f1_per_class: [0.29, 0.437, 0.182, 0.3, 0.104, 0.17, 0.494, 0.436, 0.076, 0.41]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=126248)[0m top1: 0.20382462686567165
[2m[36m(func pid=126248)[0m top5: 0.7434701492537313
[2m[36m(func pid=126248)[0m f1_micro: 0.20382462686567165
[2m[36m(func pid=126248)[0m f1_macro: 0.17958084522922763
[2m[36m(func pid=126248)[0m f1_weighted: 0.1932931638465184
[2m[36m(func pid=126248)[0m f1_per_class: [0.045, 0.171, 0.166, 0.311, 0.084, 0.382, 0.006, 0.44, 0.065, 0.125]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=124580)[0m top1: 0.1669776119402985
[2m[36m(func pid=124580)[0m top5: 0.6450559701492538
[2m[36m(func pid=124580)[0m f1_micro: 0.1669776119402985
[2m[36m(func pid=124580)[0m f1_macro: 0.14252336964742507
[2m[36m(func pid=124580)[0m f1_weighted: 0.1906560001984036
[2m[36m(func pid=124580)[0m f1_per_class: [0.06, 0.303, 0.077, 0.266, 0.063, 0.275, 0.065, 0.111, 0.116, 0.089]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=125328)[0m top1: 0.166044776119403
[2m[36m(func pid=125328)[0m top5: 0.6875
[2m[36m(func pid=125328)[0m f1_micro: 0.166044776119403
[2m[36m(func pid=125328)[0m f1_macro: 0.09782153253943035
[2m[36m(func pid=125328)[0m f1_weighted: 0.07860029604599646
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.421, 0.324, 0.0, 0.011, 0.015, 0.0, 0.0, 0.0, 0.207]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.3250 | Steps: 2 | Val loss: 3.8661 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 2.1762 | Steps: 2 | Val loss: 2.2110 | Batch size: 32 | lr: 0.0001 | Duration: 3.07s
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.8223 | Steps: 2 | Val loss: 11.4702 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 1.8372 | Steps: 2 | Val loss: 29.7477 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
== Status ==
Current time: 2024-01-07 03:03:31 (running for 00:39:31.95)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: 0.327
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00017 | RUNNING    | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.325 |      0.269 |                   74 |
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  1.067 |      0.143 |                   52 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  2.156 |      0.098 |                   52 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.202 |      0.18  |                   45 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.40625
[2m[36m(func pid=120129)[0m top5: 0.8889925373134329
[2m[36m(func pid=120129)[0m f1_micro: 0.40625
[2m[36m(func pid=120129)[0m f1_macro: 0.26896942482977015
[2m[36m(func pid=120129)[0m f1_weighted: 0.3946681433225076
[2m[36m(func pid=120129)[0m f1_per_class: [0.247, 0.445, 0.2, 0.335, 0.095, 0.21, 0.578, 0.303, 0.026, 0.25]
[2m[36m(func pid=120129)[0m 
[2m[36m(func pid=124580)[0m top1: 0.20335820895522388
[2m[36m(func pid=124580)[0m top5: 0.7271455223880597
[2m[36m(func pid=124580)[0m f1_micro: 0.20335820895522388
[2m[36m(func pid=124580)[0m f1_macro: 0.1617979622939215
[2m[36m(func pid=124580)[0m f1_weighted: 0.2349091395327582
[2m[36m(func pid=124580)[0m f1_per_class: [0.056, 0.231, 0.108, 0.29, 0.092, 0.157, 0.259, 0.21, 0.093, 0.122]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=126248)[0m top1: 0.2019589552238806
[2m[36m(func pid=126248)[0m top5: 0.7546641791044776
[2m[36m(func pid=126248)[0m f1_micro: 0.2019589552238806
[2m[36m(func pid=126248)[0m f1_macro: 0.1809022403928205
[2m[36m(func pid=126248)[0m f1_weighted: 0.19190527937903282
[2m[36m(func pid=126248)[0m f1_per_class: [0.048, 0.172, 0.175, 0.315, 0.086, 0.354, 0.006, 0.441, 0.065, 0.146]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=125328)[0m top1: 0.17630597014925373
[2m[36m(func pid=125328)[0m top5: 0.7294776119402985
[2m[36m(func pid=125328)[0m f1_micro: 0.17630597014925373
[2m[36m(func pid=125328)[0m f1_macro: 0.08607184726212773
[2m[36m(func pid=125328)[0m f1_weighted: 0.0765327423982575
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.4, 0.353, 0.0, 0.0, 0.025, 0.006, 0.0, 0.0, 0.077]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=120129)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.0901 | Steps: 2 | Val loss: 3.6018 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.4955 | Steps: 2 | Val loss: 11.6990 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 2.1639 | Steps: 2 | Val loss: 2.2078 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
== Status ==
Current time: 2024-01-07 03:03:36 (running for 00:39:37.33)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: 0.32525000000000004
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 3 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.822 |      0.162 |                   53 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  1.837 |      0.086 |                   53 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.176 |      0.181 |                   46 |
| train_6ed81_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=120129)[0m top1: 0.40205223880597013
[2m[36m(func pid=120129)[0m top5: 0.8885261194029851
[2m[36m(func pid=120129)[0m f1_micro: 0.4020522388059702
[2m[36m(func pid=120129)[0m f1_macro: 0.2946430980242692
[2m[36m(func pid=120129)[0m f1_weighted: 0.4035397895146565
[2m[36m(func pid=120129)[0m f1_per_class: [0.323, 0.453, 0.267, 0.373, 0.095, 0.247, 0.56, 0.201, 0.026, 0.4]
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 1.6880 | Steps: 2 | Val loss: 27.3153 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
[2m[36m(func pid=124580)[0m top1: 0.23227611940298507
[2m[36m(func pid=124580)[0m top5: 0.7513992537313433
[2m[36m(func pid=124580)[0m f1_micro: 0.23227611940298507
[2m[36m(func pid=124580)[0m f1_macro: 0.1393978552057583
[2m[36m(func pid=124580)[0m f1_weighted: 0.2544079323411654
[2m[36m(func pid=124580)[0m f1_per_class: [0.015, 0.242, 0.0, 0.268, 0.074, 0.016, 0.425, 0.072, 0.069, 0.214]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=126248)[0m top1: 0.19916044776119404
[2m[36m(func pid=126248)[0m top5: 0.7630597014925373
[2m[36m(func pid=126248)[0m f1_micro: 0.19916044776119404
[2m[36m(func pid=126248)[0m f1_macro: 0.18081980422394323
[2m[36m(func pid=126248)[0m f1_weighted: 0.18812455537473802
[2m[36m(func pid=126248)[0m f1_per_class: [0.051, 0.157, 0.175, 0.301, 0.084, 0.358, 0.012, 0.444, 0.063, 0.162]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=125328)[0m top1: 0.1767723880597015
[2m[36m(func pid=125328)[0m top5: 0.7681902985074627
[2m[36m(func pid=125328)[0m f1_micro: 0.1767723880597015
[2m[36m(func pid=125328)[0m f1_macro: 0.09274276486146064
[2m[36m(func pid=125328)[0m f1_weighted: 0.08688525515497758
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.414, 0.353, 0.0, 0.007, 0.056, 0.021, 0.0, 0.0, 0.077]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 2.1675 | Steps: 2 | Val loss: 12.3400 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 2.1316 | Steps: 2 | Val loss: 2.2034 | Batch size: 32 | lr: 0.0001 | Duration: 3.14s
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 1.7593 | Steps: 2 | Val loss: 24.9587 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
[2m[36m(func pid=124580)[0m top1: 0.25652985074626866
[2m[36m(func pid=124580)[0m top5: 0.7966417910447762
[2m[36m(func pid=124580)[0m f1_micro: 0.25652985074626866
[2m[36m(func pid=124580)[0m f1_macro: 0.1504736493593707
[2m[36m(func pid=124580)[0m f1_weighted: 0.26380228730049843
[2m[36m(func pid=124580)[0m f1_per_class: [0.021, 0.265, 0.0, 0.233, 0.071, 0.024, 0.479, 0.015, 0.064, 0.333]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=126248)[0m top1: 0.19869402985074627
[2m[36m(func pid=126248)[0m top5: 0.7653917910447762
[2m[36m(func pid=126248)[0m f1_micro: 0.19869402985074627
[2m[36m(func pid=126248)[0m f1_macro: 0.17938245994764057
[2m[36m(func pid=126248)[0m f1_weighted: 0.18758686361422142
[2m[36m(func pid=126248)[0m f1_per_class: [0.05, 0.149, 0.176, 0.309, 0.079, 0.358, 0.009, 0.441, 0.061, 0.162]
[2m[36m(func pid=125328)[0m top1: 0.16184701492537312
[2m[36m(func pid=125328)[0m top5: 0.7873134328358209
[2m[36m(func pid=125328)[0m f1_micro: 0.16184701492537312
[2m[36m(func pid=125328)[0m f1_macro: 0.12223555960643773
[2m[36m(func pid=125328)[0m f1_weighted: 0.10205764609635574
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.407, 0.338, 0.0, 0.028, 0.089, 0.021, 0.201, 0.0, 0.138]
== Status ==
Current time: 2024-01-07 03:03:42 (running for 00:39:43.10)
Memory usage on this node: 22.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: 0.32525000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  2.167 |      0.15  |                   55 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  1.688 |      0.093 |                   54 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.164 |      0.181 |                   47 |
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=137284)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=137284)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=137284)[0m Configuration completed!
[2m[36m(func pid=137284)[0m New optimizer parameters:
[2m[36m(func pid=137284)[0m SGD (
[2m[36m(func pid=137284)[0m Parameter Group 0
[2m[36m(func pid=137284)[0m     dampening: 0
[2m[36m(func pid=137284)[0m     differentiable: False
[2m[36m(func pid=137284)[0m     foreach: None
[2m[36m(func pid=137284)[0m     lr: 0.001
[2m[36m(func pid=137284)[0m     maximize: False
[2m[36m(func pid=137284)[0m     momentum: 0.9
[2m[36m(func pid=137284)[0m     nesterov: False
[2m[36m(func pid=137284)[0m     weight_decay: 1e-05
[2m[36m(func pid=137284)[0m )
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.8826 | Steps: 2 | Val loss: 12.8571 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 1.6224 | Steps: 2 | Val loss: 23.5406 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 03:03:47 (running for 00:39:48.59)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: 0.32525000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.883 |      0.204 |                   56 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  1.759 |      0.122 |                   55 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.132 |      0.179 |                   48 |
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=124580)[0m top1: 0.30177238805970147
[2m[36m(func pid=124580)[0m top5: 0.8138992537313433
[2m[36m(func pid=124580)[0m f1_micro: 0.30177238805970147
[2m[36m(func pid=124580)[0m f1_macro: 0.20375045331074335
[2m[36m(func pid=124580)[0m f1_weighted: 0.3086660758087062
[2m[36m(func pid=124580)[0m f1_per_class: [0.024, 0.342, 0.0, 0.209, 0.05, 0.189, 0.497, 0.206, 0.136, 0.385]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 2.2298 | Steps: 2 | Val loss: 2.2012 | Batch size: 32 | lr: 0.0001 | Duration: 3.18s
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 3.0746 | Steps: 2 | Val loss: 2.3688 | Batch size: 32 | lr: 0.001 | Duration: 4.43s
[2m[36m(func pid=125328)[0m top1: 0.11007462686567164
[2m[36m(func pid=125328)[0m top5: 0.7779850746268657
[2m[36m(func pid=125328)[0m f1_micro: 0.11007462686567164
[2m[36m(func pid=125328)[0m f1_macro: 0.10522417786648175
[2m[36m(func pid=125328)[0m f1_weighted: 0.0790560365466672
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.307, 0.239, 0.0, 0.03, 0.06, 0.0, 0.278, 0.0, 0.138]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 1.0522 | Steps: 2 | Val loss: 17.0479 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
[2m[36m(func pid=126248)[0m top1: 0.20149253731343283
[2m[36m(func pid=126248)[0m top5: 0.7705223880597015
[2m[36m(func pid=126248)[0m f1_micro: 0.20149253731343283
[2m[36m(func pid=126248)[0m f1_macro: 0.1812771633338859
[2m[36m(func pid=126248)[0m f1_weighted: 0.19023533267058124
[2m[36m(func pid=126248)[0m f1_per_class: [0.05, 0.136, 0.169, 0.326, 0.079, 0.355, 0.009, 0.445, 0.061, 0.182]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=137284)[0m top1: 0.0732276119402985
[2m[36m(func pid=137284)[0m top5: 0.3306902985074627
[2m[36m(func pid=137284)[0m f1_micro: 0.0732276119402985
[2m[36m(func pid=137284)[0m f1_macro: 0.023578114036829634
[2m[36m(func pid=137284)[0m f1_weighted: 0.030182518787372953
[2m[36m(func pid=137284)[0m f1_per_class: [0.0, 0.0, 0.0, 0.081, 0.0, 0.0, 0.0, 0.126, 0.0, 0.029]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 1.5843 | Steps: 2 | Val loss: 23.4601 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 03:03:53 (running for 00:39:53.87)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: 0.32525000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  1.052 |      0.134 |                   57 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  1.622 |      0.105 |                   56 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.23  |      0.181 |                   49 |
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  3.075 |      0.024 |                    1 |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=124580)[0m top1: 0.22527985074626866
[2m[36m(func pid=124580)[0m top5: 0.7322761194029851
[2m[36m(func pid=124580)[0m f1_micro: 0.22527985074626866
[2m[36m(func pid=124580)[0m f1_macro: 0.1344254862465109
[2m[36m(func pid=124580)[0m f1_weighted: 0.210605732541925
[2m[36m(func pid=124580)[0m f1_per_class: [0.014, 0.352, 0.0, 0.214, 0.0, 0.125, 0.194, 0.254, 0.064, 0.13]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 2.1158 | Steps: 2 | Val loss: 2.1982 | Batch size: 32 | lr: 0.0001 | Duration: 3.13s
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 2.9674 | Steps: 2 | Val loss: 2.3210 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=125328)[0m top1: 0.07882462686567164
[2m[36m(func pid=125328)[0m top5: 0.7989738805970149
[2m[36m(func pid=125328)[0m f1_micro: 0.07882462686567164
[2m[36m(func pid=125328)[0m f1_macro: 0.08674607767500853
[2m[36m(func pid=125328)[0m f1_weighted: 0.0632232916971943
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.248, 0.19, 0.0, 0.025, 0.038, 0.0, 0.227, 0.0, 0.138]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.6248 | Steps: 2 | Val loss: 23.6837 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=126248)[0m top1: 0.20102611940298507
[2m[36m(func pid=126248)[0m top5: 0.777518656716418
[2m[36m(func pid=126248)[0m f1_micro: 0.2010261194029851
[2m[36m(func pid=126248)[0m f1_macro: 0.18164141383115645
[2m[36m(func pid=126248)[0m f1_weighted: 0.18969319676650095
[2m[36m(func pid=126248)[0m f1_per_class: [0.049, 0.131, 0.178, 0.327, 0.078, 0.358, 0.009, 0.441, 0.063, 0.182]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=137284)[0m top1: 0.1333955223880597
[2m[36m(func pid=137284)[0m top5: 0.4920708955223881
[2m[36m(func pid=137284)[0m f1_micro: 0.1333955223880597
[2m[36m(func pid=137284)[0m f1_macro: 0.07112106805395178
[2m[36m(func pid=137284)[0m f1_weighted: 0.09465564537044178
[2m[36m(func pid=137284)[0m f1_per_class: [0.0, 0.01, 0.03, 0.244, 0.0, 0.0, 0.0, 0.427, 0.0, 0.0]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 1.6190 | Steps: 2 | Val loss: 22.6655 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
== Status ==
Current time: 2024-01-07 03:03:58 (running for 00:39:59.37)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: 0.32525000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.625 |      0.089 |                   58 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  1.584 |      0.087 |                   57 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.116 |      0.182 |                   50 |
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  2.967 |      0.071 |                    2 |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=124580)[0m top1: 0.17164179104477612
[2m[36m(func pid=124580)[0m top5: 0.6338619402985075
[2m[36m(func pid=124580)[0m f1_micro: 0.17164179104477612
[2m[36m(func pid=124580)[0m f1_macro: 0.08875114224699203
[2m[36m(func pid=124580)[0m f1_weighted: 0.13309670300478307
[2m[36m(func pid=124580)[0m f1_per_class: [0.024, 0.327, 0.0, 0.157, 0.0, 0.046, 0.051, 0.176, 0.035, 0.072]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 2.2931 | Steps: 2 | Val loss: 2.1887 | Batch size: 32 | lr: 0.0001 | Duration: 3.39s
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 2.7817 | Steps: 2 | Val loss: 2.3104 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=125328)[0m top1: 0.06110074626865672
[2m[36m(func pid=125328)[0m top5: 0.8316231343283582
[2m[36m(func pid=125328)[0m f1_micro: 0.06110074626865672
[2m[36m(func pid=125328)[0m f1_macro: 0.0691244465676429
[2m[36m(func pid=125328)[0m f1_weighted: 0.05312983528751186
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.216, 0.131, 0.0, 0.023, 0.049, 0.0, 0.134, 0.0, 0.138]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.7437 | Steps: 2 | Val loss: 28.6417 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=126248)[0m top1: 0.19542910447761194
[2m[36m(func pid=126248)[0m top5: 0.78125
[2m[36m(func pid=126248)[0m f1_micro: 0.19542910447761194
[2m[36m(func pid=126248)[0m f1_macro: 0.17813159994092492
[2m[36m(func pid=126248)[0m f1_weighted: 0.1827335970591862
[2m[36m(func pid=126248)[0m f1_per_class: [0.057, 0.111, 0.179, 0.312, 0.071, 0.35, 0.012, 0.445, 0.065, 0.178]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=137284)[0m top1: 0.03544776119402985
[2m[36m(func pid=137284)[0m top5: 0.5811567164179104
[2m[36m(func pid=137284)[0m f1_micro: 0.03544776119402985
[2m[36m(func pid=137284)[0m f1_macro: 0.020727530910462352
[2m[36m(func pid=137284)[0m f1_weighted: 0.04014797655905438
[2m[36m(func pid=137284)[0m f1_per_class: [0.0, 0.0, 0.014, 0.131, 0.0, 0.0, 0.0, 0.062, 0.0, 0.0]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 1.7351 | Steps: 2 | Val loss: 21.4643 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 03:04:03 (running for 00:40:04.69)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: 0.32525000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.744 |      0.082 |                   59 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  1.619 |      0.069 |                   58 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.293 |      0.178 |                   51 |
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  2.782 |      0.021 |                    3 |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=124580)[0m top1: 0.15904850746268656
[2m[36m(func pid=124580)[0m top5: 0.5816231343283582
[2m[36m(func pid=124580)[0m f1_micro: 0.15904850746268656
[2m[36m(func pid=124580)[0m f1_macro: 0.08200909824323935
[2m[36m(func pid=124580)[0m f1_weighted: 0.11840610173323596
[2m[36m(func pid=124580)[0m f1_per_class: [0.031, 0.317, 0.0, 0.142, 0.0, 0.046, 0.022, 0.186, 0.015, 0.062]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 2.6648 | Steps: 2 | Val loss: 2.3012 | Batch size: 32 | lr: 0.001 | Duration: 2.76s
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 2.0930 | Steps: 2 | Val loss: 2.1854 | Batch size: 32 | lr: 0.0001 | Duration: 3.06s
[2m[36m(func pid=125328)[0m top1: 0.06110074626865672
[2m[36m(func pid=125328)[0m top5: 0.8619402985074627
[2m[36m(func pid=125328)[0m f1_micro: 0.06110074626865672
[2m[36m(func pid=125328)[0m f1_macro: 0.07261209459254077
[2m[36m(func pid=125328)[0m f1_weighted: 0.05271231368368595
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.18, 0.121, 0.0, 0.024, 0.116, 0.0, 0.092, 0.0, 0.194]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.7693 | Steps: 2 | Val loss: 31.4817 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=137284)[0m top1: 0.027052238805970148
[2m[36m(func pid=137284)[0m top5: 0.5755597014925373
[2m[36m(func pid=137284)[0m f1_micro: 0.027052238805970148
[2m[36m(func pid=137284)[0m f1_macro: 0.012502327099681474
[2m[36m(func pid=137284)[0m f1_weighted: 0.031225691776175322
[2m[36m(func pid=137284)[0m f1_per_class: [0.0, 0.0, 0.013, 0.112, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=126248)[0m top1: 0.1958955223880597
[2m[36m(func pid=126248)[0m top5: 0.7873134328358209
[2m[36m(func pid=126248)[0m f1_micro: 0.19589552238805974
[2m[36m(func pid=126248)[0m f1_macro: 0.1777206819188432
[2m[36m(func pid=126248)[0m f1_weighted: 0.1824510215477297
[2m[36m(func pid=126248)[0m f1_per_class: [0.057, 0.108, 0.179, 0.315, 0.072, 0.347, 0.012, 0.443, 0.066, 0.178]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 1.5781 | Steps: 2 | Val loss: 19.0592 | Batch size: 32 | lr: 0.1 | Duration: 3.06s
== Status ==
Current time: 2024-01-07 03:04:09 (running for 00:40:10.15)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: 0.32525000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.769 |      0.085 |                   60 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  1.735 |      0.073 |                   59 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.093 |      0.178 |                   52 |
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  2.665 |      0.013 |                    4 |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=124580)[0m top1: 0.14225746268656717
[2m[36m(func pid=124580)[0m top5: 0.5643656716417911
[2m[36m(func pid=124580)[0m f1_micro: 0.14225746268656717
[2m[36m(func pid=124580)[0m f1_macro: 0.08491539888779784
[2m[36m(func pid=124580)[0m f1_weighted: 0.11427501821293401
[2m[36m(func pid=124580)[0m f1_per_class: [0.036, 0.296, 0.0, 0.133, 0.044, 0.053, 0.022, 0.206, 0.0, 0.059]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 2.5307 | Steps: 2 | Val loss: 2.2844 | Batch size: 32 | lr: 0.001 | Duration: 3.04s
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 2.1822 | Steps: 2 | Val loss: 2.1839 | Batch size: 32 | lr: 0.0001 | Duration: 3.16s
[2m[36m(func pid=125328)[0m top1: 0.08069029850746269
[2m[36m(func pid=125328)[0m top5: 0.8791977611940298
[2m[36m(func pid=125328)[0m f1_micro: 0.08069029850746269
[2m[36m(func pid=125328)[0m f1_macro: 0.09261875806186057
[2m[36m(func pid=125328)[0m f1_weighted: 0.06644829826918787
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.197, 0.121, 0.0, 0.026, 0.175, 0.0, 0.148, 0.0, 0.258]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.7232 | Steps: 2 | Val loss: 30.7123 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=137284)[0m top1: 0.05177238805970149
[2m[36m(func pid=137284)[0m top5: 0.5988805970149254
[2m[36m(func pid=137284)[0m f1_micro: 0.05177238805970149
[2m[36m(func pid=137284)[0m f1_macro: 0.021839447765154806
[2m[36m(func pid=137284)[0m f1_weighted: 0.05632035419726944
[2m[36m(func pid=137284)[0m f1_per_class: [0.0, 0.005, 0.015, 0.198, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=126248)[0m top1: 0.19542910447761194
[2m[36m(func pid=126248)[0m top5: 0.7868470149253731
[2m[36m(func pid=126248)[0m f1_micro: 0.19542910447761194
[2m[36m(func pid=126248)[0m f1_macro: 0.17672517454594172
[2m[36m(func pid=126248)[0m f1_weighted: 0.18377120654332524
[2m[36m(func pid=126248)[0m f1_per_class: [0.054, 0.109, 0.176, 0.319, 0.068, 0.34, 0.015, 0.457, 0.043, 0.186]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 1.4833 | Steps: 2 | Val loss: 17.2975 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
== Status ==
Current time: 2024-01-07 03:04:14 (running for 00:40:15.56)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: 0.32525000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.723 |      0.102 |                   61 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  1.578 |      0.093 |                   60 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.182 |      0.177 |                   53 |
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  2.531 |      0.022 |                    5 |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=124580)[0m top1: 0.134794776119403
[2m[36m(func pid=124580)[0m top5: 0.605410447761194
[2m[36m(func pid=124580)[0m f1_micro: 0.134794776119403
[2m[36m(func pid=124580)[0m f1_macro: 0.1022013347878394
[2m[36m(func pid=124580)[0m f1_weighted: 0.13341504771254797
[2m[36m(func pid=124580)[0m f1_per_class: [0.038, 0.236, 0.0, 0.139, 0.126, 0.06, 0.102, 0.246, 0.0, 0.075]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 2.4775 | Steps: 2 | Val loss: 2.2608 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 2.0885 | Steps: 2 | Val loss: 2.1784 | Batch size: 32 | lr: 0.0001 | Duration: 3.11s
[2m[36m(func pid=125328)[0m top1: 0.09235074626865672
[2m[36m(func pid=125328)[0m top5: 0.8852611940298507
[2m[36m(func pid=125328)[0m f1_micro: 0.09235074626865672
[2m[36m(func pid=125328)[0m f1_macro: 0.09847490541953001
[2m[36m(func pid=125328)[0m f1_weighted: 0.07486542552976631
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.212, 0.123, 0.0, 0.029, 0.193, 0.012, 0.149, 0.0, 0.267]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 1.4855 | Steps: 2 | Val loss: 29.4221 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=137284)[0m top1: 0.12126865671641791
[2m[36m(func pid=137284)[0m top5: 0.6389925373134329
[2m[36m(func pid=137284)[0m f1_micro: 0.12126865671641791
[2m[36m(func pid=137284)[0m f1_macro: 0.04167097265452206
[2m[36m(func pid=137284)[0m f1_weighted: 0.0945942313413728
[2m[36m(func pid=137284)[0m f1_per_class: [0.056, 0.009, 0.023, 0.329, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=126248)[0m top1: 0.1958955223880597
[2m[36m(func pid=126248)[0m top5: 0.789179104477612
[2m[36m(func pid=126248)[0m f1_micro: 0.19589552238805974
[2m[36m(func pid=126248)[0m f1_macro: 0.17441423875606715
[2m[36m(func pid=126248)[0m f1_weighted: 0.1811532824171317
[2m[36m(func pid=126248)[0m f1_per_class: [0.06, 0.095, 0.191, 0.32, 0.069, 0.353, 0.012, 0.439, 0.042, 0.162]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 1.3638 | Steps: 2 | Val loss: 15.8136 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=124580)[0m top1: 0.17957089552238806
[2m[36m(func pid=124580)[0m top5: 0.6609141791044776
[2m[36m(func pid=124580)[0m f1_micro: 0.17957089552238806
[2m[36m(func pid=124580)[0m f1_macro: 0.1512176221607759
[2m[36m(func pid=124580)[0m f1_weighted: 0.20705786937455847
[2m[36m(func pid=124580)[0m f1_per_class: [0.072, 0.211, 0.0, 0.123, 0.13, 0.083, 0.338, 0.325, 0.115, 0.116]
== Status ==
Current time: 2024-01-07 03:04:20 (running for 00:40:20.90)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: 0.32525000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  1.485 |      0.151 |                   62 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  1.483 |      0.098 |                   61 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.088 |      0.174 |                   54 |
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  2.477 |      0.042 |                    6 |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 2.3863 | Steps: 2 | Val loss: 2.2343 | Batch size: 32 | lr: 0.001 | Duration: 3.08s
[2m[36m(func pid=125328)[0m top1: 0.09514925373134328
[2m[36m(func pid=125328)[0m top5: 0.8922574626865671
[2m[36m(func pid=125328)[0m f1_micro: 0.09514925373134328
[2m[36m(func pid=125328)[0m f1_macro: 0.10457063256710394
[2m[36m(func pid=125328)[0m f1_weighted: 0.08330431189586206
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.225, 0.129, 0.0, 0.029, 0.159, 0.036, 0.201, 0.0, 0.267]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 2.1484 | Steps: 2 | Val loss: 2.1755 | Batch size: 32 | lr: 0.0001 | Duration: 3.20s
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 1.5134 | Steps: 2 | Val loss: 27.6119 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=137284)[0m top1: 0.15951492537313433
[2m[36m(func pid=137284)[0m top5: 0.7019589552238806
[2m[36m(func pid=137284)[0m f1_micro: 0.15951492537313433
[2m[36m(func pid=137284)[0m f1_macro: 0.06629328693818577
[2m[36m(func pid=137284)[0m f1_weighted: 0.10587945188555033
[2m[36m(func pid=137284)[0m f1_per_class: [0.067, 0.023, 0.053, 0.321, 0.08, 0.055, 0.0, 0.062, 0.0, 0.0]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 1.5398 | Steps: 2 | Val loss: 14.3320 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=126248)[0m top1: 0.19402985074626866
[2m[36m(func pid=126248)[0m top5: 0.7975746268656716
[2m[36m(func pid=126248)[0m f1_micro: 0.19402985074626866
[2m[36m(func pid=126248)[0m f1_macro: 0.1744480079097452
[2m[36m(func pid=126248)[0m f1_weighted: 0.18039094884582121
[2m[36m(func pid=126248)[0m f1_per_class: [0.06, 0.085, 0.198, 0.329, 0.068, 0.331, 0.015, 0.424, 0.062, 0.171]
[2m[36m(func pid=126248)[0m 
== Status ==
Current time: 2024-01-07 03:04:25 (running for 00:40:26.11)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: 0.32525000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  1.513 |      0.173 |                   63 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  1.364 |      0.105 |                   62 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.148 |      0.174 |                   55 |
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  2.386 |      0.066 |                    7 |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=124580)[0m top1: 0.21875
[2m[36m(func pid=124580)[0m top5: 0.7098880597014925
[2m[36m(func pid=124580)[0m f1_micro: 0.21875
[2m[36m(func pid=124580)[0m f1_macro: 0.17265999884945107
[2m[36m(func pid=124580)[0m f1_weighted: 0.24415914866712338
[2m[36m(func pid=124580)[0m f1_per_class: [0.068, 0.256, 0.0, 0.113, 0.099, 0.125, 0.423, 0.344, 0.125, 0.173]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 2.3233 | Steps: 2 | Val loss: 2.1981 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=125328)[0m top1: 0.11240671641791045
[2m[36m(func pid=125328)[0m top5: 0.8908582089552238
[2m[36m(func pid=125328)[0m f1_micro: 0.11240671641791045
[2m[36m(func pid=125328)[0m f1_macro: 0.11545691861209495
[2m[36m(func pid=125328)[0m f1_weighted: 0.11008415721492562
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.244, 0.125, 0.0, 0.03, 0.148, 0.114, 0.227, 0.0, 0.267]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 2.1791 | Steps: 2 | Val loss: 2.1760 | Batch size: 32 | lr: 0.0001 | Duration: 3.11s
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.5587 | Steps: 2 | Val loss: 26.3702 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=137284)[0m top1: 0.20055970149253732
[2m[36m(func pid=137284)[0m top5: 0.8236940298507462
[2m[36m(func pid=137284)[0m f1_micro: 0.20055970149253732
[2m[36m(func pid=137284)[0m f1_macro: 0.1234381272134761
[2m[36m(func pid=137284)[0m f1_weighted: 0.18575873477384328
[2m[36m(func pid=137284)[0m f1_per_class: [0.093, 0.081, 0.123, 0.308, 0.171, 0.157, 0.195, 0.107, 0.0, 0.0]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 2.0284 | Steps: 2 | Val loss: 14.4164 | Batch size: 32 | lr: 0.1 | Duration: 2.75s
== Status ==
Current time: 2024-01-07 03:04:30 (running for 00:40:31.38)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: 0.32525000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.559 |      0.159 |                   64 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  1.54  |      0.115 |                   63 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.148 |      0.174 |                   55 |
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  2.323 |      0.123 |                    8 |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=124580)[0m top1: 0.20569029850746268
[2m[36m(func pid=124580)[0m top5: 0.7388059701492538
[2m[36m(func pid=124580)[0m f1_micro: 0.20569029850746268
[2m[36m(func pid=124580)[0m f1_macro: 0.15883588981946511
[2m[36m(func pid=124580)[0m f1_weighted: 0.20451056917689292
[2m[36m(func pid=124580)[0m f1_per_class: [0.061, 0.332, 0.0, 0.102, 0.114, 0.124, 0.269, 0.285, 0.109, 0.193]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=126248)[0m top1: 0.1912313432835821
[2m[36m(func pid=126248)[0m top5: 0.7957089552238806
[2m[36m(func pid=126248)[0m f1_micro: 0.19123134328358207
[2m[36m(func pid=126248)[0m f1_macro: 0.17143621062924924
[2m[36m(func pid=126248)[0m f1_weighted: 0.17850835250635752
[2m[36m(func pid=126248)[0m f1_per_class: [0.059, 0.094, 0.196, 0.316, 0.069, 0.34, 0.015, 0.427, 0.04, 0.158]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 2.3180 | Steps: 2 | Val loss: 2.1694 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=125328)[0m top1: 0.12080223880597014
[2m[36m(func pid=125328)[0m top5: 0.882929104477612
[2m[36m(func pid=125328)[0m f1_micro: 0.12080223880597014
[2m[36m(func pid=125328)[0m f1_macro: 0.11901650597361244
[2m[36m(func pid=125328)[0m f1_weighted: 0.12270773938968041
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.263, 0.127, 0.0, 0.029, 0.122, 0.155, 0.227, 0.0, 0.267]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.4621 | Steps: 2 | Val loss: 24.7485 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 2.0578 | Steps: 2 | Val loss: 2.1727 | Batch size: 32 | lr: 0.0001 | Duration: 3.15s
[2m[36m(func pid=137284)[0m top1: 0.24440298507462688
[2m[36m(func pid=137284)[0m top5: 0.8558768656716418
[2m[36m(func pid=137284)[0m f1_micro: 0.24440298507462688
[2m[36m(func pid=137284)[0m f1_macro: 0.15757057172698236
[2m[36m(func pid=137284)[0m f1_weighted: 0.258198083559296
[2m[36m(func pid=137284)[0m f1_per_class: [0.105, 0.112, 0.202, 0.303, 0.091, 0.28, 0.377, 0.107, 0.0, 0.0]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 1.4832 | Steps: 2 | Val loss: 15.0576 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
== Status ==
Current time: 2024-01-07 03:04:36 (running for 00:40:36.84)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: 0.32525000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.462 |      0.16  |                   65 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  2.028 |      0.119 |                   64 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.179 |      0.171 |                   56 |
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  2.318 |      0.158 |                    9 |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=124580)[0m top1: 0.20289179104477612
[2m[36m(func pid=124580)[0m top5: 0.7854477611940298
[2m[36m(func pid=124580)[0m f1_micro: 0.20289179104477612
[2m[36m(func pid=124580)[0m f1_macro: 0.15981316861477196
[2m[36m(func pid=124580)[0m f1_weighted: 0.18312763834687149
[2m[36m(func pid=124580)[0m f1_per_class: [0.054, 0.375, 0.0, 0.109, 0.159, 0.21, 0.138, 0.25, 0.125, 0.178]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=126248)[0m top1: 0.19076492537313433
[2m[36m(func pid=126248)[0m top5: 0.7961753731343284
[2m[36m(func pid=126248)[0m f1_micro: 0.19076492537313436
[2m[36m(func pid=126248)[0m f1_macro: 0.16721922643794937
[2m[36m(func pid=126248)[0m f1_weighted: 0.1760498436603244
[2m[36m(func pid=126248)[0m f1_per_class: [0.062, 0.08, 0.208, 0.325, 0.07, 0.33, 0.012, 0.422, 0.041, 0.122]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 2.1835 | Steps: 2 | Val loss: 2.1431 | Batch size: 32 | lr: 0.001 | Duration: 2.72s
[2m[36m(func pid=125328)[0m top1: 0.10914179104477612
[2m[36m(func pid=125328)[0m top5: 0.8810634328358209
[2m[36m(func pid=125328)[0m f1_micro: 0.10914179104477612
[2m[36m(func pid=125328)[0m f1_macro: 0.11281604129527933
[2m[36m(func pid=125328)[0m f1_weighted: 0.11564151203367413
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.247, 0.143, 0.0, 0.026, 0.067, 0.164, 0.214, 0.0, 0.267]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 1.1437 | Steps: 2 | Val loss: 20.7563 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 2.1206 | Steps: 2 | Val loss: 2.1701 | Batch size: 32 | lr: 0.0001 | Duration: 3.07s
[2m[36m(func pid=137284)[0m top1: 0.25699626865671643
[2m[36m(func pid=137284)[0m top5: 0.8917910447761194
[2m[36m(func pid=137284)[0m f1_micro: 0.25699626865671643
[2m[36m(func pid=137284)[0m f1_macro: 0.20131166001944742
[2m[36m(func pid=137284)[0m f1_weighted: 0.2871435900355725
[2m[36m(func pid=137284)[0m f1_per_class: [0.119, 0.193, 0.333, 0.283, 0.087, 0.326, 0.406, 0.19, 0.0, 0.077]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 1.3547 | Steps: 2 | Val loss: 16.1771 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 03:04:41 (running for 00:40:42.32)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: 0.32525000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  1.144 |      0.156 |                   66 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  1.483 |      0.113 |                   65 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.058 |      0.167 |                   57 |
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  2.184 |      0.201 |                   10 |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=124580)[0m top1: 0.19776119402985073
[2m[36m(func pid=124580)[0m top5: 0.8073694029850746
[2m[36m(func pid=124580)[0m f1_micro: 0.19776119402985073
[2m[36m(func pid=124580)[0m f1_macro: 0.1556612419235855
[2m[36m(func pid=124580)[0m f1_weighted: 0.17262461212927868
[2m[36m(func pid=124580)[0m f1_per_class: [0.06, 0.392, 0.0, 0.119, 0.167, 0.251, 0.073, 0.241, 0.102, 0.152]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=126248)[0m top1: 0.19869402985074627
[2m[36m(func pid=126248)[0m top5: 0.7966417910447762
[2m[36m(func pid=126248)[0m f1_micro: 0.19869402985074627
[2m[36m(func pid=126248)[0m f1_macro: 0.1780917857153445
[2m[36m(func pid=126248)[0m f1_weighted: 0.18868537921918654
[2m[36m(func pid=126248)[0m f1_per_class: [0.059, 0.118, 0.204, 0.331, 0.069, 0.34, 0.018, 0.438, 0.043, 0.16]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 2.1505 | Steps: 2 | Val loss: 2.1191 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=125328)[0m top1: 0.09888059701492537
[2m[36m(func pid=125328)[0m top5: 0.8843283582089553
[2m[36m(func pid=125328)[0m f1_micro: 0.09888059701492537
[2m[36m(func pid=125328)[0m f1_macro: 0.1085002200911311
[2m[36m(func pid=125328)[0m f1_weighted: 0.10717972275048943
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.237, 0.145, 0.0, 0.024, 0.031, 0.163, 0.162, 0.0, 0.323]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 1.0036 | Steps: 2 | Val loss: 14.6517 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=137284)[0m top1: 0.23507462686567165
[2m[36m(func pid=137284)[0m top5: 0.8955223880597015
[2m[36m(func pid=137284)[0m f1_micro: 0.23507462686567163
[2m[36m(func pid=137284)[0m f1_macro: 0.2060415434960662
[2m[36m(func pid=137284)[0m f1_weighted: 0.2693326109545497
[2m[36m(func pid=137284)[0m f1_per_class: [0.137, 0.259, 0.323, 0.244, 0.056, 0.241, 0.338, 0.386, 0.0, 0.077]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 2.0744 | Steps: 2 | Val loss: 2.1666 | Batch size: 32 | lr: 0.0001 | Duration: 3.01s
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 1.5404 | Steps: 2 | Val loss: 17.4945 | Batch size: 32 | lr: 0.1 | Duration: 2.74s
== Status ==
Current time: 2024-01-07 03:04:46 (running for 00:40:47.65)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: 0.32525000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  1.004 |      0.159 |                   67 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  1.355 |      0.109 |                   66 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.121 |      0.178 |                   58 |
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  2.151 |      0.206 |                   11 |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=124580)[0m top1: 0.18610074626865672
[2m[36m(func pid=124580)[0m top5: 0.8227611940298507
[2m[36m(func pid=124580)[0m f1_micro: 0.1861007462686567
[2m[36m(func pid=124580)[0m f1_macro: 0.15895524820188764
[2m[36m(func pid=124580)[0m f1_weighted: 0.18235268150974807
[2m[36m(func pid=124580)[0m f1_per_class: [0.059, 0.359, 0.0, 0.148, 0.137, 0.303, 0.079, 0.242, 0.082, 0.18]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 2.0710 | Steps: 2 | Val loss: 2.0847 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=126248)[0m top1: 0.20102611940298507
[2m[36m(func pid=126248)[0m top5: 0.8083022388059702
[2m[36m(func pid=126248)[0m f1_micro: 0.2010261194029851
[2m[36m(func pid=126248)[0m f1_macro: 0.18235714922199425
[2m[36m(func pid=126248)[0m f1_weighted: 0.19069675474197467
[2m[36m(func pid=126248)[0m f1_per_class: [0.061, 0.105, 0.212, 0.332, 0.07, 0.345, 0.027, 0.446, 0.043, 0.182]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=125328)[0m top1: 0.09048507462686567
[2m[36m(func pid=125328)[0m top5: 0.8838619402985075
[2m[36m(func pid=125328)[0m f1_micro: 0.09048507462686567
[2m[36m(func pid=125328)[0m f1_macro: 0.10011579436225841
[2m[36m(func pid=125328)[0m f1_weighted: 0.09647101025794062
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.235, 0.163, 0.0, 0.023, 0.02, 0.146, 0.092, 0.0, 0.323]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.9757 | Steps: 2 | Val loss: 11.3937 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=137284)[0m top1: 0.2593283582089552
[2m[36m(func pid=137284)[0m top5: 0.90625
[2m[36m(func pid=137284)[0m f1_micro: 0.2593283582089552
[2m[36m(func pid=137284)[0m f1_macro: 0.2264712940054447
[2m[36m(func pid=137284)[0m f1_weighted: 0.2983809818315667
[2m[36m(func pid=137284)[0m f1_per_class: [0.161, 0.274, 0.303, 0.246, 0.051, 0.256, 0.4, 0.453, 0.048, 0.074]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 2.0607 | Steps: 2 | Val loss: 2.1608 | Batch size: 32 | lr: 0.0001 | Duration: 3.19s
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 1.3237 | Steps: 2 | Val loss: 18.3242 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
== Status ==
Current time: 2024-01-07 03:04:52 (running for 00:40:52.85)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: 0.32525000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.976 |      0.148 |                   68 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  1.54  |      0.1   |                   67 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.074 |      0.182 |                   59 |
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  2.071 |      0.226 |                   12 |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=124580)[0m top1: 0.17257462686567165
[2m[36m(func pid=124580)[0m top5: 0.8288246268656716
[2m[36m(func pid=124580)[0m f1_micro: 0.17257462686567165
[2m[36m(func pid=124580)[0m f1_macro: 0.14818647203874077
[2m[36m(func pid=124580)[0m f1_weighted: 0.18812392916212922
[2m[36m(func pid=124580)[0m f1_per_class: [0.057, 0.273, 0.0, 0.182, 0.108, 0.259, 0.136, 0.238, 0.088, 0.142]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 1.9900 | Steps: 2 | Val loss: 2.0635 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=126248)[0m top1: 0.2019589552238806
[2m[36m(func pid=126248)[0m top5: 0.8138992537313433
[2m[36m(func pid=126248)[0m f1_micro: 0.2019589552238806
[2m[36m(func pid=126248)[0m f1_macro: 0.18560865374131671
[2m[36m(func pid=126248)[0m f1_weighted: 0.19264356026408982
[2m[36m(func pid=126248)[0m f1_per_class: [0.068, 0.109, 0.22, 0.336, 0.067, 0.331, 0.03, 0.456, 0.043, 0.195]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=125328)[0m top1: 0.08255597014925373
[2m[36m(func pid=125328)[0m top5: 0.8847947761194029
[2m[36m(func pid=125328)[0m f1_micro: 0.08255597014925373
[2m[36m(func pid=125328)[0m f1_macro: 0.09354779096343886
[2m[36m(func pid=125328)[0m f1_weighted: 0.08552336443430206
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.229, 0.174, 0.0, 0.023, 0.019, 0.122, 0.047, 0.0, 0.323]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.4250 | Steps: 2 | Val loss: 9.5778 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=137284)[0m top1: 0.271455223880597
[2m[36m(func pid=137284)[0m top5: 0.9127798507462687
[2m[36m(func pid=137284)[0m f1_micro: 0.271455223880597
[2m[36m(func pid=137284)[0m f1_macro: 0.24385086847146947
[2m[36m(func pid=137284)[0m f1_weighted: 0.3139945031036633
[2m[36m(func pid=137284)[0m f1_per_class: [0.177, 0.289, 0.278, 0.267, 0.051, 0.228, 0.414, 0.522, 0.086, 0.126]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 1.3262 | Steps: 2 | Val loss: 18.7184 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 1.9860 | Steps: 2 | Val loss: 2.1548 | Batch size: 32 | lr: 0.0001 | Duration: 3.13s
[2m[36m(func pid=124580)[0m top1: 0.20335820895522388
[2m[36m(func pid=124580)[0m top5: 0.8372201492537313
[2m[36m(func pid=124580)[0m f1_micro: 0.20335820895522388
[2m[36m(func pid=124580)[0m f1_macro: 0.1825357572536461
[2m[36m(func pid=124580)[0m f1_weighted: 0.2349115079512614
[2m[36m(func pid=124580)[0m f1_per_class: [0.061, 0.25, 0.222, 0.232, 0.101, 0.21, 0.269, 0.253, 0.109, 0.119]
[2m[36m(func pid=124580)[0m 
== Status ==
Current time: 2024-01-07 03:04:57 (running for 00:40:58.26)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: 0.32525000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.425 |      0.183 |                   69 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  1.324 |      0.094 |                   68 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.061 |      0.186 |                   60 |
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  1.99  |      0.244 |                   13 |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 1.9263 | Steps: 2 | Val loss: 2.0536 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=125328)[0m top1: 0.0732276119402985
[2m[36m(func pid=125328)[0m top5: 0.8894589552238806
[2m[36m(func pid=125328)[0m f1_micro: 0.0732276119402985
[2m[36m(func pid=125328)[0m f1_macro: 0.08385353969652738
[2m[36m(func pid=125328)[0m f1_weighted: 0.0691646182314849
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.231, 0.186, 0.0, 0.023, 0.017, 0.068, 0.047, 0.0, 0.267]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=126248)[0m top1: 0.20615671641791045
[2m[36m(func pid=126248)[0m top5: 0.820429104477612
[2m[36m(func pid=126248)[0m f1_micro: 0.20615671641791045
[2m[36m(func pid=126248)[0m f1_macro: 0.18900323645071276
[2m[36m(func pid=126248)[0m f1_weighted: 0.1978245196343377
[2m[36m(func pid=126248)[0m f1_per_class: [0.073, 0.109, 0.224, 0.336, 0.067, 0.339, 0.045, 0.455, 0.043, 0.2]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.3248 | Steps: 2 | Val loss: 8.4501 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=137284)[0m top1: 0.25093283582089554
[2m[36m(func pid=137284)[0m top5: 0.9076492537313433
[2m[36m(func pid=137284)[0m f1_micro: 0.25093283582089554
[2m[36m(func pid=137284)[0m f1_macro: 0.24469529170199347
[2m[36m(func pid=137284)[0m f1_weighted: 0.2951466834836079
[2m[36m(func pid=137284)[0m f1_per_class: [0.245, 0.276, 0.314, 0.324, 0.046, 0.198, 0.313, 0.508, 0.102, 0.121]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 1.4474 | Steps: 2 | Val loss: 17.8061 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 2.0054 | Steps: 2 | Val loss: 2.1519 | Batch size: 32 | lr: 0.0001 | Duration: 3.07s
== Status ==
Current time: 2024-01-07 03:05:02 (running for 00:41:03.58)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: 0.32525000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.325 |      0.192 |                   70 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  1.326 |      0.084 |                   69 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  1.986 |      0.189 |                   61 |
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  1.926 |      0.245 |                   14 |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=124580)[0m top1: 0.25279850746268656
[2m[36m(func pid=124580)[0m top5: 0.8479477611940298
[2m[36m(func pid=124580)[0m f1_micro: 0.25279850746268656
[2m[36m(func pid=124580)[0m f1_macro: 0.1922119072116739
[2m[36m(func pid=124580)[0m f1_weighted: 0.29253529067601997
[2m[36m(func pid=124580)[0m f1_per_class: [0.056, 0.254, 0.217, 0.284, 0.083, 0.135, 0.448, 0.222, 0.109, 0.114]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 1.8991 | Steps: 2 | Val loss: 2.0358 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=125328)[0m top1: 0.07416044776119403
[2m[36m(func pid=125328)[0m top5: 0.8908582089552238
[2m[36m(func pid=125328)[0m f1_micro: 0.07416044776119403
[2m[36m(func pid=125328)[0m f1_macro: 0.08968650780280882
[2m[36m(func pid=125328)[0m f1_weighted: 0.06068931118386972
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.245, 0.238, 0.0, 0.025, 0.043, 0.018, 0.062, 0.0, 0.267]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=126248)[0m top1: 0.20708955223880596
[2m[36m(func pid=126248)[0m top5: 0.8185634328358209
[2m[36m(func pid=126248)[0m f1_micro: 0.20708955223880596
[2m[36m(func pid=126248)[0m f1_macro: 0.19104253187682835
[2m[36m(func pid=126248)[0m f1_weighted: 0.19752042235945577
[2m[36m(func pid=126248)[0m f1_per_class: [0.079, 0.112, 0.239, 0.333, 0.065, 0.347, 0.039, 0.462, 0.042, 0.19]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.4213 | Steps: 2 | Val loss: 7.6765 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=137284)[0m top1: 0.27005597014925375
[2m[36m(func pid=137284)[0m top5: 0.9048507462686567
[2m[36m(func pid=137284)[0m f1_micro: 0.27005597014925375
[2m[36m(func pid=137284)[0m f1_macro: 0.27292656771199786
[2m[36m(func pid=137284)[0m f1_weighted: 0.3112016220412091
[2m[36m(func pid=137284)[0m f1_per_class: [0.255, 0.247, 0.293, 0.351, 0.045, 0.267, 0.316, 0.548, 0.096, 0.31]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 1.3631 | Steps: 2 | Val loss: 17.0407 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 2.1952 | Steps: 2 | Val loss: 2.1520 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
== Status ==
Current time: 2024-01-07 03:05:08 (running for 00:41:08.87)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: 0.32525000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.421 |      0.182 |                   71 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  1.447 |      0.09  |                   70 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.005 |      0.191 |                   62 |
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  1.899 |      0.273 |                   15 |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=124580)[0m top1: 0.2826492537313433
[2m[36m(func pid=124580)[0m top5: 0.8610074626865671
[2m[36m(func pid=124580)[0m f1_micro: 0.2826492537313433
[2m[36m(func pid=124580)[0m f1_macro: 0.18231095155042104
[2m[36m(func pid=124580)[0m f1_weighted: 0.31279377650352447
[2m[36m(func pid=124580)[0m f1_per_class: [0.062, 0.257, 0.215, 0.338, 0.029, 0.039, 0.516, 0.137, 0.113, 0.117]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 1.8405 | Steps: 2 | Val loss: 2.0130 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=125328)[0m top1: 0.08582089552238806
[2m[36m(func pid=125328)[0m top5: 0.886660447761194
[2m[36m(func pid=125328)[0m f1_micro: 0.08582089552238806
[2m[36m(func pid=125328)[0m f1_macro: 0.09831517949194549
[2m[36m(func pid=125328)[0m f1_weighted: 0.06491377990423428
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.266, 0.205, 0.003, 0.027, 0.067, 0.0, 0.092, 0.0, 0.323]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=126248)[0m top1: 0.2080223880597015
[2m[36m(func pid=126248)[0m top5: 0.8208955223880597
[2m[36m(func pid=126248)[0m f1_micro: 0.2080223880597015
[2m[36m(func pid=126248)[0m f1_macro: 0.19230835628571136
[2m[36m(func pid=126248)[0m f1_weighted: 0.20252884268680196
[2m[36m(func pid=126248)[0m f1_per_class: [0.071, 0.143, 0.224, 0.331, 0.065, 0.351, 0.039, 0.466, 0.043, 0.19]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.6207 | Steps: 2 | Val loss: 7.0753 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=137284)[0m top1: 0.279384328358209
[2m[36m(func pid=137284)[0m top5: 0.8903917910447762
[2m[36m(func pid=137284)[0m f1_micro: 0.279384328358209
[2m[36m(func pid=137284)[0m f1_macro: 0.2658377609307413
[2m[36m(func pid=137284)[0m f1_weighted: 0.30872740040308094
[2m[36m(func pid=137284)[0m f1_per_class: [0.258, 0.24, 0.227, 0.399, 0.049, 0.284, 0.268, 0.527, 0.074, 0.333]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 1.2410 | Steps: 2 | Val loss: 15.0311 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 03:05:13 (running for 00:41:14.23)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: 0.32525000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.621 |      0.205 |                   72 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  1.363 |      0.098 |                   71 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.195 |      0.192 |                   63 |
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  1.841 |      0.266 |                   16 |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=124580)[0m top1: 0.3185634328358209
[2m[36m(func pid=124580)[0m top5: 0.8684701492537313
[2m[36m(func pid=124580)[0m f1_micro: 0.3185634328358209
[2m[36m(func pid=124580)[0m f1_macro: 0.20477381868747896
[2m[36m(func pid=124580)[0m f1_weighted: 0.3411364007741648
[2m[36m(func pid=124580)[0m f1_per_class: [0.075, 0.296, 0.247, 0.375, 0.0, 0.047, 0.535, 0.204, 0.132, 0.137]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 1.9890 | Steps: 2 | Val loss: 2.1471 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 1.7650 | Steps: 2 | Val loss: 1.9954 | Batch size: 32 | lr: 0.001 | Duration: 2.76s
[2m[36m(func pid=125328)[0m top1: 0.10167910447761194
[2m[36m(func pid=125328)[0m top5: 0.8894589552238806
[2m[36m(func pid=125328)[0m f1_micro: 0.10167910447761194
[2m[36m(func pid=125328)[0m f1_macro: 0.1251687003931833
[2m[36m(func pid=125328)[0m f1_weighted: 0.07790561985241878
[2m[36m(func pid=125328)[0m f1_per_class: [0.0, 0.28, 0.238, 0.003, 0.03, 0.1, 0.0, 0.188, 0.0, 0.412]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=126248)[0m top1: 0.20942164179104478
[2m[36m(func pid=126248)[0m top5: 0.824160447761194
[2m[36m(func pid=126248)[0m f1_micro: 0.20942164179104478
[2m[36m(func pid=126248)[0m f1_macro: 0.194044040891267
[2m[36m(func pid=126248)[0m f1_weighted: 0.20075927324492618
[2m[36m(func pid=126248)[0m f1_per_class: [0.074, 0.133, 0.232, 0.33, 0.066, 0.359, 0.036, 0.462, 0.043, 0.205]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.6083 | Steps: 2 | Val loss: 6.8025 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=137284)[0m top1: 0.26492537313432835
[2m[36m(func pid=137284)[0m top5: 0.8801305970149254
[2m[36m(func pid=137284)[0m f1_micro: 0.26492537313432835
[2m[36m(func pid=137284)[0m f1_macro: 0.2214787998448385
[2m[36m(func pid=137284)[0m f1_weighted: 0.26579140692885
[2m[36m(func pid=137284)[0m f1_per_class: [0.231, 0.19, 0.227, 0.462, 0.055, 0.237, 0.135, 0.466, 0.04, 0.171]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 13.7034 | Steps: 2 | Val loss: 14.2239 | Batch size: 32 | lr: 0.1 | Duration: 2.99s
== Status ==
Current time: 2024-01-07 03:05:18 (running for 00:41:19.72)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: 0.32525000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.608 |      0.218 |                   73 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  1.241 |      0.125 |                   72 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  1.989 |      0.194 |                   64 |
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  1.765 |      0.221 |                   17 |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=124580)[0m top1: 0.3283582089552239
[2m[36m(func pid=124580)[0m top5: 0.8782649253731343
[2m[36m(func pid=124580)[0m f1_micro: 0.3283582089552239
[2m[36m(func pid=124580)[0m f1_macro: 0.21753535269968877
[2m[36m(func pid=124580)[0m f1_weighted: 0.35107161457921726
[2m[36m(func pid=124580)[0m f1_per_class: [0.057, 0.329, 0.258, 0.42, 0.0, 0.091, 0.48, 0.261, 0.139, 0.142]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 1.9827 | Steps: 2 | Val loss: 2.1457 | Batch size: 32 | lr: 0.0001 | Duration: 3.10s
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 1.7203 | Steps: 2 | Val loss: 1.9820 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
[2m[36m(func pid=125328)[0m top1: 0.11240671641791045
[2m[36m(func pid=125328)[0m top5: 0.8838619402985075
[2m[36m(func pid=125328)[0m f1_micro: 0.11240671641791045
[2m[36m(func pid=125328)[0m f1_macro: 0.13149107599308898
[2m[36m(func pid=125328)[0m f1_weighted: 0.08249931393121904
[2m[36m(func pid=125328)[0m f1_per_class: [0.03, 0.293, 0.167, 0.0, 0.034, 0.102, 0.0, 0.227, 0.0, 0.462]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=126248)[0m top1: 0.21222014925373134
[2m[36m(func pid=126248)[0m top5: 0.824160447761194
[2m[36m(func pid=126248)[0m f1_micro: 0.21222014925373134
[2m[36m(func pid=126248)[0m f1_macro: 0.19122544780532985
[2m[36m(func pid=126248)[0m f1_weighted: 0.20198342591218013
[2m[36m(func pid=126248)[0m f1_per_class: [0.075, 0.134, 0.239, 0.342, 0.067, 0.36, 0.031, 0.461, 0.041, 0.163]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.7036 | Steps: 2 | Val loss: 6.8713 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
[2m[36m(func pid=137284)[0m top1: 0.2719216417910448
[2m[36m(func pid=137284)[0m top5: 0.8745335820895522
[2m[36m(func pid=137284)[0m f1_micro: 0.2719216417910448
[2m[36m(func pid=137284)[0m f1_macro: 0.21546309692808707
[2m[36m(func pid=137284)[0m f1_weighted: 0.26350707630734405
[2m[36m(func pid=137284)[0m f1_per_class: [0.264, 0.143, 0.222, 0.503, 0.055, 0.207, 0.128, 0.471, 0.022, 0.14]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 2.1041 | Steps: 2 | Val loss: 11.2972 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 03:05:24 (running for 00:41:25.09)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: 0.32525000000000004
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00018 | RUNNING    | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.704 |      0.207 |                   74 |
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  | 13.703 |      0.131 |                   73 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  1.983 |      0.191 |                   65 |
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  1.72  |      0.215 |                   18 |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=124580)[0m top1: 0.2989738805970149
[2m[36m(func pid=124580)[0m top5: 0.8857276119402985
[2m[36m(func pid=124580)[0m f1_micro: 0.2989738805970149
[2m[36m(func pid=124580)[0m f1_macro: 0.20685153891406127
[2m[36m(func pid=124580)[0m f1_weighted: 0.3171773107889762
[2m[36m(func pid=124580)[0m f1_per_class: [0.035, 0.333, 0.264, 0.432, 0.0, 0.125, 0.343, 0.242, 0.142, 0.152]
[2m[36m(func pid=124580)[0m 
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 1.9794 | Steps: 2 | Val loss: 2.1419 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 1.6606 | Steps: 2 | Val loss: 1.9566 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=125328)[0m top1: 0.13059701492537312
[2m[36m(func pid=125328)[0m top5: 0.8889925373134329
[2m[36m(func pid=125328)[0m f1_micro: 0.13059701492537312
[2m[36m(func pid=125328)[0m f1_macro: 0.12643344481276414
[2m[36m(func pid=125328)[0m f1_weighted: 0.10987770655682845
[2m[36m(func pid=125328)[0m f1_per_class: [0.053, 0.285, 0.0, 0.013, 0.039, 0.175, 0.056, 0.252, 0.0, 0.391]
[2m[36m(func pid=125328)[0m 
[2m[36m(func pid=126248)[0m top1: 0.20755597014925373
[2m[36m(func pid=126248)[0m top5: 0.8250932835820896
[2m[36m(func pid=126248)[0m f1_micro: 0.20755597014925375
[2m[36m(func pid=126248)[0m f1_macro: 0.18934307746947626
[2m[36m(func pid=126248)[0m f1_weighted: 0.1984448426389642
[2m[36m(func pid=126248)[0m f1_per_class: [0.08, 0.154, 0.242, 0.338, 0.067, 0.327, 0.027, 0.433, 0.04, 0.185]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=137284)[0m top1: 0.2691231343283582
[2m[36m(func pid=137284)[0m top5: 0.8833955223880597
[2m[36m(func pid=137284)[0m f1_micro: 0.2691231343283582
[2m[36m(func pid=137284)[0m f1_macro: 0.21308608657584388
[2m[36m(func pid=137284)[0m f1_weighted: 0.2586356705384428
[2m[36m(func pid=137284)[0m f1_per_class: [0.253, 0.141, 0.247, 0.493, 0.058, 0.194, 0.132, 0.447, 0.021, 0.145]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=124580)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.8524 | Steps: 2 | Val loss: 7.2240 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
[2m[36m(func pid=125328)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 3.9728 | Steps: 2 | Val loss: 11.1911 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=124580)[0m top1: 0.27472014925373134
[2m[36m(func pid=124580)[0m top5: 0.886660447761194
[2m[36m(func pid=124580)[0m f1_micro: 0.27472014925373134
[2m[36m(func pid=124580)[0m f1_macro: 0.20305107456720836
[2m[36m(func pid=124580)[0m f1_weighted: 0.2949836651045667
[2m[36m(func pid=124580)[0m f1_per_class: [0.0, 0.3, 0.308, 0.432, 0.018, 0.209, 0.265, 0.2, 0.133, 0.166]
== Status ==
Current time: 2024-01-07 03:05:29 (running for 00:41:30.53)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=19
Bracket: Iter 75.000: 0.3235
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 PENDING, 3 RUNNING, 19 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00019 | RUNNING    | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  2.104 |      0.126 |                   74 |
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  1.979 |      0.189 |                   66 |
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  1.661 |      0.213 |                   19 |
| train_6ed81_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 1.9969 | Steps: 2 | Val loss: 2.1400 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 1.5640 | Steps: 2 | Val loss: 1.9363 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=125328)[0m top1: 0.14085820895522388
[2m[36m(func pid=125328)[0m top5: 0.8838619402985075
[2m[36m(func pid=125328)[0m f1_micro: 0.14085820895522388
[2m[36m(func pid=125328)[0m f1_macro: 0.1188545241736531
[2m[36m(func pid=125328)[0m f1_weighted: 0.14250473766672087
[2m[36m(func pid=125328)[0m f1_per_class: [0.049, 0.246, 0.0, 0.013, 0.04, 0.206, 0.21, 0.091, 0.0, 0.333]
[2m[36m(func pid=126248)[0m top1: 0.2080223880597015
[2m[36m(func pid=126248)[0m top5: 0.8274253731343284
[2m[36m(func pid=126248)[0m f1_micro: 0.2080223880597015
[2m[36m(func pid=126248)[0m f1_macro: 0.18714600893703484
[2m[36m(func pid=126248)[0m f1_weighted: 0.19662192975676634
[2m[36m(func pid=126248)[0m f1_per_class: [0.085, 0.137, 0.253, 0.34, 0.067, 0.335, 0.027, 0.428, 0.043, 0.157]
[2m[36m(func pid=137284)[0m top1: 0.29617537313432835
[2m[36m(func pid=137284)[0m top5: 0.8843283582089553
[2m[36m(func pid=137284)[0m f1_micro: 0.29617537313432835
[2m[36m(func pid=137284)[0m f1_macro: 0.2439689582869878
[2m[36m(func pid=137284)[0m f1_weighted: 0.3003164633723161
[2m[36m(func pid=137284)[0m f1_per_class: [0.266, 0.179, 0.282, 0.498, 0.055, 0.242, 0.217, 0.481, 0.022, 0.199]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 2.0323 | Steps: 2 | Val loss: 2.1332 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 1.5156 | Steps: 2 | Val loss: 1.9522 | Batch size: 32 | lr: 0.001 | Duration: 3.03s
[2m[36m(func pid=126248)[0m top1: 0.20708955223880596
[2m[36m(func pid=126248)[0m top5: 0.8330223880597015
[2m[36m(func pid=126248)[0m f1_micro: 0.20708955223880596
[2m[36m(func pid=126248)[0m f1_macro: 0.1897005776622803
[2m[36m(func pid=126248)[0m f1_weighted: 0.19467762763165408
[2m[36m(func pid=126248)[0m f1_per_class: [0.087, 0.128, 0.259, 0.331, 0.066, 0.345, 0.03, 0.424, 0.042, 0.186]
[2m[36m(func pid=137284)[0m top1: 0.29524253731343286
[2m[36m(func pid=137284)[0m top5: 0.8619402985074627
[2m[36m(func pid=137284)[0m f1_micro: 0.29524253731343286
[2m[36m(func pid=137284)[0m f1_macro: 0.2470477740635196
[2m[36m(func pid=137284)[0m f1_weighted: 0.29869914722345375
[2m[36m(func pid=137284)[0m f1_per_class: [0.269, 0.169, 0.253, 0.507, 0.052, 0.231, 0.202, 0.532, 0.024, 0.233]
[2m[36m(func pid=141974)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141974)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=141974)[0m Configuration completed!
[2m[36m(func pid=141974)[0m New optimizer parameters:
[2m[36m(func pid=141974)[0m SGD (
[2m[36m(func pid=141974)[0m Parameter Group 0
[2m[36m(func pid=141974)[0m     dampening: 0
[2m[36m(func pid=141974)[0m     differentiable: False
[2m[36m(func pid=141974)[0m     foreach: None
[2m[36m(func pid=141974)[0m     lr: 0.01
[2m[36m(func pid=141974)[0m     maximize: False
[2m[36m(func pid=141974)[0m     momentum: 0.9
[2m[36m(func pid=141974)[0m     nesterov: False
[2m[36m(func pid=141974)[0m     weight_decay: 1e-05
[2m[36m(func pid=141974)[0m )
[2m[36m(func pid=141974)[0m 
== Status ==
Current time: 2024-01-07 03:05:37 (running for 00:41:38.39)
Memory usage on this node: 21.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  1.997 |      0.187 |                   67 |
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  1.564 |      0.244 |                   20 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=141976)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=141976)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=141976)[0m Configuration completed!
[2m[36m(func pid=141976)[0m New optimizer parameters:
[2m[36m(func pid=141976)[0m SGD (
[2m[36m(func pid=141976)[0m Parameter Group 0
[2m[36m(func pid=141976)[0m     dampening: 0
[2m[36m(func pid=141976)[0m     differentiable: False
[2m[36m(func pid=141976)[0m     foreach: None
[2m[36m(func pid=141976)[0m     lr: 0.1
[2m[36m(func pid=141976)[0m     maximize: False
[2m[36m(func pid=141976)[0m     momentum: 0.9
[2m[36m(func pid=141976)[0m     nesterov: False
[2m[36m(func pid=141976)[0m     weight_decay: 1e-05
[2m[36m(func pid=141976)[0m )
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 2.0090 | Steps: 2 | Val loss: 2.1318 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 1.4587 | Steps: 2 | Val loss: 1.9367 | Batch size: 32 | lr: 0.001 | Duration: 3.07s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 3.0138 | Steps: 2 | Val loss: 2.6276 | Batch size: 32 | lr: 0.01 | Duration: 4.81s
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 4.7599 | Steps: 2 | Val loss: 956.8746 | Batch size: 32 | lr: 0.1 | Duration: 4.83s
== Status ==
Current time: 2024-01-07 03:05:43 (running for 00:41:44.73)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.032 |      0.19  |                   68 |
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  1.516 |      0.247 |                   21 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |        |            |                      |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=126248)[0m top1: 0.21128731343283583
[2m[36m(func pid=126248)[0m top5: 0.8316231343283582
[2m[36m(func pid=126248)[0m f1_micro: 0.21128731343283583
[2m[36m(func pid=126248)[0m f1_macro: 0.19634365317524358
[2m[36m(func pid=126248)[0m f1_weighted: 0.2029308603394548
[2m[36m(func pid=126248)[0m f1_per_class: [0.087, 0.155, 0.262, 0.326, 0.065, 0.35, 0.042, 0.435, 0.041, 0.2]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=137284)[0m top1: 0.2896455223880597
[2m[36m(func pid=137284)[0m top5: 0.8610074626865671
[2m[36m(func pid=137284)[0m f1_micro: 0.2896455223880597
[2m[36m(func pid=137284)[0m f1_macro: 0.24323994309333039
[2m[36m(func pid=137284)[0m f1_weighted: 0.29375841183861595
[2m[36m(func pid=137284)[0m f1_per_class: [0.241, 0.162, 0.345, 0.506, 0.056, 0.204, 0.203, 0.519, 0.05, 0.147]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=141974)[0m top1: 0.006063432835820896
[2m[36m(func pid=141974)[0m top5: 0.355410447761194
[2m[36m(func pid=141974)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=141974)[0m f1_macro: 0.001205377839592026
[2m[36m(func pid=141974)[0m f1_weighted: 7.308727572153144e-05
[2m[36m(func pid=141974)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141976)[0m top1: 0.020522388059701493
[2m[36m(func pid=141976)[0m top5: 0.5125932835820896
[2m[36m(func pid=141976)[0m f1_micro: 0.020522388059701493
[2m[36m(func pid=141976)[0m f1_macro: 0.0040219378427787935
[2m[36m(func pid=141976)[0m f1_weighted: 0.000825397691615051
[2m[36m(func pid=141976)[0m f1_per_class: [0.04, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 1.7205 | Steps: 2 | Val loss: 1.9037 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 2.1623 | Steps: 2 | Val loss: 2.1330 | Batch size: 32 | lr: 0.0001 | Duration: 3.14s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 2.7381 | Steps: 2 | Val loss: 2.9275 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 4.2787 | Steps: 2 | Val loss: 28467.8887 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=137284)[0m top1: 0.279384328358209
[2m[36m(func pid=137284)[0m top5: 0.8698694029850746
[2m[36m(func pid=137284)[0m f1_micro: 0.279384328358209
[2m[36m(func pid=137284)[0m f1_macro: 0.23136233951676094
[2m[36m(func pid=137284)[0m f1_weighted: 0.2751425888488371
[2m[36m(func pid=137284)[0m f1_per_class: [0.237, 0.217, 0.364, 0.509, 0.057, 0.145, 0.14, 0.453, 0.071, 0.121]
== Status ==
Current time: 2024-01-07 03:05:49 (running for 00:41:50.36)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.009 |      0.196 |                   69 |
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  1.72  |      0.231 |                   23 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  3.014 |      0.001 |                    1 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  4.76  |      0.004 |                    1 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=126248)[0m top1: 0.21548507462686567
[2m[36m(func pid=126248)[0m top5: 0.8330223880597015
[2m[36m(func pid=126248)[0m f1_micro: 0.21548507462686567
[2m[36m(func pid=126248)[0m f1_macro: 0.2023454243897304
[2m[36m(func pid=126248)[0m f1_weighted: 0.2127384962058728
[2m[36m(func pid=126248)[0m f1_per_class: [0.085, 0.175, 0.239, 0.34, 0.064, 0.342, 0.051, 0.443, 0.04, 0.244]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=141974)[0m top1: 0.008395522388059701
[2m[36m(func pid=141974)[0m top5: 0.5041977611940298
[2m[36m(func pid=141974)[0m f1_micro: 0.008395522388059701
[2m[36m(func pid=141974)[0m f1_macro: 0.0032860583911292
[2m[36m(func pid=141974)[0m f1_weighted: 0.00043823893892801864
[2m[36m(func pid=141974)[0m f1_per_class: [0.017, 0.0, 0.016, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141976)[0m top1: 0.17210820895522388
[2m[36m(func pid=141976)[0m top5: 0.5727611940298507
[2m[36m(func pid=141976)[0m f1_micro: 0.17210820895522388
[2m[36m(func pid=141976)[0m f1_macro: 0.029367290091524074
[2m[36m(func pid=141976)[0m f1_weighted: 0.05054351699520701
[2m[36m(func pid=141976)[0m f1_per_class: [0.0, 0.294, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 1.3639 | Steps: 2 | Val loss: 1.8992 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 1.9225 | Steps: 2 | Val loss: 2.1308 | Batch size: 32 | lr: 0.0001 | Duration: 3.13s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 2.3967 | Steps: 2 | Val loss: 3.4493 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 4.5982 | Steps: 2 | Val loss: 171325.1406 | Batch size: 32 | lr: 0.1 | Duration: 3.04s
== Status ==
Current time: 2024-01-07 03:05:54 (running for 00:41:55.68)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  2.162 |      0.202 |                   70 |
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  1.364 |      0.217 |                   24 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  2.738 |      0.003 |                    2 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  4.279 |      0.029 |                    2 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=137284)[0m top1: 0.26865671641791045
[2m[36m(func pid=137284)[0m top5: 0.8796641791044776
[2m[36m(func pid=137284)[0m f1_micro: 0.26865671641791045
[2m[36m(func pid=137284)[0m f1_macro: 0.21722185563291513
[2m[36m(func pid=137284)[0m f1_weighted: 0.2530360638176534
[2m[36m(func pid=137284)[0m f1_per_class: [0.185, 0.206, 0.419, 0.505, 0.07, 0.066, 0.123, 0.362, 0.095, 0.142]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=126248)[0m top1: 0.21175373134328357
[2m[36m(func pid=126248)[0m top5: 0.8362873134328358
[2m[36m(func pid=126248)[0m f1_micro: 0.21175373134328357
[2m[36m(func pid=126248)[0m f1_macro: 0.2002762849725554
[2m[36m(func pid=126248)[0m f1_weighted: 0.20813943434209298
[2m[36m(func pid=126248)[0m f1_per_class: [0.093, 0.165, 0.259, 0.337, 0.062, 0.337, 0.048, 0.438, 0.038, 0.227]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=141974)[0m top1: 0.08815298507462686
[2m[36m(func pid=141974)[0m top5: 0.6352611940298507
[2m[36m(func pid=141974)[0m f1_micro: 0.08815298507462686
[2m[36m(func pid=141974)[0m f1_macro: 0.044444034264132
[2m[36m(func pid=141974)[0m f1_weighted: 0.07265705007198699
[2m[36m(func pid=141974)[0m f1_per_class: [0.011, 0.331, 0.022, 0.0, 0.0, 0.047, 0.033, 0.0, 0.0, 0.0]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141976)[0m top1: 0.006063432835820896
[2m[36m(func pid=141976)[0m top5: 0.5093283582089553
[2m[36m(func pid=141976)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=141976)[0m f1_macro: 0.001205377839592026
[2m[36m(func pid=141976)[0m f1_weighted: 7.308727572153144e-05
[2m[36m(func pid=141976)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 1.4427 | Steps: 2 | Val loss: 1.8775 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 1.9052 | Steps: 2 | Val loss: 2.1256 | Batch size: 32 | lr: 0.0001 | Duration: 3.09s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 2.1652 | Steps: 2 | Val loss: 3.6239 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 12.8557 | Steps: 2 | Val loss: 302605.6250 | Batch size: 32 | lr: 0.1 | Duration: 2.75s
== Status ==
Current time: 2024-01-07 03:06:00 (running for 00:42:00.95)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  1.923 |      0.2   |                   71 |
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  1.443 |      0.231 |                   25 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  2.397 |      0.044 |                    3 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  4.598 |      0.001 |                    3 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=137284)[0m top1: 0.27845149253731344
[2m[36m(func pid=137284)[0m top5: 0.8843283582089553
[2m[36m(func pid=137284)[0m f1_micro: 0.27845149253731344
[2m[36m(func pid=137284)[0m f1_macro: 0.23092999804132855
[2m[36m(func pid=137284)[0m f1_weighted: 0.27233464524187173
[2m[36m(func pid=137284)[0m f1_per_class: [0.188, 0.266, 0.409, 0.498, 0.075, 0.077, 0.15, 0.364, 0.138, 0.144]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=126248)[0m top1: 0.21082089552238806
[2m[36m(func pid=126248)[0m top5: 0.8432835820895522
[2m[36m(func pid=126248)[0m f1_micro: 0.21082089552238809
[2m[36m(func pid=126248)[0m f1_macro: 0.20155587551797255
[2m[36m(func pid=126248)[0m f1_weighted: 0.20538902983083443
[2m[36m(func pid=126248)[0m f1_per_class: [0.094, 0.166, 0.265, 0.332, 0.062, 0.326, 0.045, 0.442, 0.04, 0.244]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=141974)[0m top1: 0.1226679104477612
[2m[36m(func pid=141974)[0m top5: 0.6277985074626866
[2m[36m(func pid=141974)[0m f1_micro: 0.1226679104477612
[2m[36m(func pid=141974)[0m f1_macro: 0.042418829016172166
[2m[36m(func pid=141974)[0m f1_weighted: 0.05393272929596389
[2m[36m(func pid=141974)[0m f1_per_class: [0.0, 0.293, 0.033, 0.0, 0.0, 0.008, 0.003, 0.01, 0.0, 0.077]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141976)[0m top1: 0.006063432835820896
[2m[36m(func pid=141976)[0m top5: 0.5093283582089553
[2m[36m(func pid=141976)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=141976)[0m f1_macro: 0.001205377839592026
[2m[36m(func pid=141976)[0m f1_weighted: 7.308727572153144e-05
[2m[36m(func pid=141976)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 1.3092 | Steps: 2 | Val loss: 1.8312 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 1.9293 | Steps: 2 | Val loss: 2.1240 | Batch size: 32 | lr: 0.0001 | Duration: 3.23s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 2.0636 | Steps: 2 | Val loss: 3.4398 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 5.7864 | Steps: 2 | Val loss: 75018.7266 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 03:06:05 (running for 00:42:06.17)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  1.905 |      0.202 |                   72 |
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  1.309 |      0.264 |                   26 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  2.165 |      0.042 |                    4 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  | 12.856 |      0.001 |                    4 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=137284)[0m top1: 0.3185634328358209
[2m[36m(func pid=137284)[0m top5: 0.882929104477612
[2m[36m(func pid=137284)[0m f1_micro: 0.3185634328358209
[2m[36m(func pid=137284)[0m f1_macro: 0.263727211404845
[2m[36m(func pid=137284)[0m f1_weighted: 0.33435771367371414
[2m[36m(func pid=137284)[0m f1_per_class: [0.208, 0.346, 0.34, 0.493, 0.076, 0.151, 0.271, 0.435, 0.156, 0.161]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=126248)[0m top1: 0.208955223880597
[2m[36m(func pid=126248)[0m top5: 0.8479477611940298
[2m[36m(func pid=126248)[0m f1_micro: 0.208955223880597
[2m[36m(func pid=126248)[0m f1_macro: 0.1966085778817202
[2m[36m(func pid=126248)[0m f1_weighted: 0.20091208081576986
[2m[36m(func pid=126248)[0m f1_per_class: [0.096, 0.15, 0.268, 0.331, 0.061, 0.335, 0.036, 0.446, 0.042, 0.2]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=141974)[0m top1: 0.10820895522388059
[2m[36m(func pid=141974)[0m top5: 0.7374067164179104
[2m[36m(func pid=141974)[0m f1_micro: 0.10820895522388059
[2m[36m(func pid=141974)[0m f1_macro: 0.09995252658491878
[2m[36m(func pid=141974)[0m f1_weighted: 0.11229627814494045
[2m[36m(func pid=141974)[0m f1_per_class: [0.0, 0.295, 0.031, 0.157, 0.209, 0.09, 0.0, 0.066, 0.0, 0.151]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141976)[0m top1: 0.006063432835820896
[2m[36m(func pid=141976)[0m top5: 0.5093283582089553
[2m[36m(func pid=141976)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=141976)[0m f1_macro: 0.001205377839592026
[2m[36m(func pid=141976)[0m f1_weighted: 7.308727572153144e-05
[2m[36m(func pid=141976)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 1.2067 | Steps: 2 | Val loss: 1.8190 | Batch size: 32 | lr: 0.001 | Duration: 2.67s
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 1.9264 | Steps: 2 | Val loss: 2.1199 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 1.7087 | Steps: 2 | Val loss: 3.4410 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
== Status ==
Current time: 2024-01-07 03:06:10 (running for 00:42:11.23)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  1.929 |      0.197 |                   73 |
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  1.207 |      0.298 |                   27 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  2.064 |      0.1   |                    5 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  5.786 |      0.001 |                    5 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=137284)[0m top1: 0.36380597014925375
[2m[36m(func pid=137284)[0m top5: 0.8777985074626866
[2m[36m(func pid=137284)[0m f1_micro: 0.3638059701492538
[2m[36m(func pid=137284)[0m f1_macro: 0.2975880378276473
[2m[36m(func pid=137284)[0m f1_weighted: 0.39043803001357086
[2m[36m(func pid=137284)[0m f1_per_class: [0.245, 0.444, 0.339, 0.487, 0.081, 0.214, 0.371, 0.511, 0.112, 0.17]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 3.0418 | Steps: 2 | Val loss: 24967.7051 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
[2m[36m(func pid=126248)[0m top1: 0.21082089552238806
[2m[36m(func pid=126248)[0m top5: 0.8493470149253731
[2m[36m(func pid=126248)[0m f1_micro: 0.21082089552238809
[2m[36m(func pid=126248)[0m f1_macro: 0.19614198820853673
[2m[36m(func pid=126248)[0m f1_weighted: 0.20429552640767323
[2m[36m(func pid=126248)[0m f1_per_class: [0.102, 0.146, 0.272, 0.336, 0.061, 0.323, 0.051, 0.446, 0.04, 0.186]
[2m[36m(func pid=126248)[0m 
[2m[36m(func pid=141974)[0m top1: 0.12639925373134328
[2m[36m(func pid=141974)[0m top5: 0.746268656716418
[2m[36m(func pid=141974)[0m f1_micro: 0.12639925373134328
[2m[36m(func pid=141974)[0m f1_macro: 0.09951264476737473
[2m[36m(func pid=141974)[0m f1_weighted: 0.12295684163675254
[2m[36m(func pid=141974)[0m f1_per_class: [0.053, 0.0, 0.032, 0.344, 0.238, 0.082, 0.027, 0.09, 0.0, 0.129]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141976)[0m top1: 0.006063432835820896
[2m[36m(func pid=141976)[0m top5: 0.5093283582089553
[2m[36m(func pid=141976)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=141976)[0m f1_macro: 0.001205377839592026
[2m[36m(func pid=141976)[0m f1_weighted: 7.308727572153144e-05
[2m[36m(func pid=141976)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 1.2278 | Steps: 2 | Val loss: 1.8305 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 1.6359 | Steps: 2 | Val loss: 3.1994 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=126248)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 1.9182 | Steps: 2 | Val loss: 2.1184 | Batch size: 32 | lr: 0.0001 | Duration: 3.06s
== Status ==
Current time: 2024-01-07 03:06:15 (running for 00:42:16.47)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: 0.32175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00020 | RUNNING    | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  1.926 |      0.196 |                   74 |
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  1.228 |      0.306 |                   28 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  1.709 |      0.1   |                    6 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  3.042 |      0.001 |                    6 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=137284)[0m top1: 0.36613805970149255
[2m[36m(func pid=137284)[0m top5: 0.8736007462686567
[2m[36m(func pid=137284)[0m f1_micro: 0.36613805970149255
[2m[36m(func pid=137284)[0m f1_macro: 0.3056311809536463
[2m[36m(func pid=137284)[0m f1_weighted: 0.3964454254712827
[2m[36m(func pid=137284)[0m f1_per_class: [0.273, 0.454, 0.333, 0.481, 0.077, 0.265, 0.369, 0.522, 0.105, 0.177]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 2.2998 | Steps: 2 | Val loss: 13724.9141 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=141974)[0m top1: 0.10820895522388059
[2m[36m(func pid=141974)[0m top5: 0.7555970149253731
[2m[36m(func pid=141974)[0m f1_micro: 0.10820895522388059
[2m[36m(func pid=141974)[0m f1_macro: 0.11543072603760743
[2m[36m(func pid=141974)[0m f1_weighted: 0.111867876489321
[2m[36m(func pid=141974)[0m f1_per_class: [0.062, 0.189, 0.045, 0.158, 0.211, 0.135, 0.018, 0.153, 0.018, 0.167]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=126248)[0m top1: 0.21828358208955223
[2m[36m(func pid=126248)[0m top5: 0.8498134328358209
[2m[36m(func pid=126248)[0m f1_micro: 0.21828358208955223
[2m[36m(func pid=126248)[0m f1_macro: 0.2037636037831852
[2m[36m(func pid=126248)[0m f1_weighted: 0.2163530403937672
[2m[36m(func pid=126248)[0m f1_per_class: [0.103, 0.15, 0.275, 0.346, 0.06, 0.335, 0.074, 0.446, 0.04, 0.208]
[2m[36m(func pid=141976)[0m top1: 0.006063432835820896
[2m[36m(func pid=141976)[0m top5: 0.5093283582089553
[2m[36m(func pid=141976)[0m f1_micro: 0.006063432835820896
[2m[36m(func pid=141976)[0m f1_macro: 0.0012059369202226345
[2m[36m(func pid=141976)[0m f1_weighted: 7.312117520006647e-05
[2m[36m(func pid=141976)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 1.0816 | Steps: 2 | Val loss: 1.8298 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 1.5175 | Steps: 2 | Val loss: 3.2484 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
== Status ==
Current time: 2024-01-07 03:06:20 (running for 00:42:21.78)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: 0.32
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  1.082 |      0.312 |                   29 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  1.636 |      0.115 |                    7 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  2.3   |      0.001 |                    7 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=137284)[0m top1: 0.3694029850746269
[2m[36m(func pid=137284)[0m top5: 0.8782649253731343
[2m[36m(func pid=137284)[0m f1_micro: 0.3694029850746269
[2m[36m(func pid=137284)[0m f1_macro: 0.311910816002925
[2m[36m(func pid=137284)[0m f1_weighted: 0.40138371509477677
[2m[36m(func pid=137284)[0m f1_per_class: [0.252, 0.432, 0.333, 0.476, 0.072, 0.288, 0.388, 0.551, 0.103, 0.224]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 2.1960 | Steps: 2 | Val loss: 7010.8091 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
[2m[36m(func pid=141974)[0m top1: 0.1333955223880597
[2m[36m(func pid=141974)[0m top5: 0.7798507462686567
[2m[36m(func pid=141974)[0m f1_micro: 0.1333955223880597
[2m[36m(func pid=141974)[0m f1_macro: 0.13524943360598418
[2m[36m(func pid=141974)[0m f1_weighted: 0.11266288834112465
[2m[36m(func pid=141974)[0m f1_per_class: [0.062, 0.439, 0.052, 0.003, 0.261, 0.158, 0.003, 0.196, 0.012, 0.167]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141976)[0m top1: 0.006996268656716418
[2m[36m(func pid=141976)[0m top5: 0.5153917910447762
[2m[36m(func pid=141976)[0m f1_micro: 0.006996268656716418
[2m[36m(func pid=141976)[0m f1_macro: 0.02121099208197485
[2m[36m(func pid=141976)[0m f1_weighted: 0.00156596500497049
[2m[36m(func pid=141976)[0m f1_per_class: [0.0, 0.0, 0.012, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 1.0994 | Steps: 2 | Val loss: 1.8354 | Batch size: 32 | lr: 0.001 | Duration: 3.11s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 1.2289 | Steps: 2 | Val loss: 3.5073 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
== Status ==
Current time: 2024-01-07 03:06:26 (running for 00:42:27.25)
Memory usage on this node: 22.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: 0.32
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  1.099 |      0.314 |                   30 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  1.518 |      0.135 |                    8 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  2.196 |      0.021 |                    8 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=137284)[0m top1: 0.37593283582089554
[2m[36m(func pid=137284)[0m top5: 0.8810634328358209
[2m[36m(func pid=137284)[0m f1_micro: 0.37593283582089554
[2m[36m(func pid=137284)[0m f1_macro: 0.3143846114000649
[2m[36m(func pid=137284)[0m f1_weighted: 0.4125321076886807
[2m[36m(func pid=137284)[0m f1_per_class: [0.198, 0.473, 0.275, 0.45, 0.074, 0.296, 0.422, 0.561, 0.13, 0.266]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 2.0171 | Steps: 2 | Val loss: 3197.4075 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
[2m[36m(func pid=141974)[0m top1: 0.15485074626865672
[2m[36m(func pid=141974)[0m top5: 0.7686567164179104
[2m[36m(func pid=141974)[0m f1_micro: 0.15485074626865672
[2m[36m(func pid=141974)[0m f1_macro: 0.12800467897107154
[2m[36m(func pid=141974)[0m f1_weighted: 0.10813467386749694
[2m[36m(func pid=141974)[0m f1_per_class: [0.068, 0.493, 0.062, 0.0, 0.341, 0.016, 0.012, 0.221, 0.0, 0.067]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141976)[0m top1: 0.008395522388059701
[2m[36m(func pid=141976)[0m top5: 0.5251865671641791
[2m[36m(func pid=141976)[0m f1_micro: 0.008395522388059701
[2m[36m(func pid=141976)[0m f1_macro: 0.020483502093362103
[2m[36m(func pid=141976)[0m f1_weighted: 0.0032818408613987543
[2m[36m(func pid=141976)[0m f1_per_class: [0.0, 0.011, 0.012, 0.0, 0.182, 0.0, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 1.1475 | Steps: 2 | Val loss: 1.8785 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 1.2973 | Steps: 2 | Val loss: 4.2654 | Batch size: 32 | lr: 0.01 | Duration: 3.07s
== Status ==
Current time: 2024-01-07 03:06:31 (running for 00:42:32.61)
Memory usage on this node: 22.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: 0.32
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  1.148 |      0.307 |                   31 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  1.229 |      0.128 |                    9 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  2.017 |      0.02  |                    9 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=137284)[0m top1: 0.36847014925373134
[2m[36m(func pid=137284)[0m top5: 0.8722014925373134
[2m[36m(func pid=137284)[0m f1_micro: 0.3684701492537314
[2m[36m(func pid=137284)[0m f1_macro: 0.3066111966318642
[2m[36m(func pid=137284)[0m f1_weighted: 0.4082022588008732
[2m[36m(func pid=137284)[0m f1_per_class: [0.162, 0.51, 0.214, 0.415, 0.08, 0.308, 0.421, 0.545, 0.122, 0.291]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 4.7374 | Steps: 2 | Val loss: 857.8981 | Batch size: 32 | lr: 0.1 | Duration: 2.99s
[2m[36m(func pid=141974)[0m top1: 0.1287313432835821
[2m[36m(func pid=141974)[0m top5: 0.7182835820895522
[2m[36m(func pid=141974)[0m f1_micro: 0.1287313432835821
[2m[36m(func pid=141974)[0m f1_macro: 0.11359637481900542
[2m[36m(func pid=141974)[0m f1_weighted: 0.10896731147441728
[2m[36m(func pid=141974)[0m f1_per_class: [0.06, 0.487, 0.119, 0.029, 0.19, 0.0, 0.003, 0.211, 0.0, 0.036]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141976)[0m top1: 0.012126865671641791
[2m[36m(func pid=141976)[0m top5: 0.5699626865671642
[2m[36m(func pid=141976)[0m f1_micro: 0.012126865671641791
[2m[36m(func pid=141976)[0m f1_macro: 0.013057641817986205
[2m[36m(func pid=141976)[0m f1_weighted: 0.01056783795786829
[2m[36m(func pid=141976)[0m f1_per_class: [0.0, 0.037, 0.014, 0.0, 0.043, 0.031, 0.0, 0.005, 0.0, 0.0]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 1.0371 | Steps: 2 | Val loss: 1.9639 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
== Status ==
Current time: 2024-01-07 03:06:36 (running for 00:42:37.80)
Memory usage on this node: 22.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: 0.32
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  1.037 |      0.278 |                   32 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  1.297 |      0.114 |                   10 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  4.737 |      0.013 |                   10 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=137284)[0m top1: 0.32369402985074625
[2m[36m(func pid=137284)[0m top5: 0.8456156716417911
[2m[36m(func pid=137284)[0m f1_micro: 0.32369402985074625
[2m[36m(func pid=137284)[0m f1_macro: 0.2781550607193569
[2m[36m(func pid=137284)[0m f1_weighted: 0.36468035739452753
[2m[36m(func pid=137284)[0m f1_per_class: [0.144, 0.499, 0.232, 0.397, 0.082, 0.272, 0.323, 0.486, 0.164, 0.182]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 1.2248 | Steps: 2 | Val loss: 5.2549 | Batch size: 32 | lr: 0.01 | Duration: 3.12s
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 13.3762 | Steps: 2 | Val loss: 418.6019 | Batch size: 32 | lr: 0.1 | Duration: 3.05s
[2m[36m(func pid=141974)[0m top1: 0.09235074626865672
[2m[36m(func pid=141974)[0m top5: 0.5951492537313433
[2m[36m(func pid=141974)[0m f1_micro: 0.09235074626865672
[2m[36m(func pid=141974)[0m f1_macro: 0.09132968104899152
[2m[36m(func pid=141974)[0m f1_weighted: 0.09821560390772857
[2m[36m(func pid=141974)[0m f1_per_class: [0.062, 0.421, 0.124, 0.078, 0.197, 0.0, 0.0, 0.0, 0.0, 0.031]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141976)[0m top1: 0.03824626865671642
[2m[36m(func pid=141976)[0m top5: 0.5363805970149254
[2m[36m(func pid=141976)[0m f1_micro: 0.03824626865671642
[2m[36m(func pid=141976)[0m f1_macro: 0.028425405583521152
[2m[36m(func pid=141976)[0m f1_weighted: 0.030670029667172805
[2m[36m(func pid=141976)[0m f1_per_class: [0.0, 0.065, 0.021, 0.003, 0.0, 0.126, 0.0, 0.068, 0.0, 0.0]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.9376 | Steps: 2 | Val loss: 1.9138 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 1.3828 | Steps: 2 | Val loss: 4.5981 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 03:06:42 (running for 00:42:43.35)
Memory usage on this node: 22.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: 0.32
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  0.938 |      0.296 |                   33 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  1.225 |      0.091 |                   11 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  | 13.376 |      0.028 |                   11 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=137284)[0m top1: 0.34328358208955223
[2m[36m(func pid=137284)[0m top5: 0.8521455223880597
[2m[36m(func pid=137284)[0m f1_micro: 0.34328358208955223
[2m[36m(func pid=137284)[0m f1_macro: 0.29602038821214877
[2m[36m(func pid=137284)[0m f1_weighted: 0.37978723199066505
[2m[36m(func pid=137284)[0m f1_per_class: [0.181, 0.504, 0.314, 0.43, 0.081, 0.268, 0.333, 0.514, 0.159, 0.176]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 2.9344 | Steps: 2 | Val loss: 170.4778 | Batch size: 32 | lr: 0.1 | Duration: 3.05s
[2m[36m(func pid=141974)[0m top1: 0.18936567164179105
[2m[36m(func pid=141974)[0m top5: 0.8367537313432836
[2m[36m(func pid=141974)[0m f1_micro: 0.18936567164179105
[2m[36m(func pid=141974)[0m f1_macro: 0.16399515749158988
[2m[36m(func pid=141974)[0m f1_weighted: 0.19139207069583009
[2m[36m(func pid=141974)[0m f1_per_class: [0.048, 0.458, 0.061, 0.029, 0.068, 0.156, 0.2, 0.344, 0.089, 0.186]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141976)[0m top1: 0.279384328358209
[2m[36m(func pid=141976)[0m top5: 0.7122201492537313
[2m[36m(func pid=141976)[0m f1_micro: 0.279384328358209
[2m[36m(func pid=141976)[0m f1_macro: 0.05900193213927953
[2m[36m(func pid=141976)[0m f1_weighted: 0.1470270383105055
[2m[36m(func pid=141976)[0m f1_per_class: [0.0, 0.128, 0.0, 0.439, 0.0, 0.024, 0.0, 0.0, 0.0, 0.0]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 1.3693 | Steps: 2 | Val loss: 1.8164 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 1.7424 | Steps: 2 | Val loss: 4.3305 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
== Status ==
Current time: 2024-01-07 03:06:48 (running for 00:42:48.86)
Memory usage on this node: 22.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: 0.32
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  1.369 |      0.322 |                   34 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  1.383 |      0.164 |                   12 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  2.934 |      0.059 |                   12 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=137284)[0m top1: 0.3787313432835821
[2m[36m(func pid=137284)[0m top5: 0.8745335820895522
[2m[36m(func pid=137284)[0m f1_micro: 0.3787313432835821
[2m[36m(func pid=137284)[0m f1_macro: 0.32173816827007257
[2m[36m(func pid=137284)[0m f1_weighted: 0.40784429409881046
[2m[36m(func pid=137284)[0m f1_per_class: [0.205, 0.508, 0.344, 0.441, 0.063, 0.317, 0.385, 0.555, 0.129, 0.271]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 2.4265 | Steps: 2 | Val loss: 177.5292 | Batch size: 32 | lr: 0.1 | Duration: 3.20s
[2m[36m(func pid=141974)[0m top1: 0.22761194029850745
[2m[36m(func pid=141974)[0m top5: 0.8283582089552238
[2m[36m(func pid=141974)[0m f1_micro: 0.22761194029850745
[2m[36m(func pid=141974)[0m f1_macro: 0.18752167496133615
[2m[36m(func pid=141974)[0m f1_weighted: 0.22869101318425367
[2m[36m(func pid=141974)[0m f1_per_class: [0.065, 0.476, 0.048, 0.035, 0.07, 0.144, 0.305, 0.363, 0.087, 0.28]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 1.0544 | Steps: 2 | Val loss: 1.8266 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=141976)[0m top1: 0.057369402985074626
[2m[36m(func pid=141976)[0m top5: 0.6357276119402985
[2m[36m(func pid=141976)[0m f1_micro: 0.057369402985074626
[2m[36m(func pid=141976)[0m f1_macro: 0.02942806957166284
[2m[36m(func pid=141976)[0m f1_weighted: 0.05178316801371493
[2m[36m(func pid=141976)[0m f1_per_class: [0.0, 0.228, 0.017, 0.038, 0.0, 0.008, 0.003, 0.0, 0.0, 0.0]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.9748 | Steps: 2 | Val loss: 4.6874 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
== Status ==
Current time: 2024-01-07 03:06:53 (running for 00:42:54.10)
Memory usage on this node: 22.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: 0.32
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  1.054 |      0.294 |                   35 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  1.742 |      0.188 |                   13 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  2.426 |      0.029 |                   13 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=137284)[0m top1: 0.3451492537313433
[2m[36m(func pid=137284)[0m top5: 0.8838619402985075
[2m[36m(func pid=137284)[0m f1_micro: 0.3451492537313433
[2m[36m(func pid=137284)[0m f1_macro: 0.293604621018016
[2m[36m(func pid=137284)[0m f1_weighted: 0.3631622294582789
[2m[36m(func pid=137284)[0m f1_per_class: [0.169, 0.525, 0.317, 0.407, 0.08, 0.292, 0.286, 0.465, 0.148, 0.246]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 2.0899 | Steps: 2 | Val loss: 224.5596 | Batch size: 32 | lr: 0.1 | Duration: 3.07s
[2m[36m(func pid=141974)[0m top1: 0.07695895522388059
[2m[36m(func pid=141974)[0m top5: 0.7560634328358209
[2m[36m(func pid=141974)[0m f1_micro: 0.07695895522388059
[2m[36m(func pid=141974)[0m f1_macro: 0.09012284339704707
[2m[36m(func pid=141974)[0m f1_weighted: 0.0645806035409727
[2m[36m(func pid=141974)[0m f1_per_class: [0.059, 0.045, 0.062, 0.01, 0.17, 0.038, 0.078, 0.4, 0.0, 0.039]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.9980 | Steps: 2 | Val loss: 1.7977 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=141976)[0m top1: 0.05690298507462686
[2m[36m(func pid=141976)[0m top5: 0.5452425373134329
[2m[36m(func pid=141976)[0m f1_micro: 0.05690298507462686
[2m[36m(func pid=141976)[0m f1_macro: 0.029274033914058407
[2m[36m(func pid=141976)[0m f1_weighted: 0.04991593484442165
[2m[36m(func pid=141976)[0m f1_per_class: [0.006, 0.226, 0.02, 0.0, 0.0, 0.008, 0.033, 0.0, 0.0, 0.0]
[2m[36m(func pid=141976)[0m 
== Status ==
Current time: 2024-01-07 03:06:58 (running for 00:42:59.52)
Memory usage on this node: 22.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: 0.32
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  0.998 |      0.319 |                   36 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.975 |      0.09  |                   14 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  2.09  |      0.029 |                   14 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=137284)[0m top1: 0.36847014925373134
[2m[36m(func pid=137284)[0m top5: 0.8889925373134329
[2m[36m(func pid=137284)[0m f1_micro: 0.3684701492537314
[2m[36m(func pid=137284)[0m f1_macro: 0.319081214520608
[2m[36m(func pid=137284)[0m f1_weighted: 0.387943857318838
[2m[36m(func pid=137284)[0m f1_per_class: [0.167, 0.525, 0.344, 0.431, 0.08, 0.343, 0.32, 0.486, 0.138, 0.358]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.9253 | Steps: 2 | Val loss: 3.9515 | Batch size: 32 | lr: 0.01 | Duration: 3.10s
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 2.3773 | Steps: 2 | Val loss: 119.5617 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=141974)[0m top1: 0.1767723880597015
[2m[36m(func pid=141974)[0m top5: 0.8264925373134329
[2m[36m(func pid=141974)[0m f1_micro: 0.1767723880597015
[2m[36m(func pid=141974)[0m f1_macro: 0.1466344629701802
[2m[36m(func pid=141974)[0m f1_weighted: 0.1562663749774592
[2m[36m(func pid=141974)[0m f1_per_class: [0.087, 0.026, 0.076, 0.007, 0.29, 0.138, 0.353, 0.399, 0.025, 0.066]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.9100 | Steps: 2 | Val loss: 1.7770 | Batch size: 32 | lr: 0.001 | Duration: 3.06s
[2m[36m(func pid=141976)[0m top1: 0.08022388059701492
[2m[36m(func pid=141976)[0m top5: 0.48600746268656714
[2m[36m(func pid=141976)[0m f1_micro: 0.08022388059701492
[2m[36m(func pid=141976)[0m f1_macro: 0.03721919590178542
[2m[36m(func pid=141976)[0m f1_weighted: 0.06062642410474383
[2m[36m(func pid=141976)[0m f1_per_class: [0.01, 0.288, 0.029, 0.0, 0.0, 0.015, 0.03, 0.0, 0.0, 0.0]
[2m[36m(func pid=141976)[0m 
== Status ==
Current time: 2024-01-07 03:07:04 (running for 00:43:04.88)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: 0.32
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  0.91  |      0.338 |                   37 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.925 |      0.147 |                   15 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  2.377 |      0.037 |                   15 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=137284)[0m top1: 0.39505597014925375
[2m[36m(func pid=137284)[0m top5: 0.8852611940298507
[2m[36m(func pid=137284)[0m f1_micro: 0.39505597014925375
[2m[36m(func pid=137284)[0m f1_macro: 0.3382067004039852
[2m[36m(func pid=137284)[0m f1_weighted: 0.4237164757226144
[2m[36m(func pid=137284)[0m f1_per_class: [0.172, 0.509, 0.333, 0.455, 0.077, 0.34, 0.414, 0.547, 0.134, 0.4]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.8277 | Steps: 2 | Val loss: 3.2787 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 1.9582 | Steps: 2 | Val loss: 63.0315 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=141974)[0m top1: 0.22388059701492538
[2m[36m(func pid=141974)[0m top5: 0.840018656716418
[2m[36m(func pid=141974)[0m f1_micro: 0.22388059701492538
[2m[36m(func pid=141974)[0m f1_macro: 0.18607436733990837
[2m[36m(func pid=141974)[0m f1_weighted: 0.2281043414955143
[2m[36m(func pid=141974)[0m f1_per_class: [0.088, 0.361, 0.073, 0.042, 0.167, 0.229, 0.334, 0.357, 0.094, 0.116]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.8898 | Steps: 2 | Val loss: 1.8741 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=141976)[0m top1: 0.12919776119402984
[2m[36m(func pid=141976)[0m top5: 0.6791044776119403
[2m[36m(func pid=141976)[0m f1_micro: 0.12919776119402984
[2m[36m(func pid=141976)[0m f1_macro: 0.08597147307477268
[2m[36m(func pid=141976)[0m f1_weighted: 0.10123093850746184
[2m[36m(func pid=141976)[0m f1_per_class: [0.02, 0.332, 0.037, 0.0, 0.0, 0.159, 0.033, 0.251, 0.027, 0.0]
[2m[36m(func pid=141976)[0m 
== Status ==
Current time: 2024-01-07 03:07:09 (running for 00:43:10.26)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: 0.32
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  0.89  |      0.319 |                   38 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.828 |      0.186 |                   16 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.958 |      0.086 |                   16 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=137284)[0m top1: 0.3596082089552239
[2m[36m(func pid=137284)[0m top5: 0.8638059701492538
[2m[36m(func pid=137284)[0m f1_micro: 0.35960820895522383
[2m[36m(func pid=137284)[0m f1_macro: 0.31940574367633856
[2m[36m(func pid=137284)[0m f1_weighted: 0.38723572153981684
[2m[36m(func pid=137284)[0m f1_per_class: [0.16, 0.511, 0.323, 0.446, 0.067, 0.334, 0.301, 0.563, 0.141, 0.35]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.6229 | Steps: 2 | Val loss: 2.7621 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 2.2392 | Steps: 2 | Val loss: 26.9405 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=141974)[0m top1: 0.25
[2m[36m(func pid=141974)[0m top5: 0.8460820895522388
[2m[36m(func pid=141974)[0m f1_micro: 0.25
[2m[36m(func pid=141974)[0m f1_macro: 0.21714806085242397
[2m[36m(func pid=141974)[0m f1_weighted: 0.26095075626330677
[2m[36m(func pid=141974)[0m f1_per_class: [0.092, 0.461, 0.124, 0.071, 0.128, 0.245, 0.337, 0.407, 0.126, 0.18]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 1.0489 | Steps: 2 | Val loss: 1.8802 | Batch size: 32 | lr: 0.001 | Duration: 3.06s
[2m[36m(func pid=141976)[0m top1: 0.1478544776119403
[2m[36m(func pid=141976)[0m top5: 0.6240671641791045
[2m[36m(func pid=141976)[0m f1_micro: 0.1478544776119403
[2m[36m(func pid=141976)[0m f1_macro: 0.10967410224689622
[2m[36m(func pid=141976)[0m f1_weighted: 0.13535141803871525
[2m[36m(func pid=141976)[0m f1_per_class: [0.028, 0.373, 0.069, 0.079, 0.0, 0.217, 0.021, 0.287, 0.0, 0.022]
[2m[36m(func pid=141976)[0m 
== Status ==
Current time: 2024-01-07 03:07:14 (running for 00:43:15.67)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: 0.32
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  1.049 |      0.314 |                   39 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.623 |      0.217 |                   17 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  2.239 |      0.11  |                   17 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=137284)[0m top1: 0.3572761194029851
[2m[36m(func pid=137284)[0m top5: 0.8647388059701493
[2m[36m(func pid=137284)[0m f1_micro: 0.35727611940298515
[2m[36m(func pid=137284)[0m f1_macro: 0.3141055624636385
[2m[36m(func pid=137284)[0m f1_weighted: 0.3844332574973845
[2m[36m(func pid=137284)[0m f1_per_class: [0.181, 0.504, 0.357, 0.458, 0.069, 0.307, 0.296, 0.541, 0.173, 0.254]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.6336 | Steps: 2 | Val loss: 2.3832 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 1.7026 | Steps: 2 | Val loss: 19.2979 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=141974)[0m top1: 0.3903917910447761
[2m[36m(func pid=141974)[0m top5: 0.8880597014925373
[2m[36m(func pid=141974)[0m f1_micro: 0.39039179104477606
[2m[36m(func pid=141974)[0m f1_macro: 0.30867511866285546
[2m[36m(func pid=141974)[0m f1_weighted: 0.3891965972224661
[2m[36m(func pid=141974)[0m f1_per_class: [0.191, 0.474, 0.264, 0.226, 0.105, 0.281, 0.569, 0.467, 0.169, 0.34]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.7347 | Steps: 2 | Val loss: 1.8848 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=141976)[0m top1: 0.21641791044776118
[2m[36m(func pid=141976)[0m top5: 0.7854477611940298
[2m[36m(func pid=141976)[0m f1_micro: 0.21641791044776118
[2m[36m(func pid=141976)[0m f1_macro: 0.15350760385595233
[2m[36m(func pid=141976)[0m f1_weighted: 0.1856165832730974
[2m[36m(func pid=141976)[0m f1_per_class: [0.052, 0.374, 0.167, 0.083, 0.0, 0.135, 0.202, 0.286, 0.055, 0.182]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=137284)[0m top1: 0.36800373134328357
[2m[36m(func pid=137284)[0m top5: 0.8642723880597015
[2m[36m(func pid=137284)[0m f1_micro: 0.3680037313432836
[2m[36m(func pid=137284)[0m f1_macro: 0.3187058602549265
[2m[36m(func pid=137284)[0m f1_weighted: 0.3921348153760629
[2m[36m(func pid=137284)[0m f1_per_class: [0.221, 0.527, 0.355, 0.452, 0.067, 0.306, 0.324, 0.48, 0.168, 0.288]
[2m[36m(func pid=137284)[0m 
== Status ==
Current time: 2024-01-07 03:07:20 (running for 00:43:21.02)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: 0.32
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  0.735 |      0.319 |                   40 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.634 |      0.309 |                   18 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.703 |      0.154 |                   18 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.6685 | Steps: 2 | Val loss: 2.6094 | Batch size: 32 | lr: 0.01 | Duration: 3.10s
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 1.6263 | Steps: 2 | Val loss: 19.6525 | Batch size: 32 | lr: 0.1 | Duration: 3.02s
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.7860 | Steps: 2 | Val loss: 1.8864 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=141974)[0m top1: 0.373134328358209
[2m[36m(func pid=141974)[0m top5: 0.8889925373134329
[2m[36m(func pid=141974)[0m f1_micro: 0.373134328358209
[2m[36m(func pid=141974)[0m f1_macro: 0.3137470665705575
[2m[36m(func pid=141974)[0m f1_weighted: 0.36102350252326487
[2m[36m(func pid=141974)[0m f1_per_class: [0.268, 0.455, 0.471, 0.256, 0.099, 0.223, 0.485, 0.455, 0.044, 0.382]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141976)[0m top1: 0.2523320895522388
[2m[36m(func pid=141976)[0m top5: 0.7798507462686567
[2m[36m(func pid=141976)[0m f1_micro: 0.2523320895522388
[2m[36m(func pid=141976)[0m f1_macro: 0.171520709386665
[2m[36m(func pid=141976)[0m f1_weighted: 0.21447803493088097
[2m[36m(func pid=141976)[0m f1_per_class: [0.059, 0.386, 0.189, 0.0, 0.061, 0.0, 0.393, 0.406, 0.1, 0.12]
[2m[36m(func pid=141976)[0m 
== Status ==
Current time: 2024-01-07 03:07:25 (running for 00:43:26.39)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: 0.32
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  0.786 |      0.31  |                   41 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.668 |      0.314 |                   19 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.626 |      0.172 |                   19 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=137284)[0m top1: 0.3670708955223881
[2m[36m(func pid=137284)[0m top5: 0.8675373134328358
[2m[36m(func pid=137284)[0m f1_micro: 0.3670708955223881
[2m[36m(func pid=137284)[0m f1_macro: 0.31039121742164355
[2m[36m(func pid=137284)[0m f1_weighted: 0.39192373304022504
[2m[36m(func pid=137284)[0m f1_per_class: [0.2, 0.545, 0.314, 0.449, 0.068, 0.307, 0.316, 0.5, 0.166, 0.239]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.6287 | Steps: 2 | Val loss: 2.4238 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 1.8736 | Steps: 2 | Val loss: 15.5014 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.6914 | Steps: 2 | Val loss: 1.7795 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
[2m[36m(func pid=141974)[0m top1: 0.333955223880597
[2m[36m(func pid=141974)[0m top5: 0.8899253731343284
[2m[36m(func pid=141974)[0m f1_micro: 0.333955223880597
[2m[36m(func pid=141974)[0m f1_macro: 0.28285452441047093
[2m[36m(func pid=141974)[0m f1_weighted: 0.3404762612672441
[2m[36m(func pid=141974)[0m f1_per_class: [0.168, 0.477, 0.2, 0.268, 0.09, 0.265, 0.376, 0.437, 0.191, 0.356]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141976)[0m top1: 0.23367537313432835
[2m[36m(func pid=141976)[0m top5: 0.7882462686567164
[2m[36m(func pid=141976)[0m f1_micro: 0.23367537313432835
[2m[36m(func pid=141976)[0m f1_macro: 0.15955438392506543
[2m[36m(func pid=141976)[0m f1_weighted: 0.2168244566344656
[2m[36m(func pid=141976)[0m f1_per_class: [0.047, 0.409, 0.173, 0.044, 0.014, 0.008, 0.355, 0.344, 0.143, 0.059]
[2m[36m(func pid=141976)[0m 
== Status ==
Current time: 2024-01-07 03:07:30 (running for 00:43:31.67)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: 0.32
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  0.691 |      0.338 |                   42 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.629 |      0.283 |                   20 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.874 |      0.16  |                   20 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=137284)[0m top1: 0.3987873134328358
[2m[36m(func pid=137284)[0m top5: 0.8875932835820896
[2m[36m(func pid=137284)[0m f1_micro: 0.3987873134328358
[2m[36m(func pid=137284)[0m f1_macro: 0.3383098143605624
[2m[36m(func pid=137284)[0m f1_weighted: 0.4268318383972954
[2m[36m(func pid=137284)[0m f1_per_class: [0.214, 0.512, 0.278, 0.479, 0.077, 0.338, 0.396, 0.542, 0.178, 0.367]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.5017 | Steps: 2 | Val loss: 2.9343 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 1.5533 | Steps: 2 | Val loss: 11.5223 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.8231 | Steps: 2 | Val loss: 1.7221 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=141974)[0m top1: 0.2560634328358209
[2m[36m(func pid=141974)[0m top5: 0.8493470149253731
[2m[36m(func pid=141974)[0m f1_micro: 0.2560634328358209
[2m[36m(func pid=141974)[0m f1_macro: 0.23787917978728293
[2m[36m(func pid=141974)[0m f1_weighted: 0.2872684392244082
[2m[36m(func pid=141974)[0m f1_per_class: [0.076, 0.211, 0.279, 0.1, 0.111, 0.317, 0.51, 0.392, 0.169, 0.214]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141976)[0m top1: 0.23087686567164178
[2m[36m(func pid=141976)[0m top5: 0.8017723880597015
[2m[36m(func pid=141976)[0m f1_micro: 0.23087686567164178
[2m[36m(func pid=141976)[0m f1_macro: 0.16579967045726332
[2m[36m(func pid=141976)[0m f1_weighted: 0.21122147438416294
[2m[36m(func pid=141976)[0m f1_per_class: [0.061, 0.365, 0.084, 0.276, 0.0, 0.314, 0.042, 0.334, 0.0, 0.182]
[2m[36m(func pid=141976)[0m 
== Status ==
Current time: 2024-01-07 03:07:36 (running for 00:43:37.16)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: 0.32
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  0.823 |      0.351 |                   43 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.502 |      0.238 |                   21 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.553 |      0.166 |                   21 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=137284)[0m top1: 0.4207089552238806
[2m[36m(func pid=137284)[0m top5: 0.8997201492537313
[2m[36m(func pid=137284)[0m f1_micro: 0.4207089552238806
[2m[36m(func pid=137284)[0m f1_macro: 0.35057213982873037
[2m[36m(func pid=137284)[0m f1_weighted: 0.4514576715698067
[2m[36m(func pid=137284)[0m f1_per_class: [0.225, 0.498, 0.256, 0.488, 0.085, 0.349, 0.471, 0.556, 0.173, 0.405]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.4348 | Steps: 2 | Val loss: 2.9603 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 1.9233 | Steps: 2 | Val loss: 8.4353 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.7579 | Steps: 2 | Val loss: 1.7326 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=141974)[0m top1: 0.2868470149253731
[2m[36m(func pid=141974)[0m top5: 0.8540111940298507
[2m[36m(func pid=141974)[0m f1_micro: 0.2868470149253731
[2m[36m(func pid=141974)[0m f1_macro: 0.23231861391996173
[2m[36m(func pid=141974)[0m f1_weighted: 0.2987515315396513
[2m[36m(func pid=141974)[0m f1_per_class: [0.078, 0.11, 0.212, 0.141, 0.129, 0.302, 0.586, 0.302, 0.218, 0.244]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141976)[0m top1: 0.2513992537313433
[2m[36m(func pid=141976)[0m top5: 0.7947761194029851
[2m[36m(func pid=141976)[0m f1_micro: 0.2513992537313433
[2m[36m(func pid=141976)[0m f1_macro: 0.17238196125947405
[2m[36m(func pid=141976)[0m f1_weighted: 0.20284691274405958
[2m[36m(func pid=141976)[0m f1_per_class: [0.08, 0.109, 0.095, 0.406, 0.084, 0.387, 0.0, 0.376, 0.0, 0.188]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=137284)[0m top1: 0.4230410447761194
[2m[36m(func pid=137284)[0m top5: 0.8987873134328358
[2m[36m(func pid=137284)[0m f1_micro: 0.4230410447761194
[2m[36m(func pid=137284)[0m f1_macro: 0.34808904705299937
[2m[36m(func pid=137284)[0m f1_weighted: 0.4551428655970784
[2m[36m(func pid=137284)[0m f1_per_class: [0.234, 0.507, 0.242, 0.487, 0.065, 0.344, 0.482, 0.561, 0.159, 0.4]
[2m[36m(func pid=137284)[0m 
== Status ==
Current time: 2024-01-07 03:07:41 (running for 00:43:42.55)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: 0.32
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  0.758 |      0.348 |                   44 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.435 |      0.232 |                   22 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.923 |      0.172 |                   22 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 1.6409 | Steps: 2 | Val loss: 6.7180 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.3889 | Steps: 2 | Val loss: 2.6546 | Batch size: 32 | lr: 0.01 | Duration: 3.07s
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.6691 | Steps: 2 | Val loss: 1.8104 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=141974)[0m top1: 0.322294776119403
[2m[36m(func pid=141974)[0m top5: 0.847481343283582
[2m[36m(func pid=141974)[0m f1_micro: 0.322294776119403
[2m[36m(func pid=141974)[0m f1_macro: 0.26300997004949556
[2m[36m(func pid=141974)[0m f1_weighted: 0.3397740089639125
[2m[36m(func pid=141974)[0m f1_per_class: [0.126, 0.176, 0.353, 0.283, 0.122, 0.191, 0.564, 0.487, 0.138, 0.19]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141976)[0m top1: 0.15345149253731344
[2m[36m(func pid=141976)[0m top5: 0.7453358208955224
[2m[36m(func pid=141976)[0m f1_micro: 0.15345149253731344
[2m[36m(func pid=141976)[0m f1_macro: 0.1558181224576088
[2m[36m(func pid=141976)[0m f1_weighted: 0.1432985847711431
[2m[36m(func pid=141976)[0m f1_per_class: [0.061, 0.255, 0.143, 0.092, 0.074, 0.403, 0.0, 0.364, 0.1, 0.066]
[2m[36m(func pid=141976)[0m 
== Status ==
Current time: 2024-01-07 03:07:46 (running for 00:43:47.81)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: 0.32
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  0.669 |      0.34  |                   45 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.389 |      0.263 |                   23 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.641 |      0.156 |                   23 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=137284)[0m top1: 0.3927238805970149
[2m[36m(func pid=137284)[0m top5: 0.8815298507462687
[2m[36m(func pid=137284)[0m f1_micro: 0.39272388059701496
[2m[36m(func pid=137284)[0m f1_macro: 0.3401868652454191
[2m[36m(func pid=137284)[0m f1_weighted: 0.42310334186887105
[2m[36m(func pid=137284)[0m f1_per_class: [0.201, 0.496, 0.297, 0.479, 0.081, 0.348, 0.385, 0.565, 0.18, 0.368]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 2.0047 | Steps: 2 | Val loss: 5.3682 | Batch size: 32 | lr: 0.1 | Duration: 3.01s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.3286 | Steps: 2 | Val loss: 2.6669 | Batch size: 32 | lr: 0.01 | Duration: 3.10s
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.7056 | Steps: 2 | Val loss: 1.8782 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=141974)[0m top1: 0.2630597014925373
[2m[36m(func pid=141974)[0m top5: 0.8325559701492538
[2m[36m(func pid=141974)[0m f1_micro: 0.2630597014925373
[2m[36m(func pid=141974)[0m f1_macro: 0.2502632488598689
[2m[36m(func pid=141974)[0m f1_weighted: 0.28616468606611445
[2m[36m(func pid=141974)[0m f1_per_class: [0.14, 0.315, 0.235, 0.175, 0.157, 0.375, 0.348, 0.418, 0.133, 0.207]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141976)[0m top1: 0.18050373134328357
[2m[36m(func pid=141976)[0m top5: 0.8078358208955224
[2m[36m(func pid=141976)[0m f1_micro: 0.18050373134328357
[2m[36m(func pid=141976)[0m f1_macro: 0.16263368479670942
[2m[36m(func pid=141976)[0m f1_weighted: 0.19097004813661667
[2m[36m(func pid=141976)[0m f1_per_class: [0.059, 0.363, 0.222, 0.0, 0.017, 0.082, 0.297, 0.404, 0.106, 0.076]
[2m[36m(func pid=141976)[0m 
== Status ==
Current time: 2024-01-07 03:07:52 (running for 00:43:53.02)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: 0.32
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  0.706 |      0.331 |                   46 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.329 |      0.25  |                   24 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  2.005 |      0.163 |                   24 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=137284)[0m top1: 0.36800373134328357
[2m[36m(func pid=137284)[0m top5: 0.8759328358208955
[2m[36m(func pid=137284)[0m f1_micro: 0.3680037313432836
[2m[36m(func pid=137284)[0m f1_macro: 0.3305971398048045
[2m[36m(func pid=137284)[0m f1_weighted: 0.39890255401452973
[2m[36m(func pid=137284)[0m f1_per_class: [0.186, 0.519, 0.313, 0.46, 0.069, 0.331, 0.313, 0.57, 0.208, 0.337]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.5063 | Steps: 2 | Val loss: 4.2107 | Batch size: 32 | lr: 0.01 | Duration: 3.07s
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 1.7606 | Steps: 2 | Val loss: 4.5015 | Batch size: 32 | lr: 0.1 | Duration: 3.12s
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 1.0324 | Steps: 2 | Val loss: 1.7916 | Batch size: 32 | lr: 0.001 | Duration: 3.05s
[2m[36m(func pid=141976)[0m top1: 0.18330223880597016
[2m[36m(func pid=141976)[0m top5: 0.8041044776119403
[2m[36m(func pid=141976)[0m f1_micro: 0.18330223880597016
[2m[36m(func pid=141976)[0m f1_macro: 0.17022255814966844
[2m[36m(func pid=141976)[0m f1_weighted: 0.18705245790865543
[2m[36m(func pid=141976)[0m f1_per_class: [0.066, 0.163, 0.224, 0.075, 0.065, 0.0, 0.344, 0.442, 0.137, 0.186]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=141974)[0m top1: 0.1310634328358209
[2m[36m(func pid=141974)[0m top5: 0.6753731343283582
[2m[36m(func pid=141974)[0m f1_micro: 0.1310634328358209
[2m[36m(func pid=141974)[0m f1_macro: 0.12571557863774765
[2m[36m(func pid=141974)[0m f1_weighted: 0.14002760739964082
[2m[36m(func pid=141974)[0m f1_per_class: [0.076, 0.296, 0.102, 0.074, 0.111, 0.227, 0.101, 0.088, 0.1, 0.083]
[2m[36m(func pid=141974)[0m 
== Status ==
Current time: 2024-01-07 03:07:57 (running for 00:43:58.35)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: 0.32
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  1.032 |      0.353 |                   47 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.506 |      0.126 |                   25 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.761 |      0.17  |                   25 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=137284)[0m top1: 0.39972014925373134
[2m[36m(func pid=137284)[0m top5: 0.8899253731343284
[2m[36m(func pid=137284)[0m f1_micro: 0.39972014925373134
[2m[36m(func pid=137284)[0m f1_macro: 0.35263448525096786
[2m[36m(func pid=137284)[0m f1_weighted: 0.4354869677556693
[2m[36m(func pid=137284)[0m f1_per_class: [0.212, 0.539, 0.317, 0.467, 0.06, 0.333, 0.423, 0.521, 0.182, 0.473]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 1.8006 | Steps: 2 | Val loss: 4.4352 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.3791 | Steps: 2 | Val loss: 4.4082 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.5156 | Steps: 2 | Val loss: 1.7311 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=141976)[0m top1: 0.2574626865671642
[2m[36m(func pid=141976)[0m top5: 0.8176305970149254
[2m[36m(func pid=141976)[0m f1_micro: 0.2574626865671642
[2m[36m(func pid=141976)[0m f1_macro: 0.2049365152483796
[2m[36m(func pid=141976)[0m f1_weighted: 0.2345886484081519
[2m[36m(func pid=141976)[0m f1_per_class: [0.099, 0.067, 0.229, 0.48, 0.08, 0.209, 0.116, 0.318, 0.153, 0.3]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=141974)[0m top1: 0.1296641791044776
[2m[36m(func pid=141974)[0m top5: 0.7504664179104478
[2m[36m(func pid=141974)[0m f1_micro: 0.1296641791044776
[2m[36m(func pid=141974)[0m f1_macro: 0.1346176932174375
[2m[36m(func pid=141974)[0m f1_weighted: 0.1349426085074176
[2m[36m(func pid=141974)[0m f1_per_class: [0.083, 0.288, 0.108, 0.091, 0.088, 0.159, 0.063, 0.269, 0.114, 0.085]
[2m[36m(func pid=141974)[0m 
== Status ==
Current time: 2024-01-07 03:08:02 (running for 00:44:03.73)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: 0.32
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  0.516 |      0.354 |                   48 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.379 |      0.135 |                   26 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.801 |      0.205 |                   26 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=137284)[0m top1: 0.4118470149253731
[2m[36m(func pid=137284)[0m top5: 0.8973880597014925
[2m[36m(func pid=137284)[0m f1_micro: 0.4118470149253731
[2m[36m(func pid=137284)[0m f1_macro: 0.35418400066036576
[2m[36m(func pid=137284)[0m f1_weighted: 0.4410496255742699
[2m[36m(func pid=137284)[0m f1_per_class: [0.198, 0.514, 0.333, 0.477, 0.077, 0.301, 0.455, 0.557, 0.155, 0.475]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 6.6459 | Steps: 2 | Val loss: 3.5467 | Batch size: 32 | lr: 0.1 | Duration: 2.99s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.2226 | Steps: 2 | Val loss: 3.4320 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.6302 | Steps: 2 | Val loss: 1.7358 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=141976)[0m top1: 0.2560634328358209
[2m[36m(func pid=141976)[0m top5: 0.8680037313432836
[2m[36m(func pid=141976)[0m f1_micro: 0.2560634328358209
[2m[36m(func pid=141976)[0m f1_macro: 0.18091241360893226
[2m[36m(func pid=141976)[0m f1_weighted: 0.24158530731729772
[2m[36m(func pid=141976)[0m f1_per_class: [0.095, 0.124, 0.0, 0.398, 0.109, 0.358, 0.134, 0.372, 0.076, 0.143]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=141974)[0m top1: 0.27705223880597013
[2m[36m(func pid=141974)[0m top5: 0.840018656716418
[2m[36m(func pid=141974)[0m f1_micro: 0.27705223880597013
[2m[36m(func pid=141974)[0m f1_macro: 0.2602074580217404
[2m[36m(func pid=141974)[0m f1_weighted: 0.29727923450640753
[2m[36m(func pid=141974)[0m f1_per_class: [0.081, 0.401, 0.214, 0.12, 0.083, 0.337, 0.379, 0.531, 0.169, 0.286]
[2m[36m(func pid=141974)[0m 
== Status ==
Current time: 2024-01-07 03:08:08 (running for 00:44:09.19)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: 0.32
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  0.63  |      0.354 |                   49 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.223 |      0.26  |                   27 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  6.646 |      0.181 |                   27 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=137284)[0m top1: 0.4141791044776119
[2m[36m(func pid=137284)[0m top5: 0.894589552238806
[2m[36m(func pid=137284)[0m f1_micro: 0.4141791044776119
[2m[36m(func pid=137284)[0m f1_macro: 0.353551856912075
[2m[36m(func pid=137284)[0m f1_weighted: 0.44063080075866307
[2m[36m(func pid=137284)[0m f1_per_class: [0.211, 0.492, 0.357, 0.499, 0.075, 0.336, 0.434, 0.541, 0.185, 0.406]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 2.2430 | Steps: 2 | Val loss: 2.5703 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.7387 | Steps: 2 | Val loss: 3.9331 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.7132 | Steps: 2 | Val loss: 1.7930 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=141976)[0m top1: 0.22388059701492538
[2m[36m(func pid=141976)[0m top5: 0.8782649253731343
[2m[36m(func pid=141976)[0m f1_micro: 0.22388059701492538
[2m[36m(func pid=141976)[0m f1_macro: 0.20914325536870884
[2m[36m(func pid=141976)[0m f1_weighted: 0.22579526730947772
[2m[36m(func pid=141976)[0m f1_per_class: [0.081, 0.087, 0.39, 0.259, 0.09, 0.385, 0.211, 0.424, 0.026, 0.138]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=141974)[0m top1: 0.24673507462686567
[2m[36m(func pid=141974)[0m top5: 0.8134328358208955
[2m[36m(func pid=141974)[0m f1_micro: 0.24673507462686567
[2m[36m(func pid=141974)[0m f1_macro: 0.20625513322109995
[2m[36m(func pid=141974)[0m f1_weighted: 0.2346862416735426
[2m[36m(func pid=141974)[0m f1_per_class: [0.108, 0.471, 0.091, 0.148, 0.074, 0.389, 0.183, 0.0, 0.145, 0.455]
[2m[36m(func pid=141974)[0m 
== Status ==
Current time: 2024-01-07 03:08:13 (running for 00:44:14.60)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: 0.32
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  0.713 |      0.34  |                   50 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.739 |      0.206 |                   28 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  2.243 |      0.209 |                   28 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=137284)[0m top1: 0.40298507462686567
[2m[36m(func pid=137284)[0m top5: 0.8782649253731343
[2m[36m(func pid=137284)[0m f1_micro: 0.40298507462686567
[2m[36m(func pid=137284)[0m f1_macro: 0.34034263814022336
[2m[36m(func pid=137284)[0m f1_weighted: 0.4270036589040833
[2m[36m(func pid=137284)[0m f1_per_class: [0.227, 0.529, 0.345, 0.494, 0.077, 0.349, 0.376, 0.51, 0.163, 0.333]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 1.6243 | Steps: 2 | Val loss: 2.5139 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.1805 | Steps: 2 | Val loss: 4.4842 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.5134 | Steps: 2 | Val loss: 1.8801 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=141976)[0m top1: 0.25
[2m[36m(func pid=141976)[0m top5: 0.8568097014925373
[2m[36m(func pid=141976)[0m f1_micro: 0.25
[2m[36m(func pid=141976)[0m f1_macro: 0.22891798328519147
[2m[36m(func pid=141976)[0m f1_weighted: 0.25662078623277484
[2m[36m(func pid=141976)[0m f1_per_class: [0.086, 0.212, 0.299, 0.335, 0.13, 0.351, 0.169, 0.482, 0.051, 0.175]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=141974)[0m top1: 0.2103544776119403
[2m[36m(func pid=141974)[0m top5: 0.7700559701492538
[2m[36m(func pid=141974)[0m f1_micro: 0.2103544776119403
[2m[36m(func pid=141974)[0m f1_macro: 0.1881474599455023
[2m[36m(func pid=141974)[0m f1_weighted: 0.1890995190879229
[2m[36m(func pid=141974)[0m f1_per_class: [0.132, 0.448, 0.16, 0.202, 0.093, 0.325, 0.021, 0.0, 0.092, 0.408]
[2m[36m(func pid=141974)[0m 
== Status ==
Current time: 2024-01-07 03:08:19 (running for 00:44:19.85)
Memory usage on this node: 22.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: 0.32
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  0.513 |      0.317 |                   51 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.18  |      0.188 |                   29 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.624 |      0.229 |                   29 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=137284)[0m top1: 0.3726679104477612
[2m[36m(func pid=137284)[0m top5: 0.8656716417910447
[2m[36m(func pid=137284)[0m f1_micro: 0.3726679104477612
[2m[36m(func pid=137284)[0m f1_macro: 0.31678431699659765
[2m[36m(func pid=137284)[0m f1_weighted: 0.39652309246751843
[2m[36m(func pid=137284)[0m f1_per_class: [0.192, 0.516, 0.377, 0.488, 0.08, 0.332, 0.32, 0.382, 0.186, 0.296]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 1.6239 | Steps: 2 | Val loss: 2.4719 | Batch size: 32 | lr: 0.1 | Duration: 3.08s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.5181 | Steps: 2 | Val loss: 3.7852 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.5133 | Steps: 2 | Val loss: 1.9878 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=141976)[0m top1: 0.271455223880597
[2m[36m(func pid=141976)[0m top5: 0.8479477611940298
[2m[36m(func pid=141976)[0m f1_micro: 0.271455223880597
[2m[36m(func pid=141976)[0m f1_macro: 0.263543213141645
[2m[36m(func pid=141976)[0m f1_weighted: 0.31332218296523173
[2m[36m(func pid=141976)[0m f1_per_class: [0.088, 0.373, 0.303, 0.273, 0.106, 0.306, 0.326, 0.508, 0.136, 0.216]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=141974)[0m top1: 0.23740671641791045
[2m[36m(func pid=141974)[0m top5: 0.8386194029850746
[2m[36m(func pid=141974)[0m f1_micro: 0.23740671641791045
[2m[36m(func pid=141974)[0m f1_macro: 0.25001669884989247
[2m[36m(func pid=141974)[0m f1_weighted: 0.2663916855952783
[2m[36m(func pid=141974)[0m f1_per_class: [0.138, 0.405, 0.328, 0.329, 0.084, 0.314, 0.118, 0.364, 0.108, 0.312]
[2m[36m(func pid=141974)[0m 
== Status ==
Current time: 2024-01-07 03:08:24 (running for 00:44:25.17)
Memory usage on this node: 22.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: 0.32
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  0.513 |      0.315 |                   52 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.518 |      0.25  |                   30 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.624 |      0.264 |                   30 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=137284)[0m top1: 0.34281716417910446
[2m[36m(func pid=137284)[0m top5: 0.8726679104477612
[2m[36m(func pid=137284)[0m f1_micro: 0.34281716417910446
[2m[36m(func pid=137284)[0m f1_macro: 0.31523008820912807
[2m[36m(func pid=137284)[0m f1_weighted: 0.3800180994174807
[2m[36m(func pid=137284)[0m f1_per_class: [0.141, 0.495, 0.409, 0.438, 0.092, 0.319, 0.304, 0.539, 0.171, 0.245]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 1.9949 | Steps: 2 | Val loss: 2.5217 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.3916 | Steps: 2 | Val loss: 3.4785 | Batch size: 32 | lr: 0.01 | Duration: 3.08s
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.4611 | Steps: 2 | Val loss: 1.9750 | Batch size: 32 | lr: 0.001 | Duration: 2.70s
[2m[36m(func pid=141976)[0m top1: 0.23274253731343283
[2m[36m(func pid=141976)[0m top5: 0.8180970149253731
[2m[36m(func pid=141976)[0m f1_micro: 0.23274253731343286
[2m[36m(func pid=141976)[0m f1_macro: 0.25770143713367866
[2m[36m(func pid=141976)[0m f1_weighted: 0.2694854977367759
[2m[36m(func pid=141976)[0m f1_per_class: [0.084, 0.418, 0.375, 0.138, 0.06, 0.268, 0.31, 0.382, 0.15, 0.392]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=141974)[0m top1: 0.2681902985074627
[2m[36m(func pid=141974)[0m top5: 0.8698694029850746
[2m[36m(func pid=141974)[0m f1_micro: 0.2681902985074627
[2m[36m(func pid=141974)[0m f1_macro: 0.2821458317146844
[2m[36m(func pid=141974)[0m f1_weighted: 0.2545020549338012
[2m[36m(func pid=141974)[0m f1_per_class: [0.189, 0.444, 0.552, 0.083, 0.062, 0.269, 0.271, 0.452, 0.183, 0.317]
[2m[36m(func pid=141974)[0m 
== Status ==
Current time: 2024-01-07 03:08:29 (running for 00:44:30.26)
Memory usage on this node: 22.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: 0.32
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  0.461 |      0.322 |                   53 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.392 |      0.282 |                   31 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.995 |      0.258 |                   31 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=137284)[0m top1: 0.3423507462686567
[2m[36m(func pid=137284)[0m top5: 0.8852611940298507
[2m[36m(func pid=137284)[0m f1_micro: 0.3423507462686567
[2m[36m(func pid=137284)[0m f1_macro: 0.32213110310296017
[2m[36m(func pid=137284)[0m f1_weighted: 0.3801298044409547
[2m[36m(func pid=137284)[0m f1_per_class: [0.131, 0.481, 0.375, 0.428, 0.1, 0.317, 0.318, 0.541, 0.178, 0.354]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 1.7180 | Steps: 2 | Val loss: 2.1124 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.2335 | Steps: 2 | Val loss: 4.1355 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.5151 | Steps: 2 | Val loss: 1.7777 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=141976)[0m top1: 0.27052238805970147
[2m[36m(func pid=141976)[0m top5: 0.8605410447761194
[2m[36m(func pid=141976)[0m f1_micro: 0.27052238805970147
[2m[36m(func pid=141976)[0m f1_macro: 0.2764368685503712
[2m[36m(func pid=141976)[0m f1_weighted: 0.3154461221645505
[2m[36m(func pid=141976)[0m f1_per_class: [0.087, 0.383, 0.438, 0.142, 0.081, 0.312, 0.46, 0.384, 0.205, 0.273]
[2m[36m(func pid=141976)[0m 
== Status ==
Current time: 2024-01-07 03:08:34 (running for 00:44:35.40)
Memory usage on this node: 22.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: 0.32
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  0.515 |      0.353 |                   54 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.392 |      0.282 |                   31 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.718 |      0.276 |                   32 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=137284)[0m top1: 0.4085820895522388
[2m[36m(func pid=137284)[0m top5: 0.8959888059701493
[2m[36m(func pid=137284)[0m f1_micro: 0.40858208955223885
[2m[36m(func pid=137284)[0m f1_macro: 0.3532534664588775
[2m[36m(func pid=137284)[0m f1_weighted: 0.4433317707082891
[2m[36m(func pid=137284)[0m f1_per_class: [0.175, 0.496, 0.353, 0.502, 0.096, 0.347, 0.431, 0.57, 0.173, 0.389]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=141974)[0m top1: 0.27845149253731344
[2m[36m(func pid=141974)[0m top5: 0.8628731343283582
[2m[36m(func pid=141974)[0m f1_micro: 0.27845149253731344
[2m[36m(func pid=141974)[0m f1_macro: 0.25572948247916116
[2m[36m(func pid=141974)[0m f1_weighted: 0.23766072472854521
[2m[36m(func pid=141974)[0m f1_per_class: [0.194, 0.438, 0.375, 0.026, 0.079, 0.145, 0.329, 0.376, 0.217, 0.377]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 1.4903 | Steps: 2 | Val loss: 1.8487 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.4545 | Steps: 2 | Val loss: 1.7866 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.3279 | Steps: 2 | Val loss: 3.9628 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=141976)[0m top1: 0.3381529850746269
[2m[36m(func pid=141976)[0m top5: 0.8861940298507462
[2m[36m(func pid=141976)[0m f1_micro: 0.3381529850746269
[2m[36m(func pid=141976)[0m f1_macro: 0.3033414407852812
[2m[36m(func pid=141976)[0m f1_weighted: 0.38702724644089936
[2m[36m(func pid=141976)[0m f1_per_class: [0.1, 0.354, 0.444, 0.309, 0.103, 0.373, 0.525, 0.507, 0.104, 0.214]
[2m[36m(func pid=141976)[0m 
== Status ==
Current time: 2024-01-07 03:08:39 (running for 00:44:40.72)
Memory usage on this node: 22.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: 0.32
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  0.455 |      0.344 |                   55 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.233 |      0.256 |                   32 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.49  |      0.303 |                   33 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=137284)[0m top1: 0.40951492537313433
[2m[36m(func pid=137284)[0m top5: 0.8936567164179104
[2m[36m(func pid=137284)[0m f1_micro: 0.40951492537313433
[2m[36m(func pid=137284)[0m f1_macro: 0.3436491763290711
[2m[36m(func pid=137284)[0m f1_weighted: 0.4435764479764154
[2m[36m(func pid=137284)[0m f1_per_class: [0.198, 0.513, 0.333, 0.509, 0.071, 0.351, 0.431, 0.487, 0.164, 0.378]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=141974)[0m top1: 0.2905783582089552
[2m[36m(func pid=141974)[0m top5: 0.8675373134328358
[2m[36m(func pid=141974)[0m f1_micro: 0.2905783582089552
[2m[36m(func pid=141974)[0m f1_macro: 0.27975431925687444
[2m[36m(func pid=141974)[0m f1_weighted: 0.27190446337756263
[2m[36m(func pid=141974)[0m f1_per_class: [0.168, 0.42, 0.556, 0.01, 0.097, 0.228, 0.439, 0.4, 0.179, 0.302]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 3.3061 | Steps: 2 | Val loss: 1.8091 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.4675 | Steps: 2 | Val loss: 1.8137 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.2521 | Steps: 2 | Val loss: 3.6517 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=141976)[0m top1: 0.3829291044776119
[2m[36m(func pid=141976)[0m top5: 0.9057835820895522
[2m[36m(func pid=141976)[0m f1_micro: 0.3829291044776119
[2m[36m(func pid=141976)[0m f1_macro: 0.24061888920186725
[2m[36m(func pid=141976)[0m f1_weighted: 0.3909061182555285
[2m[36m(func pid=141976)[0m f1_per_class: [0.034, 0.279, 0.143, 0.54, 0.062, 0.22, 0.448, 0.49, 0.043, 0.148]
[2m[36m(func pid=141976)[0m 
== Status ==
Current time: 2024-01-07 03:08:45 (running for 00:44:45.92)
Memory usage on this node: 22.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: 0.32
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  0.468 |      0.345 |                   56 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.328 |      0.28  |                   33 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  3.306 |      0.241 |                   34 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=137284)[0m top1: 0.40578358208955223
[2m[36m(func pid=137284)[0m top5: 0.8875932835820896
[2m[36m(func pid=137284)[0m f1_micro: 0.40578358208955223
[2m[36m(func pid=137284)[0m f1_macro: 0.3452205297036883
[2m[36m(func pid=137284)[0m f1_weighted: 0.4381495002485171
[2m[36m(func pid=137284)[0m f1_per_class: [0.21, 0.518, 0.321, 0.51, 0.086, 0.352, 0.404, 0.5, 0.181, 0.37]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=141974)[0m top1: 0.2355410447761194
[2m[36m(func pid=141974)[0m top5: 0.8563432835820896
[2m[36m(func pid=141974)[0m f1_micro: 0.2355410447761194
[2m[36m(func pid=141974)[0m f1_macro: 0.27025201934342924
[2m[36m(func pid=141974)[0m f1_weighted: 0.22802548538792156
[2m[36m(func pid=141974)[0m f1_per_class: [0.156, 0.414, 0.759, 0.053, 0.088, 0.298, 0.239, 0.359, 0.158, 0.178]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 1.3380 | Steps: 2 | Val loss: 1.7883 | Batch size: 32 | lr: 0.1 | Duration: 3.03s
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.4627 | Steps: 2 | Val loss: 1.8372 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.3567 | Steps: 2 | Val loss: 3.9546 | Batch size: 32 | lr: 0.01 | Duration: 3.05s
== Status ==
Current time: 2024-01-07 03:08:50 (running for 00:44:50.97)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: 0.32
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  0.468 |      0.345 |                   56 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.252 |      0.27  |                   34 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.338 |      0.277 |                   35 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141976)[0m top1: 0.3987873134328358
[2m[36m(func pid=141976)[0m top5: 0.9127798507462687
[2m[36m(func pid=141976)[0m f1_micro: 0.3987873134328358
[2m[36m(func pid=141976)[0m f1_macro: 0.27666007047270014
[2m[36m(func pid=141976)[0m f1_weighted: 0.3992880162216631
[2m[36m(func pid=141976)[0m f1_per_class: [0.03, 0.207, 0.143, 0.566, 0.062, 0.113, 0.51, 0.498, 0.128, 0.51]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=137284)[0m top1: 0.39972014925373134
[2m[36m(func pid=137284)[0m top5: 0.8838619402985075
[2m[36m(func pid=137284)[0m f1_micro: 0.39972014925373134
[2m[36m(func pid=137284)[0m f1_macro: 0.34557491675634144
[2m[36m(func pid=137284)[0m f1_weighted: 0.4295431987737169
[2m[36m(func pid=137284)[0m f1_per_class: [0.207, 0.498, 0.333, 0.513, 0.096, 0.339, 0.377, 0.545, 0.213, 0.333]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=141974)[0m top1: 0.20569029850746268
[2m[36m(func pid=141974)[0m top5: 0.8120335820895522
[2m[36m(func pid=141974)[0m f1_micro: 0.20569029850746268
[2m[36m(func pid=141974)[0m f1_macro: 0.22968076256875633
[2m[36m(func pid=141974)[0m f1_weighted: 0.230532653152438
[2m[36m(func pid=141974)[0m f1_per_class: [0.145, 0.385, 0.449, 0.097, 0.088, 0.263, 0.274, 0.215, 0.107, 0.273]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 1.8604 | Steps: 2 | Val loss: 1.8069 | Batch size: 32 | lr: 0.1 | Duration: 3.11s
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.6070 | Steps: 2 | Val loss: 1.7898 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.2517 | Steps: 2 | Val loss: 3.6006 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
== Status ==
Current time: 2024-01-07 03:08:55 (running for 00:44:56.58)
Memory usage on this node: 22.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: 0.32
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  0.607 |      0.35  |                   58 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.357 |      0.23  |                   35 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.338 |      0.277 |                   35 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=137284)[0m top1: 0.4076492537313433
[2m[36m(func pid=137284)[0m top5: 0.8922574626865671
[2m[36m(func pid=137284)[0m f1_micro: 0.4076492537313433
[2m[36m(func pid=137284)[0m f1_macro: 0.3501441475061431
[2m[36m(func pid=137284)[0m f1_weighted: 0.4379391565073625
[2m[36m(func pid=137284)[0m f1_per_class: [0.198, 0.487, 0.377, 0.506, 0.107, 0.316, 0.431, 0.542, 0.177, 0.361]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=141976)[0m top1: 0.37033582089552236
[2m[36m(func pid=141976)[0m top5: 0.9034514925373134
[2m[36m(func pid=141976)[0m f1_micro: 0.37033582089552236
[2m[36m(func pid=141976)[0m f1_macro: 0.31824324730418996
[2m[36m(func pid=141976)[0m f1_weighted: 0.4000547482486416
[2m[36m(func pid=141976)[0m f1_per_class: [0.121, 0.219, 0.632, 0.512, 0.059, 0.18, 0.522, 0.486, 0.153, 0.299]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=141974)[0m top1: 0.27238805970149255
[2m[36m(func pid=141974)[0m top5: 0.8059701492537313
[2m[36m(func pid=141974)[0m f1_micro: 0.27238805970149255
[2m[36m(func pid=141974)[0m f1_macro: 0.24381849785553628
[2m[36m(func pid=141974)[0m f1_weighted: 0.29278930771873707
[2m[36m(func pid=141974)[0m f1_per_class: [0.179, 0.389, 0.369, 0.094, 0.097, 0.19, 0.502, 0.247, 0.135, 0.235]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.4596 | Steps: 2 | Val loss: 1.9945 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 1.2369 | Steps: 2 | Val loss: 1.7698 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.3956 | Steps: 2 | Val loss: 2.9996 | Batch size: 32 | lr: 0.01 | Duration: 3.16s
== Status ==
Current time: 2024-01-07 03:09:01 (running for 00:45:01.90)
Memory usage on this node: 22.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: 0.32
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  0.46  |      0.308 |                   59 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.252 |      0.244 |                   36 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.86  |      0.318 |                   36 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=137284)[0m top1: 0.3451492537313433
[2m[36m(func pid=137284)[0m top5: 0.8754664179104478
[2m[36m(func pid=137284)[0m f1_micro: 0.3451492537313433
[2m[36m(func pid=137284)[0m f1_macro: 0.3081442676040175
[2m[36m(func pid=137284)[0m f1_weighted: 0.3733653259574237
[2m[36m(func pid=137284)[0m f1_per_class: [0.158, 0.501, 0.305, 0.463, 0.104, 0.268, 0.272, 0.544, 0.163, 0.303]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=141976)[0m top1: 0.34794776119402987
[2m[36m(func pid=141976)[0m top5: 0.9118470149253731
[2m[36m(func pid=141976)[0m f1_micro: 0.34794776119402987
[2m[36m(func pid=141976)[0m f1_macro: 0.31961101389909896
[2m[36m(func pid=141976)[0m f1_weighted: 0.39014753172512096
[2m[36m(func pid=141976)[0m f1_per_class: [0.112, 0.236, 0.632, 0.394, 0.077, 0.33, 0.553, 0.359, 0.175, 0.329]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=141974)[0m top1: 0.28218283582089554
[2m[36m(func pid=141974)[0m top5: 0.8451492537313433
[2m[36m(func pid=141974)[0m f1_micro: 0.28218283582089554
[2m[36m(func pid=141974)[0m f1_macro: 0.29831806941590644
[2m[36m(func pid=141974)[0m f1_weighted: 0.3015978482160248
[2m[36m(func pid=141974)[0m f1_per_class: [0.314, 0.383, 0.611, 0.153, 0.078, 0.171, 0.452, 0.332, 0.135, 0.353]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.3611 | Steps: 2 | Val loss: 1.9425 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 1.4468 | Steps: 2 | Val loss: 1.9660 | Batch size: 32 | lr: 0.1 | Duration: 2.99s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.1575 | Steps: 2 | Val loss: 2.4747 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=137284)[0m top1: 0.37546641791044777
[2m[36m(func pid=137284)[0m top5: 0.8736007462686567
[2m[36m(func pid=137284)[0m f1_micro: 0.3754664179104477
[2m[36m(func pid=137284)[0m f1_macro: 0.3338582023853568
[2m[36m(func pid=137284)[0m f1_weighted: 0.4098615474203739
[2m[36m(func pid=137284)[0m f1_per_class: [0.171, 0.524, 0.333, 0.478, 0.088, 0.311, 0.341, 0.563, 0.195, 0.333]
== Status ==
Current time: 2024-01-07 03:09:06 (running for 00:45:07.39)
Memory usage on this node: 22.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: 0.32
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  0.361 |      0.334 |                   60 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.396 |      0.298 |                   37 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.237 |      0.32  |                   37 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=141976)[0m top1: 0.30363805970149255
[2m[36m(func pid=141976)[0m top5: 0.8992537313432836
[2m[36m(func pid=141976)[0m f1_micro: 0.30363805970149255
[2m[36m(func pid=141976)[0m f1_macro: 0.3059820937134598
[2m[36m(func pid=141976)[0m f1_weighted: 0.3452663901355884
[2m[36m(func pid=141976)[0m f1_per_class: [0.111, 0.226, 0.632, 0.293, 0.077, 0.363, 0.479, 0.486, 0.051, 0.343]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=141974)[0m top1: 0.341884328358209
[2m[36m(func pid=141974)[0m top5: 0.8899253731343284
[2m[36m(func pid=141974)[0m f1_micro: 0.341884328358209
[2m[36m(func pid=141974)[0m f1_macro: 0.34056567598349147
[2m[36m(func pid=141974)[0m f1_weighted: 0.37951104421137927
[2m[36m(func pid=141974)[0m f1_per_class: [0.299, 0.392, 0.696, 0.366, 0.077, 0.277, 0.459, 0.364, 0.176, 0.3]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.4495 | Steps: 2 | Val loss: 1.8497 | Batch size: 32 | lr: 0.001 | Duration: 3.06s
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 1.2638 | Steps: 2 | Val loss: 2.0521 | Batch size: 32 | lr: 0.1 | Duration: 3.10s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.3490 | Steps: 2 | Val loss: 4.2171 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
== Status ==
Current time: 2024-01-07 03:09:11 (running for 00:45:12.78)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: 0.32
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  0.45  |      0.34  |                   61 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.157 |      0.341 |                   38 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.447 |      0.306 |                   38 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=137284)[0m top1: 0.40205223880597013
[2m[36m(func pid=137284)[0m top5: 0.878731343283582
[2m[36m(func pid=137284)[0m f1_micro: 0.4020522388059702
[2m[36m(func pid=137284)[0m f1_macro: 0.3404357323269404
[2m[36m(func pid=137284)[0m f1_weighted: 0.4323469139958319
[2m[36m(func pid=137284)[0m f1_per_class: [0.221, 0.538, 0.272, 0.519, 0.084, 0.327, 0.374, 0.488, 0.198, 0.384]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=141976)[0m top1: 0.2728544776119403
[2m[36m(func pid=141976)[0m top5: 0.898320895522388
[2m[36m(func pid=141976)[0m f1_micro: 0.2728544776119403
[2m[36m(func pid=141976)[0m f1_macro: 0.28853362150839784
[2m[36m(func pid=141976)[0m f1_weighted: 0.29208981759422775
[2m[36m(func pid=141976)[0m f1_per_class: [0.112, 0.118, 0.632, 0.316, 0.07, 0.381, 0.332, 0.506, 0.019, 0.4]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=141974)[0m top1: 0.19309701492537312
[2m[36m(func pid=141974)[0m top5: 0.7854477611940298
[2m[36m(func pid=141974)[0m f1_micro: 0.19309701492537315
[2m[36m(func pid=141974)[0m f1_macro: 0.19539414703893004
[2m[36m(func pid=141974)[0m f1_weighted: 0.23202906407626211
[2m[36m(func pid=141974)[0m f1_per_class: [0.137, 0.345, 0.522, 0.335, 0.1, 0.132, 0.169, 0.056, 0.096, 0.062]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.5064 | Steps: 2 | Val loss: 1.7227 | Batch size: 32 | lr: 0.001 | Duration: 3.04s
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 1.3017 | Steps: 2 | Val loss: 1.9340 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.2132 | Steps: 2 | Val loss: 7.6248 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=137284)[0m top1: 0.4291044776119403
[2m[36m(func pid=137284)[0m top5: 0.898320895522388
[2m[36m(func pid=137284)[0m f1_micro: 0.4291044776119403
[2m[36m(func pid=137284)[0m f1_macro: 0.36914888667453216
[2m[36m(func pid=137284)[0m f1_weighted: 0.4572906493983739
[2m[36m(func pid=137284)[0m f1_per_class: [0.261, 0.534, 0.338, 0.508, 0.09, 0.349, 0.452, 0.52, 0.167, 0.473]
[2m[36m(func pid=137284)[0m 
== Status ==
Current time: 2024-01-07 03:09:17 (running for 00:45:18.29)
Memory usage on this node: 22.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: 0.32
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  0.506 |      0.369 |                   62 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.349 |      0.195 |                   39 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.264 |      0.289 |                   39 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141976)[0m top1: 0.2891791044776119
[2m[36m(func pid=141976)[0m top5: 0.9053171641791045
[2m[36m(func pid=141976)[0m f1_micro: 0.2891791044776119
[2m[36m(func pid=141976)[0m f1_macro: 0.29808830498864736
[2m[36m(func pid=141976)[0m f1_weighted: 0.29500513675338624
[2m[36m(func pid=141976)[0m f1_per_class: [0.108, 0.097, 0.632, 0.414, 0.081, 0.389, 0.252, 0.466, 0.166, 0.378]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=141974)[0m top1: 0.10307835820895522
[2m[36m(func pid=141974)[0m top5: 0.6217350746268657
[2m[36m(func pid=141974)[0m f1_micro: 0.10307835820895522
[2m[36m(func pid=141974)[0m f1_macro: 0.07552426179392954
[2m[36m(func pid=141974)[0m f1_weighted: 0.1119461294727092
[2m[36m(func pid=141974)[0m f1_per_class: [0.098, 0.247, 0.0, 0.224, 0.115, 0.023, 0.003, 0.0, 0.0, 0.045]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.3585 | Steps: 2 | Val loss: 1.7446 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 1.6122 | Steps: 2 | Val loss: 1.7986 | Batch size: 32 | lr: 0.1 | Duration: 3.15s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.1259 | Steps: 2 | Val loss: 6.7236 | Batch size: 32 | lr: 0.01 | Duration: 3.07s
== Status ==
Current time: 2024-01-07 03:09:22 (running for 00:45:23.45)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: 0.32
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  0.358 |      0.369 |                   63 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.213 |      0.076 |                   40 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.302 |      0.298 |                   40 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=137284)[0m top1: 0.4244402985074627
[2m[36m(func pid=137284)[0m top5: 0.8973880597014925
[2m[36m(func pid=137284)[0m f1_micro: 0.4244402985074627
[2m[36m(func pid=137284)[0m f1_macro: 0.36853385649380443
[2m[36m(func pid=137284)[0m f1_weighted: 0.4563837669106043
[2m[36m(func pid=137284)[0m f1_per_class: [0.232, 0.539, 0.308, 0.504, 0.075, 0.346, 0.446, 0.539, 0.198, 0.5]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=141976)[0m top1: 0.37779850746268656
[2m[36m(func pid=141976)[0m top5: 0.914179104477612
[2m[36m(func pid=141976)[0m f1_micro: 0.3777985074626865
[2m[36m(func pid=141976)[0m f1_macro: 0.3249677882632389
[2m[36m(func pid=141976)[0m f1_weighted: 0.41147177534058016
[2m[36m(func pid=141976)[0m f1_per_class: [0.125, 0.313, 0.632, 0.424, 0.077, 0.261, 0.564, 0.458, 0.15, 0.246]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=141974)[0m top1: 0.11986940298507463
[2m[36m(func pid=141974)[0m top5: 0.6310634328358209
[2m[36m(func pid=141974)[0m f1_micro: 0.11986940298507463
[2m[36m(func pid=141974)[0m f1_macro: 0.13951782094005877
[2m[36m(func pid=141974)[0m f1_weighted: 0.13292563987169803
[2m[36m(func pid=141974)[0m f1_per_class: [0.106, 0.186, 0.6, 0.315, 0.096, 0.052, 0.0, 0.0, 0.0, 0.04]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.3594 | Steps: 2 | Val loss: 1.8184 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 1.2709 | Steps: 2 | Val loss: 1.8979 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.2424 | Steps: 2 | Val loss: 4.3028 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
== Status ==
Current time: 2024-01-07 03:09:27 (running for 00:45:28.80)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: 0.32
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  0.359 |      0.352 |                   64 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.126 |      0.14  |                   41 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.612 |      0.325 |                   41 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=137284)[0m top1: 0.4118470149253731
[2m[36m(func pid=137284)[0m top5: 0.8875932835820896
[2m[36m(func pid=137284)[0m f1_micro: 0.4118470149253731
[2m[36m(func pid=137284)[0m f1_macro: 0.3517835600287042
[2m[36m(func pid=137284)[0m f1_weighted: 0.4422996042837293
[2m[36m(func pid=137284)[0m f1_per_class: [0.227, 0.555, 0.262, 0.494, 0.073, 0.347, 0.409, 0.498, 0.185, 0.467]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=141976)[0m top1: 0.3353544776119403
[2m[36m(func pid=141976)[0m top5: 0.9039179104477612
[2m[36m(func pid=141976)[0m f1_micro: 0.3353544776119403
[2m[36m(func pid=141976)[0m f1_macro: 0.2797826933887978
[2m[36m(func pid=141976)[0m f1_weighted: 0.36220980773977257
[2m[36m(func pid=141976)[0m f1_per_class: [0.105, 0.279, 0.632, 0.298, 0.066, 0.208, 0.597, 0.319, 0.048, 0.247]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=141974)[0m top1: 0.19869402985074627
[2m[36m(func pid=141974)[0m top5: 0.7140858208955224
[2m[36m(func pid=141974)[0m f1_micro: 0.19869402985074627
[2m[36m(func pid=141974)[0m f1_macro: 0.21066792355977776
[2m[36m(func pid=141974)[0m f1_weighted: 0.2063364608746069
[2m[36m(func pid=141974)[0m f1_per_class: [0.184, 0.239, 0.818, 0.481, 0.082, 0.117, 0.003, 0.101, 0.028, 0.053]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.3849 | Steps: 2 | Val loss: 1.7798 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 1.4380 | Steps: 2 | Val loss: 1.8657 | Batch size: 32 | lr: 0.1 | Duration: 3.11s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.1294 | Steps: 2 | Val loss: 2.6645 | Batch size: 32 | lr: 0.01 | Duration: 3.05s
== Status ==
Current time: 2024-01-07 03:09:33 (running for 00:45:34.02)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: 0.32
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  0.385 |      0.358 |                   65 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.242 |      0.211 |                   42 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.271 |      0.28  |                   42 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=137284)[0m top1: 0.43283582089552236
[2m[36m(func pid=137284)[0m top5: 0.8927238805970149
[2m[36m(func pid=137284)[0m f1_micro: 0.43283582089552236
[2m[36m(func pid=137284)[0m f1_macro: 0.35812258864351215
[2m[36m(func pid=137284)[0m f1_weighted: 0.4631409180806401
[2m[36m(func pid=137284)[0m f1_per_class: [0.233, 0.556, 0.233, 0.518, 0.087, 0.365, 0.45, 0.5, 0.187, 0.452]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=141976)[0m top1: 0.333955223880597
[2m[36m(func pid=141976)[0m top5: 0.9039179104477612
[2m[36m(func pid=141976)[0m f1_micro: 0.333955223880597
[2m[36m(func pid=141976)[0m f1_macro: 0.32060880171311623
[2m[36m(func pid=141976)[0m f1_weighted: 0.3724863502208747
[2m[36m(func pid=141976)[0m f1_per_class: [0.099, 0.191, 0.522, 0.315, 0.08, 0.361, 0.559, 0.5, 0.109, 0.471]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=141974)[0m top1: 0.322294776119403
[2m[36m(func pid=141974)[0m top5: 0.8847947761194029
[2m[36m(func pid=141974)[0m f1_micro: 0.322294776119403
[2m[36m(func pid=141974)[0m f1_macro: 0.3310217875945837
[2m[36m(func pid=141974)[0m f1_weighted: 0.3217817992684373
[2m[36m(func pid=141974)[0m f1_per_class: [0.241, 0.355, 0.846, 0.498, 0.091, 0.345, 0.132, 0.448, 0.114, 0.241]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.6024 | Steps: 2 | Val loss: 1.7508 | Batch size: 32 | lr: 0.001 | Duration: 3.06s
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 1.2009 | Steps: 2 | Val loss: 1.9740 | Batch size: 32 | lr: 0.1 | Duration: 3.09s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.2448 | Steps: 2 | Val loss: 2.5690 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
== Status ==
Current time: 2024-01-07 03:09:38 (running for 00:45:39.51)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: 0.32
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  0.602 |      0.361 |                   66 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.129 |      0.331 |                   43 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.438 |      0.321 |                   43 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=137284)[0m top1: 0.435634328358209
[2m[36m(func pid=137284)[0m top5: 0.8973880597014925
[2m[36m(func pid=137284)[0m f1_micro: 0.435634328358209
[2m[36m(func pid=137284)[0m f1_macro: 0.36143976553149
[2m[36m(func pid=137284)[0m f1_weighted: 0.4650842818664935
[2m[36m(func pid=137284)[0m f1_per_class: [0.206, 0.533, 0.247, 0.522, 0.099, 0.336, 0.468, 0.545, 0.2, 0.459]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=141976)[0m top1: 0.3111007462686567
[2m[36m(func pid=141976)[0m top5: 0.8913246268656716
[2m[36m(func pid=141976)[0m f1_micro: 0.3111007462686567
[2m[36m(func pid=141976)[0m f1_macro: 0.30606827095751277
[2m[36m(func pid=141976)[0m f1_weighted: 0.33511673621068067
[2m[36m(func pid=141976)[0m f1_per_class: [0.101, 0.172, 0.552, 0.352, 0.104, 0.314, 0.44, 0.444, 0.07, 0.512]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=141974)[0m top1: 0.3885261194029851
[2m[36m(func pid=141974)[0m top5: 0.8843283582089553
[2m[36m(func pid=141974)[0m f1_micro: 0.3885261194029851
[2m[36m(func pid=141974)[0m f1_macro: 0.3532247048182363
[2m[36m(func pid=141974)[0m f1_weighted: 0.40163499922037854
[2m[36m(func pid=141974)[0m f1_per_class: [0.301, 0.468, 0.647, 0.487, 0.08, 0.386, 0.331, 0.407, 0.164, 0.262]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.3846 | Steps: 2 | Val loss: 1.8425 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 1.8608 | Steps: 2 | Val loss: 1.9511 | Batch size: 32 | lr: 0.1 | Duration: 3.01s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.2290 | Steps: 2 | Val loss: 4.7558 | Batch size: 32 | lr: 0.01 | Duration: 3.06s
== Status ==
Current time: 2024-01-07 03:09:43 (running for 00:45:44.80)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: 0.32
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  0.385 |      0.339 |                   67 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.245 |      0.353 |                   44 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.201 |      0.306 |                   44 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=137284)[0m top1: 0.39225746268656714
[2m[36m(func pid=137284)[0m top5: 0.8973880597014925
[2m[36m(func pid=137284)[0m f1_micro: 0.39225746268656714
[2m[36m(func pid=137284)[0m f1_macro: 0.33877605798768873
[2m[36m(func pid=137284)[0m f1_weighted: 0.427965557782309
[2m[36m(func pid=137284)[0m f1_per_class: [0.16, 0.514, 0.25, 0.475, 0.11, 0.317, 0.417, 0.518, 0.175, 0.452]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=141976)[0m top1: 0.3591417910447761
[2m[36m(func pid=141976)[0m top5: 0.8917910447761194
[2m[36m(func pid=141976)[0m f1_micro: 0.3591417910447761
[2m[36m(func pid=141976)[0m f1_macro: 0.30218104662633327
[2m[36m(func pid=141976)[0m f1_weighted: 0.3676105124022172
[2m[36m(func pid=141976)[0m f1_per_class: [0.045, 0.315, 0.5, 0.491, 0.107, 0.256, 0.367, 0.394, 0.183, 0.364]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=141974)[0m top1: 0.2667910447761194
[2m[36m(func pid=141974)[0m top5: 0.8274253731343284
[2m[36m(func pid=141974)[0m f1_micro: 0.2667910447761194
[2m[36m(func pid=141974)[0m f1_macro: 0.167695327252121
[2m[36m(func pid=141974)[0m f1_weighted: 0.22863832968349715
[2m[36m(func pid=141974)[0m f1_per_class: [0.131, 0.472, 0.0, 0.233, 0.091, 0.319, 0.103, 0.133, 0.089, 0.106]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.3272 | Steps: 2 | Val loss: 1.7835 | Batch size: 32 | lr: 0.001 | Duration: 3.07s
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 1.1904 | Steps: 2 | Val loss: 1.8991 | Batch size: 32 | lr: 0.1 | Duration: 3.04s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.4331 | Steps: 2 | Val loss: 4.6715 | Batch size: 32 | lr: 0.01 | Duration: 3.05s
== Status ==
Current time: 2024-01-07 03:09:49 (running for 00:45:50.29)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: 0.32
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  0.327 |      0.355 |                   68 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.229 |      0.168 |                   45 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.861 |      0.302 |                   45 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=137284)[0m top1: 0.42630597014925375
[2m[36m(func pid=137284)[0m top5: 0.9011194029850746
[2m[36m(func pid=137284)[0m f1_micro: 0.4263059701492538
[2m[36m(func pid=137284)[0m f1_macro: 0.3546955910997791
[2m[36m(func pid=137284)[0m f1_weighted: 0.46264456194883624
[2m[36m(func pid=137284)[0m f1_per_class: [0.185, 0.518, 0.237, 0.5, 0.097, 0.36, 0.486, 0.53, 0.186, 0.448]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=141976)[0m top1: 0.4039179104477612
[2m[36m(func pid=141976)[0m top5: 0.8824626865671642
[2m[36m(func pid=141976)[0m f1_micro: 0.4039179104477612
[2m[36m(func pid=141976)[0m f1_macro: 0.29305246277533026
[2m[36m(func pid=141976)[0m f1_weighted: 0.41349179390678187
[2m[36m(func pid=141976)[0m f1_per_class: [0.038, 0.403, 0.514, 0.415, 0.082, 0.318, 0.585, 0.031, 0.227, 0.317]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=141974)[0m top1: 0.2579291044776119
[2m[36m(func pid=141974)[0m top5: 0.7406716417910447
[2m[36m(func pid=141974)[0m f1_micro: 0.2579291044776119
[2m[36m(func pid=141974)[0m f1_macro: 0.15811821682418511
[2m[36m(func pid=141974)[0m f1_weighted: 0.21781267400754406
[2m[36m(func pid=141974)[0m f1_per_class: [0.274, 0.507, 0.0, 0.347, 0.12, 0.218, 0.0, 0.0, 0.057, 0.059]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.4164 | Steps: 2 | Val loss: 1.7808 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 1.4641 | Steps: 2 | Val loss: 2.0230 | Batch size: 32 | lr: 0.1 | Duration: 3.04s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.5280 | Steps: 2 | Val loss: 3.2667 | Batch size: 32 | lr: 0.01 | Duration: 3.22s
== Status ==
Current time: 2024-01-07 03:09:54 (running for 00:45:55.64)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: 0.32
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  0.416 |      0.348 |                   69 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.433 |      0.158 |                   46 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.19  |      0.293 |                   46 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=137284)[0m top1: 0.435634328358209
[2m[36m(func pid=137284)[0m top5: 0.8969216417910447
[2m[36m(func pid=137284)[0m f1_micro: 0.435634328358209
[2m[36m(func pid=137284)[0m f1_macro: 0.3476157336009369
[2m[36m(func pid=137284)[0m f1_weighted: 0.4710636372666432
[2m[36m(func pid=137284)[0m f1_per_class: [0.205, 0.529, 0.208, 0.523, 0.077, 0.347, 0.509, 0.458, 0.145, 0.475]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=141976)[0m top1: 0.36473880597014924
[2m[36m(func pid=141976)[0m top5: 0.8791977611940298
[2m[36m(func pid=141976)[0m f1_micro: 0.36473880597014924
[2m[36m(func pid=141976)[0m f1_macro: 0.26153996979427724
[2m[36m(func pid=141976)[0m f1_weighted: 0.3725841407644987
[2m[36m(func pid=141976)[0m f1_per_class: [0.094, 0.408, 0.5, 0.296, 0.076, 0.231, 0.598, 0.031, 0.151, 0.23]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=141974)[0m top1: 0.292910447761194
[2m[36m(func pid=141974)[0m top5: 0.8955223880597015
[2m[36m(func pid=141974)[0m f1_micro: 0.292910447761194
[2m[36m(func pid=141974)[0m f1_macro: 0.257609619388126
[2m[36m(func pid=141974)[0m f1_weighted: 0.2568151390073928
[2m[36m(func pid=141974)[0m f1_per_class: [0.232, 0.539, 0.489, 0.391, 0.081, 0.204, 0.048, 0.0, 0.103, 0.49]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.3164 | Steps: 2 | Val loss: 1.8961 | Batch size: 32 | lr: 0.001 | Duration: 3.03s
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 1.1174 | Steps: 2 | Val loss: 2.1290 | Batch size: 32 | lr: 0.1 | Duration: 3.06s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.3807 | Steps: 2 | Val loss: 3.2301 | Batch size: 32 | lr: 0.01 | Duration: 3.20s
== Status ==
Current time: 2024-01-07 03:10:00 (running for 00:46:01.16)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: 0.32
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  0.316 |      0.348 |                   70 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.528 |      0.258 |                   47 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.464 |      0.262 |                   47 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=137284)[0m top1: 0.3969216417910448
[2m[36m(func pid=137284)[0m top5: 0.886660447761194
[2m[36m(func pid=137284)[0m f1_micro: 0.3969216417910448
[2m[36m(func pid=137284)[0m f1_macro: 0.3482693683419865
[2m[36m(func pid=137284)[0m f1_weighted: 0.4308787686466784
[2m[36m(func pid=137284)[0m f1_per_class: [0.176, 0.526, 0.259, 0.505, 0.077, 0.347, 0.367, 0.541, 0.253, 0.431]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=141976)[0m top1: 0.2555970149253731
[2m[36m(func pid=141976)[0m top5: 0.8773320895522388
[2m[36m(func pid=141976)[0m f1_micro: 0.2555970149253731
[2m[36m(func pid=141976)[0m f1_macro: 0.25005504562759595
[2m[36m(func pid=141976)[0m f1_weighted: 0.271396142998974
[2m[36m(func pid=141976)[0m f1_per_class: [0.077, 0.3, 0.5, 0.289, 0.09, 0.266, 0.25, 0.363, 0.171, 0.194]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=141974)[0m top1: 0.2905783582089552
[2m[36m(func pid=141974)[0m top5: 0.9011194029850746
[2m[36m(func pid=141974)[0m f1_micro: 0.2905783582089552
[2m[36m(func pid=141974)[0m f1_macro: 0.23700186854062005
[2m[36m(func pid=141974)[0m f1_weighted: 0.3155971413339424
[2m[36m(func pid=141974)[0m f1_per_class: [0.204, 0.193, 0.176, 0.375, 0.055, 0.222, 0.414, 0.261, 0.137, 0.333]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.2909 | Steps: 2 | Val loss: 1.9027 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.9672 | Steps: 2 | Val loss: 2.2191 | Batch size: 32 | lr: 0.1 | Duration: 3.06s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.1801 | Steps: 2 | Val loss: 3.1074 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 03:10:05 (running for 00:46:06.58)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: 0.32
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  0.291 |      0.328 |                   71 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.381 |      0.237 |                   48 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.117 |      0.25  |                   48 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=137284)[0m top1: 0.3843283582089552
[2m[36m(func pid=137284)[0m top5: 0.8857276119402985
[2m[36m(func pid=137284)[0m f1_micro: 0.3843283582089552
[2m[36m(func pid=137284)[0m f1_macro: 0.32806882320504815
[2m[36m(func pid=137284)[0m f1_weighted: 0.41307463706760994
[2m[36m(func pid=137284)[0m f1_per_class: [0.176, 0.514, 0.267, 0.49, 0.085, 0.335, 0.343, 0.545, 0.189, 0.337]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=141976)[0m top1: 0.22574626865671643
[2m[36m(func pid=141976)[0m top5: 0.875
[2m[36m(func pid=141976)[0m f1_micro: 0.22574626865671643
[2m[36m(func pid=141976)[0m f1_macro: 0.24487323719930973
[2m[36m(func pid=141976)[0m f1_weighted: 0.22641413589380166
[2m[36m(func pid=141976)[0m f1_per_class: [0.095, 0.211, 0.529, 0.304, 0.111, 0.306, 0.123, 0.306, 0.213, 0.25]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=141974)[0m top1: 0.324160447761194
[2m[36m(func pid=141974)[0m top5: 0.9127798507462687
[2m[36m(func pid=141974)[0m f1_micro: 0.324160447761194
[2m[36m(func pid=141974)[0m f1_macro: 0.27572461232531187
[2m[36m(func pid=141974)[0m f1_weighted: 0.34210909405685175
[2m[36m(func pid=141974)[0m f1_per_class: [0.262, 0.185, 0.136, 0.461, 0.059, 0.415, 0.322, 0.396, 0.122, 0.4]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.4382 | Steps: 2 | Val loss: 1.7926 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 7.8149 | Steps: 2 | Val loss: 2.8053 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.1506 | Steps: 2 | Val loss: 2.9498 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
== Status ==
Current time: 2024-01-07 03:10:11 (running for 00:46:11.87)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: 0.32
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  0.438 |      0.343 |                   72 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.18  |      0.276 |                   49 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  0.967 |      0.245 |                   49 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=137284)[0m top1: 0.40951492537313433
[2m[36m(func pid=137284)[0m top5: 0.8908582089552238
[2m[36m(func pid=137284)[0m f1_micro: 0.40951492537313433
[2m[36m(func pid=137284)[0m f1_macro: 0.34340420788355364
[2m[36m(func pid=137284)[0m f1_weighted: 0.4319070949784052
[2m[36m(func pid=137284)[0m f1_per_class: [0.234, 0.539, 0.299, 0.502, 0.08, 0.341, 0.377, 0.537, 0.155, 0.37]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=141976)[0m top1: 0.34281716417910446
[2m[36m(func pid=141976)[0m top5: 0.8736007462686567
[2m[36m(func pid=141976)[0m f1_micro: 0.34281716417910446
[2m[36m(func pid=141976)[0m f1_macro: 0.27040022286645005
[2m[36m(func pid=141976)[0m f1_weighted: 0.3586835766421344
[2m[36m(func pid=141976)[0m f1_per_class: [0.085, 0.441, 0.304, 0.396, 0.059, 0.296, 0.343, 0.421, 0.171, 0.188]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=141974)[0m top1: 0.34888059701492535
[2m[36m(func pid=141974)[0m top5: 0.917910447761194
[2m[36m(func pid=141974)[0m f1_micro: 0.34888059701492535
[2m[36m(func pid=141974)[0m f1_macro: 0.25811164388943536
[2m[36m(func pid=141974)[0m f1_weighted: 0.35272895584774994
[2m[36m(func pid=141974)[0m f1_per_class: [0.32, 0.401, 0.153, 0.458, 0.037, 0.369, 0.319, 0.075, 0.079, 0.372]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.2815 | Steps: 2 | Val loss: 1.8058 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 3.5320 | Steps: 2 | Val loss: 3.3653 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.2939 | Steps: 2 | Val loss: 2.8570 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
== Status ==
Current time: 2024-01-07 03:10:16 (running for 00:46:17.33)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: 0.32
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  0.281 |      0.341 |                   73 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.151 |      0.258 |                   50 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  7.815 |      0.27  |                   50 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=137284)[0m top1: 0.41511194029850745
[2m[36m(func pid=137284)[0m top5: 0.8936567164179104
[2m[36m(func pid=137284)[0m f1_micro: 0.4151119402985075
[2m[36m(func pid=137284)[0m f1_macro: 0.3406995211426807
[2m[36m(func pid=137284)[0m f1_weighted: 0.44398571916028057
[2m[36m(func pid=137284)[0m f1_per_class: [0.238, 0.533, 0.25, 0.489, 0.079, 0.336, 0.441, 0.507, 0.177, 0.359]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=141976)[0m top1: 0.27098880597014924
[2m[36m(func pid=141976)[0m top5: 0.8731343283582089
[2m[36m(func pid=141976)[0m f1_micro: 0.27098880597014924
[2m[36m(func pid=141976)[0m f1_macro: 0.19687093590128696
[2m[36m(func pid=141976)[0m f1_weighted: 0.2369369207295728
[2m[36m(func pid=141976)[0m f1_per_class: [0.078, 0.416, 0.209, 0.376, 0.052, 0.078, 0.059, 0.414, 0.157, 0.13]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=141974)[0m top1: 0.34794776119402987
[2m[36m(func pid=141974)[0m top5: 0.9230410447761194
[2m[36m(func pid=141974)[0m f1_micro: 0.34794776119402987
[2m[36m(func pid=141974)[0m f1_macro: 0.25521131896025834
[2m[36m(func pid=141974)[0m f1_weighted: 0.3522244743524956
[2m[36m(func pid=141974)[0m f1_per_class: [0.189, 0.268, 0.393, 0.505, 0.071, 0.361, 0.345, 0.181, 0.046, 0.194]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.2934 | Steps: 2 | Val loss: 1.9122 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 4.4765 | Steps: 2 | Val loss: 4.2631 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.0897 | Steps: 2 | Val loss: 2.9297 | Batch size: 32 | lr: 0.01 | Duration: 3.17s
[2m[36m(func pid=137284)[0m top1: 0.38899253731343286
[2m[36m(func pid=137284)[0m top5: 0.8815298507462687== Status ==
Current time: 2024-01-07 03:10:21 (running for 00:46:22.64)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: 0.32
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00021 | RUNNING    | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  0.293 |      0.335 |                   74 |
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.294 |      0.255 |                   51 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  3.532 |      0.197 |                   51 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)



[2m[36m(func pid=137284)[0m f1_micro: 0.38899253731343286
[2m[36m(func pid=137284)[0m f1_macro: 0.3346311100248308
[2m[36m(func pid=137284)[0m f1_weighted: 0.41295636485278386
[2m[36m(func pid=137284)[0m f1_per_class: [0.202, 0.526, 0.308, 0.496, 0.091, 0.32, 0.331, 0.55, 0.192, 0.33]
[2m[36m(func pid=137284)[0m 
[2m[36m(func pid=141976)[0m top1: 0.23041044776119404
[2m[36m(func pid=141976)[0m top5: 0.8680037313432836
[2m[36m(func pid=141976)[0m f1_micro: 0.23041044776119404
[2m[36m(func pid=141976)[0m f1_macro: 0.18785040529802974
[2m[36m(func pid=141976)[0m f1_weighted: 0.211062009335319
[2m[36m(func pid=141976)[0m f1_per_class: [0.054, 0.055, 0.189, 0.439, 0.092, 0.319, 0.048, 0.317, 0.132, 0.234]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=141974)[0m top1: 0.3512126865671642
[2m[36m(func pid=141974)[0m top5: 0.9020522388059702
[2m[36m(func pid=141974)[0m f1_micro: 0.3512126865671642
[2m[36m(func pid=141974)[0m f1_macro: 0.27387850584673773
[2m[36m(func pid=141974)[0m f1_weighted: 0.3736260322255703
[2m[36m(func pid=141974)[0m f1_per_class: [0.044, 0.21, 0.556, 0.422, 0.065, 0.441, 0.461, 0.438, 0.024, 0.077]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=137284)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.2727 | Steps: 2 | Val loss: 2.0074 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 2.4008 | Steps: 2 | Val loss: 8.9978 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
== Status ==
Current time: 2024-01-07 03:10:27 (running for 00:46:27.84)
Memory usage on this node: 22.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: 0.31925000000000003
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.09  |      0.274 |                   52 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  4.476 |      0.188 |                   52 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
| train_6ed81_00017 | TERMINATED | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.09  |      0.295 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=137284)[0m top1: 0.363339552238806
[2m[36m(func pid=137284)[0m top5: 0.867070895522388
[2m[36m(func pid=137284)[0m f1_micro: 0.363339552238806
[2m[36m(func pid=137284)[0m f1_macro: 0.3172770487906595
[2m[36m(func pid=137284)[0m f1_weighted: 0.3794419573855694
[2m[36m(func pid=137284)[0m f1_per_class: [0.212, 0.498, 0.31, 0.505, 0.082, 0.299, 0.24, 0.533, 0.181, 0.313]
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.0710 | Steps: 2 | Val loss: 3.0380 | Batch size: 32 | lr: 0.01 | Duration: 3.21s
[2m[36m(func pid=141976)[0m top1: 0.15438432835820895
[2m[36m(func pid=141976)[0m top5: 0.7751865671641791
[2m[36m(func pid=141976)[0m f1_micro: 0.15438432835820895
[2m[36m(func pid=141976)[0m f1_macro: 0.13634030401693883
[2m[36m(func pid=141976)[0m f1_weighted: 0.09326011881029478
[2m[36m(func pid=141976)[0m f1_per_class: [0.0, 0.048, 0.076, 0.0, 0.103, 0.433, 0.031, 0.324, 0.111, 0.238]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=141974)[0m top1: 0.3414179104477612
[2m[36m(func pid=141974)[0m top5: 0.9006529850746269
[2m[36m(func pid=141974)[0m f1_micro: 0.3414179104477612
[2m[36m(func pid=141974)[0m f1_macro: 0.21333933747291223
[2m[36m(func pid=141974)[0m f1_weighted: 0.36395506266680705
[2m[36m(func pid=141974)[0m f1_per_class: [0.042, 0.221, 0.0, 0.395, 0.066, 0.378, 0.483, 0.426, 0.045, 0.077]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 2.6638 | Steps: 2 | Val loss: 8.2699 | Batch size: 32 | lr: 0.1 | Duration: 3.02s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.0642 | Steps: 2 | Val loss: 2.9329 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
== Status ==
Current time: 2024-01-07 03:10:34 (running for 00:46:35.34)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: 0.31925000000000003
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.071 |      0.213 |                   53 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  2.664 |      0.133 |                   54 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
| train_6ed81_00017 | TERMINATED | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.09  |      0.295 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141976)[0m top1: 0.12546641791044777
[2m[36m(func pid=141976)[0m top5: 0.6875
[2m[36m(func pid=141976)[0m f1_micro: 0.12546641791044777
[2m[36m(func pid=141976)[0m f1_macro: 0.132609475876376
[2m[36m(func pid=141976)[0m f1_weighted: 0.1393866051103175
[2m[36m(func pid=141976)[0m f1_per_class: [0.026, 0.286, 0.116, 0.0, 0.141, 0.177, 0.162, 0.274, 0.088, 0.058]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=141974)[0m top1: 0.3498134328358209
[2m[36m(func pid=141974)[0m top5: 0.9034514925373134
[2m[36m(func pid=141974)[0m f1_micro: 0.3498134328358209
[2m[36m(func pid=141974)[0m f1_macro: 0.23807517866816896
[2m[36m(func pid=141974)[0m f1_weighted: 0.36658159695977743
[2m[36m(func pid=141974)[0m f1_per_class: [0.082, 0.256, 0.0, 0.436, 0.073, 0.264, 0.462, 0.401, 0.141, 0.267]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 1.8209 | Steps: 2 | Val loss: 10.2607 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.0923 | Steps: 2 | Val loss: 2.8267 | Batch size: 32 | lr: 0.01 | Duration: 3.11s
== Status ==
Current time: 2024-01-07 03:10:39 (running for 00:46:40.64)
Memory usage on this node: 19.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: 0.31925000000000003
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.064 |      0.238 |                   54 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.821 |      0.109 |                   55 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
| train_6ed81_00017 | TERMINATED | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.09  |      0.295 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141976)[0m top1: 0.18050373134328357
[2m[36m(func pid=141976)[0m top5: 0.652518656716418
[2m[36m(func pid=141976)[0m f1_micro: 0.18050373134328357
[2m[36m(func pid=141976)[0m f1_macro: 0.10881356263211908
[2m[36m(func pid=141976)[0m f1_weighted: 0.190987949721703
[2m[36m(func pid=141976)[0m f1_per_class: [0.0, 0.3, 0.076, 0.0, 0.065, 0.016, 0.441, 0.014, 0.101, 0.075]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=141974)[0m top1: 0.365205223880597
[2m[36m(func pid=141974)[0m top5: 0.9039179104477612
[2m[36m(func pid=141974)[0m f1_micro: 0.365205223880597
[2m[36m(func pid=141974)[0m f1_macro: 0.3540125339717156
[2m[36m(func pid=141974)[0m f1_weighted: 0.37972894277665276
[2m[36m(func pid=141974)[0m f1_per_class: [0.265, 0.208, 0.88, 0.494, 0.087, 0.242, 0.45, 0.384, 0.211, 0.318]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 1.7391 | Steps: 2 | Val loss: 9.1927 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.0900 | Steps: 2 | Val loss: 3.5002 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
[2m[36m(func pid=141976)[0m top1: 0.20988805970149255
[2m[36m(func pid=141976)[0m top5: 0.6683768656716418
[2m[36m(func pid=141976)[0m f1_micro: 0.20988805970149255
[2m[36m(func pid=141976)[0m f1_macro: 0.15863218122397155
[2m[36m(func pid=141976)[0m f1_weighted: 0.2096982185964841
[2m[36m(func pid=141976)[0m f1_per_class: [0.017, 0.22, 0.072, 0.003, 0.077, 0.087, 0.441, 0.385, 0.119, 0.166]
== Status ==
Current time: 2024-01-07 03:10:45 (running for 00:46:46.08)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: 0.31925000000000003
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.092 |      0.354 |                   55 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.739 |      0.159 |                   56 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
| train_6ed81_00017 | TERMINATED | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.09  |      0.295 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=141974)[0m top1: 0.300839552238806
[2m[36m(func pid=141974)[0m top5: 0.8348880597014925
[2m[36m(func pid=141974)[0m f1_micro: 0.300839552238806
[2m[36m(func pid=141974)[0m f1_macro: 0.26765692063114044
[2m[36m(func pid=141974)[0m f1_weighted: 0.3200935457091907
[2m[36m(func pid=141974)[0m f1_per_class: [0.17, 0.118, 0.329, 0.386, 0.102, 0.287, 0.408, 0.393, 0.143, 0.341]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 1.8304 | Steps: 2 | Val loss: 7.1412 | Batch size: 32 | lr: 0.1 | Duration: 3.13s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.0610 | Steps: 2 | Val loss: 4.6478 | Batch size: 32 | lr: 0.01 | Duration: 3.12s
[2m[36m(func pid=141976)[0m top1: 0.20708955223880596
[2m[36m(func pid=141976)[0m top5: 0.6958955223880597
[2m[36m(func pid=141976)[0m f1_micro: 0.20708955223880596
[2m[36m(func pid=141976)[0m f1_macro: 0.16786071588160786
[2m[36m(func pid=141976)[0m f1_weighted: 0.2010115081421853
[2m[36m(func pid=141976)[0m f1_per_class: [0.049, 0.19, 0.074, 0.369, 0.105, 0.319, 0.015, 0.297, 0.087, 0.172]
[2m[36m(func pid=141976)[0m 
== Status ==
Current time: 2024-01-07 03:10:50 (running for 00:46:51.70)
Memory usage on this node: 19.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: 0.31925000000000003
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.09  |      0.268 |                   56 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.83  |      0.168 |                   57 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
| train_6ed81_00017 | TERMINATED | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.09  |      0.295 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141974)[0m top1: 0.24113805970149255
[2m[36m(func pid=141974)[0m top5: 0.7705223880597015
[2m[36m(func pid=141974)[0m f1_micro: 0.24113805970149255
[2m[36m(func pid=141974)[0m f1_macro: 0.22086739042743458
[2m[36m(func pid=141974)[0m f1_weighted: 0.2526458985537552
[2m[36m(func pid=141974)[0m f1_per_class: [0.116, 0.096, 0.189, 0.194, 0.122, 0.345, 0.362, 0.394, 0.132, 0.259]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 1.7162 | Steps: 2 | Val loss: 4.5233 | Batch size: 32 | lr: 0.1 | Duration: 2.99s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.0367 | Steps: 2 | Val loss: 4.7401 | Batch size: 32 | lr: 0.01 | Duration: 3.06s
[2m[36m(func pid=141976)[0m top1: 0.23740671641791045
[2m[36m(func pid=141976)[0m top5: 0.7098880597014925
[2m[36m(func pid=141976)[0m f1_micro: 0.23740671641791045
[2m[36m(func pid=141976)[0m f1_macro: 0.1728408150808322
[2m[36m(func pid=141976)[0m f1_weighted: 0.20903915118004193
[2m[36m(func pid=141976)[0m f1_per_class: [0.067, 0.152, 0.092, 0.453, 0.173, 0.258, 0.0, 0.33, 0.113, 0.091]
[2m[36m(func pid=141976)[0m 
== Status ==
Current time: 2024-01-07 03:10:56 (running for 00:46:57.19)
Memory usage on this node: 19.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: 0.31925000000000003
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.061 |      0.221 |                   57 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.716 |      0.173 |                   58 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
| train_6ed81_00017 | TERMINATED | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.09  |      0.295 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141974)[0m top1: 0.24720149253731344
[2m[36m(func pid=141974)[0m top5: 0.7625932835820896
[2m[36m(func pid=141974)[0m f1_micro: 0.24720149253731344
[2m[36m(func pid=141974)[0m f1_macro: 0.22874714002874671
[2m[36m(func pid=141974)[0m f1_weighted: 0.2643309832141019
[2m[36m(func pid=141974)[0m f1_per_class: [0.111, 0.249, 0.167, 0.166, 0.136, 0.354, 0.333, 0.418, 0.137, 0.216]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 1.6919 | Steps: 2 | Val loss: 3.1460 | Batch size: 32 | lr: 0.1 | Duration: 3.14s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.4081 | Steps: 2 | Val loss: 3.6341 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
== Status ==
Current time: 2024-01-07 03:11:01 (running for 00:47:02.69)
Memory usage on this node: 19.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: 0.31925000000000003
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.037 |      0.229 |                   58 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.716 |      0.173 |                   58 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
| train_6ed81_00017 | TERMINATED | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.09  |      0.295 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141976)[0m top1: 0.1958955223880597
[2m[36m(func pid=141976)[0m top5: 0.7527985074626866
[2m[36m(func pid=141976)[0m f1_micro: 0.19589552238805974
[2m[36m(func pid=141976)[0m f1_macro: 0.16356381291351296
[2m[36m(func pid=141976)[0m f1_weighted: 0.20680857942283876
[2m[36m(func pid=141976)[0m f1_per_class: [0.09, 0.087, 0.096, 0.367, 0.232, 0.024, 0.182, 0.448, 0.055, 0.055]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=141974)[0m top1: 0.2905783582089552
[2m[36m(func pid=141974)[0m top5: 0.8176305970149254
[2m[36m(func pid=141974)[0m f1_micro: 0.2905783582089552
[2m[36m(func pid=141974)[0m f1_macro: 0.22435969078643975
[2m[36m(func pid=141974)[0m f1_weighted: 0.32301122041156266
[2m[36m(func pid=141974)[0m f1_per_class: [0.15, 0.279, 0.145, 0.273, 0.106, 0.346, 0.464, 0.161, 0.153, 0.167]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 1.8434 | Steps: 2 | Val loss: 2.8730 | Batch size: 32 | lr: 0.1 | Duration: 3.12s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.0192 | Steps: 2 | Val loss: 3.3444 | Batch size: 32 | lr: 0.01 | Duration: 3.20s
== Status ==
Current time: 2024-01-07 03:11:07 (running for 00:47:08.04)
Memory usage on this node: 19.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: 0.31925000000000003
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.408 |      0.224 |                   59 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.692 |      0.164 |                   59 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
| train_6ed81_00017 | TERMINATED | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.09  |      0.295 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141976)[0m top1: 0.2798507462686567
[2m[36m(func pid=141976)[0m top5: 0.7887126865671642
[2m[36m(func pid=141976)[0m f1_micro: 0.2798507462686567
[2m[36m(func pid=141976)[0m f1_macro: 0.2118056886833187
[2m[36m(func pid=141976)[0m f1_weighted: 0.31896775936097616
[2m[36m(func pid=141976)[0m f1_per_class: [0.089, 0.181, 0.0, 0.292, 0.197, 0.097, 0.532, 0.491, 0.099, 0.139]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=141974)[0m top1: 0.3246268656716418
[2m[36m(func pid=141974)[0m top5: 0.8512126865671642
[2m[36m(func pid=141974)[0m f1_micro: 0.3246268656716418
[2m[36m(func pid=141974)[0m f1_macro: 0.22115561990123123
[2m[36m(func pid=141974)[0m f1_weighted: 0.35214085241710164
[2m[36m(func pid=141974)[0m f1_per_class: [0.234, 0.342, 0.144, 0.376, 0.07, 0.184, 0.515, 0.0, 0.181, 0.168]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 1.3101 | Steps: 2 | Val loss: 2.3124 | Batch size: 32 | lr: 0.1 | Duration: 3.09s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.1230 | Steps: 2 | Val loss: 3.1145 | Batch size: 32 | lr: 0.01 | Duration: 3.13s
== Status ==
Current time: 2024-01-07 03:11:12 (running for 00:47:13.74)
Memory usage on this node: 19.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: 0.31925000000000003
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.019 |      0.221 |                   60 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.843 |      0.212 |                   60 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
| train_6ed81_00017 | TERMINATED | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.09  |      0.295 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141976)[0m top1: 0.30736940298507465
[2m[36m(func pid=141976)[0m top5: 0.8381529850746269
[2m[36m(func pid=141976)[0m f1_micro: 0.30736940298507465
[2m[36m(func pid=141976)[0m f1_macro: 0.2705482662633188
[2m[36m(func pid=141976)[0m f1_weighted: 0.3470668734686677
[2m[36m(func pid=141976)[0m f1_per_class: [0.092, 0.159, 0.189, 0.342, 0.146, 0.197, 0.532, 0.509, 0.152, 0.386]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=141974)[0m top1: 0.2933768656716418
[2m[36m(func pid=141974)[0m top5: 0.8652052238805971
[2m[36m(func pid=141974)[0m f1_micro: 0.2933768656716418
[2m[36m(func pid=141974)[0m f1_macro: 0.23114925381652957
[2m[36m(func pid=141974)[0m f1_weighted: 0.3124734717242659
[2m[36m(func pid=141974)[0m f1_per_class: [0.282, 0.374, 0.164, 0.412, 0.08, 0.267, 0.291, 0.0, 0.155, 0.286]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 1.2462 | Steps: 2 | Val loss: 2.3249 | Batch size: 32 | lr: 0.1 | Duration: 3.13s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.1113 | Steps: 2 | Val loss: 3.5261 | Batch size: 32 | lr: 0.01 | Duration: 3.12s
== Status ==
Current time: 2024-01-07 03:11:18 (running for 00:47:19.33)
Memory usage on this node: 19.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: 0.31925000000000003
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.123 |      0.231 |                   61 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.31  |      0.271 |                   61 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
| train_6ed81_00017 | TERMINATED | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.09  |      0.295 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141976)[0m top1: 0.31763059701492535
[2m[36m(func pid=141976)[0m top5: 0.8409514925373134
[2m[36m(func pid=141976)[0m f1_micro: 0.31763059701492535
[2m[36m(func pid=141976)[0m f1_macro: 0.28561523899047997
[2m[36m(func pid=141976)[0m f1_weighted: 0.3568028594335707
[2m[36m(func pid=141976)[0m f1_per_class: [0.102, 0.168, 0.189, 0.401, 0.19, 0.27, 0.481, 0.481, 0.117, 0.456]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=141974)[0m top1: 0.24813432835820895
[2m[36m(func pid=141974)[0m top5: 0.8260261194029851
[2m[36m(func pid=141974)[0m f1_micro: 0.24813432835820895
[2m[36m(func pid=141974)[0m f1_macro: 0.2058914621517549
[2m[36m(func pid=141974)[0m f1_weighted: 0.2523323104095972
[2m[36m(func pid=141974)[0m f1_per_class: [0.231, 0.343, 0.194, 0.411, 0.066, 0.4, 0.062, 0.031, 0.108, 0.213]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 1.1696 | Steps: 2 | Val loss: 2.2007 | Batch size: 32 | lr: 0.1 | Duration: 3.07s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.2606 | Steps: 2 | Val loss: 3.5519 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
== Status ==
Current time: 2024-01-07 03:11:24 (running for 00:47:24.90)
Memory usage on this node: 19.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: 0.31925000000000003
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.111 |      0.206 |                   62 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.246 |      0.286 |                   62 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
| train_6ed81_00017 | TERMINATED | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.09  |      0.295 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141976)[0m top1: 0.3628731343283582
[2m[36m(func pid=141976)[0m top5: 0.8456156716417911
[2m[36m(func pid=141976)[0m f1_micro: 0.3628731343283582
[2m[36m(func pid=141976)[0m f1_macro: 0.2810087450405175
[2m[36m(func pid=141976)[0m f1_weighted: 0.37599131823805576
[2m[36m(func pid=141976)[0m f1_per_class: [0.108, 0.037, 0.207, 0.435, 0.169, 0.359, 0.565, 0.447, 0.125, 0.358]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=141974)[0m top1: 0.27472014925373134
[2m[36m(func pid=141974)[0m top5: 0.7975746268656716
[2m[36m(func pid=141974)[0m f1_micro: 0.27472014925373134
[2m[36m(func pid=141974)[0m f1_macro: 0.21996283049693868
[2m[36m(func pid=141974)[0m f1_weighted: 0.2744969047362007
[2m[36m(func pid=141974)[0m f1_per_class: [0.166, 0.383, 0.238, 0.47, 0.098, 0.418, 0.042, 0.098, 0.12, 0.167]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 1.1326 | Steps: 2 | Val loss: 2.1101 | Batch size: 32 | lr: 0.1 | Duration: 3.07s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.0273 | Steps: 2 | Val loss: 5.2929 | Batch size: 32 | lr: 0.01 | Duration: 3.06s
== Status ==
Current time: 2024-01-07 03:11:29 (running for 00:47:30.43)
Memory usage on this node: 19.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: 0.31925000000000003
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.261 |      0.22  |                   63 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.17  |      0.281 |                   63 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
| train_6ed81_00017 | TERMINATED | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.09  |      0.295 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141976)[0m top1: 0.404384328358209
[2m[36m(func pid=141976)[0m top5: 0.8521455223880597
[2m[36m(func pid=141976)[0m f1_micro: 0.404384328358209
[2m[36m(func pid=141976)[0m f1_macro: 0.3049838702574169
[2m[36m(func pid=141976)[0m f1_weighted: 0.41217221347294136
[2m[36m(func pid=141976)[0m f1_per_class: [0.118, 0.102, 0.242, 0.465, 0.2, 0.429, 0.585, 0.486, 0.137, 0.286]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=141974)[0m top1: 0.14365671641791045
[2m[36m(func pid=141974)[0m top5: 0.7075559701492538
[2m[36m(func pid=141974)[0m f1_micro: 0.14365671641791045
[2m[36m(func pid=141974)[0m f1_macro: 0.18065327826652727
[2m[36m(func pid=141974)[0m f1_weighted: 0.1429884612142924
[2m[36m(func pid=141974)[0m f1_per_class: [0.074, 0.289, 0.415, 0.086, 0.135, 0.262, 0.048, 0.245, 0.136, 0.117]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 1.1657 | Steps: 2 | Val loss: 2.1301 | Batch size: 32 | lr: 0.1 | Duration: 3.05s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.1752 | Steps: 2 | Val loss: 5.5473 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
== Status ==
Current time: 2024-01-07 03:11:34 (running for 00:47:35.81)
Memory usage on this node: 19.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: 0.31925000000000003
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.027 |      0.181 |                   64 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.133 |      0.305 |                   64 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
| train_6ed81_00017 | TERMINATED | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.09  |      0.295 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141976)[0m top1: 0.40951492537313433
[2m[36m(func pid=141976)[0m top5: 0.8502798507462687
[2m[36m(func pid=141976)[0m f1_micro: 0.40951492537313433
[2m[36m(func pid=141976)[0m f1_macro: 0.2974436047732821
[2m[36m(func pid=141976)[0m f1_weighted: 0.41255202075108305
[2m[36m(func pid=141976)[0m f1_per_class: [0.072, 0.117, 0.269, 0.53, 0.28, 0.381, 0.55, 0.442, 0.111, 0.222]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=141974)[0m top1: 0.19076492537313433
[2m[36m(func pid=141974)[0m top5: 0.7611940298507462
[2m[36m(func pid=141974)[0m f1_micro: 0.19076492537313436
[2m[36m(func pid=141974)[0m f1_macro: 0.26617832956737725
[2m[36m(func pid=141974)[0m f1_weighted: 0.1985582902532029
[2m[36m(func pid=141974)[0m f1_per_class: [0.077, 0.276, 0.71, 0.065, 0.165, 0.321, 0.197, 0.351, 0.2, 0.3]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 1.0689 | Steps: 2 | Val loss: 2.2335 | Batch size: 32 | lr: 0.1 | Duration: 3.14s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.1942 | Steps: 2 | Val loss: 4.4746 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
== Status ==
Current time: 2024-01-07 03:11:40 (running for 00:47:41.54)
Memory usage on this node: 19.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: 0.31925000000000003
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.175 |      0.266 |                   65 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.166 |      0.297 |                   65 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
| train_6ed81_00017 | TERMINATED | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.09  |      0.295 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141976)[0m top1: 0.4118470149253731
[2m[36m(func pid=141976)[0m top5: 0.8493470149253731
[2m[36m(func pid=141976)[0m f1_micro: 0.4118470149253731
[2m[36m(func pid=141976)[0m f1_macro: 0.3003494291893706
[2m[36m(func pid=141976)[0m f1_weighted: 0.4054109376699368
[2m[36m(func pid=141976)[0m f1_per_class: [0.126, 0.112, 0.341, 0.485, 0.208, 0.319, 0.606, 0.327, 0.15, 0.33]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=141974)[0m top1: 0.2248134328358209
[2m[36m(func pid=141974)[0m top5: 0.8222947761194029
[2m[36m(func pid=141974)[0m f1_micro: 0.2248134328358209
[2m[36m(func pid=141974)[0m f1_macro: 0.2955099289218064
[2m[36m(func pid=141974)[0m f1_weighted: 0.24650919773993432
[2m[36m(func pid=141974)[0m f1_per_class: [0.082, 0.29, 0.786, 0.1, 0.103, 0.367, 0.295, 0.359, 0.192, 0.381]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 1.2399 | Steps: 2 | Val loss: 2.2914 | Batch size: 32 | lr: 0.1 | Duration: 3.15s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.0345 | Steps: 2 | Val loss: 3.4323 | Batch size: 32 | lr: 0.01 | Duration: 3.18s
== Status ==
Current time: 2024-01-07 03:11:46 (running for 00:47:47.11)
Memory usage on this node: 19.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: 0.31925000000000003
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.194 |      0.296 |                   66 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.069 |      0.3   |                   66 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
| train_6ed81_00017 | TERMINATED | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.09  |      0.295 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141976)[0m top1: 0.3614738805970149
[2m[36m(func pid=141976)[0m top5: 0.8540111940298507
[2m[36m(func pid=141976)[0m f1_micro: 0.3614738805970149
[2m[36m(func pid=141976)[0m f1_macro: 0.31273430138692704
[2m[36m(func pid=141976)[0m f1_weighted: 0.37717312343971265
[2m[36m(func pid=141976)[0m f1_per_class: [0.109, 0.096, 0.4, 0.459, 0.105, 0.394, 0.48, 0.502, 0.151, 0.431]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=141974)[0m top1: 0.2728544776119403
[2m[36m(func pid=141974)[0m top5: 0.8596082089552238
[2m[36m(func pid=141974)[0m f1_micro: 0.2728544776119403
[2m[36m(func pid=141974)[0m f1_macro: 0.30427500875018193
[2m[36m(func pid=141974)[0m f1_weighted: 0.3100134231529067
[2m[36m(func pid=141974)[0m f1_per_class: [0.111, 0.17, 0.71, 0.317, 0.077, 0.357, 0.387, 0.335, 0.129, 0.45]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 1.4771 | Steps: 2 | Val loss: 2.4722 | Batch size: 32 | lr: 0.1 | Duration: 3.03s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.0162 | Steps: 2 | Val loss: 3.0875 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
== Status ==
Current time: 2024-01-07 03:11:52 (running for 00:47:52.88)
Memory usage on this node: 19.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: 0.31925000000000003
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.035 |      0.304 |                   67 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.24  |      0.313 |                   67 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
| train_6ed81_00017 | TERMINATED | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.09  |      0.295 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141976)[0m top1: 0.27098880597014924
[2m[36m(func pid=141976)[0m top5: 0.8409514925373134
[2m[36m(func pid=141976)[0m f1_micro: 0.27098880597014924
[2m[36m(func pid=141976)[0m f1_macro: 0.2543365018552574
[2m[36m(func pid=141976)[0m f1_weighted: 0.2434085914351408
[2m[36m(func pid=141976)[0m f1_per_class: [0.101, 0.119, 0.419, 0.447, 0.108, 0.386, 0.057, 0.385, 0.155, 0.366]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=141974)[0m top1: 0.3474813432835821
[2m[36m(func pid=141974)[0m top5: 0.8754664179104478
[2m[36m(func pid=141974)[0m f1_micro: 0.3474813432835821
[2m[36m(func pid=141974)[0m f1_macro: 0.3343386093674602
[2m[36m(func pid=141974)[0m f1_weighted: 0.37678464897443553
[2m[36m(func pid=141974)[0m f1_per_class: [0.19, 0.156, 0.706, 0.487, 0.072, 0.355, 0.46, 0.305, 0.139, 0.474]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 1.0060 | Steps: 2 | Val loss: 2.6850 | Batch size: 32 | lr: 0.1 | Duration: 3.15s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.0502 | Steps: 2 | Val loss: 3.0162 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
== Status ==
Current time: 2024-01-07 03:11:57 (running for 00:47:58.34)
Memory usage on this node: 19.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: 0.31925000000000003
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.016 |      0.334 |                   68 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.477 |      0.254 |                   68 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
| train_6ed81_00017 | TERMINATED | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.09  |      0.295 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141976)[0m top1: 0.23227611940298507
[2m[36m(func pid=141976)[0m top5: 0.8572761194029851
[2m[36m(func pid=141976)[0m f1_micro: 0.23227611940298507
[2m[36m(func pid=141976)[0m f1_macro: 0.21676144337413636
[2m[36m(func pid=141976)[0m f1_weighted: 0.2149642045070321
[2m[36m(func pid=141976)[0m f1_per_class: [0.094, 0.251, 0.39, 0.365, 0.091, 0.238, 0.042, 0.29, 0.172, 0.234]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=141974)[0m top1: 0.37033582089552236
[2m[36m(func pid=141974)[0m top5: 0.882929104477612
[2m[36m(func pid=141974)[0m f1_micro: 0.37033582089552236
[2m[36m(func pid=141974)[0m f1_macro: 0.3312668225256303
[2m[36m(func pid=141974)[0m f1_weighted: 0.3888651252747642
[2m[36m(func pid=141974)[0m f1_per_class: [0.264, 0.121, 0.667, 0.546, 0.064, 0.351, 0.473, 0.251, 0.154, 0.421]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 1.0300 | Steps: 2 | Val loss: 2.4535 | Batch size: 32 | lr: 0.1 | Duration: 3.25s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.1531 | Steps: 2 | Val loss: 2.8145 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
== Status ==
Current time: 2024-01-07 03:12:03 (running for 00:48:03.97)
Memory usage on this node: 19.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: 0.31925000000000003
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.05  |      0.331 |                   69 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.006 |      0.217 |                   69 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
| train_6ed81_00017 | TERMINATED | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.09  |      0.295 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141976)[0m top1: 0.3041044776119403
[2m[36m(func pid=141976)[0m top5: 0.8642723880597015
[2m[36m(func pid=141976)[0m f1_micro: 0.3041044776119403
[2m[36m(func pid=141976)[0m f1_macro: 0.2706047907247859
[2m[36m(func pid=141976)[0m f1_weighted: 0.3279817873311652
[2m[36m(func pid=141976)[0m f1_per_class: [0.091, 0.343, 0.381, 0.365, 0.133, 0.223, 0.347, 0.455, 0.123, 0.246]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=141974)[0m top1: 0.3628731343283582
[2m[36m(func pid=141974)[0m top5: 0.8913246268656716
[2m[36m(func pid=141974)[0m f1_micro: 0.3628731343283582
[2m[36m(func pid=141974)[0m f1_macro: 0.3262491017333054
[2m[36m(func pid=141974)[0m f1_weighted: 0.3677592398604167
[2m[36m(func pid=141974)[0m f1_per_class: [0.252, 0.121, 0.688, 0.582, 0.066, 0.33, 0.385, 0.192, 0.168, 0.478]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.0206 | Steps: 2 | Val loss: 2.9912 | Batch size: 32 | lr: 0.01 | Duration: 3.08s
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 1.3025 | Steps: 2 | Val loss: 2.2578 | Batch size: 32 | lr: 0.1 | Duration: 3.16s
== Status ==
Current time: 2024-01-07 03:12:08 (running for 00:48:09.38)
Memory usage on this node: 19.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: 0.31925000000000003
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.153 |      0.326 |                   70 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.03  |      0.271 |                   70 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
| train_6ed81_00017 | TERMINATED | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.09  |      0.295 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141976)[0m top1: 0.39225746268656714
[2m[36m(func pid=141976)[0m top5: 0.8819962686567164
[2m[36m(func pid=141976)[0m f1_micro: 0.39225746268656714
[2m[36m(func pid=141976)[0m f1_macro: 0.28594032159237015
[2m[36m(func pid=141976)[0m f1_weighted: 0.40060990836665183
[2m[36m(func pid=141976)[0m f1_per_class: [0.093, 0.323, 0.364, 0.43, 0.2, 0.285, 0.591, 0.016, 0.158, 0.4]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=141974)[0m top1: 0.34375
[2m[36m(func pid=141974)[0m top5: 0.8941231343283582
[2m[36m(func pid=141974)[0m f1_micro: 0.34375
[2m[36m(func pid=141974)[0m f1_macro: 0.30539586126479523
[2m[36m(func pid=141974)[0m f1_weighted: 0.3407024654639656
[2m[36m(func pid=141974)[0m f1_per_class: [0.268, 0.193, 0.667, 0.57, 0.071, 0.308, 0.29, 0.083, 0.242, 0.364]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.0542 | Steps: 2 | Val loss: 2.9488 | Batch size: 32 | lr: 0.01 | Duration: 3.15s
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 1.7971 | Steps: 2 | Val loss: 2.2744 | Batch size: 32 | lr: 0.1 | Duration: 3.26s
== Status ==
Current time: 2024-01-07 03:12:14 (running for 00:48:14.98)
Memory usage on this node: 19.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: 0.31925000000000003
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.021 |      0.305 |                   71 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.303 |      0.286 |                   71 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
| train_6ed81_00017 | TERMINATED | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.09  |      0.295 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141976)[0m top1: 0.3316231343283582
[2m[36m(func pid=141976)[0m top5: 0.871268656716418
[2m[36m(func pid=141976)[0m f1_micro: 0.3316231343283582
[2m[36m(func pid=141976)[0m f1_macro: 0.2739136372292033
[2m[36m(func pid=141976)[0m f1_weighted: 0.3587575542470365
[2m[36m(func pid=141976)[0m f1_per_class: [0.098, 0.199, 0.471, 0.415, 0.101, 0.305, 0.521, 0.071, 0.113, 0.444]
[2m[36m(func pid=141974)[0m top1: 0.35261194029850745
[2m[36m(func pid=141974)[0m top5: 0.8950559701492538
[2m[36m(func pid=141974)[0m f1_micro: 0.35261194029850745
[2m[36m(func pid=141974)[0m f1_macro: 0.30620270034811736
[2m[36m(func pid=141974)[0m f1_weighted: 0.3526709024289888
[2m[36m(func pid=141974)[0m f1_per_class: [0.242, 0.342, 0.649, 0.558, 0.07, 0.306, 0.267, 0.043, 0.232, 0.355]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 1.1682 | Steps: 2 | Val loss: 2.4643 | Batch size: 32 | lr: 0.1 | Duration: 3.16s
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.0431 | Steps: 2 | Val loss: 2.6709 | Batch size: 32 | lr: 0.01 | Duration: 3.34s
== Status ==
Current time: 2024-01-07 03:12:19 (running for 00:48:20.67)
Memory usage on this node: 19.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: 0.31925000000000003
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.054 |      0.306 |                   72 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.797 |      0.274 |                   72 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
| train_6ed81_00017 | TERMINATED | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.09  |      0.295 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141976)[0m top1: 0.283115671641791
[2m[36m(func pid=141976)[0m top5: 0.8661380597014925
[2m[36m(func pid=141976)[0m f1_micro: 0.283115671641791
[2m[36m(func pid=141976)[0m f1_macro: 0.2532373820861538
[2m[36m(func pid=141976)[0m f1_weighted: 0.3130093219118967
[2m[36m(func pid=141976)[0m f1_per_class: [0.115, 0.152, 0.0, 0.297, 0.073, 0.398, 0.397, 0.466, 0.144, 0.491]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=141974)[0m top1: 0.3675373134328358
[2m[36m(func pid=141974)[0m top5: 0.8987873134328358
[2m[36m(func pid=141974)[0m f1_micro: 0.36753731343283574
[2m[36m(func pid=141974)[0m f1_macro: 0.3225675366519471
[2m[36m(func pid=141974)[0m f1_weighted: 0.37532167251333115
[2m[36m(func pid=141974)[0m f1_per_class: [0.234, 0.425, 0.649, 0.547, 0.082, 0.31, 0.29, 0.101, 0.258, 0.329]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.0369 | Steps: 2 | Val loss: 2.5148 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 1.1700 | Steps: 2 | Val loss: 2.5433 | Batch size: 32 | lr: 0.1 | Duration: 3.11s
== Status ==
Current time: 2024-01-07 03:12:25 (running for 00:48:26.45)
Memory usage on this node: 19.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: 0.31925000000000003
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.043 |      0.323 |                   73 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.168 |      0.253 |                   73 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
| train_6ed81_00017 | TERMINATED | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.09  |      0.295 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141974)[0m top1: 0.3833955223880597
[2m[36m(func pid=141974)[0m top5: 0.8950559701492538
[2m[36m(func pid=141974)[0m f1_micro: 0.3833955223880597
[2m[36m(func pid=141974)[0m f1_macro: 0.32986588748510387
[2m[36m(func pid=141974)[0m f1_weighted: 0.3991869131589614
[2m[36m(func pid=141974)[0m f1_per_class: [0.269, 0.419, 0.615, 0.538, 0.067, 0.337, 0.373, 0.107, 0.228, 0.347]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141976)[0m top1: 0.2719216417910448
[2m[36m(func pid=141976)[0m top5: 0.8596082089552238
[2m[36m(func pid=141976)[0m f1_micro: 0.2719216417910448
[2m[36m(func pid=141976)[0m f1_macro: 0.2385893525845741
[2m[36m(func pid=141976)[0m f1_weighted: 0.2910498950450658
[2m[36m(func pid=141976)[0m f1_per_class: [0.112, 0.214, 0.111, 0.316, 0.085, 0.366, 0.293, 0.46, 0.076, 0.353]
[2m[36m(func pid=141976)[0m 
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.0031 | Steps: 2 | Val loss: 2.4354 | Batch size: 32 | lr: 0.01 | Duration: 3.10s
[2m[36m(func pid=141976)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 1.1848 | Steps: 2 | Val loss: 2.6989 | Batch size: 32 | lr: 0.1 | Duration: 3.06s
== Status ==
Current time: 2024-01-07 03:12:31 (running for 00:48:32.04)
Memory usage on this node: 19.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: 0.31925000000000003
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.037 |      0.33  |                   74 |
| train_6ed81_00023 | RUNNING    | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.17  |      0.239 |                   74 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
| train_6ed81_00017 | TERMINATED | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.09  |      0.295 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141974)[0m top1: 0.3941231343283582
[2m[36m(func pid=141974)[0m top5: 0.8964552238805971
[2m[36m(func pid=141974)[0m f1_micro: 0.3941231343283582
[2m[36m(func pid=141974)[0m f1_macro: 0.3415575506166869
[2m[36m(func pid=141974)[0m f1_weighted: 0.4153716185692466
[2m[36m(func pid=141974)[0m f1_per_class: [0.276, 0.388, 0.571, 0.533, 0.077, 0.331, 0.426, 0.229, 0.251, 0.333]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141976)[0m top1: 0.2887126865671642
[2m[36m(func pid=141976)[0m top5: 0.8498134328358209
[2m[36m(func pid=141976)[0m f1_micro: 0.2887126865671642
[2m[36m(func pid=141976)[0m f1_macro: 0.2526042583785108
[2m[36m(func pid=141976)[0m f1_weighted: 0.31534650922517626
[2m[36m(func pid=141976)[0m f1_per_class: [0.105, 0.298, 0.356, 0.325, 0.0, 0.172, 0.381, 0.519, 0.064, 0.306]
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 75] | Train loss: 0.0145 | Steps: 2 | Val loss: 2.4509 | Batch size: 32 | lr: 0.01 | Duration: 3.06s
== Status ==
Current time: 2024-01-07 03:12:36 (running for 00:48:37.59)
Memory usage on this node: 16.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: 0.32175
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.003 |      0.342 |                   75 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
| train_6ed81_00017 | TERMINATED | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.09  |      0.295 |                   75 |
| train_6ed81_00018 | TERMINATED | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.852 |      0.203 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141974)[0m top1: 0.39365671641791045
[2m[36m(func pid=141974)[0m top5: 0.9020522388059702
[2m[36m(func pid=141974)[0m f1_micro: 0.3936567164179104
[2m[36m(func pid=141974)[0m f1_macro: 0.34862686511332436
[2m[36m(func pid=141974)[0m f1_weighted: 0.4196173677967609
[2m[36m(func pid=141974)[0m f1_per_class: [0.321, 0.36, 0.585, 0.529, 0.08, 0.298, 0.466, 0.262, 0.205, 0.38]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 76] | Train loss: 0.0060 | Steps: 2 | Val loss: 2.5200 | Batch size: 32 | lr: 0.01 | Duration: 3.12s
== Status ==
Current time: 2024-01-07 03:12:42 (running for 00:48:42.97)
Memory usage on this node: 16.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: 0.32175
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.015 |      0.349 |                   76 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
| train_6ed81_00017 | TERMINATED | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.09  |      0.295 |                   75 |
| train_6ed81_00018 | TERMINATED | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.852 |      0.203 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141974)[0m top1: 0.384794776119403
[2m[36m(func pid=141974)[0m top5: 0.9015858208955224
[2m[36m(func pid=141974)[0m f1_micro: 0.384794776119403
[2m[36m(func pid=141974)[0m f1_macro: 0.33610826403883587
[2m[36m(func pid=141974)[0m f1_weighted: 0.4116410075577655
[2m[36m(func pid=141974)[0m f1_per_class: [0.337, 0.323, 0.558, 0.528, 0.067, 0.224, 0.486, 0.286, 0.209, 0.343]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 77] | Train loss: 0.0082 | Steps: 2 | Val loss: 2.5892 | Batch size: 32 | lr: 0.01 | Duration: 3.24s
== Status ==
Current time: 2024-01-07 03:12:47 (running for 00:48:48.74)
Memory usage on this node: 16.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: 0.32175
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.006 |      0.336 |                   77 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
| train_6ed81_00017 | TERMINATED | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.09  |      0.295 |                   75 |
| train_6ed81_00018 | TERMINATED | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.852 |      0.203 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141974)[0m top1: 0.38619402985074625
[2m[36m(func pid=141974)[0m top5: 0.8969216417910447
[2m[36m(func pid=141974)[0m f1_micro: 0.3861940298507463
[2m[36m(func pid=141974)[0m f1_macro: 0.33692095317556625
[2m[36m(func pid=141974)[0m f1_weighted: 0.41315690739876426
[2m[36m(func pid=141974)[0m f1_per_class: [0.34, 0.316, 0.545, 0.533, 0.068, 0.232, 0.488, 0.29, 0.198, 0.358]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 78] | Train loss: 0.0210 | Steps: 2 | Val loss: 2.6189 | Batch size: 32 | lr: 0.01 | Duration: 3.18s
== Status ==
Current time: 2024-01-07 03:12:53 (running for 00:48:54.42)
Memory usage on this node: 16.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: 0.32175
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.008 |      0.337 |                   78 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
| train_6ed81_00017 | TERMINATED | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.09  |      0.295 |                   75 |
| train_6ed81_00018 | TERMINATED | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.852 |      0.203 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141974)[0m top1: 0.38526119402985076
[2m[36m(func pid=141974)[0m top5: 0.8955223880597015
[2m[36m(func pid=141974)[0m f1_micro: 0.38526119402985076
[2m[36m(func pid=141974)[0m f1_macro: 0.33926818130841047
[2m[36m(func pid=141974)[0m f1_weighted: 0.41125981629092456
[2m[36m(func pid=141974)[0m f1_per_class: [0.333, 0.324, 0.585, 0.53, 0.074, 0.225, 0.483, 0.285, 0.195, 0.358]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 79] | Train loss: 0.0090 | Steps: 2 | Val loss: 2.6578 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
== Status ==
Current time: 2024-01-07 03:12:59 (running for 00:49:00.15)
Memory usage on this node: 16.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: 0.32175
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.021 |      0.339 |                   79 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
| train_6ed81_00017 | TERMINATED | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.09  |      0.295 |                   75 |
| train_6ed81_00018 | TERMINATED | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.852 |      0.203 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141974)[0m top1: 0.3763992537313433
[2m[36m(func pid=141974)[0m top5: 0.894589552238806
[2m[36m(func pid=141974)[0m f1_micro: 0.3763992537313433
[2m[36m(func pid=141974)[0m f1_macro: 0.34050215261578953
[2m[36m(func pid=141974)[0m f1_weighted: 0.4042974287532561
[2m[36m(func pid=141974)[0m f1_per_class: [0.336, 0.315, 0.585, 0.518, 0.08, 0.239, 0.468, 0.285, 0.203, 0.375]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 80] | Train loss: 0.0302 | Steps: 2 | Val loss: 2.6677 | Batch size: 32 | lr: 0.01 | Duration: 3.17s
== Status ==
Current time: 2024-01-07 03:13:04 (running for 00:49:05.72)
Memory usage on this node: 16.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: 0.32175
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.009 |      0.341 |                   80 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
| train_6ed81_00017 | TERMINATED | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.09  |      0.295 |                   75 |
| train_6ed81_00018 | TERMINATED | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.852 |      0.203 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141974)[0m top1: 0.3656716417910448
[2m[36m(func pid=141974)[0m top5: 0.8875932835820896
[2m[36m(func pid=141974)[0m f1_micro: 0.3656716417910448
[2m[36m(func pid=141974)[0m f1_macro: 0.32364677192017915
[2m[36m(func pid=141974)[0m f1_weighted: 0.3935537825014365
[2m[36m(func pid=141974)[0m f1_per_class: [0.292, 0.306, 0.533, 0.513, 0.082, 0.253, 0.445, 0.281, 0.186, 0.345]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 81] | Train loss: 0.0060 | Steps: 2 | Val loss: 2.7107 | Batch size: 32 | lr: 0.01 | Duration: 3.06s
== Status ==
Current time: 2024-01-07 03:13:10 (running for 00:49:11.51)
Memory usage on this node: 16.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: 0.32175
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.03  |      0.324 |                   81 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
| train_6ed81_00017 | TERMINATED | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.09  |      0.295 |                   75 |
| train_6ed81_00018 | TERMINATED | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.852 |      0.203 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141974)[0m top1: 0.35774253731343286
[2m[36m(func pid=141974)[0m top5: 0.8889925373134329
[2m[36m(func pid=141974)[0m f1_micro: 0.35774253731343286
[2m[36m(func pid=141974)[0m f1_macro: 0.31659166401274486
[2m[36m(func pid=141974)[0m f1_weighted: 0.38416677611894623
[2m[36m(func pid=141974)[0m f1_per_class: [0.267, 0.306, 0.5, 0.511, 0.084, 0.265, 0.415, 0.274, 0.181, 0.364]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 82] | Train loss: 0.0081 | Steps: 2 | Val loss: 2.7595 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
== Status ==
Current time: 2024-01-07 03:13:16 (running for 00:49:17.19)
Memory usage on this node: 16.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: 0.32175
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.006 |      0.317 |                   82 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
| train_6ed81_00017 | TERMINATED | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.09  |      0.295 |                   75 |
| train_6ed81_00018 | TERMINATED | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.852 |      0.203 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141974)[0m top1: 0.3568097014925373
[2m[36m(func pid=141974)[0m top5: 0.8880597014925373
[2m[36m(func pid=141974)[0m f1_micro: 0.3568097014925374
[2m[36m(func pid=141974)[0m f1_macro: 0.3204596706451212
[2m[36m(func pid=141974)[0m f1_weighted: 0.3804592461542956
[2m[36m(func pid=141974)[0m f1_per_class: [0.282, 0.3, 0.5, 0.508, 0.089, 0.296, 0.394, 0.266, 0.206, 0.364]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 83] | Train loss: 0.0537 | Steps: 2 | Val loss: 2.8476 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 03:13:22 (running for 00:49:23.16)
Memory usage on this node: 16.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: 0.32175
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.008 |      0.32  |                   83 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
| train_6ed81_00017 | TERMINATED | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.09  |      0.295 |                   75 |
| train_6ed81_00018 | TERMINATED | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.852 |      0.203 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141974)[0m top1: 0.34794776119402987
[2m[36m(func pid=141974)[0m top5: 0.8871268656716418
[2m[36m(func pid=141974)[0m f1_micro: 0.34794776119402987
[2m[36m(func pid=141974)[0m f1_macro: 0.3281828571177929
[2m[36m(func pid=141974)[0m f1_weighted: 0.37253758579807905
[2m[36m(func pid=141974)[0m f1_per_class: [0.23, 0.321, 0.595, 0.491, 0.096, 0.304, 0.373, 0.231, 0.207, 0.433]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 84] | Train loss: 0.0083 | Steps: 2 | Val loss: 3.0275 | Batch size: 32 | lr: 0.01 | Duration: 3.06s
== Status ==
Current time: 2024-01-07 03:13:27 (running for 00:49:28.48)
Memory usage on this node: 16.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: 0.32175
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.054 |      0.328 |                   84 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
| train_6ed81_00017 | TERMINATED | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.09  |      0.295 |                   75 |
| train_6ed81_00018 | TERMINATED | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.852 |      0.203 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141974)[0m top1: 0.33302238805970147
[2m[36m(func pid=141974)[0m top5: 0.8847947761194029
[2m[36m(func pid=141974)[0m f1_micro: 0.33302238805970147
[2m[36m(func pid=141974)[0m f1_macro: 0.3402686755686687
[2m[36m(func pid=141974)[0m f1_weighted: 0.360731411954138
[2m[36m(func pid=141974)[0m f1_per_class: [0.194, 0.309, 0.75, 0.454, 0.101, 0.337, 0.361, 0.228, 0.212, 0.456]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 85] | Train loss: 0.0416 | Steps: 2 | Val loss: 3.2667 | Batch size: 32 | lr: 0.01 | Duration: 3.07s
== Status ==
Current time: 2024-01-07 03:13:33 (running for 00:49:34.16)
Memory usage on this node: 16.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: 0.32175
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.008 |      0.34  |                   85 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
| train_6ed81_00017 | TERMINATED | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.09  |      0.295 |                   75 |
| train_6ed81_00018 | TERMINATED | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.852 |      0.203 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141974)[0m top1: 0.3045708955223881
[2m[36m(func pid=141974)[0m top5: 0.8791977611940298
[2m[36m(func pid=141974)[0m f1_micro: 0.3045708955223881
[2m[36m(func pid=141974)[0m f1_macro: 0.3252163250366357
[2m[36m(func pid=141974)[0m f1_weighted: 0.3403792968343187
[2m[36m(func pid=141974)[0m f1_per_class: [0.168, 0.316, 0.632, 0.419, 0.086, 0.289, 0.341, 0.207, 0.24, 0.553]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 86] | Train loss: 0.0421 | Steps: 2 | Val loss: 3.3049 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
== Status ==
Current time: 2024-01-07 03:13:38 (running for 00:49:39.72)
Memory usage on this node: 16.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: 0.32175
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.042 |      0.325 |                   86 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
| train_6ed81_00017 | TERMINATED | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.09  |      0.295 |                   75 |
| train_6ed81_00018 | TERMINATED | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.852 |      0.203 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141974)[0m top1: 0.29384328358208955
[2m[36m(func pid=141974)[0m top5: 0.8773320895522388
[2m[36m(func pid=141974)[0m f1_micro: 0.29384328358208955
[2m[36m(func pid=141974)[0m f1_macro: 0.3030574663831409
[2m[36m(func pid=141974)[0m f1_weighted: 0.3333436444912109
[2m[36m(func pid=141974)[0m f1_per_class: [0.157, 0.327, 0.471, 0.404, 0.071, 0.267, 0.339, 0.204, 0.249, 0.542]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 87] | Train loss: 0.1178 | Steps: 2 | Val loss: 2.9344 | Batch size: 32 | lr: 0.01 | Duration: 3.24s
== Status ==
Current time: 2024-01-07 03:13:44 (running for 00:49:45.47)
Memory usage on this node: 16.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: 0.32175
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.042 |      0.303 |                   87 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
| train_6ed81_00017 | TERMINATED | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.09  |      0.295 |                   75 |
| train_6ed81_00018 | TERMINATED | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.852 |      0.203 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141974)[0m top1: 0.3292910447761194
[2m[36m(func pid=141974)[0m top5: 0.8852611940298507
[2m[36m(func pid=141974)[0m f1_micro: 0.3292910447761194
[2m[36m(func pid=141974)[0m f1_macro: 0.33230885833193025
[2m[36m(func pid=141974)[0m f1_weighted: 0.3623361315620637
[2m[36m(func pid=141974)[0m f1_per_class: [0.209, 0.363, 0.636, 0.475, 0.063, 0.254, 0.347, 0.22, 0.226, 0.531]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 88] | Train loss: 0.0442 | Steps: 2 | Val loss: 2.6604 | Batch size: 32 | lr: 0.01 | Duration: 3.03s
== Status ==
Current time: 2024-01-07 03:13:50 (running for 00:49:51.37)
Memory usage on this node: 16.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: 0.32175
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.118 |      0.332 |                   88 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
| train_6ed81_00017 | TERMINATED | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.09  |      0.295 |                   75 |
| train_6ed81_00018 | TERMINATED | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.852 |      0.203 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141974)[0m top1: 0.37220149253731344
[2m[36m(func pid=141974)[0m top5: 0.8913246268656716
[2m[36m(func pid=141974)[0m f1_micro: 0.3722014925373134
[2m[36m(func pid=141974)[0m f1_macro: 0.3598514213228459
[2m[36m(func pid=141974)[0m f1_weighted: 0.3929804270174627
[2m[36m(func pid=141974)[0m f1_per_class: [0.284, 0.37, 0.769, 0.501, 0.02, 0.346, 0.378, 0.235, 0.234, 0.462]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 89] | Train loss: 0.0355 | Steps: 2 | Val loss: 2.6482 | Batch size: 32 | lr: 0.01 | Duration: 3.07s
== Status ==
Current time: 2024-01-07 03:13:56 (running for 00:49:56.83)
Memory usage on this node: 16.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: 0.32175
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.044 |      0.36  |                   89 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
| train_6ed81_00017 | TERMINATED | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.09  |      0.295 |                   75 |
| train_6ed81_00018 | TERMINATED | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.852 |      0.203 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141974)[0m top1: 0.3572761194029851
[2m[36m(func pid=141974)[0m top5: 0.8969216417910447
[2m[36m(func pid=141974)[0m f1_micro: 0.35727611940298515
[2m[36m(func pid=141974)[0m f1_macro: 0.35435174440299216
[2m[36m(func pid=141974)[0m f1_weighted: 0.3718048194999026
[2m[36m(func pid=141974)[0m f1_per_class: [0.326, 0.192, 0.769, 0.517, 0.0, 0.357, 0.376, 0.307, 0.221, 0.48]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 90] | Train loss: 0.0788 | Steps: 2 | Val loss: 2.7586 | Batch size: 32 | lr: 0.01 | Duration: 3.17s
== Status ==
Current time: 2024-01-07 03:14:01 (running for 00:50:02.37)
Memory usage on this node: 16.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: 0.32175
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.036 |      0.354 |                   90 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
| train_6ed81_00017 | TERMINATED | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.09  |      0.295 |                   75 |
| train_6ed81_00018 | TERMINATED | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.852 |      0.203 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141974)[0m top1: 0.3451492537313433
[2m[36m(func pid=141974)[0m top5: 0.894589552238806
[2m[36m(func pid=141974)[0m f1_micro: 0.3451492537313433
[2m[36m(func pid=141974)[0m f1_macro: 0.36154868449318517
[2m[36m(func pid=141974)[0m f1_weighted: 0.36563118225075786
[2m[36m(func pid=141974)[0m f1_per_class: [0.348, 0.16, 0.786, 0.51, 0.051, 0.324, 0.379, 0.351, 0.226, 0.48]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 91] | Train loss: 0.0078 | Steps: 2 | Val loss: 3.0040 | Batch size: 32 | lr: 0.01 | Duration: 3.21s
== Status ==
Current time: 2024-01-07 03:14:07 (running for 00:50:08.19)
Memory usage on this node: 16.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: 0.32175
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.079 |      0.362 |                   91 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
| train_6ed81_00017 | TERMINATED | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.09  |      0.295 |                   75 |
| train_6ed81_00018 | TERMINATED | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.852 |      0.203 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141974)[0m top1: 0.322294776119403
[2m[36m(func pid=141974)[0m top5: 0.8889925373134329
[2m[36m(func pid=141974)[0m f1_micro: 0.322294776119403
[2m[36m(func pid=141974)[0m f1_macro: 0.3470912184704945
[2m[36m(func pid=141974)[0m f1_weighted: 0.35079031382840314
[2m[36m(func pid=141974)[0m f1_per_class: [0.326, 0.124, 0.71, 0.479, 0.054, 0.292, 0.388, 0.38, 0.23, 0.489]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 92] | Train loss: 0.0065 | Steps: 2 | Val loss: 3.2606 | Batch size: 32 | lr: 0.01 | Duration: 3.26s
== Status ==
Current time: 2024-01-07 03:14:13 (running for 00:50:13.88)
Memory usage on this node: 16.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: 0.32175
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.008 |      0.347 |                   92 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
| train_6ed81_00017 | TERMINATED | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.09  |      0.295 |                   75 |
| train_6ed81_00018 | TERMINATED | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.852 |      0.203 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141974)[0m top1: 0.2994402985074627
[2m[36m(func pid=141974)[0m top5: 0.886660447761194
[2m[36m(func pid=141974)[0m f1_micro: 0.2994402985074627
[2m[36m(func pid=141974)[0m f1_macro: 0.3279170987155085
[2m[36m(func pid=141974)[0m f1_weighted: 0.33529972158724636
[2m[36m(func pid=141974)[0m f1_per_class: [0.319, 0.136, 0.615, 0.436, 0.051, 0.284, 0.375, 0.404, 0.204, 0.455]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 93] | Train loss: 0.0113 | Steps: 2 | Val loss: 3.4088 | Batch size: 32 | lr: 0.01 | Duration: 3.05s
== Status ==
Current time: 2024-01-07 03:14:19 (running for 00:50:19.85)
Memory usage on this node: 16.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: 0.32175
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.006 |      0.328 |                   93 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
| train_6ed81_00017 | TERMINATED | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.09  |      0.295 |                   75 |
| train_6ed81_00018 | TERMINATED | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.852 |      0.203 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141974)[0m top1: 0.2868470149253731
[2m[36m(func pid=141974)[0m top5: 0.8796641791044776
[2m[36m(func pid=141974)[0m f1_micro: 0.2868470149253731
[2m[36m(func pid=141974)[0m f1_macro: 0.32300833102336607
[2m[36m(func pid=141974)[0m f1_weighted: 0.3221544754251397
[2m[36m(func pid=141974)[0m f1_per_class: [0.336, 0.14, 0.571, 0.409, 0.05, 0.283, 0.352, 0.404, 0.215, 0.468]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 94] | Train loss: 0.0140 | Steps: 2 | Val loss: 3.5140 | Batch size: 32 | lr: 0.01 | Duration: 3.12s
== Status ==
Current time: 2024-01-07 03:14:24 (running for 00:50:25.40)
Memory usage on this node: 16.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: 0.32175
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.011 |      0.323 |                   94 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
| train_6ed81_00017 | TERMINATED | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.09  |      0.295 |                   75 |
| train_6ed81_00018 | TERMINATED | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.852 |      0.203 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141974)[0m top1: 0.28171641791044777
[2m[36m(func pid=141974)[0m top5: 0.8698694029850746
[2m[36m(func pid=141974)[0m f1_micro: 0.28171641791044777
[2m[36m(func pid=141974)[0m f1_macro: 0.31316535730458583
[2m[36m(func pid=141974)[0m f1_weighted: 0.3190281234423096
[2m[36m(func pid=141974)[0m f1_per_class: [0.294, 0.153, 0.522, 0.391, 0.05, 0.277, 0.355, 0.417, 0.215, 0.458]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 95] | Train loss: 0.0775 | Steps: 2 | Val loss: 3.4814 | Batch size: 32 | lr: 0.01 | Duration: 3.18s
== Status ==
Current time: 2024-01-07 03:14:30 (running for 00:50:30.98)
Memory usage on this node: 16.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: 0.32175
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.014 |      0.313 |                   95 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
| train_6ed81_00017 | TERMINATED | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.09  |      0.295 |                   75 |
| train_6ed81_00018 | TERMINATED | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.852 |      0.203 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141974)[0m top1: 0.28125
[2m[36m(func pid=141974)[0m top5: 0.8638059701492538
[2m[36m(func pid=141974)[0m f1_micro: 0.28125
[2m[36m(func pid=141974)[0m f1_macro: 0.3100150492229757
[2m[36m(func pid=141974)[0m f1_weighted: 0.3189040719255919
[2m[36m(func pid=141974)[0m f1_per_class: [0.283, 0.195, 0.471, 0.391, 0.052, 0.262, 0.338, 0.417, 0.211, 0.481]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 96] | Train loss: 0.0092 | Steps: 2 | Val loss: 3.3291 | Batch size: 32 | lr: 0.01 | Duration: 3.11s
== Status ==
Current time: 2024-01-07 03:14:35 (running for 00:50:36.66)
Memory usage on this node: 16.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: 0.32175
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.077 |      0.31  |                   96 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
| train_6ed81_00017 | TERMINATED | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.09  |      0.295 |                   75 |
| train_6ed81_00018 | TERMINATED | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.852 |      0.203 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141974)[0m top1: 0.28451492537313433
[2m[36m(func pid=141974)[0m top5: 0.8610074626865671
[2m[36m(func pid=141974)[0m f1_micro: 0.28451492537313433
[2m[36m(func pid=141974)[0m f1_macro: 0.3108345587503031
[2m[36m(func pid=141974)[0m f1_weighted: 0.3171850214779222
[2m[36m(func pid=141974)[0m f1_per_class: [0.288, 0.225, 0.5, 0.389, 0.059, 0.27, 0.316, 0.4, 0.221, 0.441]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 97] | Train loss: 0.0147 | Steps: 2 | Val loss: 3.2495 | Batch size: 32 | lr: 0.01 | Duration: 3.29s
== Status ==
Current time: 2024-01-07 03:14:41 (running for 00:50:42.40)
Memory usage on this node: 16.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: 0.32175
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.009 |      0.311 |                   97 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
| train_6ed81_00017 | TERMINATED | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.09  |      0.295 |                   75 |
| train_6ed81_00018 | TERMINATED | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.852 |      0.203 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141974)[0m top1: 0.28777985074626866
[2m[36m(func pid=141974)[0m top5: 0.8544776119402985
[2m[36m(func pid=141974)[0m f1_micro: 0.28777985074626866
[2m[36m(func pid=141974)[0m f1_macro: 0.2944861294066267
[2m[36m(func pid=141974)[0m f1_weighted: 0.31559595591531037
[2m[36m(func pid=141974)[0m f1_per_class: [0.23, 0.245, 0.444, 0.402, 0.067, 0.274, 0.294, 0.39, 0.227, 0.371]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 98] | Train loss: 0.0160 | Steps: 2 | Val loss: 3.2524 | Batch size: 32 | lr: 0.01 | Duration: 3.05s
== Status ==
Current time: 2024-01-07 03:14:47 (running for 00:50:48.05)
Memory usage on this node: 16.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: 0.32175
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.015 |      0.294 |                   98 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
| train_6ed81_00017 | TERMINATED | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.09  |      0.295 |                   75 |
| train_6ed81_00018 | TERMINATED | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.852 |      0.203 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141974)[0m top1: 0.28404850746268656
[2m[36m(func pid=141974)[0m top5: 0.8418843283582089
[2m[36m(func pid=141974)[0m f1_micro: 0.28404850746268656
[2m[36m(func pid=141974)[0m f1_macro: 0.28425581019076274
[2m[36m(func pid=141974)[0m f1_weighted: 0.30664675849171924
[2m[36m(func pid=141974)[0m f1_per_class: [0.201, 0.281, 0.421, 0.407, 0.07, 0.286, 0.251, 0.316, 0.215, 0.393]
[2m[36m(func pid=141974)[0m 
[2m[36m(func pid=141974)[0m [N0-GPU0] | [Epoch: 99] | Train loss: 0.0035 | Steps: 2 | Val loss: 3.2582 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
== Status ==
Current time: 2024-01-07 03:14:52 (running for 00:50:53.57)
Memory usage on this node: 16.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: 0.32175
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00022 | RUNNING    | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.016 |      0.284 |                   99 |
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
| train_6ed81_00017 | TERMINATED | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.09  |      0.295 |                   75 |
| train_6ed81_00018 | TERMINATED | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.852 |      0.203 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
... 4 more trials not shown (4 TERMINATED)


== Status ==
Current time: 2024-01-07 03:14:53 (running for 00:50:54.15)
Memory usage on this node: 16.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=24
Bracket: Iter 75.000: 0.32175
Resources requested: 0/72 CPUs, 0/4 GPUs, 0.0/120.16 GiB heap, 0.0/55.49 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (24 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   f1_macro |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------|
| train_6ed81_00000 | TERMINATED | 192.168.7.53:38305  | 0.0001 |       0.99 |         0      |  0.666 |      0.334 |                  100 |
| train_6ed81_00001 | TERMINATED | 192.168.7.53:38679  | 0.001  |       0.99 |         0      |  0.137 |      0.292 |                  100 |
| train_6ed81_00002 | TERMINATED | 192.168.7.53:39098  | 0.01   |       0.99 |         0      |  0.516 |      0.16  |                  100 |
| train_6ed81_00003 | TERMINATED | 192.168.7.53:39517  | 0.1    |       0.99 |         0      |  1.625 |      0.148 |                   75 |
| train_6ed81_00004 | TERMINATED | 192.168.7.53:55782  | 0.0001 |       0.9  |         0      |  1.954 |      0.208 |                   75 |
| train_6ed81_00005 | TERMINATED | 192.168.7.53:60934  | 0.001  |       0.9  |         0      |  0.162 |      0.335 |                  100 |
| train_6ed81_00006 | TERMINATED | 192.168.7.53:62121  | 0.01   |       0.9  |         0      |  0.01  |      0.25  |                   75 |
| train_6ed81_00007 | TERMINATED | 192.168.7.53:62614  | 0.1    |       0.9  |         0      |  1.028 |      0.232 |                  100 |
| train_6ed81_00008 | TERMINATED | 192.168.7.53:73645  | 0.0001 |       0.99 |         0.0001 |  0.911 |      0.316 |                   75 |
| train_6ed81_00009 | TERMINATED | 192.168.7.53:79460  | 0.001  |       0.99 |         0.0001 |  1.102 |      0.257 |                  100 |
| train_6ed81_00010 | TERMINATED | 192.168.7.53:83696  | 0.01   |       0.99 |         0.0001 |  1.45  |      0.198 |                   75 |
| train_6ed81_00011 | TERMINATED | 192.168.7.53:85373  | 0.1    |       0.99 |         0.0001 |  2.111 |      0.188 |                   75 |
| train_6ed81_00012 | TERMINATED | 192.168.7.53:91054  | 0.0001 |       0.9  |         0.0001 |  1.977 |      0.212 |                   75 |
| train_6ed81_00013 | TERMINATED | 192.168.7.53:101178 | 0.001  |       0.9  |         0.0001 |  0.146 |      0.346 |                  100 |
| train_6ed81_00014 | TERMINATED | 192.168.7.53:102297 | 0.01   |       0.9  |         0.0001 |  0.013 |      0.307 |                  100 |
| train_6ed81_00015 | TERMINATED | 192.168.7.53:103229 | 0.1    |       0.9  |         0.0001 |  1.34  |      0.299 |                   75 |
| train_6ed81_00016 | TERMINATED | 192.168.7.53:108657 | 0.0001 |       0.99 |         1e-05  |  1.205 |      0.273 |                   75 |
| train_6ed81_00017 | TERMINATED | 192.168.7.53:120129 | 0.001  |       0.99 |         1e-05  |  0.09  |      0.295 |                   75 |
| train_6ed81_00018 | TERMINATED | 192.168.7.53:124580 | 0.01   |       0.99 |         1e-05  |  0.852 |      0.203 |                   75 |
| train_6ed81_00019 | TERMINATED | 192.168.7.53:125328 | 0.1    |       0.99 |         1e-05  |  3.973 |      0.119 |                   75 |
| train_6ed81_00020 | TERMINATED | 192.168.7.53:126248 | 0.0001 |       0.9  |         1e-05  |  1.918 |      0.204 |                   75 |
| train_6ed81_00021 | TERMINATED | 192.168.7.53:137284 | 0.001  |       0.9  |         1e-05  |  0.273 |      0.317 |                   75 |
| train_6ed81_00022 | TERMINATED | 192.168.7.53:141974 | 0.01   |       0.9  |         1e-05  |  0.003 |      0.27  |                  100 |
| train_6ed81_00023 | TERMINATED | 192.168.7.53:141976 | 0.1    |       0.9  |         1e-05  |  1.185 |      0.253 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+------------+----------------------+


[2m[36m(func pid=141974)[0m top1: 0.2868470149253731
[2m[36m(func pid=141974)[0m top5: 0.8381529850746269
[2m[36m(func pid=141974)[0m f1_micro: 0.2868470149253731
[2m[36m(func pid=141974)[0m f1_macro: 0.2695860298034677
[2m[36m(func pid=141974)[0m f1_weighted: 0.305368552888924
[2m[36m(func pid=141974)[0m f1_per_class: [0.175, 0.295, 0.333, 0.412, 0.08, 0.313, 0.235, 0.287, 0.201, 0.364]
2024-01-07 03:14:53,351	INFO tune.py:798 -- Total run time: 3055.06 seconds (3054.13 seconds for the tuning loop).
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** STEP 1341336.1 ON aap04 CANCELLED AT 2024-01-07T03:14:58 ***
srun: error: aap04: task 0: Exited with exit code 1
