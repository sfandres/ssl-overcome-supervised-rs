IP Head: 192.168.7.53:6379
STARTING HEAD at aap04
2024-01-07 08:31:12,837	INFO usage_lib.py:461 -- Usage stats collection is enabled by default without user confirmation because this terminal is detected to be non-interactive. To disable this, add `--disable-usage-stats` to the command that starts the cluster, or run the following command: `ray disable-usage-stats` before starting the cluster. See https://docs.ray.io/en/master/cluster/usage-stats.html for more details.
2024-01-07 08:31:12,837	INFO scripts.py:710 -- Local node IP: 192.168.7.53
2024-01-07 08:31:15,377	SUCC scripts.py:747 -- --------------------
2024-01-07 08:31:15,377	SUCC scripts.py:748 -- Ray runtime started.
2024-01-07 08:31:15,377	SUCC scripts.py:749 -- --------------------
2024-01-07 08:31:15,377	INFO scripts.py:751 -- Next steps
2024-01-07 08:31:15,377	INFO scripts.py:752 -- To connect to this Ray runtime from another node, run
2024-01-07 08:31:15,377	INFO scripts.py:755 --   ray start --address='192.168.7.53:6379'
2024-01-07 08:31:15,377	INFO scripts.py:771 -- Alternatively, use the following Python code:
2024-01-07 08:31:15,377	INFO scripts.py:773 -- import ray
2024-01-07 08:31:15,378	INFO scripts.py:777 -- ray.init(address='auto', _node_ip_address='192.168.7.53')
2024-01-07 08:31:15,378	INFO scripts.py:790 -- To see the status of the cluster, use
2024-01-07 08:31:15,378	INFO scripts.py:791 --   ray status
2024-01-07 08:31:15,378	INFO scripts.py:801 -- If connection fails, check your firewall settings and network configuration.
2024-01-07 08:31:15,378	INFO scripts.py:809 -- To terminate the Ray runtime, run
2024-01-07 08:31:15,378	INFO scripts.py:810 --   ray stop
2024-01-07 08:31:15,378	INFO scripts.py:891 -- --block
2024-01-07 08:31:15,378	INFO scripts.py:892 -- This command will now block forever until terminated by a signal.
2024-01-07 08:31:15,378	INFO scripts.py:895 -- Running subprocesses are monitored and a message will be printed if any of them terminate unexpectedly. Subprocesses exit with SIGTERM will be treated as graceful, thus NOT reported.

torch initial seed:              16416848065859070732
torch current seed:              42
torch.cuda.is_available():       True
torch.cuda.device_count():       4
torch.cuda.current_device():     0
torch.cuda.device(0):            <torch.cuda.device object at 0x7f398d0030d0>
torch.cuda.get_device_name(0):   Tesla V100-PCIE-32GB
torch.backends.cudnn.benchmark:  False
os.sched_getaffinity:            72
os.cpu_count():                  72

model_name:          Supervised
task_name:           multilabel
backbone_name:       resnet18
input_data:          None
dataset_name:        Sentinel2AndaluciaLULC
dataset_level:       Level_N2
train_rate:          5
epochs:              100
learning_rate:       0.01
save_every:          5
batch_size:          32
num_workers:         4
ini_weights:         imagenet
seed:                42
dropout:             None
transfer_learning:   FT
show:                False
verbose:             False
balanced_dataset:    False
torch_compile:       False
distributed:         False
ray_tune:            gridsearch
load_best_hyperparameters: False
grace_period:        75
num_samples_trials:  1
gpus_per_trial:      1

Using ImageNet weights

Supervised model resnet18 with imagenet weights
Old final fully-connected layer: Linear(in_features=512, out_features=1000, bias=True)
No dropout layer
New final fully-connected layer: Linear(in_features=512, out_features=10, bias=True)
Fine-tuning adjusted
Device: 0

Setting a new configuration using tune.grid_search

2024-01-07 08:31:57,945	INFO worker.py:1364 -- Connecting to existing Ray cluster at address: 192.168.7.53:6379...
2024-01-07 08:31:57,964	INFO worker.py:1553 -- Connected to Ray cluster.
2024-01-07 08:32:21,298	WARNING worker.py:1866 -- Warning: The actor ImplicitFunc is very large (44 MiB). Check that its definition is not implicitly capturing a large array or other object in scope. Tip: use ray.put() to put large objects in the Ray object store.
== Status ==
Current time: 2024-01-07 08:32:21 (running for 00:00:22.37)
Memory usage on this node: 13.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (23 PENDING, 1 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |
|-------------------+----------+---------------------+--------+------------+----------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |
| train_d77f6_00001 | PENDING  |                     | 0.001  |       0.99 |         0      |
| train_d77f6_00002 | PENDING  |                     | 0.01   |       0.99 |         0      |
| train_d77f6_00003 | PENDING  |                     | 0.1    |       0.99 |         0      |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |
+-------------------+----------+---------------------+--------+------------+----------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=104469)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=104469)[0m Configuration completed!
[2m[36m(func pid=104469)[0m New optimizer parameters:
[2m[36m(func pid=104469)[0m SGD (
[2m[36m(func pid=104469)[0m Parameter Group 0
[2m[36m(func pid=104469)[0m     dampening: 0
[2m[36m(func pid=104469)[0m     differentiable: False
[2m[36m(func pid=104469)[0m     foreach: None
[2m[36m(func pid=104469)[0m     lr: 0.0001
[2m[36m(func pid=104469)[0m     maximize: False
[2m[36m(func pid=104469)[0m     momentum: 0.99
[2m[36m(func pid=104469)[0m     nesterov: False
[2m[36m(func pid=104469)[0m     weight_decay: 0
[2m[36m(func pid=104469)[0m )
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 1.0827 | Steps: 2 | Val loss: 0.8110 | Batch size: 32 | lr: 0.0001 | Duration: 4.77s
[2m[36m(func pid=104469)[0m rmse: 0.1786845326423645
[2m[36m(func pid=104469)[0m mae:  0.13119161128997803
[2m[36m(func pid=104469)[0m rmse_per_class: [0.105, 0.266, 0.087, 0.325, 0.1, 0.192, 0.304, 0.153, 0.139, 0.116]
== Status ==
Current time: 2024-01-07 08:32:31 (running for 00:00:32.60)
Memory usage on this node: 15.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (22 PENDING, 2 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |
|-------------------+----------+---------------------+--------+------------+----------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |
| train_d77f6_00002 | PENDING  |                     | 0.01   |       0.99 |         0      |
| train_d77f6_00003 | PENDING  |                     | 0.1    |       0.99 |         0      |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |
+-------------------+----------+---------------------+--------+------------+----------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104843)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=104843)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=104843)[0m Configuration completed!
[2m[36m(func pid=104843)[0m New optimizer parameters:
[2m[36m(func pid=104843)[0m SGD (
[2m[36m(func pid=104843)[0m Parameter Group 0
[2m[36m(func pid=104843)[0m     dampening: 0
[2m[36m(func pid=104843)[0m     differentiable: False
[2m[36m(func pid=104843)[0m     foreach: None
[2m[36m(func pid=104843)[0m     lr: 0.001
[2m[36m(func pid=104843)[0m     maximize: False
[2m[36m(func pid=104843)[0m     momentum: 0.99
[2m[36m(func pid=104843)[0m     nesterov: False
[2m[36m(func pid=104843)[0m     weight_decay: 0
[2m[36m(func pid=104843)[0m )
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 1.0791 | Steps: 2 | Val loss: 0.7928 | Batch size: 32 | lr: 0.001 | Duration: 4.64s
[2m[36m(func pid=104843)[0m rmse: 0.1785503476858139
[2m[36m(func pid=104843)[0m mae:  0.13106036186218262
[2m[36m(func pid=104843)[0m rmse_per_class: [0.105, 0.266, 0.086, 0.325, 0.1, 0.192, 0.304, 0.153, 0.139, 0.116]
== Status ==
Current time: 2024-01-07 08:32:39 (running for 00:00:40.79)
Memory usage on this node: 17.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (21 PENDING, 3 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |
|-------------------+----------+---------------------+--------+------------+----------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |
| train_d77f6_00003 | PENDING  |                     | 0.1    |       0.99 |         0      |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |
+-------------------+----------+---------------------+--------+------------+----------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=105266)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=105266)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=105266)[0m Configuration completed!
[2m[36m(func pid=105266)[0m New optimizer parameters:
[2m[36m(func pid=105266)[0m SGD (
[2m[36m(func pid=105266)[0m Parameter Group 0
[2m[36m(func pid=105266)[0m     dampening: 0
[2m[36m(func pid=105266)[0m     differentiable: False
[2m[36m(func pid=105266)[0m     foreach: None
[2m[36m(func pid=105266)[0m     lr: 0.01
[2m[36m(func pid=105266)[0m     maximize: False
[2m[36m(func pid=105266)[0m     momentum: 0.99
[2m[36m(func pid=105266)[0m     nesterov: False
[2m[36m(func pid=105266)[0m     weight_decay: 0
[2m[36m(func pid=105266)[0m )
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 1.0293 | Steps: 2 | Val loss: 0.6448 | Batch size: 32 | lr: 0.01 | Duration: 4.78s
[2m[36m(func pid=105266)[0m rmse: 0.17790022492408752
[2m[36m(func pid=105266)[0m mae:  0.13037793338298798
[2m[36m(func pid=105266)[0m rmse_per_class: [0.104, 0.267, 0.085, 0.325, 0.097, 0.192, 0.301, 0.155, 0.139, 0.114]
== Status ==
Current time: 2024-01-07 08:32:47 (running for 00:00:48.71)
Memory usage on this node: 20.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |
|-------------------+----------+---------------------+--------+------------+----------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |
+-------------------+----------+---------------------+--------+------------+----------------+
... 4 more trials not shown (4 PENDING)


== Status ==
Current time: 2024-01-07 08:32:55 (running for 00:00:56.58)
Memory usage on this node: 22.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  1.083 |  0.179 |                    1 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |        |        |                      |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |        |        |                      |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |        |        |                      |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=105685)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=105685)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=105685)[0m Configuration completed!
[2m[36m(func pid=105685)[0m New optimizer parameters:
[2m[36m(func pid=105685)[0m SGD (
[2m[36m(func pid=105685)[0m Parameter Group 0
[2m[36m(func pid=105685)[0m     dampening: 0
[2m[36m(func pid=105685)[0m     differentiable: False
[2m[36m(func pid=105685)[0m     foreach: None
[2m[36m(func pid=105685)[0m     lr: 0.1
[2m[36m(func pid=105685)[0m     maximize: False
[2m[36m(func pid=105685)[0m     momentum: 0.99
[2m[36m(func pid=105685)[0m     nesterov: False
[2m[36m(func pid=105685)[0m     weight_decay: 0
[2m[36m(func pid=105685)[0m )
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 1.0793 | Steps: 2 | Val loss: 0.8121 | Batch size: 32 | lr: 0.0001 | Duration: 3.03s
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.6901 | Steps: 2 | Val loss: 0.4152 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 1.0339 | Steps: 2 | Val loss: 0.7532 | Batch size: 32 | lr: 0.001 | Duration: 3.08s
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 0.7693 | Steps: 2 | Val loss: 0.3256 | Batch size: 32 | lr: 0.1 | Duration: 4.67s
== Status ==
Current time: 2024-01-07 08:33:00 (running for 00:01:01.62)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  1.083 |  0.179 |                    1 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  1.079 |  0.179 |                    1 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  1.029 |  0.178 |                    1 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |        |        |                      |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=105266)[0m rmse: 0.17616978287696838
[2m[36m(func pid=105266)[0m mae:  0.12863455712795258
[2m[36m(func pid=105266)[0m rmse_per_class: [0.104, 0.269, 0.086, 0.326, 0.091, 0.192, 0.292, 0.152, 0.141, 0.109]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104469)[0m rmse: 0.1791791170835495
[2m[36m(func pid=104469)[0m mae:  0.13158102333545685
[2m[36m(func pid=104469)[0m rmse_per_class: [0.105, 0.266, 0.089, 0.325, 0.102, 0.193, 0.305, 0.153, 0.139, 0.116]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.1788930594921112
[2m[36m(func pid=104843)[0m mae:  0.13126471638679504
[2m[36m(func pid=104843)[0m rmse_per_class: [0.104, 0.266, 0.087, 0.325, 0.101, 0.192, 0.304, 0.155, 0.139, 0.116]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.1713477224111557
[2m[36m(func pid=105685)[0m mae:  0.12296293675899506
[2m[36m(func pid=105685)[0m rmse_per_class: [0.106, 0.274, 0.086, 0.339, 0.071, 0.189, 0.269, 0.13, 0.153, 0.097]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.4356 | Steps: 2 | Val loss: 0.3203 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 1.0694 | Steps: 2 | Val loss: 0.8124 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.9467 | Steps: 2 | Val loss: 0.6913 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.5499 | Steps: 2 | Val loss: 0.5136 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
== Status ==
Current time: 2024-01-07 08:33:06 (running for 00:01:07.32)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  1.079 |  0.179 |                    2 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  1.034 |  0.179 |                    2 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.436 |  0.173 |                    3 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.769 |  0.171 |                    1 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m rmse: 0.17959390580654144
[2m[36m(func pid=104469)[0m mae:  0.13189658522605896
[2m[36m(func pid=104469)[0m rmse_per_class: [0.105, 0.266, 0.09, 0.325, 0.103, 0.193, 0.306, 0.153, 0.139, 0.116]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=105266)[0m rmse: 0.17316079139709473
[2m[36m(func pid=105266)[0m mae:  0.12564298510551453
[2m[36m(func pid=105266)[0m rmse_per_class: [0.106, 0.27, 0.09, 0.332, 0.083, 0.191, 0.276, 0.137, 0.148, 0.101]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.17906948924064636
[2m[36m(func pid=104843)[0m mae:  0.13130173087120056
[2m[36m(func pid=104843)[0m rmse_per_class: [0.104, 0.266, 0.088, 0.324, 0.101, 0.193, 0.305, 0.156, 0.139, 0.115]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.1897062212228775
[2m[36m(func pid=105685)[0m mae:  0.12385944277048111
[2m[36m(func pid=105685)[0m rmse_per_class: [0.096, 0.286, 0.049, 0.362, 0.055, 0.193, 0.448, 0.148, 0.164, 0.095]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.4086 | Steps: 2 | Val loss: 0.3429 | Batch size: 32 | lr: 0.01 | Duration: 2.76s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.8427 | Steps: 2 | Val loss: 0.6123 | Batch size: 32 | lr: 0.001 | Duration: 2.70s
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 1.0589 | Steps: 2 | Val loss: 0.8089 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.7601 | Steps: 2 | Val loss: 0.6622 | Batch size: 32 | lr: 0.1 | Duration: 2.63s
== Status ==
Current time: 2024-01-07 08:33:11 (running for 00:01:12.56)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  1.069 |  0.18  |                    3 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.843 |  0.179 |                    4 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.436 |  0.173 |                    3 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.55  |  0.19  |                    2 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104843)[0m rmse: 0.179124653339386
[2m[36m(func pid=104843)[0m mae:  0.13120874762535095
[2m[36m(func pid=104843)[0m rmse_per_class: [0.104, 0.267, 0.089, 0.324, 0.101, 0.193, 0.304, 0.156, 0.139, 0.115]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=104469)[0m rmse: 0.17994888126850128
[2m[36m(func pid=104469)[0m mae:  0.13216206431388855
[2m[36m(func pid=104469)[0m rmse_per_class: [0.105, 0.266, 0.09, 0.325, 0.104, 0.193, 0.307, 0.154, 0.138, 0.117]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=105266)[0m rmse: 0.1717158854007721
[2m[36m(func pid=105266)[0m mae:  0.1222207099199295
[2m[36m(func pid=105266)[0m rmse_per_class: [0.107, 0.271, 0.086, 0.341, 0.071, 0.19, 0.266, 0.133, 0.158, 0.095]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.22075751423835754
[2m[36m(func pid=105685)[0m mae:  0.14201511442661285
[2m[36m(func pid=105685)[0m rmse_per_class: [0.105, 0.298, 0.048, 0.382, 0.056, 0.217, 0.696, 0.155, 0.152, 0.097]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.7217 | Steps: 2 | Val loss: 0.5269 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 1.0376 | Steps: 2 | Val loss: 0.7999 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.4698 | Steps: 2 | Val loss: 0.4075 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.7435 | Steps: 2 | Val loss: 0.7047 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
== Status ==
Current time: 2024-01-07 08:33:16 (running for 00:01:17.79)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  1.059 |  0.18  |                    4 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.722 |  0.179 |                    5 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.409 |  0.172 |                    4 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.76  |  0.221 |                    3 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104843)[0m rmse: 0.17893803119659424
[2m[36m(func pid=104843)[0m mae:  0.13087162375450134
[2m[36m(func pid=104843)[0m rmse_per_class: [0.104, 0.268, 0.089, 0.324, 0.1, 0.193, 0.302, 0.156, 0.139, 0.114]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105266)[0m rmse: 0.17383798956871033
[2m[36m(func pid=105266)[0m mae:  0.11947794258594513
[2m[36m(func pid=105266)[0m rmse_per_class: [0.104, 0.272, 0.073, 0.352, 0.061, 0.189, 0.294, 0.14, 0.162, 0.092]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104469)[0m rmse: 0.18021932244300842
[2m[36m(func pid=104469)[0m mae:  0.13237109780311584
[2m[36m(func pid=104469)[0m rmse_per_class: [0.105, 0.266, 0.09, 0.325, 0.105, 0.194, 0.308, 0.154, 0.138, 0.118]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.2286933958530426
[2m[36m(func pid=105685)[0m mae:  0.1454620361328125
[2m[36m(func pid=105685)[0m rmse_per_class: [0.109, 0.301, 0.049, 0.385, 0.056, 0.222, 0.702, 0.156, 0.209, 0.097]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.6142 | Steps: 2 | Val loss: 0.4492 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.5551 | Steps: 2 | Val loss: 0.4810 | Batch size: 32 | lr: 0.01 | Duration: 2.71s
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 1.0156 | Steps: 2 | Val loss: 0.7880 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.5896 | Steps: 2 | Val loss: 0.6831 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
== Status ==
Current time: 2024-01-07 08:33:22 (running for 00:01:22.94)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  1.038 |  0.18  |                    5 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.722 |  0.179 |                    5 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.555 |  0.181 |                    6 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.743 |  0.229 |                    4 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104843)[0m rmse: 0.17859169840812683
[2m[36m(func pid=104843)[0m mae:  0.13040617108345032
[2m[36m(func pid=104843)[0m rmse_per_class: [0.104, 0.269, 0.09, 0.325, 0.099, 0.193, 0.299, 0.154, 0.14, 0.113]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105266)[0m rmse: 0.18089571595191956
[2m[36m(func pid=105266)[0m mae:  0.11983363330364227
[2m[36m(func pid=105266)[0m rmse_per_class: [0.099, 0.274, 0.057, 0.362, 0.056, 0.19, 0.37, 0.148, 0.161, 0.092]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104469)[0m rmse: 0.18047139048576355
[2m[36m(func pid=104469)[0m mae:  0.13254579901695251
[2m[36m(func pid=104469)[0m rmse_per_class: [0.105, 0.266, 0.091, 0.325, 0.105, 0.194, 0.309, 0.154, 0.138, 0.119]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.21627774834632874
[2m[36m(func pid=105685)[0m mae:  0.13018223643302917
[2m[36m(func pid=105685)[0m rmse_per_class: [0.106, 0.297, 0.049, 0.362, 0.056, 0.174, 0.398, 0.156, 0.466, 0.097]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.5205 | Steps: 2 | Val loss: 0.3883 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.6057 | Steps: 2 | Val loss: 0.5449 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.9913 | Steps: 2 | Val loss: 0.7724 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.4171 | Steps: 2 | Val loss: 0.7551 | Batch size: 32 | lr: 0.1 | Duration: 2.72s
== Status ==
Current time: 2024-01-07 08:33:27 (running for 00:01:28.06)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  1.016 |  0.18  |                    6 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.614 |  0.179 |                    6 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.606 |  0.19  |                    7 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.59  |  0.216 |                    5 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=105266)[0m rmse: 0.19028647243976593
[2m[36m(func pid=105266)[0m mae:  0.12317521870136261
[2m[36m(func pid=105266)[0m rmse_per_class: [0.094, 0.276, 0.047, 0.371, 0.055, 0.194, 0.462, 0.152, 0.157, 0.094]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.1779235303401947
[2m[36m(func pid=104843)[0m mae:  0.12966440618038177
[2m[36m(func pid=104843)[0m rmse_per_class: [0.105, 0.27, 0.092, 0.326, 0.097, 0.193, 0.294, 0.151, 0.141, 0.112]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=104469)[0m rmse: 0.18067926168441772
[2m[36m(func pid=104469)[0m mae:  0.1326989233493805
[2m[36m(func pid=104469)[0m rmse_per_class: [0.106, 0.266, 0.091, 0.325, 0.105, 0.194, 0.309, 0.154, 0.138, 0.119]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.2248775064945221
[2m[36m(func pid=105685)[0m mae:  0.1405419409275055
[2m[36m(func pid=105685)[0m rmse_per_class: [0.086, 0.284, 0.031, 0.329, 0.056, 0.422, 0.296, 0.155, 0.491, 0.097]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.6527 | Steps: 2 | Val loss: 0.5931 | Batch size: 32 | lr: 0.01 | Duration: 2.76s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.4602 | Steps: 2 | Val loss: 0.3471 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.9660 | Steps: 2 | Val loss: 0.7524 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.4189 | Steps: 2 | Val loss: 0.8488 | Batch size: 32 | lr: 0.1 | Duration: 2.72s
[2m[36m(func pid=105266)[0m rmse: 0.19941174983978271
[2m[36m(func pid=105266)[0m mae:  0.1278735101222992
[2m[36m(func pid=105266)[0m rmse_per_class: [0.092, 0.28, 0.045, 0.378, 0.056, 0.199, 0.54, 0.154, 0.155, 0.095]
[2m[36m(func pid=105266)[0m 
== Status ==
Current time: 2024-01-07 08:33:32 (running for 00:01:33.19)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.991 |  0.181 |                    7 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.521 |  0.178 |                    7 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.653 |  0.199 |                    8 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.417 |  0.225 |                    6 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104843)[0m rmse: 0.17711682617664337
[2m[36m(func pid=104843)[0m mae:  0.12878310680389404
[2m[36m(func pid=104843)[0m rmse_per_class: [0.106, 0.27, 0.094, 0.328, 0.094, 0.192, 0.288, 0.145, 0.143, 0.11]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=104469)[0m rmse: 0.18076862394809723
[2m[36m(func pid=104469)[0m mae:  0.1327359825372696
[2m[36m(func pid=104469)[0m rmse_per_class: [0.106, 0.266, 0.091, 0.324, 0.106, 0.194, 0.31, 0.154, 0.138, 0.12]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.2330121248960495
[2m[36m(func pid=105685)[0m mae:  0.144385427236557
[2m[36m(func pid=105685)[0m rmse_per_class: [0.177, 0.278, 0.033, 0.347, 0.056, 0.395, 0.339, 0.15, 0.456, 0.097]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.6574 | Steps: 2 | Val loss: 0.6219 | Batch size: 32 | lr: 0.01 | Duration: 2.65s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.4170 | Steps: 2 | Val loss: 0.3252 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.9348 | Steps: 2 | Val loss: 0.7285 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.4147 | Steps: 2 | Val loss: 0.8243 | Batch size: 32 | lr: 0.1 | Duration: 2.76s
[2m[36m(func pid=105266)[0m rmse: 0.2064501941204071
[2m[36m(func pid=105266)[0m mae:  0.13216236233711243
[2m[36m(func pid=105266)[0m rmse_per_class: [0.092, 0.283, 0.046, 0.382, 0.056, 0.204, 0.596, 0.155, 0.155, 0.096]
[2m[36m(func pid=105266)[0m 
== Status ==
Current time: 2024-01-07 08:33:37 (running for 00:01:38.55)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.966 |  0.181 |                    8 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.417 |  0.176 |                    9 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.657 |  0.206 |                    9 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.419 |  0.233 |                    7 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104843)[0m rmse: 0.1761200726032257
[2m[36m(func pid=104843)[0m mae:  0.12766717374324799
[2m[36m(func pid=104843)[0m rmse_per_class: [0.107, 0.271, 0.096, 0.33, 0.091, 0.192, 0.282, 0.14, 0.146, 0.107]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=104469)[0m rmse: 0.1808377206325531
[2m[36m(func pid=104469)[0m mae:  0.13277627527713776
[2m[36m(func pid=104469)[0m rmse_per_class: [0.106, 0.267, 0.091, 0.324, 0.105, 0.194, 0.31, 0.154, 0.138, 0.12]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.2211466133594513
[2m[36m(func pid=105685)[0m mae:  0.13037262856960297
[2m[36m(func pid=105685)[0m rmse_per_class: [0.148, 0.267, 0.056, 0.43, 0.056, 0.214, 0.325, 0.155, 0.462, 0.097]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.6571 | Steps: 2 | Val loss: 0.6280 | Batch size: 32 | lr: 0.01 | Duration: 2.73s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.3996 | Steps: 2 | Val loss: 0.3195 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.9054 | Steps: 2 | Val loss: 0.7033 | Batch size: 32 | lr: 0.0001 | Duration: 2.79s
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.4112 | Steps: 2 | Val loss: 0.9707 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=105266)[0m rmse: 0.21068933606147766
[2m[36m(func pid=105266)[0m mae:  0.1348041146993637
[2m[36m(func pid=105266)[0m rmse_per_class: [0.092, 0.284, 0.047, 0.384, 0.056, 0.206, 0.627, 0.156, 0.158, 0.097]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.17516422271728516
[2m[36m(func pid=104843)[0m mae:  0.12650148570537567
[2m[36m(func pid=104843)[0m rmse_per_class: [0.108, 0.271, 0.097, 0.332, 0.087, 0.192, 0.275, 0.136, 0.149, 0.104]
[2m[36m(func pid=104843)[0m 
== Status ==
Current time: 2024-01-07 08:33:42 (running for 00:01:43.82)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.935 |  0.181 |                    9 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.4   |  0.175 |                   10 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.657 |  0.211 |                   10 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.415 |  0.221 |                    8 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m rmse: 0.18088063597679138
[2m[36m(func pid=104469)[0m mae:  0.1327807605266571
[2m[36m(func pid=104469)[0m rmse_per_class: [0.106, 0.267, 0.09, 0.324, 0.105, 0.194, 0.31, 0.154, 0.138, 0.121]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.21623775362968445
[2m[36m(func pid=105685)[0m mae:  0.1357823610305786
[2m[36m(func pid=105685)[0m rmse_per_class: [0.108, 0.285, 0.039, 0.624, 0.056, 0.226, 0.401, 0.159, 0.168, 0.097]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.6379 | Steps: 2 | Val loss: 0.6192 | Batch size: 32 | lr: 0.01 | Duration: 2.64s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.3935 | Steps: 2 | Val loss: 0.3246 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.8712 | Steps: 2 | Val loss: 0.6766 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.4259 | Steps: 2 | Val loss: 1.0252 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=105266)[0m rmse: 0.21225745975971222
[2m[36m(func pid=105266)[0m mae:  0.13548144698143005
[2m[36m(func pid=105266)[0m rmse_per_class: [0.091, 0.282, 0.048, 0.385, 0.056, 0.207, 0.629, 0.156, 0.171, 0.097]
[2m[36m(func pid=105266)[0m 
== Status ==
Current time: 2024-01-07 08:33:48 (running for 00:01:48.96)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.905 |  0.181 |                   10 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.393 |  0.174 |                   11 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.638 |  0.212 |                   11 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.411 |  0.216 |                    9 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104843)[0m rmse: 0.17402999103069305
[2m[36m(func pid=104843)[0m mae:  0.12506572902202606
[2m[36m(func pid=104843)[0m rmse_per_class: [0.109, 0.271, 0.097, 0.335, 0.082, 0.191, 0.268, 0.134, 0.151, 0.102]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=104469)[0m rmse: 0.18095174431800842
[2m[36m(func pid=104469)[0m mae:  0.1327899992465973
[2m[36m(func pid=104469)[0m rmse_per_class: [0.106, 0.267, 0.09, 0.324, 0.105, 0.194, 0.31, 0.154, 0.138, 0.121]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.22483205795288086
[2m[36m(func pid=105685)[0m mae:  0.1358787566423416
[2m[36m(func pid=105685)[0m rmse_per_class: [0.107, 0.288, 0.136, 0.439, 0.056, 0.231, 0.501, 0.162, 0.232, 0.097]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.5890 | Steps: 2 | Val loss: 0.5905 | Batch size: 32 | lr: 0.01 | Duration: 2.68s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.4005 | Steps: 2 | Val loss: 0.3369 | Batch size: 32 | lr: 0.001 | Duration: 2.74s
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.3572 | Steps: 2 | Val loss: 1.1800 | Batch size: 32 | lr: 0.1 | Duration: 2.73s
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.8353 | Steps: 2 | Val loss: 0.6498 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=105266)[0m rmse: 0.2114829272031784
[2m[36m(func pid=105266)[0m mae:  0.1340394914150238
[2m[36m(func pid=105266)[0m rmse_per_class: [0.089, 0.277, 0.048, 0.385, 0.056, 0.203, 0.609, 0.156, 0.194, 0.097]
[2m[36m(func pid=105266)[0m 
== Status ==
Current time: 2024-01-07 08:33:53 (running for 00:01:54.02)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.871 |  0.181 |                   11 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.401 |  0.173 |                   12 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.589 |  0.211 |                   12 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.426 |  0.225 |                   10 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104843)[0m rmse: 0.17323990166187286
[2m[36m(func pid=104843)[0m mae:  0.12376465648412704
[2m[36m(func pid=104843)[0m rmse_per_class: [0.11, 0.271, 0.095, 0.337, 0.077, 0.191, 0.263, 0.134, 0.154, 0.099]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.2279932051897049
[2m[36m(func pid=105685)[0m mae:  0.1384526789188385
[2m[36m(func pid=105685)[0m rmse_per_class: [0.127, 0.289, 0.207, 0.375, 0.055, 0.23, 0.52, 0.166, 0.21, 0.1]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=104469)[0m rmse: 0.18093419075012207
[2m[36m(func pid=104469)[0m mae:  0.13272008299827576
[2m[36m(func pid=104469)[0m rmse_per_class: [0.106, 0.267, 0.09, 0.324, 0.104, 0.194, 0.309, 0.155, 0.138, 0.122]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.5280 | Steps: 2 | Val loss: 0.5500 | Batch size: 32 | lr: 0.01 | Duration: 2.64s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.4172 | Steps: 2 | Val loss: 0.3539 | Batch size: 32 | lr: 0.001 | Duration: 2.64s
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.3508 | Steps: 2 | Val loss: 0.9468 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.8029 | Steps: 2 | Val loss: 0.6227 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=105266)[0m rmse: 0.2069590538740158
[2m[36m(func pid=105266)[0m mae:  0.12963929772377014
[2m[36m(func pid=105266)[0m rmse_per_class: [0.083, 0.268, 0.048, 0.384, 0.056, 0.194, 0.562, 0.156, 0.222, 0.097]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.17273981869220734
[2m[36m(func pid=104843)[0m mae:  0.12251613289117813
[2m[36m(func pid=104843)[0m rmse_per_class: [0.11, 0.271, 0.094, 0.34, 0.073, 0.19, 0.261, 0.135, 0.156, 0.097]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.21701721847057343
[2m[36m(func pid=105685)[0m mae:  0.13606984913349152
[2m[36m(func pid=105685)[0m rmse_per_class: [0.197, 0.284, 0.074, 0.378, 0.053, 0.228, 0.392, 0.166, 0.191, 0.207]
== Status ==
Current time: 2024-01-07 08:33:59 (running for 00:02:00.11)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.835 |  0.181 |                   12 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.417 |  0.173 |                   13 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.528 |  0.207 |                   13 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.351 |  0.217 |                   12 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=104469)[0m rmse: 0.18089506030082703
[2m[36m(func pid=104469)[0m mae:  0.13264279067516327
[2m[36m(func pid=104469)[0m rmse_per_class: [0.106, 0.268, 0.09, 0.324, 0.104, 0.194, 0.309, 0.155, 0.138, 0.122]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.4906 | Steps: 2 | Val loss: 0.5097 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.4290 | Steps: 2 | Val loss: 0.3735 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.3326 | Steps: 2 | Val loss: 0.6940 | Batch size: 32 | lr: 0.1 | Duration: 2.73s
[2m[36m(func pid=105266)[0m rmse: 0.19871768355369568
[2m[36m(func pid=105266)[0m mae:  0.12222108989953995
[2m[36m(func pid=105266)[0m rmse_per_class: [0.079, 0.255, 0.048, 0.381, 0.056, 0.177, 0.471, 0.156, 0.266, 0.097]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.7619 | Steps: 2 | Val loss: 0.5938 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=104843)[0m rmse: 0.17249684035778046
[2m[36m(func pid=104843)[0m mae:  0.12131696939468384
[2m[36m(func pid=104843)[0m rmse_per_class: [0.11, 0.271, 0.09, 0.344, 0.069, 0.19, 0.262, 0.137, 0.158, 0.095]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.2181079387664795
[2m[36m(func pid=105685)[0m mae:  0.141020730137825
[2m[36m(func pid=105685)[0m rmse_per_class: [0.153, 0.279, 0.071, 0.377, 0.053, 0.22, 0.245, 0.188, 0.172, 0.423]
[2m[36m(func pid=105685)[0m 
== Status ==
Current time: 2024-01-07 08:34:04 (running for 00:02:05.75)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.762 |  0.181 |                   14 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.429 |  0.172 |                   14 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.491 |  0.199 |                   14 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.333 |  0.218 |                   13 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m rmse: 0.18083123862743378
[2m[36m(func pid=104469)[0m mae:  0.13252927362918854
[2m[36m(func pid=104469)[0m rmse_per_class: [0.106, 0.268, 0.09, 0.324, 0.104, 0.194, 0.308, 0.154, 0.138, 0.122]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.4383 | Steps: 2 | Val loss: 0.4591 | Batch size: 32 | lr: 0.01 | Duration: 2.77s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.4532 | Steps: 2 | Val loss: 0.3942 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.3114 | Steps: 2 | Val loss: 0.7280 | Batch size: 32 | lr: 0.1 | Duration: 2.73s
[2m[36m(func pid=105266)[0m rmse: 0.18586793541908264
[2m[36m(func pid=105266)[0m mae:  0.11209646612405777
[2m[36m(func pid=105266)[0m rmse_per_class: [0.08, 0.242, 0.048, 0.372, 0.056, 0.161, 0.355, 0.156, 0.291, 0.097]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.7293 | Steps: 2 | Val loss: 0.5659 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=104843)[0m rmse: 0.1725347936153412
[2m[36m(func pid=104843)[0m mae:  0.1202545315027237
[2m[36m(func pid=104843)[0m rmse_per_class: [0.11, 0.271, 0.085, 0.346, 0.066, 0.189, 0.266, 0.139, 0.16, 0.093]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.22344017028808594
[2m[36m(func pid=105685)[0m mae:  0.14945068955421448
[2m[36m(func pid=105685)[0m rmse_per_class: [0.147, 0.276, 0.087, 0.374, 0.055, 0.203, 0.294, 0.12, 0.151, 0.527]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.3931 | Steps: 2 | Val loss: 0.4212 | Batch size: 32 | lr: 0.01 | Duration: 2.65s
== Status ==
Current time: 2024-01-07 08:34:10 (running for 00:02:11.12)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.729 |  0.181 |                   15 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.453 |  0.173 |                   15 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.438 |  0.186 |                   15 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.311 |  0.223 |                   14 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m rmse: 0.18068484961986542
[2m[36m(func pid=104469)[0m mae:  0.13236571848392487
[2m[36m(func pid=104469)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.103, 0.194, 0.308, 0.154, 0.138, 0.122]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.4709 | Steps: 2 | Val loss: 0.4143 | Batch size: 32 | lr: 0.001 | Duration: 2.72s
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.3197 | Steps: 2 | Val loss: 0.6976 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
[2m[36m(func pid=105266)[0m rmse: 0.17632755637168884
[2m[36m(func pid=105266)[0m mae:  0.1055910736322403
[2m[36m(func pid=105266)[0m rmse_per_class: [0.084, 0.24, 0.045, 0.358, 0.056, 0.175, 0.244, 0.155, 0.309, 0.096]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.7001 | Steps: 2 | Val loss: 0.5386 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=104843)[0m rmse: 0.173001229763031
[2m[36m(func pid=104843)[0m mae:  0.11947411298751831
[2m[36m(func pid=104843)[0m rmse_per_class: [0.109, 0.271, 0.081, 0.349, 0.063, 0.189, 0.274, 0.141, 0.162, 0.092]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.21967163681983948
[2m[36m(func pid=105685)[0m mae:  0.14595665037631989
[2m[36m(func pid=105685)[0m rmse_per_class: [0.134, 0.267, 0.09, 0.361, 0.059, 0.194, 0.303, 0.117, 0.143, 0.529]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.3799 | Steps: 2 | Val loss: 0.3966 | Batch size: 32 | lr: 0.01 | Duration: 2.72s
== Status ==
Current time: 2024-01-07 08:34:15 (running for 00:02:16.50)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.7   |  0.181 |                   16 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.471 |  0.173 |                   16 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.393 |  0.176 |                   16 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.32  |  0.22  |                   15 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m rmse: 0.18051734566688538
[2m[36m(func pid=104469)[0m mae:  0.13216447830200195
[2m[36m(func pid=104469)[0m rmse_per_class: [0.106, 0.268, 0.09, 0.324, 0.102, 0.194, 0.307, 0.154, 0.138, 0.122]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.4865 | Steps: 2 | Val loss: 0.4347 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.2948 | Steps: 2 | Val loss: 0.6426 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=105266)[0m rmse: 0.17242205142974854
[2m[36m(func pid=105266)[0m mae:  0.10378311574459076
[2m[36m(func pid=105266)[0m rmse_per_class: [0.083, 0.24, 0.041, 0.335, 0.056, 0.218, 0.194, 0.155, 0.305, 0.095]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.6622 | Steps: 2 | Val loss: 0.5129 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=104843)[0m rmse: 0.1736273616552353
[2m[36m(func pid=104843)[0m mae:  0.11881935596466064
[2m[36m(func pid=104843)[0m rmse_per_class: [0.108, 0.271, 0.076, 0.351, 0.06, 0.189, 0.283, 0.143, 0.164, 0.092]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.22058483958244324
[2m[36m(func pid=105685)[0m mae:  0.1435912847518921
[2m[36m(func pid=105685)[0m rmse_per_class: [0.147, 0.263, 0.093, 0.342, 0.059, 0.208, 0.317, 0.141, 0.142, 0.493]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.3516 | Steps: 2 | Val loss: 0.3848 | Batch size: 32 | lr: 0.01 | Duration: 2.73s
== Status ==
Current time: 2024-01-07 08:34:20 (running for 00:02:21.69)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.662 |  0.18  |                   17 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.486 |  0.174 |                   17 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.38  |  0.172 |                   17 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.295 |  0.221 |                   16 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m rmse: 0.18039031326770782
[2m[36m(func pid=104469)[0m mae:  0.13202524185180664
[2m[36m(func pid=104469)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.101, 0.194, 0.306, 0.153, 0.139, 0.122]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.5028 | Steps: 2 | Val loss: 0.4511 | Batch size: 32 | lr: 0.001 | Duration: 2.78s
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.3019 | Steps: 2 | Val loss: 0.4756 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=105266)[0m rmse: 0.17220841348171234
[2m[36m(func pid=105266)[0m mae:  0.10470153391361237
[2m[36m(func pid=105266)[0m rmse_per_class: [0.085, 0.234, 0.033, 0.316, 0.056, 0.26, 0.205, 0.152, 0.287, 0.094]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.17418107390403748
[2m[36m(func pid=104843)[0m mae:  0.11816774308681488
[2m[36m(func pid=104843)[0m rmse_per_class: [0.107, 0.271, 0.07, 0.352, 0.059, 0.188, 0.294, 0.144, 0.164, 0.091]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.6316 | Steps: 2 | Val loss: 0.4876 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=105685)[0m rmse: 0.20549769699573517
[2m[36m(func pid=105685)[0m mae:  0.1282508224248886
[2m[36m(func pid=105685)[0m rmse_per_class: [0.154, 0.256, 0.102, 0.355, 0.061, 0.211, 0.292, 0.143, 0.137, 0.344]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.3528 | Steps: 2 | Val loss: 0.3705 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
== Status ==
Current time: 2024-01-07 08:34:26 (running for 00:02:26.89)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.632 |  0.18  |                   18 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.503 |  0.174 |                   18 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.352 |  0.172 |                   18 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.302 |  0.205 |                   17 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m rmse: 0.18023578822612762
[2m[36m(func pid=104469)[0m mae:  0.1318160593509674
[2m[36m(func pid=104469)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.324, 0.101, 0.194, 0.305, 0.153, 0.139, 0.122]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.5222 | Steps: 2 | Val loss: 0.4687 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.2924 | Steps: 2 | Val loss: 0.4469 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=105266)[0m rmse: 0.1692008674144745
[2m[36m(func pid=105266)[0m mae:  0.10350650548934937
[2m[36m(func pid=105266)[0m rmse_per_class: [0.081, 0.224, 0.028, 0.295, 0.056, 0.279, 0.23, 0.142, 0.264, 0.092]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.1753380447626114
[2m[36m(func pid=104843)[0m mae:  0.11797656863927841
[2m[36m(func pid=104843)[0m rmse_per_class: [0.106, 0.271, 0.065, 0.355, 0.057, 0.188, 0.307, 0.146, 0.166, 0.091]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.6004 | Steps: 2 | Val loss: 0.4644 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=105685)[0m rmse: 0.20104508101940155
[2m[36m(func pid=105685)[0m mae:  0.12312233448028564
[2m[36m(func pid=105685)[0m rmse_per_class: [0.206, 0.239, 0.122, 0.412, 0.067, 0.212, 0.277, 0.146, 0.163, 0.168]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.3685 | Steps: 2 | Val loss: 0.3583 | Batch size: 32 | lr: 0.01 | Duration: 2.76s
== Status ==
Current time: 2024-01-07 08:34:31 (running for 00:02:32.12)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.6   |  0.18  |                   19 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.522 |  0.175 |                   19 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.353 |  0.169 |                   19 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.292 |  0.201 |                   18 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m rmse: 0.1801709085702896
[2m[36m(func pid=104469)[0m mae:  0.1316969394683838
[2m[36m(func pid=104469)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.324, 0.1, 0.194, 0.304, 0.152, 0.139, 0.122]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.5409 | Steps: 2 | Val loss: 0.4840 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.3864 | Steps: 2 | Val loss: 0.7685 | Batch size: 32 | lr: 0.1 | Duration: 2.74s
[2m[36m(func pid=105266)[0m rmse: 0.16465754806995392
[2m[36m(func pid=105266)[0m mae:  0.10148018598556519
[2m[36m(func pid=105266)[0m rmse_per_class: [0.073, 0.216, 0.025, 0.283, 0.056, 0.276, 0.252, 0.127, 0.249, 0.09]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.17658475041389465
[2m[36m(func pid=104843)[0m mae:  0.11781052500009537
[2m[36m(func pid=104843)[0m rmse_per_class: [0.104, 0.271, 0.061, 0.356, 0.056, 0.188, 0.323, 0.148, 0.167, 0.091]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.5734 | Steps: 2 | Val loss: 0.4437 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
[2m[36m(func pid=105685)[0m rmse: 0.21553213894367218
[2m[36m(func pid=105685)[0m mae:  0.1337018609046936
[2m[36m(func pid=105685)[0m rmse_per_class: [0.263, 0.265, 0.046, 0.397, 0.065, 0.198, 0.286, 0.127, 0.338, 0.171]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.3842 | Steps: 2 | Val loss: 0.3553 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
== Status ==
Current time: 2024-01-07 08:34:36 (running for 00:02:37.33)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.573 |  0.18  |                   20 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.541 |  0.177 |                   20 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.369 |  0.165 |                   20 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.386 |  0.216 |                   19 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m rmse: 0.1799313873052597
[2m[36m(func pid=104469)[0m mae:  0.1314493715763092
[2m[36m(func pid=104469)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.324, 0.099, 0.194, 0.303, 0.151, 0.14, 0.121]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.5445 | Steps: 2 | Val loss: 0.4964 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.3249 | Steps: 2 | Val loss: 4.6086 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=105266)[0m rmse: 0.16231249272823334
[2m[36m(func pid=105266)[0m mae:  0.10063153505325317
[2m[36m(func pid=105266)[0m rmse_per_class: [0.065, 0.21, 0.025, 0.282, 0.056, 0.255, 0.268, 0.114, 0.26, 0.088]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.5472 | Steps: 2 | Val loss: 0.4248 | Batch size: 32 | lr: 0.0001 | Duration: 2.77s
[2m[36m(func pid=104843)[0m rmse: 0.1780034452676773
[2m[36m(func pid=104843)[0m mae:  0.11789558082818985
[2m[36m(func pid=104843)[0m rmse_per_class: [0.103, 0.272, 0.057, 0.358, 0.056, 0.188, 0.34, 0.149, 0.168, 0.091]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.2525429129600525
[2m[36m(func pid=105685)[0m mae:  0.1699768602848053
[2m[36m(func pid=105685)[0m rmse_per_class: [0.116, 0.304, 0.046, 0.419, 0.075, 0.198, 0.321, 0.126, 0.823, 0.098]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.3559 | Steps: 2 | Val loss: 0.3500 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
== Status ==
Current time: 2024-01-07 08:34:41 (running for 00:02:42.51)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.547 |  0.18  |                   21 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.545 |  0.178 |                   21 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.384 |  0.162 |                   21 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.325 |  0.253 |                   20 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m rmse: 0.17978742718696594
[2m[36m(func pid=104469)[0m mae:  0.13127556443214417
[2m[36m(func pid=104469)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.325, 0.099, 0.193, 0.302, 0.15, 0.14, 0.121]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.5516 | Steps: 2 | Val loss: 0.5089 | Batch size: 32 | lr: 0.001 | Duration: 2.78s
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.3123 | Steps: 2 | Val loss: 11.8672 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=105266)[0m rmse: 0.1621345579624176
[2m[36m(func pid=105266)[0m mae:  0.10032588243484497
[2m[36m(func pid=105266)[0m rmse_per_class: [0.061, 0.209, 0.029, 0.288, 0.056, 0.229, 0.277, 0.117, 0.269, 0.087]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.5222 | Steps: 2 | Val loss: 0.4065 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=104843)[0m rmse: 0.17950595915317535
[2m[36m(func pid=104843)[0m mae:  0.11805993318557739
[2m[36m(func pid=104843)[0m rmse_per_class: [0.101, 0.272, 0.053, 0.36, 0.055, 0.187, 0.358, 0.15, 0.168, 0.092]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.2579359710216522
[2m[36m(func pid=105685)[0m mae:  0.17573420703411102
[2m[36m(func pid=105685)[0m rmse_per_class: [0.113, 0.303, 0.049, 0.404, 0.075, 0.199, 0.333, 0.129, 0.878, 0.098]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.3586 | Steps: 2 | Val loss: 0.3486 | Batch size: 32 | lr: 0.01 | Duration: 2.69s
== Status ==
Current time: 2024-01-07 08:34:46 (running for 00:02:47.82)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.522 |  0.18  |                   22 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.552 |  0.18  |                   22 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.356 |  0.162 |                   22 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.312 |  0.258 |                   21 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m rmse: 0.1795601099729538
[2m[36m(func pid=104469)[0m mae:  0.13101038336753845
[2m[36m(func pid=104469)[0m rmse_per_class: [0.108, 0.27, 0.092, 0.325, 0.098, 0.193, 0.3, 0.149, 0.141, 0.12]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.5609 | Steps: 2 | Val loss: 0.5176 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=105266)[0m rmse: 0.16493482887744904
[2m[36m(func pid=105266)[0m mae:  0.101404570043087
[2m[36m(func pid=105266)[0m rmse_per_class: [0.061, 0.214, 0.033, 0.297, 0.056, 0.211, 0.282, 0.129, 0.277, 0.09]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.3761 | Steps: 2 | Val loss: 2.8791 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=104843)[0m rmse: 0.18103548884391785
[2m[36m(func pid=104843)[0m mae:  0.11837788671255112
[2m[36m(func pid=104843)[0m rmse_per_class: [0.1, 0.272, 0.05, 0.361, 0.055, 0.187, 0.373, 0.151, 0.168, 0.092]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.5044 | Steps: 2 | Val loss: 0.3911 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=105685)[0m rmse: 0.24924710392951965
[2m[36m(func pid=105685)[0m mae:  0.15678483247756958
[2m[36m(func pid=105685)[0m rmse_per_class: [0.171, 0.295, 0.048, 0.54, 0.069, 0.196, 0.338, 0.166, 0.546, 0.124]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.3623 | Steps: 2 | Val loss: 0.3553 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
== Status ==
Current time: 2024-01-07 08:34:52 (running for 00:02:53.14)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.504 |  0.179 |                   23 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.561 |  0.181 |                   23 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.359 |  0.165 |                   23 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.376 |  0.249 |                   22 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m rmse: 0.1793145388364792
[2m[36m(func pid=104469)[0m mae:  0.13074737787246704
[2m[36m(func pid=104469)[0m rmse_per_class: [0.108, 0.27, 0.092, 0.325, 0.097, 0.193, 0.299, 0.148, 0.141, 0.12]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.5757 | Steps: 2 | Val loss: 0.5235 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=105266)[0m rmse: 0.17142556607723236
[2m[36m(func pid=105266)[0m mae:  0.10479338467121124
[2m[36m(func pid=105266)[0m rmse_per_class: [0.065, 0.227, 0.032, 0.308, 0.056, 0.204, 0.284, 0.146, 0.29, 0.102]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.3098 | Steps: 2 | Val loss: 2.9842 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.4819 | Steps: 2 | Val loss: 0.3772 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
[2m[36m(func pid=104843)[0m rmse: 0.1823575645685196
[2m[36m(func pid=104843)[0m mae:  0.11868021637201309
[2m[36m(func pid=104843)[0m rmse_per_class: [0.098, 0.272, 0.048, 0.362, 0.055, 0.187, 0.387, 0.151, 0.17, 0.093]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.2181638777256012
[2m[36m(func pid=105685)[0m mae:  0.1439887285232544
[2m[36m(func pid=105685)[0m rmse_per_class: [0.253, 0.27, 0.046, 0.465, 0.098, 0.211, 0.338, 0.17, 0.138, 0.193]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.3575 | Steps: 2 | Val loss: 0.3677 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
== Status ==
Current time: 2024-01-07 08:34:57 (running for 00:02:58.32)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.482 |  0.179 |                   24 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.576 |  0.182 |                   24 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.362 |  0.171 |                   24 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.31  |  0.218 |                   23 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m rmse: 0.17914626002311707
[2m[36m(func pid=104469)[0m mae:  0.13052824139595032
[2m[36m(func pid=104469)[0m rmse_per_class: [0.108, 0.27, 0.093, 0.326, 0.096, 0.193, 0.297, 0.146, 0.142, 0.12]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.5741 | Steps: 2 | Val loss: 0.5293 | Batch size: 32 | lr: 0.001 | Duration: 2.78s
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.3201 | Steps: 2 | Val loss: 3.8388 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
[2m[36m(func pid=105266)[0m rmse: 0.17917020618915558
[2m[36m(func pid=105266)[0m mae:  0.10937218368053436
[2m[36m(func pid=105266)[0m rmse_per_class: [0.07, 0.24, 0.031, 0.318, 0.055, 0.199, 0.287, 0.165, 0.305, 0.121]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.18381111323833466
[2m[36m(func pid=104843)[0m mae:  0.11901126056909561
[2m[36m(func pid=104843)[0m rmse_per_class: [0.096, 0.272, 0.047, 0.363, 0.055, 0.187, 0.405, 0.152, 0.168, 0.093]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.4708 | Steps: 2 | Val loss: 0.3655 | Batch size: 32 | lr: 0.0001 | Duration: 2.79s
[2m[36m(func pid=105685)[0m rmse: 0.2184869796037674
[2m[36m(func pid=105685)[0m mae:  0.144768625497818
[2m[36m(func pid=105685)[0m rmse_per_class: [0.186, 0.261, 0.054, 0.457, 0.093, 0.217, 0.338, 0.163, 0.139, 0.277]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.3434 | Steps: 2 | Val loss: 0.3794 | Batch size: 32 | lr: 0.01 | Duration: 2.70s
== Status ==
Current time: 2024-01-07 08:35:02 (running for 00:03:03.54)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.471 |  0.179 |                   25 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.574 |  0.184 |                   25 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.357 |  0.179 |                   25 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.32  |  0.218 |                   24 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m rmse: 0.17911000549793243
[2m[36m(func pid=104469)[0m mae:  0.13041827082633972
[2m[36m(func pid=104469)[0m rmse_per_class: [0.108, 0.271, 0.095, 0.327, 0.095, 0.193, 0.295, 0.146, 0.142, 0.119]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.5678 | Steps: 2 | Val loss: 0.5328 | Batch size: 32 | lr: 0.001 | Duration: 2.78s
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.3000 | Steps: 2 | Val loss: 4.1334 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=105266)[0m rmse: 0.1862139105796814
[2m[36m(func pid=105266)[0m mae:  0.11345700174570084
[2m[36m(func pid=105266)[0m rmse_per_class: [0.076, 0.253, 0.038, 0.325, 0.055, 0.193, 0.29, 0.186, 0.312, 0.135]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.1850997805595398
[2m[36m(func pid=104843)[0m mae:  0.11941558122634888
[2m[36m(func pid=104843)[0m rmse_per_class: [0.095, 0.272, 0.046, 0.364, 0.055, 0.187, 0.418, 0.153, 0.168, 0.093]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.4541 | Steps: 2 | Val loss: 0.3549 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=105685)[0m rmse: 0.2122933566570282
[2m[36m(func pid=105685)[0m mae:  0.1430305540561676
[2m[36m(func pid=105685)[0m rmse_per_class: [0.171, 0.26, 0.053, 0.379, 0.071, 0.222, 0.335, 0.159, 0.236, 0.238]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.3381 | Steps: 2 | Val loss: 0.3858 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 08:35:08 (running for 00:03:08.93)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.454 |  0.179 |                   26 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.568 |  0.185 |                   26 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.343 |  0.186 |                   26 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.3   |  0.212 |                   25 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m rmse: 0.17883741855621338
[2m[36m(func pid=104469)[0m mae:  0.13012869656085968
[2m[36m(func pid=104469)[0m rmse_per_class: [0.109, 0.271, 0.094, 0.327, 0.095, 0.193, 0.293, 0.145, 0.143, 0.119]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.5765 | Steps: 2 | Val loss: 0.5330 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.2958 | Steps: 2 | Val loss: 4.4566 | Batch size: 32 | lr: 0.1 | Duration: 2.76s
[2m[36m(func pid=105266)[0m rmse: 0.19203141331672668
[2m[36m(func pid=105266)[0m mae:  0.11694035679101944
[2m[36m(func pid=105266)[0m rmse_per_class: [0.08, 0.263, 0.043, 0.328, 0.055, 0.187, 0.292, 0.212, 0.302, 0.158]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.18638202548027039
[2m[36m(func pid=104843)[0m mae:  0.11985521018505096
[2m[36m(func pid=104843)[0m rmse_per_class: [0.093, 0.272, 0.045, 0.365, 0.055, 0.187, 0.429, 0.153, 0.169, 0.094]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.4407 | Steps: 2 | Val loss: 0.3462 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=105685)[0m rmse: 0.22787339985370636
[2m[36m(func pid=105685)[0m mae:  0.14592410624027252
[2m[36m(func pid=105685)[0m rmse_per_class: [0.215, 0.278, 0.057, 0.336, 0.057, 0.226, 0.336, 0.156, 0.332, 0.286]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.3374 | Steps: 2 | Val loss: 0.3917 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 08:35:13 (running for 00:03:14.21)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.441 |  0.178 |                   27 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.576 |  0.186 |                   27 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.338 |  0.192 |                   27 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.296 |  0.228 |                   26 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m rmse: 0.17848385870456696
[2m[36m(func pid=104469)[0m mae:  0.12978146970272064
[2m[36m(func pid=104469)[0m rmse_per_class: [0.109, 0.271, 0.094, 0.328, 0.094, 0.193, 0.291, 0.143, 0.144, 0.118]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.5702 | Steps: 2 | Val loss: 0.5304 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.3243 | Steps: 2 | Val loss: 1.8384 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=105266)[0m rmse: 0.19600525498390198
[2m[36m(func pid=105266)[0m mae:  0.11960716545581818
[2m[36m(func pid=105266)[0m rmse_per_class: [0.083, 0.271, 0.045, 0.332, 0.054, 0.186, 0.294, 0.233, 0.293, 0.17]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.18749591708183289
[2m[36m(func pid=104843)[0m mae:  0.12020452320575714
[2m[36m(func pid=104843)[0m rmse_per_class: [0.092, 0.272, 0.045, 0.366, 0.056, 0.187, 0.439, 0.153, 0.172, 0.094]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.4298 | Steps: 2 | Val loss: 0.3390 | Batch size: 32 | lr: 0.0001 | Duration: 2.81s
[2m[36m(func pid=105685)[0m rmse: 0.22094741463661194
[2m[36m(func pid=105685)[0m mae:  0.13439235091209412
[2m[36m(func pid=105685)[0m rmse_per_class: [0.258, 0.29, 0.036, 0.333, 0.057, 0.224, 0.301, 0.14, 0.401, 0.169]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.3359 | Steps: 2 | Val loss: 0.3923 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.5512 | Steps: 2 | Val loss: 0.5284 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
== Status ==
Current time: 2024-01-07 08:35:18 (running for 00:03:19.34)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.43  |  0.178 |                   28 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.57  |  0.187 |                   28 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.337 |  0.196 |                   28 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.324 |  0.221 |                   27 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m rmse: 0.1780928671360016
[2m[36m(func pid=104469)[0m mae:  0.1293714940547943
[2m[36m(func pid=104469)[0m rmse_per_class: [0.109, 0.271, 0.095, 0.328, 0.092, 0.193, 0.289, 0.142, 0.144, 0.117]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.3503 | Steps: 2 | Val loss: 1.2846 | Batch size: 32 | lr: 0.1 | Duration: 2.78s
[2m[36m(func pid=105266)[0m rmse: 0.1979547142982483
[2m[36m(func pid=105266)[0m mae:  0.12098108232021332
[2m[36m(func pid=105266)[0m rmse_per_class: [0.085, 0.276, 0.046, 0.333, 0.053, 0.188, 0.291, 0.244, 0.279, 0.184]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.18833377957344055
[2m[36m(func pid=104843)[0m mae:  0.12046067416667938
[2m[36m(func pid=104843)[0m rmse_per_class: [0.091, 0.272, 0.045, 0.367, 0.056, 0.187, 0.447, 0.153, 0.172, 0.094]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.21864864230155945
[2m[36m(func pid=105685)[0m mae:  0.12906482815742493
[2m[36m(func pid=105685)[0m rmse_per_class: [0.306, 0.283, 0.052, 0.33, 0.059, 0.218, 0.271, 0.139, 0.393, 0.136]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.4202 | Steps: 2 | Val loss: 0.3336 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.3259 | Steps: 2 | Val loss: 0.3891 | Batch size: 32 | lr: 0.01 | Duration: 2.76s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.5400 | Steps: 2 | Val loss: 0.5239 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
== Status ==
Current time: 2024-01-07 08:35:23 (running for 00:03:24.70)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.42  |  0.178 |                   29 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.551 |  0.188 |                   29 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.336 |  0.198 |                   29 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.35  |  0.219 |                   28 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m rmse: 0.17782554030418396
[2m[36m(func pid=104469)[0m mae:  0.12909753620624542
[2m[36m(func pid=104469)[0m rmse_per_class: [0.11, 0.271, 0.095, 0.329, 0.092, 0.193, 0.287, 0.141, 0.145, 0.116]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.2830 | Steps: 2 | Val loss: 1.0867 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=105266)[0m rmse: 0.19720324873924255
[2m[36m(func pid=105266)[0m mae:  0.12088142335414886
[2m[36m(func pid=105266)[0m rmse_per_class: [0.086, 0.279, 0.045, 0.332, 0.052, 0.19, 0.285, 0.246, 0.266, 0.19]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.18913275003433228
[2m[36m(func pid=104843)[0m mae:  0.12068656831979752
[2m[36m(func pid=104843)[0m rmse_per_class: [0.09, 0.271, 0.045, 0.367, 0.056, 0.186, 0.455, 0.154, 0.173, 0.095]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.2340112179517746
[2m[36m(func pid=105685)[0m mae:  0.13728366792201996
[2m[36m(func pid=105685)[0m rmse_per_class: [0.376, 0.283, 0.059, 0.377, 0.065, 0.208, 0.261, 0.132, 0.151, 0.429]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.4148 | Steps: 2 | Val loss: 0.3294 | Batch size: 32 | lr: 0.0001 | Duration: 2.77s
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.3148 | Steps: 2 | Val loss: 0.3856 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.5459 | Steps: 2 | Val loss: 0.5178 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 08:35:28 (running for 00:03:29.81)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.415 |  0.178 |                   30 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.54  |  0.189 |                   30 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.326 |  0.197 |                   30 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.283 |  0.234 |                   29 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m rmse: 0.17759816348552704
[2m[36m(func pid=104469)[0m mae:  0.12885694205760956
[2m[36m(func pid=104469)[0m rmse_per_class: [0.109, 0.271, 0.096, 0.33, 0.091, 0.193, 0.286, 0.14, 0.146, 0.115]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.2920 | Steps: 2 | Val loss: 1.1404 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=105266)[0m rmse: 0.19451706111431122
[2m[36m(func pid=105266)[0m mae:  0.11955215781927109
[2m[36m(func pid=105266)[0m rmse_per_class: [0.085, 0.278, 0.044, 0.33, 0.051, 0.192, 0.281, 0.242, 0.261, 0.181]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.19001725316047668
[2m[36m(func pid=104843)[0m mae:  0.12099675834178925
[2m[36m(func pid=104843)[0m rmse_per_class: [0.089, 0.271, 0.045, 0.367, 0.056, 0.186, 0.463, 0.154, 0.175, 0.095]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.23907160758972168
[2m[36m(func pid=105685)[0m mae:  0.1433379054069519
[2m[36m(func pid=105685)[0m rmse_per_class: [0.345, 0.298, 0.075, 0.387, 0.087, 0.199, 0.267, 0.122, 0.139, 0.47]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.4030 | Steps: 2 | Val loss: 0.3259 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.2938 | Steps: 2 | Val loss: 0.3757 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.5245 | Steps: 2 | Val loss: 0.5089 | Batch size: 32 | lr: 0.001 | Duration: 2.78s
[2m[36m(func pid=104469)[0m rmse: 0.17727722227573395
[2m[36m(func pid=104469)[0m mae:  0.12849678099155426
[2m[36m(func pid=104469)[0m rmse_per_class: [0.11, 0.271, 0.096, 0.33, 0.09, 0.193, 0.284, 0.138, 0.146, 0.114]
== Status ==
Current time: 2024-01-07 08:35:34 (running for 00:03:35.00)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.403 |  0.177 |                   31 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.546 |  0.19  |                   31 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.315 |  0.195 |                   31 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.292 |  0.239 |                   30 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.3153 | Steps: 2 | Val loss: 1.0993 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=105266)[0m rmse: 0.19033236801624298
[2m[36m(func pid=105266)[0m mae:  0.1174246296286583
[2m[36m(func pid=105266)[0m rmse_per_class: [0.085, 0.276, 0.042, 0.331, 0.05, 0.193, 0.277, 0.233, 0.238, 0.177]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.1902906447649002
[2m[36m(func pid=104843)[0m mae:  0.12092775106430054
[2m[36m(func pid=104843)[0m rmse_per_class: [0.088, 0.271, 0.045, 0.367, 0.056, 0.185, 0.463, 0.154, 0.179, 0.095]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.24285320937633514
[2m[36m(func pid=105685)[0m mae:  0.1487521380186081
[2m[36m(func pid=105685)[0m rmse_per_class: [0.368, 0.291, 0.131, 0.388, 0.081, 0.202, 0.281, 0.123, 0.142, 0.421]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.4011 | Steps: 2 | Val loss: 0.3237 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.3075 | Steps: 2 | Val loss: 0.3658 | Batch size: 32 | lr: 0.01 | Duration: 2.69s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.5217 | Steps: 2 | Val loss: 0.5001 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
== Status ==
Current time: 2024-01-07 08:35:39 (running for 00:03:40.26)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.401 |  0.177 |                   32 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.525 |  0.19  |                   32 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.294 |  0.19  |                   32 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.315 |  0.243 |                   31 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m rmse: 0.17709505558013916
[2m[36m(func pid=104469)[0m mae:  0.12826116383075714
[2m[36m(func pid=104469)[0m rmse_per_class: [0.11, 0.272, 0.096, 0.331, 0.089, 0.193, 0.282, 0.137, 0.147, 0.113]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.3289 | Steps: 2 | Val loss: 1.2551 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=105266)[0m rmse: 0.18587572872638702
[2m[36m(func pid=105266)[0m mae:  0.11499985307455063
[2m[36m(func pid=105266)[0m rmse_per_class: [0.086, 0.272, 0.041, 0.333, 0.05, 0.193, 0.275, 0.224, 0.216, 0.169]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.19026844203472137
[2m[36m(func pid=104843)[0m mae:  0.12067747116088867
[2m[36m(func pid=104843)[0m rmse_per_class: [0.087, 0.269, 0.045, 0.366, 0.056, 0.185, 0.463, 0.154, 0.182, 0.095]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.2441314458847046
[2m[36m(func pid=105685)[0m mae:  0.15176261961460114
[2m[36m(func pid=105685)[0m rmse_per_class: [0.409, 0.292, 0.181, 0.389, 0.059, 0.222, 0.29, 0.133, 0.212, 0.255]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.4027 | Steps: 2 | Val loss: 0.3224 | Batch size: 32 | lr: 0.0001 | Duration: 2.78s
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.2812 | Steps: 2 | Val loss: 0.3588 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.5167 | Steps: 2 | Val loss: 0.4931 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
== Status ==
Current time: 2024-01-07 08:35:44 (running for 00:03:45.40)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.403 |  0.177 |                   33 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.522 |  0.19  |                   33 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.308 |  0.186 |                   33 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.329 |  0.244 |                   32 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m rmse: 0.17684651911258698
[2m[36m(func pid=104469)[0m mae:  0.1279650181531906
[2m[36m(func pid=104469)[0m rmse_per_class: [0.111, 0.272, 0.097, 0.332, 0.088, 0.193, 0.279, 0.137, 0.148, 0.112]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.2937 | Steps: 2 | Val loss: 1.4720 | Batch size: 32 | lr: 0.1 | Duration: 2.76s
[2m[36m(func pid=105266)[0m rmse: 0.18197821080684662
[2m[36m(func pid=105266)[0m mae:  0.11317308992147446
[2m[36m(func pid=105266)[0m rmse_per_class: [0.09, 0.267, 0.041, 0.34, 0.051, 0.191, 0.274, 0.209, 0.202, 0.155]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.1907227486371994
[2m[36m(func pid=104843)[0m mae:  0.12070325762033463
[2m[36m(func pid=104843)[0m rmse_per_class: [0.086, 0.268, 0.046, 0.367, 0.056, 0.184, 0.467, 0.154, 0.184, 0.095]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.24498264491558075
[2m[36m(func pid=105685)[0m mae:  0.15073715150356293
[2m[36m(func pid=105685)[0m rmse_per_class: [0.379, 0.284, 0.175, 0.387, 0.058, 0.229, 0.345, 0.147, 0.319, 0.128]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.3935 | Steps: 2 | Val loss: 0.3215 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.2889 | Steps: 2 | Val loss: 0.3538 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.4914 | Steps: 2 | Val loss: 0.4806 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
== Status ==
Current time: 2024-01-07 08:35:49 (running for 00:03:50.65)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.393 |  0.176 |                   34 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.517 |  0.191 |                   34 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.281 |  0.182 |                   34 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.294 |  0.245 |                   33 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m rmse: 0.17646783590316772
[2m[36m(func pid=104469)[0m mae:  0.12760767340660095
[2m[36m(func pid=104469)[0m rmse_per_class: [0.111, 0.272, 0.096, 0.333, 0.087, 0.193, 0.278, 0.136, 0.15, 0.111]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.4483 | Steps: 2 | Val loss: 0.8205 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=105266)[0m rmse: 0.17911012470722198
[2m[36m(func pid=105266)[0m mae:  0.11156369745731354
[2m[36m(func pid=105266)[0m rmse_per_class: [0.094, 0.26, 0.04, 0.346, 0.052, 0.189, 0.272, 0.2, 0.188, 0.148]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.19000020623207092
[2m[36m(func pid=104843)[0m mae:  0.12001720815896988
[2m[36m(func pid=104843)[0m rmse_per_class: [0.085, 0.267, 0.046, 0.366, 0.056, 0.182, 0.461, 0.154, 0.188, 0.095]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.23566940426826477
[2m[36m(func pid=105685)[0m mae:  0.13701720535755157
[2m[36m(func pid=105685)[0m rmse_per_class: [0.386, 0.273, 0.116, 0.398, 0.055, 0.225, 0.32, 0.153, 0.289, 0.142]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.3924 | Steps: 2 | Val loss: 0.3213 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.2843 | Steps: 2 | Val loss: 0.3483 | Batch size: 32 | lr: 0.01 | Duration: 2.65s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.4695 | Steps: 2 | Val loss: 0.4662 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
== Status ==
Current time: 2024-01-07 08:35:54 (running for 00:03:55.82)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.392 |  0.176 |                   35 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.491 |  0.19  |                   35 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.289 |  0.179 |                   35 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.448 |  0.236 |                   34 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m rmse: 0.17611072957515717
[2m[36m(func pid=104469)[0m mae:  0.1272154152393341
[2m[36m(func pid=104469)[0m rmse_per_class: [0.111, 0.272, 0.096, 0.333, 0.086, 0.192, 0.276, 0.135, 0.15, 0.109]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.3171 | Steps: 2 | Val loss: 1.3690 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
[2m[36m(func pid=105266)[0m rmse: 0.17569495737552643
[2m[36m(func pid=105266)[0m mae:  0.10974578559398651
[2m[36m(func pid=105266)[0m rmse_per_class: [0.101, 0.254, 0.041, 0.352, 0.054, 0.185, 0.264, 0.19, 0.177, 0.14]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.18928518891334534
[2m[36m(func pid=104843)[0m mae:  0.11930974572896957
[2m[36m(func pid=104843)[0m rmse_per_class: [0.084, 0.266, 0.046, 0.365, 0.056, 0.18, 0.456, 0.154, 0.191, 0.095]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.25199785828590393
[2m[36m(func pid=105685)[0m mae:  0.14279407262802124
[2m[36m(func pid=105685)[0m rmse_per_class: [0.425, 0.279, 0.055, 0.439, 0.053, 0.22, 0.303, 0.163, 0.263, 0.321]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.3895 | Steps: 2 | Val loss: 0.3217 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.2939 | Steps: 2 | Val loss: 0.3427 | Batch size: 32 | lr: 0.01 | Duration: 2.71s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.4571 | Steps: 2 | Val loss: 0.4521 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
== Status ==
Current time: 2024-01-07 08:36:00 (running for 00:04:01.13)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.39  |  0.176 |                   36 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.469 |  0.189 |                   36 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.284 |  0.176 |                   36 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.317 |  0.252 |                   35 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m rmse: 0.17583735287189484
[2m[36m(func pid=104469)[0m mae:  0.1269296556711197
[2m[36m(func pid=104469)[0m rmse_per_class: [0.111, 0.272, 0.096, 0.334, 0.085, 0.192, 0.275, 0.135, 0.151, 0.109]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=105266)[0m rmse: 0.1717292070388794
[2m[36m(func pid=105266)[0m mae:  0.10743241012096405
[2m[36m(func pid=105266)[0m rmse_per_class: [0.103, 0.248, 0.041, 0.356, 0.057, 0.18, 0.25, 0.179, 0.168, 0.136]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.4284 | Steps: 2 | Val loss: 0.7165 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
[2m[36m(func pid=104843)[0m rmse: 0.1878550946712494
[2m[36m(func pid=104843)[0m mae:  0.11819639056921005
[2m[36m(func pid=104843)[0m rmse_per_class: [0.082, 0.263, 0.046, 0.363, 0.056, 0.178, 0.448, 0.154, 0.193, 0.095]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.2319706380367279
[2m[36m(func pid=105685)[0m mae:  0.13074462115764618
[2m[36m(func pid=105685)[0m rmse_per_class: [0.266, 0.273, 0.244, 0.48, 0.055, 0.2, 0.273, 0.153, 0.201, 0.174]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.3913 | Steps: 2 | Val loss: 0.3227 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.2958 | Steps: 2 | Val loss: 0.3367 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.4627 | Steps: 2 | Val loss: 0.4392 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.3297 | Steps: 2 | Val loss: 0.7975 | Batch size: 32 | lr: 0.1 | Duration: 2.73s
== Status ==
Current time: 2024-01-07 08:36:05 (running for 00:04:06.35)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.391 |  0.176 |                   37 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.457 |  0.188 |                   37 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.294 |  0.172 |                   37 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.428 |  0.232 |                   36 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m rmse: 0.17556945979595184
[2m[36m(func pid=104469)[0m mae:  0.12662361562252045
[2m[36m(func pid=104469)[0m rmse_per_class: [0.111, 0.272, 0.095, 0.334, 0.084, 0.192, 0.273, 0.134, 0.152, 0.108]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=105266)[0m rmse: 0.16740332543849945
[2m[36m(func pid=105266)[0m mae:  0.10456043481826782
[2m[36m(func pid=105266)[0m rmse_per_class: [0.104, 0.243, 0.041, 0.356, 0.06, 0.173, 0.236, 0.167, 0.166, 0.126]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.18586544692516327
[2m[36m(func pid=104843)[0m mae:  0.11669269949197769
[2m[36m(func pid=104843)[0m rmse_per_class: [0.082, 0.259, 0.046, 0.361, 0.056, 0.176, 0.429, 0.154, 0.2, 0.095]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.23248739540576935
[2m[36m(func pid=105685)[0m mae:  0.13277706503868103
[2m[36m(func pid=105685)[0m rmse_per_class: [0.143, 0.282, 0.354, 0.451, 0.058, 0.186, 0.274, 0.155, 0.139, 0.283]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.3909 | Steps: 2 | Val loss: 0.3238 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.2661 | Steps: 2 | Val loss: 0.3283 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.4203 | Steps: 2 | Val loss: 0.4244 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.4269 | Steps: 2 | Val loss: 0.8949 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
== Status ==
Current time: 2024-01-07 08:36:10 (running for 00:04:11.57)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.391 |  0.176 |                   37 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.463 |  0.186 |                   38 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.266 |  0.163 |                   39 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.33  |  0.232 |                   37 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=105266)[0m rmse: 0.1630965620279312
[2m[36m(func pid=105266)[0m mae:  0.10130119323730469
[2m[36m(func pid=105266)[0m rmse_per_class: [0.099, 0.24, 0.041, 0.354, 0.061, 0.166, 0.222, 0.163, 0.163, 0.121]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104469)[0m rmse: 0.17519612610340118
[2m[36m(func pid=104469)[0m mae:  0.12621073424816132
[2m[36m(func pid=104469)[0m rmse_per_class: [0.111, 0.272, 0.095, 0.334, 0.083, 0.192, 0.271, 0.134, 0.152, 0.107]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.18442755937576294
[2m[36m(func pid=104843)[0m mae:  0.11552406847476959
[2m[36m(func pid=104843)[0m rmse_per_class: [0.081, 0.257, 0.047, 0.36, 0.056, 0.173, 0.417, 0.154, 0.204, 0.095]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.2267475575208664
[2m[36m(func pid=105685)[0m mae:  0.12980574369430542
[2m[36m(func pid=105685)[0m rmse_per_class: [0.128, 0.289, 0.326, 0.395, 0.058, 0.191, 0.261, 0.136, 0.142, 0.342]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.3919 | Steps: 2 | Val loss: 0.3256 | Batch size: 32 | lr: 0.0001 | Duration: 2.81s
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.2706 | Steps: 2 | Val loss: 0.3231 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.4200 | Steps: 2 | Val loss: 0.4098 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 08:36:15 (running for 00:04:16.80)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.391 |  0.175 |                   38 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.42  |  0.184 |                   39 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.271 |  0.161 |                   40 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.427 |  0.227 |                   38 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)

[2m[36m(func pid=105266)[0m rmse: 0.16060248017311096

[2m[36m(func pid=105266)[0m mae:  0.09946658462285995
[2m[36m(func pid=105266)[0m rmse_per_class: [0.094, 0.24, 0.041, 0.354, 0.065, 0.162, 0.21, 0.161, 0.158, 0.12]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.3896 | Steps: 2 | Val loss: 1.4845 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=104469)[0m rmse: 0.17499712109565735
[2m[36m(func pid=104469)[0m mae:  0.12597084045410156
[2m[36m(func pid=104469)[0m rmse_per_class: [0.111, 0.272, 0.095, 0.336, 0.082, 0.192, 0.27, 0.134, 0.153, 0.106]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.23219120502471924
[2m[36m(func pid=105685)[0m mae:  0.13896463811397552
[2m[36m(func pid=105685)[0m rmse_per_class: [0.115, 0.289, 0.283, 0.399, 0.057, 0.203, 0.274, 0.151, 0.263, 0.287]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.18177124857902527
[2m[36m(func pid=104843)[0m mae:  0.11363925784826279
[2m[36m(func pid=104843)[0m rmse_per_class: [0.08, 0.253, 0.047, 0.357, 0.056, 0.17, 0.397, 0.154, 0.208, 0.095]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.3988 | Steps: 2 | Val loss: 0.3274 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.2639 | Steps: 2 | Val loss: 0.3153 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.3332 | Steps: 2 | Val loss: 7.5355 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 08:36:21 (running for 00:04:22.04)
Memory usage on this node: 24.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.399 |  0.175 |                   40 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.42  |  0.182 |                   40 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.271 |  0.161 |                   40 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.39  |  0.232 |                   39 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m rmse: 0.1746072918176651
[2m[36m(func pid=104469)[0m mae:  0.12551134824752808
[2m[36m(func pid=104469)[0m rmse_per_class: [0.11, 0.272, 0.094, 0.336, 0.081, 0.192, 0.268, 0.134, 0.154, 0.105]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.3989 | Steps: 2 | Val loss: 0.3957 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=105266)[0m rmse: 0.15796731412410736
[2m[36m(func pid=105266)[0m mae:  0.09727094322443008
[2m[36m(func pid=105266)[0m rmse_per_class: [0.09, 0.244, 0.041, 0.349, 0.068, 0.159, 0.203, 0.153, 0.16, 0.112]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.17907309532165527
[2m[36m(func pid=104843)[0m mae:  0.11171026527881622
[2m[36m(func pid=104843)[0m rmse_per_class: [0.079, 0.25, 0.047, 0.353, 0.056, 0.168, 0.376, 0.154, 0.213, 0.095]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.24349896609783173
[2m[36m(func pid=105685)[0m mae:  0.15684908628463745
[2m[36m(func pid=105685)[0m rmse_per_class: [0.113, 0.288, 0.19, 0.394, 0.056, 0.22, 0.289, 0.177, 0.397, 0.309]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.3927 | Steps: 2 | Val loss: 0.3301 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.2857 | Steps: 2 | Val loss: 0.3117 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
== Status ==
Current time: 2024-01-07 08:36:26 (running for 00:04:27.20)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.399 |  0.175 |                   40 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.399 |  0.179 |                   41 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.286 |  0.157 |                   42 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.333 |  0.243 |                   40 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=105266)[0m rmse: 0.1573486626148224
[2m[36m(func pid=105266)[0m mae:  0.09596699476242065
[2m[36m(func pid=105266)[0m rmse_per_class: [0.087, 0.25, 0.041, 0.341, 0.067, 0.158, 0.202, 0.15, 0.16, 0.116]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.3143 | Steps: 2 | Val loss: 33.7712 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
[2m[36m(func pid=104469)[0m rmse: 0.1743832379579544
[2m[36m(func pid=104469)[0m mae:  0.12518957257270813
[2m[36m(func pid=104469)[0m rmse_per_class: [0.111, 0.272, 0.094, 0.337, 0.08, 0.192, 0.267, 0.134, 0.154, 0.104]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.3855 | Steps: 2 | Val loss: 0.3839 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=105685)[0m rmse: 0.2699207365512848
[2m[36m(func pid=105685)[0m mae:  0.18169212341308594
[2m[36m(func pid=105685)[0m rmse_per_class: [0.113, 0.285, 0.129, 0.389, 0.057, 0.232, 0.346, 0.173, 0.702, 0.273]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.17674119770526886
[2m[36m(func pid=104843)[0m mae:  0.10999447107315063
[2m[36m(func pid=104843)[0m rmse_per_class: [0.079, 0.247, 0.047, 0.349, 0.056, 0.167, 0.353, 0.154, 0.22, 0.095]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.2626 | Steps: 2 | Val loss: 0.3076 | Batch size: 32 | lr: 0.01 | Duration: 2.69s
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.3981 | Steps: 2 | Val loss: 0.3327 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=105266)[0m rmse: 0.15732860565185547
[2m[36m(func pid=105266)[0m mae:  0.09568745642900467
[2m[36m(func pid=105266)[0m rmse_per_class: [0.086, 0.255, 0.041, 0.338, 0.068, 0.16, 0.206, 0.145, 0.159, 0.115]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.3256 | Steps: 2 | Val loss: 80.9190 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.3585 | Steps: 2 | Val loss: 0.3686 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
== Status ==
Current time: 2024-01-07 08:36:31 (running for 00:04:32.86)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.398 |  0.174 |                   42 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.386 |  0.177 |                   42 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.263 |  0.157 |                   43 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.314 |  0.27  |                   41 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m rmse: 0.17411886155605316
[2m[36m(func pid=104469)[0m mae:  0.12485937029123306
[2m[36m(func pid=104469)[0m rmse_per_class: [0.111, 0.272, 0.093, 0.337, 0.078, 0.192, 0.265, 0.134, 0.155, 0.104]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.272728830575943
[2m[36m(func pid=105685)[0m mae:  0.18759049475193024
[2m[36m(func pid=105685)[0m rmse_per_class: [0.112, 0.282, 0.115, 0.389, 0.057, 0.233, 0.352, 0.187, 0.896, 0.105]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.2919 | Steps: 2 | Val loss: 0.3059 | Batch size: 32 | lr: 0.01 | Duration: 2.73s
[2m[36m(func pid=104843)[0m rmse: 0.17369745671749115
[2m[36m(func pid=104843)[0m mae:  0.10793624818325043
[2m[36m(func pid=104843)[0m rmse_per_class: [0.078, 0.244, 0.046, 0.344, 0.056, 0.166, 0.337, 0.153, 0.218, 0.095]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.3975 | Steps: 2 | Val loss: 0.3359 | Batch size: 32 | lr: 0.0001 | Duration: 2.75s
[2m[36m(func pid=105266)[0m rmse: 0.1575773060321808
[2m[36m(func pid=105266)[0m mae:  0.09522812813520432
[2m[36m(func pid=105266)[0m rmse_per_class: [0.086, 0.262, 0.04, 0.332, 0.066, 0.161, 0.212, 0.139, 0.16, 0.118]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.3395 | Steps: 2 | Val loss: 122.7829 | Batch size: 32 | lr: 0.1 | Duration: 2.73s
[2m[36m(func pid=104469)[0m rmse: 0.17395862936973572
== Status ==
Current time: 2024-01-07 08:36:37 (running for 00:04:37.96)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.397 |  0.174 |                   43 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.358 |  0.174 |                   43 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.292 |  0.158 |                   44 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.326 |  0.273 |                   42 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)

[2m[36m(func pid=104469)[0m mae:  0.12458153069019318

[2m[36m(func pid=104469)[0m rmse_per_class: [0.112, 0.272, 0.093, 0.338, 0.078, 0.192, 0.264, 0.134, 0.155, 0.103]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.3594 | Steps: 2 | Val loss: 0.3571 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=105685)[0m rmse: 0.2724073529243469
[2m[36m(func pid=105685)[0m mae:  0.18665507435798645
[2m[36m(func pid=105685)[0m rmse_per_class: [0.112, 0.274, 0.123, 0.389, 0.056, 0.233, 0.353, 0.185, 0.898, 0.101]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.2682 | Steps: 2 | Val loss: 0.3053 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=104843)[0m rmse: 0.17056351900100708
[2m[36m(func pid=104843)[0m mae:  0.10593578964471817
[2m[36m(func pid=104843)[0m rmse_per_class: [0.078, 0.24, 0.046, 0.339, 0.056, 0.166, 0.314, 0.153, 0.218, 0.095]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.4026 | Steps: 2 | Val loss: 0.3384 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=105266)[0m rmse: 0.15862895548343658
[2m[36m(func pid=105266)[0m mae:  0.09542827308177948
[2m[36m(func pid=105266)[0m rmse_per_class: [0.086, 0.27, 0.039, 0.329, 0.067, 0.163, 0.218, 0.137, 0.16, 0.118]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.3431 | Steps: 2 | Val loss: 119.7197 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.3297 | Steps: 2 | Val loss: 0.3436 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 08:36:42 (running for 00:04:43.41)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.403 |  0.174 |                   44 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.359 |  0.171 |                   44 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.268 |  0.159 |                   45 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.34  |  0.272 |                   43 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m rmse: 0.17371675372123718
[2m[36m(func pid=104469)[0m mae:  0.12427860498428345
[2m[36m(func pid=104469)[0m rmse_per_class: [0.112, 0.272, 0.091, 0.338, 0.077, 0.191, 0.263, 0.134, 0.156, 0.102]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.2682651877403259
[2m[36m(func pid=105685)[0m mae:  0.18499000370502472
[2m[36m(func pid=105685)[0m rmse_per_class: [0.112, 0.28, 0.102, 0.399, 0.057, 0.233, 0.353, 0.173, 0.879, 0.096]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.2690 | Steps: 2 | Val loss: 0.3047 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=104843)[0m rmse: 0.16718454658985138
[2m[36m(func pid=104843)[0m mae:  0.10387466102838516
[2m[36m(func pid=104843)[0m rmse_per_class: [0.078, 0.237, 0.046, 0.333, 0.056, 0.168, 0.293, 0.152, 0.215, 0.094]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.4069 | Steps: 2 | Val loss: 0.3408 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=105266)[0m rmse: 0.15919078886508942
[2m[36m(func pid=105266)[0m mae:  0.09534984827041626
[2m[36m(func pid=105266)[0m rmse_per_class: [0.087, 0.277, 0.038, 0.328, 0.067, 0.161, 0.221, 0.135, 0.165, 0.111]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.3662 | Steps: 2 | Val loss: 164.2062 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.3320 | Steps: 2 | Val loss: 0.3322 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
== Status ==
Current time: 2024-01-07 08:36:47 (running for 00:04:48.71)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.407 |  0.173 |                   45 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.33  |  0.167 |                   45 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.269 |  0.159 |                   46 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.343 |  0.268 |                   44 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m rmse: 0.17333826422691345
[2m[36m(func pid=104469)[0m mae:  0.12387204170227051
[2m[36m(func pid=104469)[0m rmse_per_class: [0.112, 0.272, 0.09, 0.338, 0.076, 0.191, 0.263, 0.134, 0.156, 0.101]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.2330869436264038
[2m[36m(func pid=105685)[0m mae:  0.1604021042585373
[2m[36m(func pid=105685)[0m rmse_per_class: [0.112, 0.297, 0.042, 0.384, 0.057, 0.233, 0.349, 0.151, 0.612, 0.094]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.1638927161693573
[2m[36m(func pid=104843)[0m mae:  0.10185132920742035
[2m[36m(func pid=104843)[0m rmse_per_class: [0.077, 0.233, 0.046, 0.326, 0.056, 0.171, 0.269, 0.152, 0.215, 0.094]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.2717 | Steps: 2 | Val loss: 0.3051 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.4021 | Steps: 2 | Val loss: 0.3433 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.3169 | Steps: 2 | Val loss: 210.0045 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=105266)[0m rmse: 0.1599782407283783
[2m[36m(func pid=105266)[0m mae:  0.09562412649393082
[2m[36m(func pid=105266)[0m rmse_per_class: [0.088, 0.284, 0.038, 0.329, 0.064, 0.159, 0.223, 0.136, 0.168, 0.112]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.3301 | Steps: 2 | Val loss: 0.3224 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
[2m[36m(func pid=104469)[0m rmse: 0.17315533757209778
[2m[36m(func pid=104469)[0m mae:  0.12357543408870697
[2m[36m(func pid=104469)[0m rmse_per_class: [0.111, 0.272, 0.09, 0.339, 0.075, 0.191, 0.262, 0.134, 0.156, 0.101]
== Status ==
Current time: 2024-01-07 08:36:53 (running for 00:04:54.06)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.402 |  0.173 |                   46 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.332 |  0.164 |                   46 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.272 |  0.16  |                   47 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.366 |  0.233 |                   45 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.2663253843784332
[2m[36m(func pid=105685)[0m mae:  0.18828414380550385
[2m[36m(func pid=105685)[0m rmse_per_class: [0.112, 0.299, 0.039, 0.407, 0.057, 0.233, 0.349, 0.15, 0.923, 0.095]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.2663 | Steps: 2 | Val loss: 0.3074 | Batch size: 32 | lr: 0.01 | Duration: 2.70s
[2m[36m(func pid=104843)[0m rmse: 0.16087444126605988
[2m[36m(func pid=104843)[0m mae:  0.1000874862074852
[2m[36m(func pid=104843)[0m rmse_per_class: [0.078, 0.23, 0.045, 0.319, 0.056, 0.176, 0.246, 0.151, 0.214, 0.094]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.4117 | Steps: 2 | Val loss: 0.3462 | Batch size: 32 | lr: 0.0001 | Duration: 2.79s
[2m[36m(func pid=105266)[0m rmse: 0.16080470383167267
[2m[36m(func pid=105266)[0m mae:  0.09608824551105499
[2m[36m(func pid=105266)[0m rmse_per_class: [0.088, 0.287, 0.039, 0.333, 0.063, 0.157, 0.223, 0.132, 0.177, 0.108]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.4024 | Steps: 2 | Val loss: 74.6335 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.3086 | Steps: 2 | Val loss: 0.3142 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
== Status ==
Current time: 2024-01-07 08:36:58 (running for 00:04:59.23)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.412 |  0.173 |                   47 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.33  |  0.161 |                   47 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.266 |  0.161 |                   48 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.317 |  0.266 |                   46 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m rmse: 0.17292526364326477
[2m[36m(func pid=104469)[0m mae:  0.12321977317333221
[2m[36m(func pid=104469)[0m rmse_per_class: [0.111, 0.272, 0.09, 0.339, 0.074, 0.191, 0.261, 0.134, 0.157, 0.1]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.2743012309074402
[2m[36m(func pid=105685)[0m mae:  0.17654021084308624
[2m[36m(func pid=105685)[0m rmse_per_class: [0.109, 0.265, 0.065, 0.386, 0.056, 0.232, 0.349, 0.156, 0.77, 0.355]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.15882816910743713
[2m[36m(func pid=104843)[0m mae:  0.09906623512506485
[2m[36m(func pid=104843)[0m rmse_per_class: [0.079, 0.227, 0.045, 0.315, 0.056, 0.182, 0.226, 0.15, 0.214, 0.093]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.2633 | Steps: 2 | Val loss: 0.3131 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.4087 | Steps: 2 | Val loss: 0.3492 | Batch size: 32 | lr: 0.0001 | Duration: 2.75s
[2m[36m(func pid=105266)[0m rmse: 0.16229316592216492
[2m[36m(func pid=105266)[0m mae:  0.09727178514003754
[2m[36m(func pid=105266)[0m rmse_per_class: [0.089, 0.29, 0.042, 0.341, 0.062, 0.158, 0.218, 0.132, 0.189, 0.103]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.4247 | Steps: 2 | Val loss: 72.4861 | Batch size: 32 | lr: 0.1 | Duration: 2.71s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.3295 | Steps: 2 | Val loss: 0.3067 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 08:37:03 (running for 00:05:04.31)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.409 |  0.173 |                   48 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.309 |  0.159 |                   48 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.263 |  0.162 |                   49 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.402 |  0.274 |                   47 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m rmse: 0.1727682203054428
[2m[36m(func pid=104469)[0m mae:  0.12298567593097687
[2m[36m(func pid=104469)[0m rmse_per_class: [0.111, 0.272, 0.089, 0.34, 0.073, 0.191, 0.261, 0.134, 0.158, 0.1]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.2932301163673401
[2m[36m(func pid=105685)[0m mae:  0.1816476434469223
[2m[36m(func pid=105685)[0m rmse_per_class: [0.111, 0.278, 0.219, 0.389, 0.056, 0.232, 0.344, 0.171, 0.741, 0.393]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.2573 | Steps: 2 | Val loss: 0.3196 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=104843)[0m rmse: 0.15667888522148132
[2m[36m(func pid=104843)[0m mae:  0.09784145653247833
[2m[36m(func pid=104843)[0m rmse_per_class: [0.081, 0.226, 0.044, 0.306, 0.056, 0.185, 0.211, 0.149, 0.216, 0.093]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.4129 | Steps: 2 | Val loss: 0.3524 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=105266)[0m rmse: 0.16390863060951233
[2m[36m(func pid=105266)[0m mae:  0.09862837940454483
[2m[36m(func pid=105266)[0m rmse_per_class: [0.09, 0.292, 0.044, 0.349, 0.061, 0.16, 0.213, 0.131, 0.198, 0.102]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.5489 | Steps: 2 | Val loss: 12.7391 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.3146 | Steps: 2 | Val loss: 0.3006 | Batch size: 32 | lr: 0.001 | Duration: 2.78s
== Status ==
Current time: 2024-01-07 08:37:08 (running for 00:05:09.64)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.413 |  0.172 |                   49 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.33  |  0.157 |                   49 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.257 |  0.164 |                   50 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.425 |  0.293 |                   48 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m rmse: 0.1724478006362915
[2m[36m(func pid=104469)[0m mae:  0.12254335731267929
[2m[36m(func pid=104469)[0m rmse_per_class: [0.111, 0.272, 0.088, 0.34, 0.072, 0.191, 0.26, 0.134, 0.158, 0.099]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.2941552400588989
[2m[36m(func pid=105685)[0m mae:  0.17610670626163483
[2m[36m(func pid=105685)[0m rmse_per_class: [0.111, 0.299, 0.385, 0.396, 0.056, 0.231, 0.325, 0.178, 0.615, 0.344]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.2595 | Steps: 2 | Val loss: 0.3298 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=104843)[0m rmse: 0.15500861406326294
[2m[36m(func pid=104843)[0m mae:  0.0970555916428566
[2m[36m(func pid=104843)[0m rmse_per_class: [0.081, 0.224, 0.043, 0.299, 0.056, 0.19, 0.2, 0.148, 0.217, 0.093]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.4164 | Steps: 2 | Val loss: 0.3557 | Batch size: 32 | lr: 0.0001 | Duration: 2.81s
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.4809 | Steps: 2 | Val loss: 1.4320 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
[2m[36m(func pid=105266)[0m rmse: 0.16576869785785675
[2m[36m(func pid=105266)[0m mae:  0.10019167512655258
[2m[36m(func pid=105266)[0m rmse_per_class: [0.092, 0.295, 0.045, 0.358, 0.061, 0.162, 0.207, 0.131, 0.209, 0.098]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.3038 | Steps: 2 | Val loss: 0.2943 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
== Status ==
Current time: 2024-01-07 08:37:14 (running for 00:05:15.05)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.416 |  0.172 |                   50 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.315 |  0.155 |                   50 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.26  |  0.166 |                   51 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.549 |  0.294 |                   49 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m rmse: 0.17230133712291718
[2m[36m(func pid=104469)[0m mae:  0.12227793782949448
[2m[36m(func pid=104469)[0m rmse_per_class: [0.112, 0.271, 0.087, 0.34, 0.071, 0.191, 0.259, 0.135, 0.159, 0.098]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.2672502100467682
[2m[36m(func pid=105685)[0m mae:  0.15890777111053467
[2m[36m(func pid=105685)[0m rmse_per_class: [0.111, 0.302, 0.32, 0.392, 0.056, 0.229, 0.289, 0.166, 0.285, 0.522]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.2555 | Steps: 2 | Val loss: 0.3389 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
[2m[36m(func pid=104843)[0m rmse: 0.15338848531246185
[2m[36m(func pid=104843)[0m mae:  0.09641484916210175
[2m[36m(func pid=104843)[0m rmse_per_class: [0.082, 0.222, 0.042, 0.293, 0.056, 0.195, 0.195, 0.146, 0.211, 0.092]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.4155 | Steps: 2 | Val loss: 0.3588 | Batch size: 32 | lr: 0.0001 | Duration: 2.77s
[2m[36m(func pid=105266)[0m rmse: 0.16716641187667847
[2m[36m(func pid=105266)[0m mae:  0.10131227970123291
[2m[36m(func pid=105266)[0m rmse_per_class: [0.097, 0.295, 0.046, 0.363, 0.059, 0.167, 0.202, 0.132, 0.216, 0.095]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.3633 | Steps: 2 | Val loss: 1.3719 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.3023 | Steps: 2 | Val loss: 0.2897 | Batch size: 32 | lr: 0.001 | Duration: 2.75s
== Status ==
Current time: 2024-01-07 08:37:19 (running for 00:05:20.20)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.416 |  0.172 |                   51 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.304 |  0.153 |                   51 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.255 |  0.167 |                   52 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.481 |  0.267 |                   50 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m rmse: 0.17224547266960144
[2m[36m(func pid=104469)[0m mae:  0.12210246175527573
[2m[36m(func pid=104469)[0m rmse_per_class: [0.112, 0.271, 0.086, 0.341, 0.07, 0.191, 0.259, 0.135, 0.159, 0.098]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.24197514355182648
[2m[36m(func pid=105685)[0m mae:  0.15329958498477936
[2m[36m(func pid=105685)[0m rmse_per_class: [0.111, 0.297, 0.089, 0.355, 0.056, 0.231, 0.316, 0.19, 0.14, 0.634]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.2510 | Steps: 2 | Val loss: 0.3449 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
[2m[36m(func pid=104843)[0m rmse: 0.1521659791469574
[2m[36m(func pid=104843)[0m mae:  0.09588998556137085
[2m[36m(func pid=104843)[0m rmse_per_class: [0.082, 0.22, 0.041, 0.288, 0.056, 0.2, 0.194, 0.143, 0.206, 0.091]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.4201 | Steps: 2 | Val loss: 0.3617 | Batch size: 32 | lr: 0.0001 | Duration: 2.72s
[2m[36m(func pid=105266)[0m rmse: 0.16783587634563446
[2m[36m(func pid=105266)[0m mae:  0.10202164947986603
[2m[36m(func pid=105266)[0m rmse_per_class: [0.106, 0.287, 0.047, 0.366, 0.062, 0.17, 0.198, 0.13, 0.219, 0.093]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.5451 | Steps: 2 | Val loss: 1.5514 | Batch size: 32 | lr: 0.1 | Duration: 2.72s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.3051 | Steps: 2 | Val loss: 0.2849 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=104469)[0m rmse: 0.17201313376426697
[2m[36m(func pid=104469)[0m mae:  0.12173040956258774
[2m[36m(func pid=104469)[0m rmse_per_class: [0.111, 0.271, 0.085, 0.341, 0.07, 0.191, 0.259, 0.135, 0.16, 0.097]
== Status ==
Current time: 2024-01-07 08:37:24 (running for 00:05:25.31)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.42  |  0.172 |                   52 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.302 |  0.152 |                   52 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.251 |  0.168 |                   53 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.363 |  0.242 |                   51 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.22888191044330597
[2m[36m(func pid=105685)[0m mae:  0.14439180493354797
[2m[36m(func pid=105685)[0m rmse_per_class: [0.11, 0.297, 0.05, 0.34, 0.056, 0.228, 0.304, 0.166, 0.14, 0.598]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.2594 | Steps: 2 | Val loss: 0.3505 | Batch size: 32 | lr: 0.01 | Duration: 2.66s
[2m[36m(func pid=104843)[0m rmse: 0.1507546603679657
[2m[36m(func pid=104843)[0m mae:  0.0951056033372879
[2m[36m(func pid=104843)[0m rmse_per_class: [0.08, 0.218, 0.041, 0.282, 0.056, 0.206, 0.196, 0.138, 0.2, 0.091]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.4172 | Steps: 2 | Val loss: 0.3642 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=105266)[0m rmse: 0.16847243905067444
[2m[36m(func pid=105266)[0m mae:  0.10245189815759659
[2m[36m(func pid=105266)[0m rmse_per_class: [0.118, 0.279, 0.047, 0.365, 0.061, 0.175, 0.195, 0.13, 0.223, 0.091]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.5109 | Steps: 2 | Val loss: 2.2950 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.3159 | Steps: 2 | Val loss: 0.2810 | Batch size: 32 | lr: 0.001 | Duration: 2.74s
[2m[36m(func pid=104469)[0m rmse: 0.17176814377307892
[2m[36m(func pid=104469)[0m mae:  0.12137522548437119
[2m[36m(func pid=104469)[0m rmse_per_class: [0.111, 0.271, 0.084, 0.342, 0.069, 0.19, 0.259, 0.135, 0.16, 0.097]
== Status ==
Current time: 2024-01-07 08:37:29 (running for 00:05:30.57)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.417 |  0.172 |                   53 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.305 |  0.151 |                   53 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.259 |  0.168 |                   54 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.545 |  0.229 |                   52 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.23816268146038055
[2m[36m(func pid=105685)[0m mae:  0.14363262057304382
[2m[36m(func pid=105685)[0m rmse_per_class: [0.111, 0.298, 0.049, 0.374, 0.056, 0.227, 0.331, 0.294, 0.14, 0.501]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.2544 | Steps: 2 | Val loss: 0.3568 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=104843)[0m rmse: 0.1491212099790573
[2m[36m(func pid=104843)[0m mae:  0.09430553019046783
[2m[36m(func pid=104843)[0m rmse_per_class: [0.08, 0.217, 0.04, 0.275, 0.056, 0.206, 0.2, 0.135, 0.193, 0.09]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.4275 | Steps: 2 | Val loss: 0.3673 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=105266)[0m rmse: 0.16987228393554688
[2m[36m(func pid=105266)[0m mae:  0.10348285734653473
[2m[36m(func pid=105266)[0m rmse_per_class: [0.136, 0.273, 0.047, 0.364, 0.06, 0.177, 0.195, 0.129, 0.226, 0.091]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.4207 | Steps: 2 | Val loss: 2.6618 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.3090 | Steps: 2 | Val loss: 0.2807 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
== Status ==
Current time: 2024-01-07 08:37:34 (running for 00:05:35.77)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.428 |  0.172 |                   54 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.316 |  0.149 |                   54 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.254 |  0.17  |                   55 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.511 |  0.238 |                   53 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m rmse: 0.1715918779373169
[2m[36m(func pid=104469)[0m mae:  0.12103774398565292
[2m[36m(func pid=104469)[0m rmse_per_class: [0.111, 0.271, 0.083, 0.343, 0.068, 0.19, 0.259, 0.135, 0.16, 0.096]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.24187013506889343
[2m[36m(func pid=105685)[0m mae:  0.14178109169006348
[2m[36m(func pid=105685)[0m rmse_per_class: [0.114, 0.3, 0.049, 0.377, 0.056, 0.231, 0.385, 0.357, 0.14, 0.409]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.2578 | Steps: 2 | Val loss: 0.3660 | Batch size: 32 | lr: 0.01 | Duration: 2.71s
[2m[36m(func pid=104843)[0m rmse: 0.1491287648677826
[2m[36m(func pid=104843)[0m mae:  0.09466147422790527
[2m[36m(func pid=104843)[0m rmse_per_class: [0.081, 0.216, 0.038, 0.273, 0.056, 0.208, 0.207, 0.132, 0.191, 0.09]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.4230 | Steps: 2 | Val loss: 0.3695 | Batch size: 32 | lr: 0.0001 | Duration: 2.78s
[2m[36m(func pid=105266)[0m rmse: 0.17161326110363007
[2m[36m(func pid=105266)[0m mae:  0.1045040637254715
[2m[36m(func pid=105266)[0m rmse_per_class: [0.151, 0.269, 0.048, 0.363, 0.06, 0.179, 0.195, 0.129, 0.231, 0.09]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.4120 | Steps: 2 | Val loss: 2.8278 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.3146 | Steps: 2 | Val loss: 0.2796 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 08:37:40 (running for 00:05:40.92)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.423 |  0.171 |                   55 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.309 |  0.149 |                   55 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.258 |  0.172 |                   56 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.421 |  0.242 |                   54 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m rmse: 0.17141687870025635
[2m[36m(func pid=104469)[0m mae:  0.12076624482870102
[2m[36m(func pid=104469)[0m rmse_per_class: [0.111, 0.271, 0.082, 0.343, 0.067, 0.19, 0.259, 0.135, 0.161, 0.096]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.22864839434623718
[2m[36m(func pid=105685)[0m mae:  0.13644811511039734
[2m[36m(func pid=105685)[0m rmse_per_class: [0.112, 0.301, 0.049, 0.356, 0.056, 0.231, 0.467, 0.159, 0.14, 0.415]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.2649 | Steps: 2 | Val loss: 0.3709 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=104843)[0m rmse: 0.14870503544807434
[2m[36m(func pid=104843)[0m mae:  0.09475292265415192
[2m[36m(func pid=104843)[0m rmse_per_class: [0.08, 0.216, 0.037, 0.272, 0.056, 0.208, 0.214, 0.126, 0.19, 0.089]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.4295 | Steps: 2 | Val loss: 0.3712 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=105266)[0m rmse: 0.17265644669532776
[2m[36m(func pid=105266)[0m mae:  0.10540105402469635
[2m[36m(func pid=105266)[0m rmse_per_class: [0.164, 0.266, 0.048, 0.361, 0.06, 0.178, 0.195, 0.129, 0.232, 0.091]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.3984 | Steps: 2 | Val loss: 2.7873 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.3167 | Steps: 2 | Val loss: 0.2788 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 08:37:45 (running for 00:05:46.22)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.43  |  0.171 |                   56 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.315 |  0.149 |                   56 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.265 |  0.173 |                   57 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.412 |  0.229 |                   55 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m rmse: 0.17123420536518097
[2m[36m(func pid=104469)[0m mae:  0.12047926336526871
[2m[36m(func pid=104469)[0m rmse_per_class: [0.11, 0.27, 0.081, 0.343, 0.066, 0.19, 0.259, 0.136, 0.161, 0.095]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.2570 | Steps: 2 | Val loss: 0.3709 | Batch size: 32 | lr: 0.01 | Duration: 2.71s
[2m[36m(func pid=105685)[0m rmse: 0.2405575066804886
[2m[36m(func pid=105685)[0m mae:  0.14539912343025208
[2m[36m(func pid=105685)[0m rmse_per_class: [0.112, 0.301, 0.049, 0.392, 0.056, 0.232, 0.427, 0.179, 0.14, 0.517]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.14805106818675995
[2m[36m(func pid=104843)[0m mae:  0.09462473541498184
[2m[36m(func pid=104843)[0m rmse_per_class: [0.079, 0.215, 0.037, 0.269, 0.056, 0.206, 0.222, 0.122, 0.187, 0.088]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.4312 | Steps: 2 | Val loss: 0.3742 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=105266)[0m rmse: 0.1722528636455536
[2m[36m(func pid=105266)[0m mae:  0.10504069179296494
[2m[36m(func pid=105266)[0m rmse_per_class: [0.168, 0.264, 0.048, 0.358, 0.062, 0.175, 0.195, 0.128, 0.231, 0.092]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.3733 | Steps: 2 | Val loss: 2.6548 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.3128 | Steps: 2 | Val loss: 0.2791 | Batch size: 32 | lr: 0.001 | Duration: 2.78s
== Status ==
Current time: 2024-01-07 08:37:50 (running for 00:05:51.51)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.431 |  0.171 |                   57 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.317 |  0.148 |                   57 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.257 |  0.172 |                   58 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.398 |  0.241 |                   56 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m rmse: 0.1711590737104416
[2m[36m(func pid=104469)[0m mae:  0.12024122476577759
[2m[36m(func pid=104469)[0m rmse_per_class: [0.111, 0.27, 0.08, 0.344, 0.066, 0.19, 0.258, 0.136, 0.162, 0.095]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.2743 | Steps: 2 | Val loss: 0.3773 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=105685)[0m rmse: 0.25768691301345825
[2m[36m(func pid=105685)[0m mae:  0.15178446471691132
[2m[36m(func pid=105685)[0m rmse_per_class: [0.112, 0.302, 0.049, 0.492, 0.056, 0.232, 0.364, 0.272, 0.14, 0.558]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.14805036783218384
[2m[36m(func pid=104843)[0m mae:  0.09492706507444382
[2m[36m(func pid=104843)[0m rmse_per_class: [0.078, 0.214, 0.036, 0.268, 0.056, 0.206, 0.229, 0.118, 0.189, 0.087]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.4285 | Steps: 2 | Val loss: 0.3760 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=105266)[0m rmse: 0.17276212573051453
[2m[36m(func pid=105266)[0m mae:  0.10542192310094833
[2m[36m(func pid=105266)[0m rmse_per_class: [0.175, 0.263, 0.047, 0.356, 0.063, 0.172, 0.195, 0.127, 0.237, 0.093]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.3783 | Steps: 2 | Val loss: 2.2216 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.3092 | Steps: 2 | Val loss: 0.2782 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
== Status ==
Current time: 2024-01-07 08:37:55 (running for 00:05:56.70)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.429 |  0.171 |                   58 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.313 |  0.148 |                   58 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.274 |  0.173 |                   59 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.373 |  0.258 |                   57 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m rmse: 0.17087185382843018
[2m[36m(func pid=104469)[0m mae:  0.11987868696451187
[2m[36m(func pid=104469)[0m rmse_per_class: [0.11, 0.27, 0.079, 0.344, 0.065, 0.19, 0.258, 0.136, 0.162, 0.095]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.2522 | Steps: 2 | Val loss: 0.3763 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
[2m[36m(func pid=105685)[0m rmse: 0.2495773285627365
[2m[36m(func pid=105685)[0m mae:  0.14874053001403809
[2m[36m(func pid=105685)[0m rmse_per_class: [0.112, 0.302, 0.048, 0.471, 0.057, 0.231, 0.34, 0.17, 0.14, 0.626]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.1474321186542511
[2m[36m(func pid=104843)[0m mae:  0.09462939202785492
[2m[36m(func pid=104843)[0m rmse_per_class: [0.074, 0.213, 0.035, 0.265, 0.056, 0.206, 0.237, 0.114, 0.187, 0.086]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105266)[0m rmse: 0.17236614227294922
[2m[36m(func pid=105266)[0m mae:  0.10542882978916168
[2m[36m(func pid=105266)[0m rmse_per_class: [0.178, 0.262, 0.049, 0.354, 0.064, 0.168, 0.195, 0.125, 0.236, 0.093]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.4332 | Steps: 2 | Val loss: 0.3779 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.3840 | Steps: 2 | Val loss: 1.9450 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.3179 | Steps: 2 | Val loss: 0.2778 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 08:38:00 (running for 00:06:01.87)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.433 |  0.171 |                   59 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.309 |  0.147 |                   59 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.252 |  0.172 |                   60 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.378 |  0.25  |                   58 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m rmse: 0.17084023356437683
[2m[36m(func pid=104469)[0m mae:  0.11970096826553345
[2m[36m(func pid=104469)[0m rmse_per_class: [0.11, 0.27, 0.078, 0.344, 0.064, 0.189, 0.258, 0.137, 0.163, 0.094]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.2464 | Steps: 2 | Val loss: 0.3734 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
[2m[36m(func pid=105685)[0m rmse: 0.24136824905872345
[2m[36m(func pid=105685)[0m mae:  0.14877848327159882
[2m[36m(func pid=105685)[0m rmse_per_class: [0.112, 0.303, 0.056, 0.329, 0.056, 0.227, 0.394, 0.143, 0.14, 0.655]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.14703312516212463
[2m[36m(func pid=104843)[0m mae:  0.09472176432609558
[2m[36m(func pid=104843)[0m rmse_per_class: [0.074, 0.213, 0.034, 0.265, 0.056, 0.203, 0.243, 0.11, 0.186, 0.085]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105266)[0m rmse: 0.17161977291107178
[2m[36m(func pid=105266)[0m mae:  0.10470900684595108
[2m[36m(func pid=105266)[0m rmse_per_class: [0.173, 0.262, 0.05, 0.352, 0.065, 0.163, 0.197, 0.124, 0.236, 0.094]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.4317 | Steps: 2 | Val loss: 0.3798 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.3614 | Steps: 2 | Val loss: 1.7173 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.3223 | Steps: 2 | Val loss: 0.2778 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
== Status ==
Current time: 2024-01-07 08:38:06 (running for 00:06:07.13)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.432 |  0.171 |                   60 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.318 |  0.147 |                   60 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.246 |  0.172 |                   61 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.384 |  0.241 |                   59 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m rmse: 0.17085158824920654
[2m[36m(func pid=104469)[0m mae:  0.11959592998027802
[2m[36m(func pid=104469)[0m rmse_per_class: [0.11, 0.27, 0.077, 0.344, 0.064, 0.189, 0.258, 0.137, 0.165, 0.094]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.2506 | Steps: 2 | Val loss: 0.3668 | Batch size: 32 | lr: 0.01 | Duration: 2.66s
[2m[36m(func pid=105685)[0m rmse: 0.2459835261106491
[2m[36m(func pid=105685)[0m mae:  0.1527339220046997
[2m[36m(func pid=105685)[0m rmse_per_class: [0.111, 0.302, 0.055, 0.367, 0.057, 0.219, 0.526, 0.135, 0.144, 0.544]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.14690425992012024
[2m[36m(func pid=104843)[0m mae:  0.0948508232831955
[2m[36m(func pid=104843)[0m rmse_per_class: [0.073, 0.213, 0.033, 0.265, 0.056, 0.198, 0.251, 0.108, 0.189, 0.085]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105266)[0m rmse: 0.17006781697273254
[2m[36m(func pid=105266)[0m mae:  0.10364160686731339
[2m[36m(func pid=105266)[0m rmse_per_class: [0.159, 0.261, 0.051, 0.348, 0.066, 0.158, 0.201, 0.124, 0.238, 0.095]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.4393 | Steps: 2 | Val loss: 0.3824 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.4002 | Steps: 2 | Val loss: 1.5437 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.3108 | Steps: 2 | Val loss: 0.2759 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 08:38:11 (running for 00:06:12.38)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.439 |  0.171 |                   61 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.322 |  0.147 |                   61 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.251 |  0.17  |                   62 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.361 |  0.246 |                   60 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m rmse: 0.17065447568893433
[2m[36m(func pid=104469)[0m mae:  0.11926932632923126
[2m[36m(func pid=104469)[0m rmse_per_class: [0.11, 0.27, 0.076, 0.344, 0.063, 0.189, 0.258, 0.137, 0.166, 0.094]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.2532 | Steps: 2 | Val loss: 0.3591 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
[2m[36m(func pid=105685)[0m rmse: 0.23533327877521515
[2m[36m(func pid=105685)[0m mae:  0.1466347575187683
[2m[36m(func pid=105685)[0m rmse_per_class: [0.111, 0.3, 0.057, 0.368, 0.058, 0.223, 0.453, 0.148, 0.151, 0.484]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.1456102728843689
[2m[36m(func pid=104843)[0m mae:  0.0942653939127922
[2m[36m(func pid=104843)[0m rmse_per_class: [0.072, 0.212, 0.032, 0.264, 0.056, 0.192, 0.256, 0.106, 0.184, 0.084]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105266)[0m rmse: 0.16857510805130005
[2m[36m(func pid=105266)[0m mae:  0.1026138886809349
[2m[36m(func pid=105266)[0m rmse_per_class: [0.143, 0.26, 0.053, 0.344, 0.066, 0.154, 0.207, 0.123, 0.24, 0.096]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.4402 | Steps: 2 | Val loss: 0.3841 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.3924 | Steps: 2 | Val loss: 1.3757 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.3114 | Steps: 2 | Val loss: 0.2748 | Batch size: 32 | lr: 0.001 | Duration: 2.75s
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.2496 | Steps: 2 | Val loss: 0.3512 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
== Status ==
Current time: 2024-01-07 08:38:16 (running for 00:06:17.60)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.44  |  0.17  |                   62 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.311 |  0.146 |                   62 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.253 |  0.169 |                   63 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.4   |  0.235 |                   61 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m rmse: 0.17044438421726227
[2m[36m(func pid=104469)[0m mae:  0.11891709268093109
[2m[36m(func pid=104469)[0m rmse_per_class: [0.11, 0.27, 0.074, 0.344, 0.063, 0.189, 0.258, 0.137, 0.165, 0.094]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.2478923499584198
[2m[36m(func pid=105685)[0m mae:  0.1573900282382965
[2m[36m(func pid=105685)[0m rmse_per_class: [0.113, 0.299, 0.152, 0.369, 0.06, 0.224, 0.299, 0.162, 0.164, 0.639]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.1447722464799881
[2m[36m(func pid=104843)[0m mae:  0.09375660121440887
[2m[36m(func pid=104843)[0m rmse_per_class: [0.07, 0.211, 0.031, 0.262, 0.055, 0.187, 0.261, 0.105, 0.181, 0.084]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105266)[0m rmse: 0.1671842783689499
[2m[36m(func pid=105266)[0m mae:  0.10155026614665985
[2m[36m(func pid=105266)[0m rmse_per_class: [0.128, 0.262, 0.053, 0.342, 0.065, 0.152, 0.212, 0.124, 0.238, 0.096]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.4456 | Steps: 2 | Val loss: 0.3845 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.3433 | Steps: 2 | Val loss: 1.3933 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.3115 | Steps: 2 | Val loss: 0.2744 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.2671 | Steps: 2 | Val loss: 0.3457 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
== Status ==
Current time: 2024-01-07 08:38:22 (running for 00:06:22.95)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.446 |  0.17  |                   63 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.311 |  0.145 |                   63 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.25  |  0.167 |                   64 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.392 |  0.248 |                   62 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m rmse: 0.17031309008598328
[2m[36m(func pid=104469)[0m mae:  0.11869863420724869
[2m[36m(func pid=104469)[0m rmse_per_class: [0.11, 0.269, 0.074, 0.344, 0.062, 0.189, 0.259, 0.137, 0.165, 0.093]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.26865798234939575
[2m[36m(func pid=105685)[0m mae:  0.16960972547531128
[2m[36m(func pid=105685)[0m rmse_per_class: [0.12, 0.291, 0.277, 0.378, 0.061, 0.225, 0.321, 0.164, 0.176, 0.674]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.14453701674938202
[2m[36m(func pid=104843)[0m mae:  0.09371790289878845
[2m[36m(func pid=104843)[0m rmse_per_class: [0.069, 0.21, 0.031, 0.262, 0.055, 0.181, 0.265, 0.106, 0.181, 0.085]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105266)[0m rmse: 0.16665145754814148
[2m[36m(func pid=105266)[0m mae:  0.10102401673793793
[2m[36m(func pid=105266)[0m rmse_per_class: [0.112, 0.266, 0.053, 0.34, 0.068, 0.151, 0.22, 0.12, 0.238, 0.097]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.4408 | Steps: 2 | Val loss: 0.3854 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.3401 | Steps: 2 | Val loss: 1.3639 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.3109 | Steps: 2 | Val loss: 0.2737 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.2431 | Steps: 2 | Val loss: 0.3430 | Batch size: 32 | lr: 0.01 | Duration: 2.64s
== Status ==
Current time: 2024-01-07 08:38:27 (running for 00:06:28.25)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.441 |  0.17  |                   64 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.312 |  0.145 |                   64 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.267 |  0.167 |                   65 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.343 |  0.269 |                   63 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m rmse: 0.16991370916366577
[2m[36m(func pid=104469)[0m mae:  0.1182166114449501
[2m[36m(func pid=104469)[0m rmse_per_class: [0.109, 0.269, 0.072, 0.344, 0.062, 0.189, 0.259, 0.138, 0.165, 0.093]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.2603892982006073
[2m[36m(func pid=105685)[0m mae:  0.16630280017852783
[2m[36m(func pid=105685)[0m rmse_per_class: [0.136, 0.283, 0.243, 0.38, 0.062, 0.226, 0.327, 0.155, 0.168, 0.623]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.14403043687343597
[2m[36m(func pid=104843)[0m mae:  0.09332127869129181
[2m[36m(func pid=104843)[0m rmse_per_class: [0.067, 0.209, 0.03, 0.262, 0.055, 0.175, 0.269, 0.109, 0.178, 0.085]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105266)[0m rmse: 0.1666007936000824
[2m[36m(func pid=105266)[0m mae:  0.10114504396915436
[2m[36m(func pid=105266)[0m rmse_per_class: [0.102, 0.267, 0.054, 0.338, 0.069, 0.15, 0.227, 0.118, 0.243, 0.098]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.4431 | Steps: 2 | Val loss: 0.3872 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.3660 | Steps: 2 | Val loss: 1.3619 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.3032 | Steps: 2 | Val loss: 0.2739 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.2712 | Steps: 2 | Val loss: 0.3453 | Batch size: 32 | lr: 0.01 | Duration: 2.76s
== Status ==
Current time: 2024-01-07 08:38:32 (running for 00:06:33.53)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.443 |  0.17  |                   65 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.311 |  0.144 |                   65 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.243 |  0.167 |                   66 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.34  |  0.26  |                   64 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m rmse: 0.1697073131799698
[2m[36m(func pid=104469)[0m mae:  0.11790581792593002
[2m[36m(func pid=104469)[0m rmse_per_class: [0.109, 0.268, 0.071, 0.344, 0.061, 0.189, 0.259, 0.138, 0.165, 0.093]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.2573239207267761
[2m[36m(func pid=105685)[0m mae:  0.16243138909339905
[2m[36m(func pid=105685)[0m rmse_per_class: [0.164, 0.278, 0.256, 0.379, 0.063, 0.226, 0.323, 0.152, 0.155, 0.579]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.14444944262504578
[2m[36m(func pid=104843)[0m mae:  0.09362717717885971
[2m[36m(func pid=104843)[0m rmse_per_class: [0.066, 0.209, 0.029, 0.263, 0.055, 0.172, 0.272, 0.112, 0.18, 0.086]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105266)[0m rmse: 0.16741736233234406
[2m[36m(func pid=105266)[0m mae:  0.10152103751897812
[2m[36m(func pid=105266)[0m rmse_per_class: [0.095, 0.266, 0.052, 0.336, 0.07, 0.15, 0.232, 0.119, 0.255, 0.099]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.4343 | Steps: 2 | Val loss: 0.3881 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.4517 | Steps: 2 | Val loss: 1.0489 | Batch size: 32 | lr: 0.1 | Duration: 2.78s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.3070 | Steps: 2 | Val loss: 0.2744 | Batch size: 32 | lr: 0.001 | Duration: 3.06s
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.2650 | Steps: 2 | Val loss: 0.3491 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 08:38:37 (running for 00:06:38.64)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.443 |  0.17  |                   65 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.303 |  0.144 |                   66 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.271 |  0.167 |                   67 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.452 |  0.248 |                   66 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104469)[0m rmse: 0.1696847528219223
[2m[36m(func pid=104469)[0m mae:  0.11770378053188324
[2m[36m(func pid=104469)[0m rmse_per_class: [0.109, 0.268, 0.07, 0.344, 0.061, 0.189, 0.26, 0.138, 0.165, 0.093]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=105685)[0m rmse: 0.24794700741767883
[2m[36m(func pid=105685)[0m mae:  0.15469345450401306
[2m[36m(func pid=105685)[0m rmse_per_class: [0.181, 0.272, 0.18, 0.376, 0.068, 0.224, 0.306, 0.145, 0.146, 0.582]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.1449219286441803
[2m[36m(func pid=104843)[0m mae:  0.09380368143320084
[2m[36m(func pid=104843)[0m rmse_per_class: [0.066, 0.209, 0.029, 0.264, 0.055, 0.169, 0.275, 0.115, 0.18, 0.087]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105266)[0m rmse: 0.16861672699451447
[2m[36m(func pid=105266)[0m mae:  0.10225961357355118
[2m[36m(func pid=105266)[0m rmse_per_class: [0.09, 0.266, 0.052, 0.334, 0.07, 0.15, 0.235, 0.119, 0.271, 0.099]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.3504 | Steps: 2 | Val loss: 0.7837 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.4337 | Steps: 2 | Val loss: 0.3890 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.3022 | Steps: 2 | Val loss: 0.2749 | Batch size: 32 | lr: 0.001 | Duration: 2.78s
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.2505 | Steps: 2 | Val loss: 0.3453 | Batch size: 32 | lr: 0.01 | Duration: 2.63s
== Status ==
Current time: 2024-01-07 08:38:42 (running for 00:06:43.83)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.17  |                   66 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.307 |  0.145 |                   67 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.265 |  0.169 |                   68 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.35  |  0.229 |                   67 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=105685)[0m rmse: 0.22898149490356445
[2m[36m(func pid=105685)[0m mae:  0.14221897721290588
[2m[36m(func pid=105685)[0m rmse_per_class: [0.152, 0.262, 0.093, 0.374, 0.068, 0.223, 0.293, 0.138, 0.136, 0.552]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=104469)[0m rmse: 0.16950426995754242
[2m[36m(func pid=104469)[0m mae:  0.11744888126850128
[2m[36m(func pid=104469)[0m rmse_per_class: [0.108, 0.268, 0.069, 0.344, 0.061, 0.189, 0.261, 0.138, 0.165, 0.093]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.14557692408561707
[2m[36m(func pid=104843)[0m mae:  0.0941157191991806
[2m[36m(func pid=104843)[0m rmse_per_class: [0.065, 0.209, 0.028, 0.265, 0.055, 0.167, 0.277, 0.12, 0.181, 0.089]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105266)[0m rmse: 0.1681557148694992
[2m[36m(func pid=105266)[0m mae:  0.10262365639209747
[2m[36m(func pid=105266)[0m rmse_per_class: [0.088, 0.261, 0.053, 0.332, 0.071, 0.15, 0.235, 0.117, 0.277, 0.1]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.3856 | Steps: 2 | Val loss: 0.7295 | Batch size: 32 | lr: 0.1 | Duration: 2.74s
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.4375 | Steps: 2 | Val loss: 0.3894 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.2999 | Steps: 2 | Val loss: 0.2761 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.2659 | Steps: 2 | Val loss: 0.3441 | Batch size: 32 | lr: 0.01 | Duration: 2.68s
[2m[36m(func pid=105685)[0m rmse: 0.2217201441526413
[2m[36m(func pid=105685)[0m mae:  0.13775299489498138
[2m[36m(func pid=105685)[0m rmse_per_class: [0.136, 0.253, 0.068, 0.384, 0.066, 0.226, 0.288, 0.152, 0.137, 0.506]
== Status ==
Current time: 2024-01-07 08:38:48 (running for 00:06:49.05)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.17  |                   67 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.302 |  0.146 |                   68 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.25  |  0.168 |                   69 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.386 |  0.222 |                   68 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=104469)[0m rmse: 0.16931527853012085
[2m[36m(func pid=104469)[0m mae:  0.11716800928115845
[2m[36m(func pid=104469)[0m rmse_per_class: [0.108, 0.268, 0.068, 0.345, 0.06, 0.188, 0.262, 0.138, 0.164, 0.093]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.14691370725631714
[2m[36m(func pid=104843)[0m mae:  0.09469114243984222
[2m[36m(func pid=104843)[0m rmse_per_class: [0.064, 0.21, 0.028, 0.265, 0.054, 0.165, 0.279, 0.128, 0.18, 0.094]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105266)[0m rmse: 0.1687057763338089
[2m[36m(func pid=105266)[0m mae:  0.10320816189050674
[2m[36m(func pid=105266)[0m rmse_per_class: [0.087, 0.258, 0.054, 0.331, 0.077, 0.15, 0.234, 0.117, 0.279, 0.1]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.3359 | Steps: 2 | Val loss: 0.6770 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.4329 | Steps: 2 | Val loss: 0.3911 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.3017 | Steps: 2 | Val loss: 0.2773 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.2524 | Steps: 2 | Val loss: 0.3416 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
== Status ==
Current time: 2024-01-07 08:38:53 (running for 00:06:54.15)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.438 |  0.169 |                   68 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.3   |  0.147 |                   69 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.266 |  0.169 |                   70 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.221 |                   69 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=105685)[0m rmse: 0.22133028507232666
[2m[36m(func pid=105685)[0m mae:  0.13718874752521515
[2m[36m(func pid=105685)[0m rmse_per_class: [0.122, 0.248, 0.088, 0.412, 0.058, 0.227, 0.303, 0.151, 0.139, 0.464]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=104469)[0m rmse: 0.16910050809383392
[2m[36m(func pid=104469)[0m mae:  0.11686019599437714
[2m[36m(func pid=104469)[0m rmse_per_class: [0.108, 0.268, 0.067, 0.344, 0.06, 0.188, 0.261, 0.139, 0.164, 0.092]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.14815133810043335
[2m[36m(func pid=104843)[0m mae:  0.09519441425800323
[2m[36m(func pid=104843)[0m rmse_per_class: [0.064, 0.211, 0.028, 0.265, 0.054, 0.165, 0.28, 0.137, 0.179, 0.099]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105266)[0m rmse: 0.1689940243959427
[2m[36m(func pid=105266)[0m mae:  0.10379679501056671
[2m[36m(func pid=105266)[0m rmse_per_class: [0.087, 0.254, 0.055, 0.332, 0.081, 0.151, 0.233, 0.119, 0.279, 0.101]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.3690 | Steps: 2 | Val loss: 0.6389 | Batch size: 32 | lr: 0.1 | Duration: 3.01s
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.4470 | Steps: 2 | Val loss: 0.3915 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.2917 | Steps: 2 | Val loss: 0.2789 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.2499 | Steps: 2 | Val loss: 0.3347 | Batch size: 32 | lr: 0.01 | Duration: 2.64s
== Status ==
Current time: 2024-01-07 08:38:58 (running for 00:06:59.46)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.433 |  0.169 |                   69 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.302 |  0.148 |                   70 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.252 |  0.169 |                   71 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.369 |  0.227 |                   70 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=105685)[0m rmse: 0.2273283302783966
[2m[36m(func pid=105685)[0m mae:  0.13986527919769287
[2m[36m(func pid=105685)[0m rmse_per_class: [0.114, 0.249, 0.124, 0.43, 0.054, 0.232, 0.336, 0.142, 0.139, 0.453]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=104469)[0m rmse: 0.16905878484249115
[2m[36m(func pid=104469)[0m mae:  0.11673841625452042
[2m[36m(func pid=104469)[0m rmse_per_class: [0.107, 0.268, 0.066, 0.344, 0.059, 0.188, 0.262, 0.139, 0.166, 0.092]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.14972545206546783
[2m[36m(func pid=104843)[0m mae:  0.09595884382724762
[2m[36m(func pid=104843)[0m rmse_per_class: [0.064, 0.213, 0.028, 0.264, 0.054, 0.165, 0.28, 0.146, 0.177, 0.105]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105266)[0m rmse: 0.16744068264961243
[2m[36m(func pid=105266)[0m mae:  0.10315276682376862
[2m[36m(func pid=105266)[0m rmse_per_class: [0.087, 0.246, 0.055, 0.33, 0.084, 0.151, 0.229, 0.118, 0.271, 0.103]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.3475 | Steps: 2 | Val loss: 0.5567 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.4349 | Steps: 2 | Val loss: 0.3916 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.2587 | Steps: 2 | Val loss: 0.3322 | Batch size: 32 | lr: 0.01 | Duration: 2.64s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.2962 | Steps: 2 | Val loss: 0.2813 | Batch size: 32 | lr: 0.001 | Duration: 2.71s
== Status ==
Current time: 2024-01-07 08:39:03 (running for 00:07:04.71)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.447 |  0.169 |                   70 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.292 |  0.15  |                   71 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.25  |  0.167 |                   72 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.347 |  0.226 |                   71 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=105685)[0m rmse: 0.22646300494670868
[2m[36m(func pid=105685)[0m mae:  0.13728439807891846
[2m[36m(func pid=105685)[0m rmse_per_class: [0.112, 0.256, 0.151, 0.424, 0.054, 0.222, 0.332, 0.133, 0.139, 0.443]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=104469)[0m rmse: 0.16882778704166412
[2m[36m(func pid=104469)[0m mae:  0.11640866845846176
[2m[36m(func pid=104469)[0m rmse_per_class: [0.107, 0.267, 0.065, 0.344, 0.059, 0.188, 0.262, 0.139, 0.165, 0.092]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=105266)[0m rmse: 0.1667921245098114
[2m[36m(func pid=105266)[0m mae:  0.1026720255613327
[2m[36m(func pid=105266)[0m rmse_per_class: [0.087, 0.241, 0.059, 0.331, 0.087, 0.15, 0.225, 0.118, 0.266, 0.104]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.151638001203537
[2m[36m(func pid=104843)[0m mae:  0.09664645045995712
[2m[36m(func pid=104843)[0m rmse_per_class: [0.064, 0.215, 0.029, 0.263, 0.054, 0.166, 0.281, 0.158, 0.178, 0.11]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.3510 | Steps: 2 | Val loss: 0.5178 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.4378 | Steps: 2 | Val loss: 0.3919 | Batch size: 32 | lr: 0.0001 | Duration: 3.07s
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.2427 | Steps: 2 | Val loss: 0.3233 | Batch size: 32 | lr: 0.01 | Duration: 2.74s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.2925 | Steps: 2 | Val loss: 0.2833 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
== Status ==
Current time: 2024-01-07 08:39:09 (running for 00:07:09.97)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.435 |  0.169 |                   71 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.296 |  0.152 |                   72 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.259 |  0.167 |                   73 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.351 |  0.231 |                   72 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=105685)[0m rmse: 0.2312738448381424
[2m[36m(func pid=105685)[0m mae:  0.13824379444122314
[2m[36m(func pid=105685)[0m rmse_per_class: [0.119, 0.264, 0.198, 0.419, 0.055, 0.214, 0.327, 0.143, 0.14, 0.434]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=104469)[0m rmse: 0.16860583424568176
[2m[36m(func pid=104469)[0m mae:  0.11615638434886932
[2m[36m(func pid=104469)[0m rmse_per_class: [0.108, 0.267, 0.064, 0.344, 0.059, 0.188, 0.262, 0.139, 0.166, 0.092]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=105266)[0m rmse: 0.1650317907333374
[2m[36m(func pid=105266)[0m mae:  0.10179392248392105
[2m[36m(func pid=105266)[0m rmse_per_class: [0.088, 0.234, 0.063, 0.329, 0.089, 0.149, 0.222, 0.116, 0.249, 0.111]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.15334025025367737
[2m[36m(func pid=104843)[0m mae:  0.09761669486761093
[2m[36m(func pid=104843)[0m rmse_per_class: [0.065, 0.216, 0.029, 0.263, 0.054, 0.167, 0.281, 0.164, 0.176, 0.119]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.3697 | Steps: 2 | Val loss: 0.5129 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.2478 | Steps: 2 | Val loss: 0.3167 | Batch size: 32 | lr: 0.01 | Duration: 2.66s
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.4370 | Steps: 2 | Val loss: 0.3926 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.2842 | Steps: 2 | Val loss: 0.2858 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=105685)[0m rmse: 0.23142781853675842
[2m[36m(func pid=105685)[0m mae:  0.1381910890340805
[2m[36m(func pid=105685)[0m rmse_per_class: [0.126, 0.267, 0.214, 0.407, 0.056, 0.212, 0.319, 0.146, 0.142, 0.426]
[2m[36m(func pid=105685)[0m 
== Status ==
Current time: 2024-01-07 08:39:14 (running for 00:07:15.16)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.438 |  0.169 |                   72 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.292 |  0.153 |                   73 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.243 |  0.165 |                   74 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.37  |  0.231 |                   73 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=105266)[0m rmse: 0.16332750022411346
[2m[36m(func pid=105266)[0m mae:  0.10096870362758636
[2m[36m(func pid=105266)[0m rmse_per_class: [0.089, 0.229, 0.061, 0.328, 0.089, 0.149, 0.22, 0.114, 0.236, 0.118]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104469)[0m rmse: 0.16867144405841827
[2m[36m(func pid=104469)[0m mae:  0.11606316268444061
[2m[36m(func pid=104469)[0m rmse_per_class: [0.107, 0.267, 0.064, 0.344, 0.058, 0.188, 0.262, 0.139, 0.166, 0.092]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.15476344525814056
[2m[36m(func pid=104843)[0m mae:  0.09847397357225418
[2m[36m(func pid=104843)[0m rmse_per_class: [0.064, 0.218, 0.029, 0.265, 0.053, 0.168, 0.28, 0.167, 0.177, 0.125]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.3470 | Steps: 2 | Val loss: 0.5151 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 75] | Train loss: 0.2412 | Steps: 2 | Val loss: 0.3128 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.2897 | Steps: 2 | Val loss: 0.2895 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.4405 | Steps: 2 | Val loss: 0.3925 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
== Status ==
Current time: 2024-01-07 08:39:19 (running for 00:07:20.29)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: -0.16300000250339508
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING  | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.437 |  0.169 |                   73 |
| train_d77f6_00001 | RUNNING  | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.284 |  0.155 |                   74 |
| train_d77f6_00002 | RUNNING  | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.248 |  0.163 |                   75 |
| train_d77f6_00003 | RUNNING  | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.347 |  0.221 |                   74 |
| train_d77f6_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=105685)[0m rmse: 0.22094698250293732
[2m[36m(func pid=105685)[0m mae:  0.13202695548534393
[2m[36m(func pid=105685)[0m rmse_per_class: [0.126, 0.274, 0.207, 0.39, 0.057, 0.206, 0.294, 0.141, 0.145, 0.37]
[2m[36m(func pid=105685)[0m 
[2m[36m(func pid=105266)[0m rmse: 0.16240277886390686
[2m[36m(func pid=105266)[0m mae:  0.10061182826757431
[2m[36m(func pid=105266)[0m rmse_per_class: [0.092, 0.225, 0.062, 0.328, 0.09, 0.15, 0.217, 0.112, 0.225, 0.122]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104469)[0m rmse: 0.16851864755153656
[2m[36m(func pid=104469)[0m mae:  0.11585555970668793
[2m[36m(func pid=104469)[0m rmse_per_class: [0.107, 0.266, 0.062, 0.344, 0.058, 0.187, 0.262, 0.139, 0.167, 0.092]
[2m[36m(func pid=104469)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.15708136558532715
[2m[36m(func pid=104843)[0m mae:  0.09977483749389648
[2m[36m(func pid=104843)[0m rmse_per_class: [0.065, 0.221, 0.029, 0.266, 0.053, 0.169, 0.279, 0.174, 0.182, 0.133]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105685)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.3357 | Steps: 2 | Val loss: 0.6623 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 76] | Train loss: 0.2445 | Steps: 2 | Val loss: 0.3106 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 75] | Train loss: 0.2867 | Steps: 2 | Val loss: 0.2921 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
[2m[36m(func pid=104469)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.4335 | Steps: 2 | Val loss: 0.3927 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
== Status ==
Current time: 2024-01-07 08:39:24 (running for 00:07:25.38)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=1
Bracket: Iter 75.000: -0.1600000038743019
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 3 RUNNING, 1 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | RUNNING    | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.44  |  0.169 |                   74 |
| train_d77f6_00001 | RUNNING    | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.29  |  0.157 |                   75 |
| train_d77f6_00002 | RUNNING    | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.162 |                   76 |
| train_d77f6_00004 | PENDING    |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | PENDING    |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING    |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=105685)[0m rmse: 0.2083100527524948
[2m[36m(func pid=105685)[0m mae:  0.12491738796234131
[2m[36m(func pid=105685)[0m rmse_per_class: [0.122, 0.275, 0.193, 0.374, 0.057, 0.2, 0.266, 0.132, 0.145, 0.32]
[2m[36m(func pid=104843)[0m rmse: 0.1586785614490509
[2m[36m(func pid=104843)[0m mae:  0.10082874447107315
[2m[36m(func pid=104843)[0m rmse_per_class: [0.065, 0.223, 0.03, 0.267, 0.053, 0.17, 0.278, 0.179, 0.182, 0.14]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105266)[0m rmse: 0.16155606508255005
[2m[36m(func pid=105266)[0m mae:  0.10040949285030365
[2m[36m(func pid=105266)[0m rmse_per_class: [0.096, 0.222, 0.062, 0.327, 0.087, 0.151, 0.214, 0.112, 0.216, 0.128]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104469)[0m rmse: 0.16830822825431824
[2m[36m(func pid=104469)[0m mae:  0.11557809263467789
[2m[36m(func pid=104469)[0m rmse_per_class: [0.107, 0.266, 0.062, 0.344, 0.058, 0.187, 0.262, 0.139, 0.166, 0.092]
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 76] | Train loss: 0.2867 | Steps: 2 | Val loss: 0.2953 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 77] | Train loss: 0.2478 | Steps: 2 | Val loss: 0.3084 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=104843)[0m rmse: 0.16050821542739868
[2m[36m(func pid=104843)[0m mae:  0.10186024010181427
[2m[36m(func pid=104843)[0m rmse_per_class: [0.066, 0.226, 0.03, 0.268, 0.053, 0.172, 0.277, 0.185, 0.184, 0.145]
[2m[36m(func pid=105266)[0m rmse: 0.16035446524620056
[2m[36m(func pid=105266)[0m mae:  0.09964194893836975
[2m[36m(func pid=105266)[0m rmse_per_class: [0.099, 0.221, 0.058, 0.327, 0.088, 0.152, 0.21, 0.111, 0.208, 0.129]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=122279)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=122279)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=122279)[0m Configuration completed!
[2m[36m(func pid=122279)[0m New optimizer parameters:
[2m[36m(func pid=122279)[0m SGD (
[2m[36m(func pid=122279)[0m Parameter Group 0
[2m[36m(func pid=122279)[0m     dampening: 0
[2m[36m(func pid=122279)[0m     differentiable: False
[2m[36m(func pid=122279)[0m     foreach: None
[2m[36m(func pid=122279)[0m     lr: 0.0001
[2m[36m(func pid=122279)[0m     maximize: False
[2m[36m(func pid=122279)[0m     momentum: 0.9
[2m[36m(func pid=122279)[0m     nesterov: False
[2m[36m(func pid=122279)[0m     weight_decay: 0
[2m[36m(func pid=122279)[0m )
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 78] | Train loss: 0.2452 | Steps: 2 | Val loss: 0.3076 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
== Status ==
Current time: 2024-01-07 08:39:30 (running for 00:07:31.39)
Memory usage on this node: 19.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (18 PENDING, 4 RUNNING, 2 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00001 | RUNNING    | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.287 |  0.159 |                   76 |
| train_d77f6_00002 | RUNNING    | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.248 |  0.16  |                   78 |
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING    |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=122389)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=122389)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=122389)[0m Configuration completed!
[2m[36m(func pid=122389)[0m New optimizer parameters:
[2m[36m(func pid=122389)[0m SGD (
[2m[36m(func pid=122389)[0m Parameter Group 0
[2m[36m(func pid=122389)[0m     dampening: 0
[2m[36m(func pid=122389)[0m     differentiable: False
[2m[36m(func pid=122389)[0m     foreach: None
[2m[36m(func pid=122389)[0m     lr: 0.001
[2m[36m(func pid=122389)[0m     maximize: False
[2m[36m(func pid=122389)[0m     momentum: 0.9
[2m[36m(func pid=122389)[0m     nesterov: False
[2m[36m(func pid=122389)[0m     weight_decay: 0
[2m[36m(func pid=122389)[0m )
[2m[36m(func pid=122389)[0m 
== Status ==
Current time: 2024-01-07 08:39:35 (running for 00:07:36.61)
Memory usage on this node: 24.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (18 PENDING, 4 RUNNING, 2 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00001 | RUNNING    | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.287 |  0.161 |                   77 |
| train_d77f6_00002 | RUNNING    | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.245 |  0.16  |                   79 |
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |        |        |                      |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING    |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=105266)[0m rmse: 0.16013725101947784
[2m[36m(func pid=105266)[0m mae:  0.09958301484584808
[2m[36m(func pid=105266)[0m rmse_per_class: [0.107, 0.221, 0.056, 0.326, 0.088, 0.152, 0.209, 0.111, 0.2, 0.133]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 1.0861 | Steps: 2 | Val loss: 0.8092 | Batch size: 32 | lr: 0.0001 | Duration: 4.52s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 77] | Train loss: 0.2858 | Steps: 2 | Val loss: 0.2982 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 79] | Train loss: 0.2411 | Steps: 2 | Val loss: 0.3047 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 1.0766 | Steps: 2 | Val loss: 0.7949 | Batch size: 32 | lr: 0.001 | Duration: 4.71s
[2m[36m(func pid=122279)[0m rmse: 0.17869606614112854
[2m[36m(func pid=122279)[0m mae:  0.13121266663074493
[2m[36m(func pid=122279)[0m rmse_per_class: [0.105, 0.266, 0.087, 0.325, 0.101, 0.192, 0.304, 0.153, 0.139, 0.116]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.16261550784111023
[2m[36m(func pid=104843)[0m mae:  0.10312595218420029
[2m[36m(func pid=104843)[0m rmse_per_class: [0.067, 0.229, 0.032, 0.269, 0.052, 0.173, 0.276, 0.193, 0.18, 0.156]
[2m[36m(func pid=104843)[0m 
== Status ==
Current time: 2024-01-07 08:39:40 (running for 00:07:41.78)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (18 PENDING, 4 RUNNING, 2 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00001 | RUNNING    | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.286 |  0.163 |                   78 |
| train_d77f6_00002 | RUNNING    | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.159 |                   80 |
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  1.086 |  0.179 |                    1 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |        |        |                      |
| train_d77f6_00006 | PENDING    |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=105266)[0m rmse: 0.1589238941669464
[2m[36m(func pid=105266)[0m mae:  0.09909508377313614
[2m[36m(func pid=105266)[0m rmse_per_class: [0.114, 0.221, 0.053, 0.324, 0.084, 0.152, 0.207, 0.11, 0.193, 0.132]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.17865131795406342
[2m[36m(func pid=122389)[0m mae:  0.13116031885147095
[2m[36m(func pid=122389)[0m rmse_per_class: [0.105, 0.266, 0.087, 0.325, 0.1, 0.192, 0.304, 0.153, 0.139, 0.116]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 1.0781 | Steps: 2 | Val loss: 0.8119 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 78] | Train loss: 0.2856 | Steps: 2 | Val loss: 0.3007 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 80] | Train loss: 0.2500 | Steps: 2 | Val loss: 0.3060 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 1.0375 | Steps: 2 | Val loss: 0.7598 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=122279)[0m rmse: 0.17916105687618256
[2m[36m(func pid=122279)[0m mae:  0.13158908486366272
[2m[36m(func pid=122279)[0m rmse_per_class: [0.104, 0.265, 0.088, 0.325, 0.102, 0.193, 0.306, 0.153, 0.139, 0.116]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.16381700336933136
[2m[36m(func pid=104843)[0m mae:  0.10398808866739273
[2m[36m(func pid=104843)[0m rmse_per_class: [0.067, 0.231, 0.032, 0.271, 0.052, 0.175, 0.274, 0.195, 0.178, 0.162]
[2m[36m(func pid=104843)[0m 
== Status ==
Current time: 2024-01-07 08:39:46 (running for 00:07:46.94)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (18 PENDING, 4 RUNNING, 2 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00001 | RUNNING    | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.286 |  0.164 |                   79 |
| train_d77f6_00002 | RUNNING    | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.25  |  0.16  |                   81 |
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  1.078 |  0.179 |                    2 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  1.077 |  0.179 |                    1 |
| train_d77f6_00006 | PENDING    |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=105266)[0m rmse: 0.15953616797924042
[2m[36m(func pid=105266)[0m mae:  0.09935541450977325
[2m[36m(func pid=105266)[0m rmse_per_class: [0.123, 0.221, 0.053, 0.324, 0.082, 0.152, 0.206, 0.11, 0.192, 0.133]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.17895738780498505
[2m[36m(func pid=122389)[0m mae:  0.1313495635986328
[2m[36m(func pid=122389)[0m rmse_per_class: [0.104, 0.266, 0.088, 0.325, 0.101, 0.192, 0.305, 0.154, 0.139, 0.115]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 1.0729 | Steps: 2 | Val loss: 0.8129 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 79] | Train loss: 0.2914 | Steps: 2 | Val loss: 0.3036 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 81] | Train loss: 0.2450 | Steps: 2 | Val loss: 0.3042 | Batch size: 32 | lr: 0.01 | Duration: 2.75s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.9610 | Steps: 2 | Val loss: 0.7089 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=122279)[0m rmse: 0.1795693039894104
[2m[36m(func pid=122279)[0m mae:  0.13190476596355438
[2m[36m(func pid=122279)[0m rmse_per_class: [0.105, 0.265, 0.089, 0.325, 0.103, 0.193, 0.307, 0.154, 0.139, 0.116]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.16548846662044525
[2m[36m(func pid=104843)[0m mae:  0.1048637256026268
[2m[36m(func pid=104843)[0m rmse_per_class: [0.067, 0.233, 0.034, 0.273, 0.052, 0.176, 0.272, 0.198, 0.177, 0.173]
[2m[36m(func pid=104843)[0m 
== Status ==
Current time: 2024-01-07 08:39:51 (running for 00:07:52.06)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (18 PENDING, 4 RUNNING, 2 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00001 | RUNNING    | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.291 |  0.165 |                   80 |
| train_d77f6_00002 | RUNNING    | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.245 |  0.159 |                   82 |
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  1.073 |  0.18  |                    3 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  1.038 |  0.179 |                    2 |
| train_d77f6_00006 | PENDING    |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=105266)[0m rmse: 0.15880481898784637
[2m[36m(func pid=105266)[0m mae:  0.09902548789978027
[2m[36m(func pid=105266)[0m rmse_per_class: [0.125, 0.221, 0.051, 0.322, 0.08, 0.151, 0.206, 0.11, 0.188, 0.134]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.179151251912117
[2m[36m(func pid=122389)[0m mae:  0.1314193606376648
[2m[36m(func pid=122389)[0m rmse_per_class: [0.104, 0.266, 0.089, 0.324, 0.101, 0.193, 0.305, 0.155, 0.139, 0.115]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 80] | Train loss: 0.2941 | Steps: 2 | Val loss: 0.3078 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 1.0566 | Steps: 2 | Val loss: 0.8124 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 82] | Train loss: 0.2541 | Steps: 2 | Val loss: 0.3069 | Batch size: 32 | lr: 0.01 | Duration: 2.76s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.8759 | Steps: 2 | Val loss: 0.6478 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=122279)[0m rmse: 0.17998886108398438
[2m[36m(func pid=122279)[0m mae:  0.13222041726112366
[2m[36m(func pid=122279)[0m rmse_per_class: [0.105, 0.266, 0.09, 0.325, 0.104, 0.193, 0.308, 0.154, 0.138, 0.117]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.16744433343410492
[2m[36m(func pid=104843)[0m mae:  0.10598225891590118
[2m[36m(func pid=104843)[0m rmse_per_class: [0.067, 0.237, 0.035, 0.276, 0.052, 0.177, 0.27, 0.199, 0.18, 0.181]
[2m[36m(func pid=104843)[0m 
== Status ==
Current time: 2024-01-07 08:39:56 (running for 00:07:57.14)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (18 PENDING, 4 RUNNING, 2 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00001 | RUNNING    | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.294 |  0.167 |                   81 |
| train_d77f6_00002 | RUNNING    | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.254 |  0.16  |                   83 |
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  1.057 |  0.18  |                    4 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.961 |  0.179 |                    3 |
| train_d77f6_00006 | PENDING    |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=105266)[0m rmse: 0.1599750816822052
[2m[36m(func pid=105266)[0m mae:  0.09962846338748932
[2m[36m(func pid=105266)[0m rmse_per_class: [0.13, 0.221, 0.051, 0.322, 0.082, 0.151, 0.208, 0.11, 0.19, 0.136]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.1792854517698288
[2m[36m(func pid=122389)[0m mae:  0.1313963383436203
[2m[36m(func pid=122389)[0m rmse_per_class: [0.104, 0.267, 0.089, 0.324, 0.101, 0.193, 0.305, 0.156, 0.138, 0.115]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 81] | Train loss: 0.2783 | Steps: 2 | Val loss: 0.3090 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 1.0484 | Steps: 2 | Val loss: 0.8078 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 83] | Train loss: 0.2406 | Steps: 2 | Val loss: 0.3051 | Batch size: 32 | lr: 0.01 | Duration: 2.66s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.7774 | Steps: 2 | Val loss: 0.5838 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=104843)[0m rmse: 0.16828195750713348
[2m[36m(func pid=104843)[0m mae:  0.1066221222281456
[2m[36m(func pid=104843)[0m rmse_per_class: [0.068, 0.239, 0.035, 0.278, 0.052, 0.178, 0.268, 0.202, 0.175, 0.187]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=122279)[0m rmse: 0.18027019500732422
[2m[36m(func pid=122279)[0m mae:  0.13243049383163452
[2m[36m(func pid=122279)[0m rmse_per_class: [0.105, 0.266, 0.09, 0.325, 0.105, 0.193, 0.309, 0.154, 0.138, 0.118]
[2m[36m(func pid=122279)[0m 
== Status ==
Current time: 2024-01-07 08:40:01 (running for 00:08:02.15)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (18 PENDING, 4 RUNNING, 2 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00001 | RUNNING    | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.278 |  0.168 |                   82 |
| train_d77f6_00002 | RUNNING    | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.159 |                   84 |
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  1.048 |  0.18  |                    5 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.876 |  0.179 |                    4 |
| train_d77f6_00006 | PENDING    |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=105266)[0m rmse: 0.15946921706199646
[2m[36m(func pid=105266)[0m mae:  0.09926549345254898
[2m[36m(func pid=105266)[0m rmse_per_class: [0.132, 0.22, 0.05, 0.321, 0.082, 0.148, 0.21, 0.11, 0.189, 0.133]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.17934463918209076
[2m[36m(func pid=122389)[0m mae:  0.1313374936580658
[2m[36m(func pid=122389)[0m rmse_per_class: [0.104, 0.267, 0.09, 0.324, 0.101, 0.193, 0.304, 0.156, 0.138, 0.115]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 82] | Train loss: 0.2772 | Steps: 2 | Val loss: 0.3124 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 1.0358 | Steps: 2 | Val loss: 0.8016 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 84] | Train loss: 0.2398 | Steps: 2 | Val loss: 0.3050 | Batch size: 32 | lr: 0.01 | Duration: 2.77s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.6911 | Steps: 2 | Val loss: 0.5232 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
== Status ==
Current time: 2024-01-07 08:40:06 (running for 00:08:07.16)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (18 PENDING, 4 RUNNING, 2 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00001 | RUNNING    | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.277 |  0.17  |                   83 |
| train_d77f6_00002 | RUNNING    | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.159 |                   84 |
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  1.048 |  0.18  |                    5 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.777 |  0.179 |                    5 |
| train_d77f6_00006 | PENDING    |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104843)[0m rmse: 0.16972126066684723
[2m[36m(func pid=104843)[0m mae:  0.10760712623596191
[2m[36m(func pid=104843)[0m rmse_per_class: [0.068, 0.241, 0.035, 0.284, 0.052, 0.179, 0.265, 0.205, 0.173, 0.194]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105266)[0m rmse: 0.15970607101917267
[2m[36m(func pid=105266)[0m mae:  0.09944892674684525
[2m[36m(func pid=105266)[0m rmse_per_class: [0.137, 0.22, 0.05, 0.322, 0.079, 0.147, 0.212, 0.11, 0.191, 0.128]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=122279)[0m rmse: 0.18047985434532166
[2m[36m(func pid=122279)[0m mae:  0.13259485363960266
[2m[36m(func pid=122279)[0m rmse_per_class: [0.105, 0.266, 0.09, 0.325, 0.105, 0.194, 0.309, 0.154, 0.138, 0.118]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.17926356196403503
[2m[36m(func pid=122389)[0m mae:  0.13115647435188293
[2m[36m(func pid=122389)[0m rmse_per_class: [0.105, 0.268, 0.09, 0.325, 0.1, 0.193, 0.303, 0.155, 0.139, 0.115]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 85] | Train loss: 0.2448 | Steps: 2 | Val loss: 0.3037 | Batch size: 32 | lr: 0.01 | Duration: 2.71s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 83] | Train loss: 0.2753 | Steps: 2 | Val loss: 0.3128 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 1.0196 | Steps: 2 | Val loss: 0.7931 | Batch size: 32 | lr: 0.0001 | Duration: 3.06s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.6195 | Steps: 2 | Val loss: 0.4709 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
== Status ==
Current time: 2024-01-07 08:40:11 (running for 00:08:12.22)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (18 PENDING, 4 RUNNING, 2 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00001 | RUNNING    | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.277 |  0.17  |                   83 |
| train_d77f6_00002 | RUNNING    | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.245 |  0.159 |                   86 |
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  1.036 |  0.18  |                    6 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.691 |  0.179 |                    6 |
| train_d77f6_00006 | PENDING    |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=105266)[0m rmse: 0.1593085080385208
[2m[36m(func pid=105266)[0m mae:  0.09905131906270981
[2m[36m(func pid=105266)[0m rmse_per_class: [0.135, 0.22, 0.049, 0.321, 0.078, 0.146, 0.214, 0.111, 0.191, 0.127]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.169521763920784
[2m[36m(func pid=104843)[0m mae:  0.10739942640066147
[2m[36m(func pid=104843)[0m rmse_per_class: [0.069, 0.242, 0.036, 0.285, 0.052, 0.18, 0.263, 0.206, 0.17, 0.191]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=122279)[0m rmse: 0.18071486055850983
[2m[36m(func pid=122279)[0m mae:  0.1327476054430008
[2m[36m(func pid=122279)[0m rmse_per_class: [0.106, 0.266, 0.09, 0.325, 0.105, 0.194, 0.31, 0.154, 0.138, 0.119]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.17922991514205933
[2m[36m(func pid=122389)[0m mae:  0.1310100555419922
[2m[36m(func pid=122389)[0m rmse_per_class: [0.105, 0.268, 0.092, 0.325, 0.1, 0.193, 0.301, 0.154, 0.139, 0.115]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 86] | Train loss: 0.2397 | Steps: 2 | Val loss: 0.3032 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 84] | Train loss: 0.2784 | Steps: 2 | Val loss: 0.3153 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.9974 | Steps: 2 | Val loss: 0.7855 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=105266)[0m rmse: 0.15901024639606476
[2m[36m(func pid=105266)[0m mae:  0.09877507388591766
[2m[36m(func pid=105266)[0m rmse_per_class: [0.132, 0.221, 0.049, 0.322, 0.075, 0.145, 0.217, 0.111, 0.195, 0.123]
[2m[36m(func pid=105266)[0m 
== Status ==
Current time: 2024-01-07 08:40:16 (running for 00:08:17.53)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (18 PENDING, 4 RUNNING, 2 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00001 | RUNNING    | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.275 |  0.17  |                   84 |
| train_d77f6_00002 | RUNNING    | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.24  |  0.159 |                   87 |
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  1.02  |  0.181 |                    7 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.62  |  0.179 |                    7 |
| train_d77f6_00006 | PENDING    |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.5595 | Steps: 2 | Val loss: 0.4273 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=104843)[0m rmse: 0.1704637110233307
[2m[36m(func pid=104843)[0m mae:  0.10780072212219238
[2m[36m(func pid=104843)[0m rmse_per_class: [0.069, 0.244, 0.036, 0.289, 0.052, 0.181, 0.261, 0.206, 0.166, 0.2]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=122279)[0m rmse: 0.18084058165550232
[2m[36m(func pid=122279)[0m mae:  0.1328408122062683
[2m[36m(func pid=122279)[0m rmse_per_class: [0.106, 0.266, 0.09, 0.324, 0.106, 0.194, 0.31, 0.154, 0.138, 0.12]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.1789536476135254
[2m[36m(func pid=122389)[0m mae:  0.1306469738483429
[2m[36m(func pid=122389)[0m rmse_per_class: [0.106, 0.269, 0.092, 0.326, 0.099, 0.193, 0.299, 0.152, 0.14, 0.114]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 85] | Train loss: 0.2829 | Steps: 2 | Val loss: 0.3167 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 87] | Train loss: 0.2384 | Steps: 2 | Val loss: 0.3016 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.9813 | Steps: 2 | Val loss: 0.7733 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 08:40:21 (running for 00:08:22.70)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (18 PENDING, 4 RUNNING, 2 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00001 | RUNNING    | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.283 |  0.171 |                   86 |
| train_d77f6_00002 | RUNNING    | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.24  |  0.159 |                   87 |
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.997 |  0.181 |                    8 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.56  |  0.179 |                    8 |
| train_d77f6_00006 | PENDING    |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104843)[0m rmse: 0.1705300211906433
[2m[36m(func pid=104843)[0m mae:  0.10775569826364517
[2m[36m(func pid=104843)[0m rmse_per_class: [0.069, 0.245, 0.037, 0.293, 0.052, 0.182, 0.261, 0.204, 0.17, 0.193]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105266)[0m rmse: 0.15850485861301422
[2m[36m(func pid=105266)[0m mae:  0.09823767840862274
[2m[36m(func pid=105266)[0m rmse_per_class: [0.129, 0.222, 0.049, 0.322, 0.074, 0.145, 0.219, 0.112, 0.195, 0.118]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.5066 | Steps: 2 | Val loss: 0.3943 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=122279)[0m rmse: 0.18098445236682892
[2m[36m(func pid=122279)[0m mae:  0.1329515278339386
[2m[36m(func pid=122279)[0m rmse_per_class: [0.106, 0.266, 0.091, 0.324, 0.106, 0.194, 0.31, 0.154, 0.138, 0.12]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.17865881323814392
[2m[36m(func pid=122389)[0m mae:  0.13026681542396545
[2m[36m(func pid=122389)[0m rmse_per_class: [0.106, 0.269, 0.093, 0.327, 0.098, 0.193, 0.297, 0.149, 0.141, 0.114]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 86] | Train loss: 0.2801 | Steps: 2 | Val loss: 0.3180 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 88] | Train loss: 0.2384 | Steps: 2 | Val loss: 0.3018 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.9676 | Steps: 2 | Val loss: 0.7609 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 08:40:27 (running for 00:08:27.95)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (18 PENDING, 4 RUNNING, 2 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00001 | RUNNING    | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.28  |  0.171 |                   87 |
| train_d77f6_00002 | RUNNING    | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.238 |  0.159 |                   88 |
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.981 |  0.181 |                    9 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.507 |  0.179 |                    9 |
| train_d77f6_00006 | PENDING    |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104843)[0m rmse: 0.17086899280548096
[2m[36m(func pid=104843)[0m mae:  0.10814686864614487
[2m[36m(func pid=104843)[0m rmse_per_class: [0.069, 0.247, 0.037, 0.3, 0.052, 0.181, 0.261, 0.198, 0.168, 0.195]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105266)[0m rmse: 0.1585926115512848
[2m[36m(func pid=105266)[0m mae:  0.09813535958528519
[2m[36m(func pid=105266)[0m rmse_per_class: [0.127, 0.224, 0.05, 0.323, 0.071, 0.145, 0.221, 0.112, 0.198, 0.116]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.4762 | Steps: 2 | Val loss: 0.3703 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=122279)[0m rmse: 0.18106476962566376
[2m[36m(func pid=122279)[0m mae:  0.13300880789756775
[2m[36m(func pid=122279)[0m rmse_per_class: [0.106, 0.266, 0.091, 0.324, 0.106, 0.194, 0.311, 0.154, 0.138, 0.121]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 87] | Train loss: 0.2799 | Steps: 2 | Val loss: 0.3171 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 89] | Train loss: 0.2417 | Steps: 2 | Val loss: 0.3006 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=122389)[0m rmse: 0.17818143963813782
[2m[36m(func pid=122389)[0m mae:  0.12977364659309387
[2m[36m(func pid=122389)[0m rmse_per_class: [0.107, 0.269, 0.094, 0.327, 0.096, 0.193, 0.294, 0.147, 0.141, 0.114]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.9482 | Steps: 2 | Val loss: 0.7474 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 08:40:32 (running for 00:08:32.97)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (18 PENDING, 4 RUNNING, 2 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00001 | RUNNING    | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.28  |  0.171 |                   87 |
| train_d77f6_00002 | RUNNING    | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.242 |  0.158 |                   90 |
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.968 |  0.181 |                   10 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.476 |  0.178 |                   10 |
| train_d77f6_00006 | PENDING    |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=105266)[0m rmse: 0.1580842286348343
[2m[36m(func pid=105266)[0m mae:  0.09755268692970276
[2m[36m(func pid=105266)[0m rmse_per_class: [0.121, 0.227, 0.05, 0.324, 0.071, 0.146, 0.221, 0.111, 0.199, 0.112]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.16991835832595825
[2m[36m(func pid=104843)[0m mae:  0.10745016485452652
[2m[36m(func pid=104843)[0m rmse_per_class: [0.07, 0.247, 0.037, 0.3, 0.053, 0.182, 0.26, 0.188, 0.165, 0.197]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.4442 | Steps: 2 | Val loss: 0.3523 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=122279)[0m rmse: 0.18112114071846008
[2m[36m(func pid=122279)[0m mae:  0.13303343951702118
[2m[36m(func pid=122279)[0m rmse_per_class: [0.106, 0.267, 0.09, 0.324, 0.106, 0.194, 0.311, 0.154, 0.138, 0.121]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 90] | Train loss: 0.2368 | Steps: 2 | Val loss: 0.2995 | Batch size: 32 | lr: 0.01 | Duration: 2.72s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 88] | Train loss: 0.2842 | Steps: 2 | Val loss: 0.3183 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=122389)[0m rmse: 0.17768242955207825
[2m[36m(func pid=122389)[0m mae:  0.1292661726474762
[2m[36m(func pid=122389)[0m rmse_per_class: [0.108, 0.269, 0.094, 0.328, 0.095, 0.192, 0.291, 0.145, 0.142, 0.113]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.9278 | Steps: 2 | Val loss: 0.7347 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=105266)[0m rmse: 0.1572466790676117
[2m[36m(func pid=105266)[0m mae:  0.09685154259204865
[2m[36m(func pid=105266)[0m rmse_per_class: [0.116, 0.229, 0.052, 0.324, 0.069, 0.145, 0.217, 0.111, 0.199, 0.11]
== Status ==
Current time: 2024-01-07 08:40:37 (running for 00:08:38.21)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (18 PENDING, 4 RUNNING, 2 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00001 | RUNNING    | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.28  |  0.17  |                   88 |
| train_d77f6_00002 | RUNNING    | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.237 |  0.157 |                   91 |
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.948 |  0.181 |                   11 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.444 |  0.178 |                   11 |
| train_d77f6_00006 | PENDING    |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.16993118822574615
[2m[36m(func pid=104843)[0m mae:  0.10728345811367035
[2m[36m(func pid=104843)[0m rmse_per_class: [0.07, 0.248, 0.037, 0.305, 0.053, 0.181, 0.261, 0.18, 0.166, 0.198]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=122279)[0m rmse: 0.18118448555469513
[2m[36m(func pid=122279)[0m mae:  0.1330745816230774
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.267, 0.09, 0.324, 0.105, 0.194, 0.311, 0.154, 0.138, 0.122]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.4335 | Steps: 2 | Val loss: 0.3401 | Batch size: 32 | lr: 0.001 | Duration: 3.11s
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 91] | Train loss: 0.2450 | Steps: 2 | Val loss: 0.2956 | Batch size: 32 | lr: 0.01 | Duration: 2.68s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 89] | Train loss: 0.2725 | Steps: 2 | Val loss: 0.3171 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=122389)[0m rmse: 0.1772419512271881
[2m[36m(func pid=122389)[0m mae:  0.1288033425807953
[2m[36m(func pid=122389)[0m rmse_per_class: [0.108, 0.269, 0.095, 0.328, 0.093, 0.192, 0.289, 0.143, 0.143, 0.113]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.9127 | Steps: 2 | Val loss: 0.7218 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
== Status ==
Current time: 2024-01-07 08:40:42 (running for 00:08:43.26)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (18 PENDING, 4 RUNNING, 2 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00001 | RUNNING    | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.284 |  0.17  |                   89 |
| train_d77f6_00002 | RUNNING    | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.245 |  0.155 |                   92 |
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.928 |  0.181 |                   12 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.434 |  0.177 |                   12 |
| train_d77f6_00006 | PENDING    |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=105266)[0m rmse: 0.15546292066574097
[2m[36m(func pid=105266)[0m mae:  0.09550812840461731
[2m[36m(func pid=105266)[0m rmse_per_class: [0.111, 0.23, 0.051, 0.322, 0.069, 0.144, 0.214, 0.11, 0.197, 0.106]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.16877076029777527
[2m[36m(func pid=104843)[0m mae:  0.10645367205142975
[2m[36m(func pid=104843)[0m rmse_per_class: [0.07, 0.248, 0.037, 0.307, 0.054, 0.181, 0.263, 0.175, 0.165, 0.188]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=122279)[0m rmse: 0.18119899928569794
[2m[36m(func pid=122279)[0m mae:  0.13307227194309235
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.267, 0.09, 0.324, 0.105, 0.194, 0.311, 0.154, 0.138, 0.122]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.4157 | Steps: 2 | Val loss: 0.3316 | Batch size: 32 | lr: 0.001 | Duration: 3.05s
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 92] | Train loss: 0.2397 | Steps: 2 | Val loss: 0.2936 | Batch size: 32 | lr: 0.01 | Duration: 2.74s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 90] | Train loss: 0.2878 | Steps: 2 | Val loss: 0.3169 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=122389)[0m rmse: 0.17670120298862457
[2m[36m(func pid=122389)[0m mae:  0.12827631831169128
[2m[36m(func pid=122389)[0m rmse_per_class: [0.108, 0.27, 0.093, 0.328, 0.092, 0.192, 0.287, 0.142, 0.143, 0.112]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.8971 | Steps: 2 | Val loss: 0.7102 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 08:40:47 (running for 00:08:48.40)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (18 PENDING, 4 RUNNING, 2 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00001 | RUNNING    | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.273 |  0.169 |                   90 |
| train_d77f6_00002 | RUNNING    | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.24  |  0.154 |                   93 |
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.913 |  0.181 |                   13 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.416 |  0.177 |                   13 |
| train_d77f6_00006 | PENDING    |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=105266)[0m rmse: 0.15423469245433807
[2m[36m(func pid=105266)[0m mae:  0.09464748203754425
[2m[36m(func pid=105266)[0m rmse_per_class: [0.107, 0.23, 0.051, 0.322, 0.07, 0.144, 0.209, 0.11, 0.197, 0.103]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.1685640513896942
[2m[36m(func pid=104843)[0m mae:  0.1060505360364914
[2m[36m(func pid=104843)[0m rmse_per_class: [0.069, 0.248, 0.038, 0.309, 0.054, 0.181, 0.265, 0.171, 0.166, 0.185]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=122279)[0m rmse: 0.18125729262828827
[2m[36m(func pid=122279)[0m mae:  0.1331000030040741
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.267, 0.09, 0.324, 0.106, 0.194, 0.311, 0.154, 0.138, 0.123]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.4039 | Steps: 2 | Val loss: 0.3260 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 93] | Train loss: 0.2402 | Steps: 2 | Val loss: 0.2914 | Batch size: 32 | lr: 0.01 | Duration: 2.77s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 91] | Train loss: 0.2723 | Steps: 2 | Val loss: 0.3168 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=122389)[0m rmse: 0.176190584897995
[2m[36m(func pid=122389)[0m mae:  0.12778998911380768
[2m[36m(func pid=122389)[0m rmse_per_class: [0.109, 0.269, 0.093, 0.328, 0.09, 0.192, 0.284, 0.14, 0.144, 0.112]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.8796 | Steps: 2 | Val loss: 0.6970 | Batch size: 32 | lr: 0.0001 | Duration: 3.10s
== Status ==
Current time: 2024-01-07 08:40:52 (running for 00:08:53.64)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (18 PENDING, 4 RUNNING, 2 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00001 | RUNNING    | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.288 |  0.169 |                   91 |
| train_d77f6_00002 | RUNNING    | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.24  |  0.153 |                   94 |
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.897 |  0.181 |                   14 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.404 |  0.176 |                   14 |
| train_d77f6_00006 | PENDING    |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=105266)[0m rmse: 0.15325342118740082
[2m[36m(func pid=105266)[0m mae:  0.09390877187252045
[2m[36m(func pid=105266)[0m rmse_per_class: [0.103, 0.231, 0.05, 0.321, 0.07, 0.143, 0.206, 0.111, 0.195, 0.103]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=104843)[0m rmse: 0.16808326542377472
[2m[36m(func pid=104843)[0m mae:  0.1057160273194313
[2m[36m(func pid=104843)[0m rmse_per_class: [0.069, 0.248, 0.038, 0.313, 0.055, 0.18, 0.266, 0.163, 0.164, 0.184]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.3975 | Steps: 2 | Val loss: 0.3223 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=122279)[0m rmse: 0.18128351867198944
[2m[36m(func pid=122279)[0m mae:  0.13309916853904724
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.267, 0.09, 0.324, 0.106, 0.194, 0.311, 0.154, 0.138, 0.123]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 94] | Train loss: 0.2584 | Steps: 2 | Val loss: 0.2916 | Batch size: 32 | lr: 0.01 | Duration: 2.73s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 92] | Train loss: 0.2671 | Steps: 2 | Val loss: 0.3156 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=122389)[0m rmse: 0.1756589710712433
[2m[36m(func pid=122389)[0m mae:  0.12731148302555084
[2m[36m(func pid=122389)[0m rmse_per_class: [0.109, 0.269, 0.092, 0.328, 0.089, 0.192, 0.283, 0.139, 0.145, 0.111]
[2m[36m(func pid=122389)[0m 
== Status ==
Current time: 2024-01-07 08:40:57 (running for 00:08:58.71)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (18 PENDING, 4 RUNNING, 2 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00001 | RUNNING    | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.272 |  0.168 |                   92 |
| train_d77f6_00002 | RUNNING    | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.258 |  0.153 |                   95 |
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.88  |  0.181 |                   15 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.397 |  0.176 |                   15 |
| train_d77f6_00006 | PENDING    |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=105266)[0m rmse: 0.15317939221858978
[2m[36m(func pid=105266)[0m mae:  0.09359162300825119
[2m[36m(func pid=105266)[0m rmse_per_class: [0.102, 0.232, 0.049, 0.32, 0.071, 0.143, 0.203, 0.11, 0.197, 0.104]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.8616 | Steps: 2 | Val loss: 0.6840 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=104843)[0m rmse: 0.16691316664218903
[2m[36m(func pid=104843)[0m mae:  0.10486503690481186
[2m[36m(func pid=104843)[0m rmse_per_class: [0.069, 0.246, 0.038, 0.318, 0.055, 0.179, 0.269, 0.159, 0.164, 0.172]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=122279)[0m rmse: 0.18130169808864594
[2m[36m(func pid=122279)[0m mae:  0.13308921456336975
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.267, 0.09, 0.324, 0.106, 0.194, 0.311, 0.154, 0.138, 0.123]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.3881 | Steps: 2 | Val loss: 0.3198 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 95] | Train loss: 0.2377 | Steps: 2 | Val loss: 0.2898 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 93] | Train loss: 0.2816 | Steps: 2 | Val loss: 0.3156 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=122389)[0m rmse: 0.1752723753452301
[2m[36m(func pid=122389)[0m mae:  0.12691597640514374
[2m[36m(func pid=122389)[0m rmse_per_class: [0.109, 0.269, 0.091, 0.328, 0.088, 0.192, 0.281, 0.138, 0.145, 0.111]
[2m[36m(func pid=122389)[0m 
== Status ==
Current time: 2024-01-07 08:41:02 (running for 00:09:03.81)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (18 PENDING, 4 RUNNING, 2 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00001 | RUNNING    | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.267 |  0.167 |                   93 |
| train_d77f6_00002 | RUNNING    | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.238 |  0.152 |                   96 |
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.862 |  0.181 |                   16 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.388 |  0.175 |                   16 |
| train_d77f6_00006 | PENDING    |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=105266)[0m rmse: 0.1524468958377838
[2m[36m(func pid=105266)[0m mae:  0.09310004115104675
[2m[36m(func pid=105266)[0m rmse_per_class: [0.101, 0.23, 0.05, 0.319, 0.072, 0.143, 0.2, 0.11, 0.194, 0.104]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.8509 | Steps: 2 | Val loss: 0.6714 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
[2m[36m(func pid=104843)[0m rmse: 0.1664808839559555
[2m[36m(func pid=104843)[0m mae:  0.10431800037622452
[2m[36m(func pid=104843)[0m rmse_per_class: [0.069, 0.246, 0.037, 0.32, 0.056, 0.179, 0.269, 0.153, 0.163, 0.172]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.3868 | Steps: 2 | Val loss: 0.3179 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 96] | Train loss: 0.2388 | Steps: 2 | Val loss: 0.2894 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=122279)[0m rmse: 0.18130555748939514
[2m[36m(func pid=122279)[0m mae:  0.1330718696117401
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.267, 0.09, 0.324, 0.105, 0.194, 0.311, 0.154, 0.138, 0.123]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 94] | Train loss: 0.2645 | Steps: 2 | Val loss: 0.3128 | Batch size: 32 | lr: 0.001 | Duration: 2.76s
== Status ==
Current time: 2024-01-07 08:41:08 (running for 00:09:08.94)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (18 PENDING, 4 RUNNING, 2 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00001 | RUNNING    | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.282 |  0.166 |                   94 |
| train_d77f6_00002 | RUNNING    | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.239 |  0.152 |                   97 |
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.851 |  0.181 |                   17 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.388 |  0.175 |                   16 |
| train_d77f6_00006 | PENDING    |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=105266)[0m rmse: 0.1523384153842926
[2m[36m(func pid=105266)[0m mae:  0.0930032730102539
[2m[36m(func pid=105266)[0m rmse_per_class: [0.1, 0.229, 0.051, 0.319, 0.073, 0.144, 0.198, 0.111, 0.193, 0.106]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.17475950717926025
[2m[36m(func pid=122389)[0m mae:  0.12644746899604797
[2m[36m(func pid=122389)[0m rmse_per_class: [0.11, 0.269, 0.09, 0.328, 0.087, 0.191, 0.28, 0.137, 0.146, 0.11]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.8333 | Steps: 2 | Val loss: 0.6592 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=104843)[0m rmse: 0.16439267992973328
[2m[36m(func pid=104843)[0m mae:  0.10306378453969955
[2m[36m(func pid=104843)[0m rmse_per_class: [0.07, 0.244, 0.037, 0.321, 0.057, 0.177, 0.27, 0.144, 0.163, 0.161]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.3814 | Steps: 2 | Val loss: 0.3165 | Batch size: 32 | lr: 0.001 | Duration: 2.74s
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 97] | Train loss: 0.2387 | Steps: 2 | Val loss: 0.2891 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=122279)[0m rmse: 0.18118520081043243
[2m[36m(func pid=122279)[0m mae:  0.13296039402484894
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.267, 0.09, 0.324, 0.105, 0.194, 0.31, 0.154, 0.138, 0.123]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 95] | Train loss: 0.2627 | Steps: 2 | Val loss: 0.3118 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
== Status ==
Current time: 2024-01-07 08:41:13 (running for 00:09:14.09)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (18 PENDING, 4 RUNNING, 2 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00001 | RUNNING    | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.265 |  0.164 |                   95 |
| train_d77f6_00002 | RUNNING    | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.239 |  0.152 |                   97 |
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.833 |  0.181 |                   18 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.381 |  0.174 |                   18 |
| train_d77f6_00006 | PENDING    |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=122389)[0m rmse: 0.17422810196876526
[2m[36m(func pid=122389)[0m mae:  0.12594729661941528
[2m[36m(func pid=122389)[0m rmse_per_class: [0.11, 0.269, 0.089, 0.327, 0.086, 0.191, 0.278, 0.137, 0.147, 0.11]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=105266)[0m rmse: 0.15243881940841675
[2m[36m(func pid=105266)[0m mae:  0.09303340315818787
[2m[36m(func pid=105266)[0m rmse_per_class: [0.102, 0.228, 0.051, 0.318, 0.073, 0.145, 0.198, 0.111, 0.191, 0.107]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.8181 | Steps: 2 | Val loss: 0.6469 | Batch size: 32 | lr: 0.0001 | Duration: 2.72s
[2m[36m(func pid=104843)[0m rmse: 0.16366063058376312
[2m[36m(func pid=104843)[0m mae:  0.1025192141532898
[2m[36m(func pid=104843)[0m rmse_per_class: [0.07, 0.244, 0.036, 0.323, 0.057, 0.176, 0.273, 0.139, 0.163, 0.155]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 98] | Train loss: 0.2482 | Steps: 2 | Val loss: 0.2911 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.3813 | Steps: 2 | Val loss: 0.3156 | Batch size: 32 | lr: 0.001 | Duration: 3.17s
[2m[36m(func pid=122279)[0m rmse: 0.18115054070949554
[2m[36m(func pid=122279)[0m mae:  0.1329340934753418
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.267, 0.09, 0.324, 0.104, 0.194, 0.31, 0.154, 0.138, 0.123]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 96] | Train loss: 0.2700 | Steps: 2 | Val loss: 0.3108 | Batch size: 32 | lr: 0.001 | Duration: 3.29s
== Status ==
Current time: 2024-01-07 08:41:18 (running for 00:09:19.61)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (18 PENDING, 4 RUNNING, 2 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00001 | RUNNING    | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.263 |  0.164 |                   96 |
| train_d77f6_00002 | RUNNING    | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.248 |  0.153 |                   99 |
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.818 |  0.181 |                   19 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.381 |  0.174 |                   18 |
| train_d77f6_00006 | PENDING    |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=105266)[0m rmse: 0.15289521217346191
[2m[36m(func pid=105266)[0m mae:  0.09304293245077133
[2m[36m(func pid=105266)[0m rmse_per_class: [0.104, 0.227, 0.051, 0.316, 0.074, 0.145, 0.197, 0.111, 0.195, 0.108]
[2m[36m(func pid=105266)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.17371150851249695
[2m[36m(func pid=122389)[0m mae:  0.1255030781030655
[2m[36m(func pid=122389)[0m rmse_per_class: [0.11, 0.269, 0.087, 0.327, 0.084, 0.191, 0.277, 0.136, 0.147, 0.109]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.8019 | Steps: 2 | Val loss: 0.6351 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=104843)[0m rmse: 0.16310621798038483
[2m[36m(func pid=104843)[0m mae:  0.10195660591125488
[2m[36m(func pid=104843)[0m rmse_per_class: [0.07, 0.244, 0.035, 0.324, 0.057, 0.175, 0.273, 0.135, 0.161, 0.155]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=105266)[0m [N0-GPU0] | [Epoch: 99] | Train loss: 0.2413 | Steps: 2 | Val loss: 0.2913 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.3766 | Steps: 2 | Val loss: 0.3148 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=122279)[0m rmse: 0.18108266592025757
[2m[36m(func pid=122279)[0m mae:  0.13285750150680542
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.267, 0.09, 0.324, 0.104, 0.194, 0.31, 0.154, 0.138, 0.123]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 97] | Train loss: 0.2655 | Steps: 2 | Val loss: 0.3086 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
== Status ==
Current time: 2024-01-07 08:41:23 (running for 00:09:24.78)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (18 PENDING, 3 RUNNING, 3 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00001 | RUNNING    | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.27  |  0.163 |                   97 |
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.802 |  0.181 |                   20 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.381 |  0.174 |                   19 |
| train_d77f6_00006 | PENDING    |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=105266)[0m rmse: 0.15314775705337524
[2m[36m(func pid=105266)[0m mae:  0.09344299137592316
[2m[36m(func pid=105266)[0m rmse_per_class: [0.107, 0.226, 0.051, 0.315, 0.074, 0.145, 0.198, 0.111, 0.192, 0.112]
[2m[36m(func pid=122389)[0m rmse: 0.17320778965950012
[2m[36m(func pid=122389)[0m mae:  0.12511029839515686
[2m[36m(func pid=122389)[0m rmse_per_class: [0.11, 0.268, 0.086, 0.326, 0.083, 0.191, 0.276, 0.136, 0.148, 0.109]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.7865 | Steps: 2 | Val loss: 0.6239 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=104843)[0m rmse: 0.16162879765033722
[2m[36m(func pid=104843)[0m mae:  0.10101187229156494
[2m[36m(func pid=104843)[0m rmse_per_class: [0.071, 0.242, 0.035, 0.326, 0.058, 0.173, 0.272, 0.13, 0.161, 0.148]
[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=122279)[0m rmse: 0.18101076781749725
[2m[36m(func pid=122279)[0m mae:  0.13277596235275269
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.267, 0.09, 0.324, 0.104, 0.194, 0.31, 0.154, 0.138, 0.123]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.3717 | Steps: 2 | Val loss: 0.3138 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 98] | Train loss: 0.2579 | Steps: 2 | Val loss: 0.3063 | Batch size: 32 | lr: 0.001 | Duration: 2.73s
[2m[36m(func pid=122389)[0m rmse: 0.17260152101516724
[2m[36m(func pid=122389)[0m mae:  0.12455855309963226
[2m[36m(func pid=122389)[0m rmse_per_class: [0.11, 0.268, 0.084, 0.325, 0.082, 0.191, 0.274, 0.136, 0.148, 0.109]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.7745 | Steps: 2 | Val loss: 0.6140 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=104843)[0m rmse: 0.1601705104112625
[2m[36m(func pid=104843)[0m mae:  0.10016731917858124
[2m[36m(func pid=104843)[0m rmse_per_class: [0.072, 0.24, 0.034, 0.328, 0.059, 0.171, 0.27, 0.126, 0.161, 0.14]
== Status ==
Current time: 2024-01-07 08:41:29 (running for 00:09:30.56)
Memory usage on this node: 22.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (17 PENDING, 4 RUNNING, 3 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00001 | RUNNING    | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.265 |  0.162 |                   98 |
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.786 |  0.181 |                   21 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.372 |  0.173 |                   21 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=104843)[0m 
[2m[36m(func pid=127565)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=127565)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=127565)[0m Configuration completed!
[2m[36m(func pid=127565)[0m New optimizer parameters:
[2m[36m(func pid=127565)[0m SGD (
[2m[36m(func pid=127565)[0m Parameter Group 0
[2m[36m(func pid=127565)[0m     dampening: 0
[2m[36m(func pid=127565)[0m     differentiable: False
[2m[36m(func pid=127565)[0m     foreach: None
[2m[36m(func pid=127565)[0m     lr: 0.01
[2m[36m(func pid=127565)[0m     maximize: False
[2m[36m(func pid=127565)[0m     momentum: 0.9
[2m[36m(func pid=127565)[0m     nesterov: False
[2m[36m(func pid=127565)[0m     weight_decay: 0
[2m[36m(func pid=127565)[0m )
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=122279)[0m rmse: 0.180993914604187
[2m[36m(func pid=122279)[0m mae:  0.1327444314956665
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.267, 0.09, 0.324, 0.104, 0.194, 0.31, 0.153, 0.138, 0.123]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.3737 | Steps: 2 | Val loss: 0.3130 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 08:41:34 (running for 00:09:35.85)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (17 PENDING, 4 RUNNING, 3 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00001 | RUNNING    | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.258 |  0.16  |                   99 |
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.775 |  0.181 |                   22 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.374 |  0.172 |                   22 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |        |        |                      |
| train_d77f6_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=122389)[0m rmse: 0.17207807302474976
[2m[36m(func pid=122389)[0m mae:  0.12413521856069565
[2m[36m(func pid=122389)[0m rmse_per_class: [0.109, 0.268, 0.083, 0.324, 0.081, 0.19, 0.274, 0.135, 0.148, 0.108]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=104843)[0m [N0-GPU0] | [Epoch: 99] | Train loss: 0.2741 | Steps: 2 | Val loss: 0.3048 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.7599 | Steps: 2 | Val loss: 0.6039 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 1.0295 | Steps: 2 | Val loss: 0.6490 | Batch size: 32 | lr: 0.01 | Duration: 4.69s
[2m[36m(func pid=104843)[0m rmse: 0.159099280834198
[2m[36m(func pid=104843)[0m mae:  0.09922725707292557
[2m[36m(func pid=104843)[0m rmse_per_class: [0.074, 0.238, 0.033, 0.328, 0.059, 0.17, 0.266, 0.123, 0.161, 0.14]
[2m[36m(func pid=122279)[0m rmse: 0.1810634434223175
[2m[36m(func pid=122279)[0m mae:  0.13276423513889313
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.267, 0.09, 0.324, 0.104, 0.194, 0.31, 0.153, 0.138, 0.124]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.3786 | Steps: 2 | Val loss: 0.3124 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=127565)[0m rmse: 0.17794132232666016
[2m[36m(func pid=127565)[0m mae:  0.1304139941930771
[2m[36m(func pid=127565)[0m rmse_per_class: [0.104, 0.267, 0.085, 0.325, 0.097, 0.192, 0.301, 0.155, 0.139, 0.114]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.17164501547813416
[2m[36m(func pid=122389)[0m mae:  0.12378281354904175
[2m[36m(func pid=122389)[0m rmse_per_class: [0.109, 0.267, 0.082, 0.324, 0.08, 0.19, 0.273, 0.135, 0.149, 0.108]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.7538 | Steps: 2 | Val loss: 0.5936 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.7124 | Steps: 2 | Val loss: 0.4378 | Batch size: 32 | lr: 0.01 | Duration: 2.77s
[2m[36m(func pid=122279)[0m rmse: 0.18097412586212158
[2m[36m(func pid=122279)[0m mae:  0.13265995681285858
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.104, 0.194, 0.309, 0.153, 0.138, 0.123]
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.3598 | Steps: 2 | Val loss: 0.3114 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=127565)[0m rmse: 0.17665736377239227
[2m[36m(func pid=127565)[0m mae:  0.12907059490680695
[2m[36m(func pid=127565)[0m rmse_per_class: [0.104, 0.268, 0.088, 0.326, 0.092, 0.192, 0.294, 0.153, 0.141, 0.109]
== Status ==
Current time: 2024-01-07 08:41:40 (running for 00:09:41.22)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.76  |  0.181 |                   23 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.379 |  0.172 |                   23 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  1.029 |  0.178 |                    1 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


== Status ==
Current time: 2024-01-07 08:41:45 (running for 00:09:46.38)
Memory usage on this node: 23.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.754 |  0.181 |                   24 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.379 |  0.172 |                   23 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  1.029 |  0.178 |                    1 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=128390)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=128390)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=128390)[0m Configuration completed!
[2m[36m(func pid=128390)[0m New optimizer parameters:
[2m[36m(func pid=128390)[0m SGD (
[2m[36m(func pid=128390)[0m Parameter Group 0
[2m[36m(func pid=128390)[0m     dampening: 0
[2m[36m(func pid=128390)[0m     differentiable: False
[2m[36m(func pid=128390)[0m     foreach: None
[2m[36m(func pid=128390)[0m     lr: 0.1
[2m[36m(func pid=128390)[0m     maximize: False
[2m[36m(func pid=128390)[0m     momentum: 0.9
[2m[36m(func pid=128390)[0m     nesterov: False
[2m[36m(func pid=128390)[0m     weight_decay: 0
[2m[36m(func pid=128390)[0m )
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.17106559872627258
[2m[36m(func pid=122389)[0m mae:  0.12332004308700562
[2m[36m(func pid=122389)[0m rmse_per_class: [0.108, 0.267, 0.08, 0.323, 0.08, 0.19, 0.272, 0.134, 0.149, 0.108]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.7383 | Steps: 2 | Val loss: 0.5848 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.4571 | Steps: 2 | Val loss: 0.3339 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.3675 | Steps: 2 | Val loss: 0.3107 | Batch size: 32 | lr: 0.001 | Duration: 3.12s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 0.7655 | Steps: 2 | Val loss: 0.3229 | Batch size: 32 | lr: 0.1 | Duration: 4.69s
== Status ==
Current time: 2024-01-07 08:41:50 (running for 00:09:51.44)
Memory usage on this node: 25.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.754 |  0.181 |                   24 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.36  |  0.171 |                   24 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.712 |  0.177 |                    2 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |        |        |                      |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=122279)[0m rmse: 0.18095698952674866
[2m[36m(func pid=122279)[0m mae:  0.13262982666492462
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.104, 0.194, 0.309, 0.153, 0.138, 0.123]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=127565)[0m rmse: 0.17449498176574707
[2m[36m(func pid=127565)[0m mae:  0.12695243954658508
[2m[36m(func pid=127565)[0m rmse_per_class: [0.106, 0.27, 0.091, 0.331, 0.086, 0.191, 0.281, 0.141, 0.145, 0.103]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.1706135869026184
[2m[36m(func pid=122389)[0m mae:  0.12297483533620834
[2m[36m(func pid=122389)[0m rmse_per_class: [0.108, 0.266, 0.079, 0.322, 0.079, 0.19, 0.271, 0.134, 0.149, 0.108]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=128390)[0m rmse: 0.17147518694400787
[2m[36m(func pid=128390)[0m mae:  0.1231648176908493
[2m[36m(func pid=128390)[0m rmse_per_class: [0.105, 0.273, 0.083, 0.342, 0.073, 0.189, 0.267, 0.133, 0.153, 0.097]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.3940 | Steps: 2 | Val loss: 0.3193 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.7287 | Steps: 2 | Val loss: 0.5759 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.3604 | Steps: 2 | Val loss: 0.3097 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.5050 | Steps: 2 | Val loss: 0.4651 | Batch size: 32 | lr: 0.1 | Duration: 3.01s
== Status ==
Current time: 2024-01-07 08:41:55 (running for 00:09:56.83)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.738 |  0.181 |                   25 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.367 |  0.171 |                   25 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.394 |  0.172 |                    4 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.765 |  0.171 |                    1 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=127565)[0m rmse: 0.1720917820930481
[2m[36m(func pid=127565)[0m mae:  0.12412242591381073
[2m[36m(func pid=127565)[0m rmse_per_class: [0.107, 0.27, 0.089, 0.337, 0.078, 0.19, 0.268, 0.133, 0.151, 0.098]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=122279)[0m rmse: 0.18089166283607483
[2m[36m(func pid=122279)[0m mae:  0.1325625479221344
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.104, 0.194, 0.309, 0.153, 0.138, 0.123]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.17008447647094727
[2m[36m(func pid=122389)[0m mae:  0.12253829091787338
[2m[36m(func pid=122389)[0m rmse_per_class: [0.107, 0.266, 0.077, 0.322, 0.078, 0.189, 0.27, 0.134, 0.149, 0.108]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=128390)[0m rmse: 0.18663547933101654
[2m[36m(func pid=128390)[0m mae:  0.1230081096291542
[2m[36m(func pid=128390)[0m rmse_per_class: [0.094, 0.281, 0.049, 0.373, 0.055, 0.189, 0.403, 0.149, 0.179, 0.094]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.4044 | Steps: 2 | Val loss: 0.3370 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.7165 | Steps: 2 | Val loss: 0.5674 | Batch size: 32 | lr: 0.0001 | Duration: 3.09s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.3623 | Steps: 2 | Val loss: 0.3089 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.6278 | Steps: 2 | Val loss: 0.5247 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 08:42:01 (running for 00:10:02.06)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.729 |  0.181 |                   26 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.36  |  0.17  |                   26 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.404 |  0.17  |                    5 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.505 |  0.187 |                    2 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=127565)[0m rmse: 0.1700097918510437
[2m[36m(func pid=127565)[0m mae:  0.1209864467382431
[2m[36m(func pid=127565)[0m rmse_per_class: [0.109, 0.269, 0.082, 0.34, 0.07, 0.188, 0.26, 0.133, 0.155, 0.095]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.16955797374248505
[2m[36m(func pid=122389)[0m mae:  0.12213747203350067
[2m[36m(func pid=122389)[0m rmse_per_class: [0.107, 0.266, 0.075, 0.321, 0.077, 0.189, 0.27, 0.134, 0.149, 0.108]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=122279)[0m rmse: 0.18083979189395905
[2m[36m(func pid=122279)[0m mae:  0.13253551721572876
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.268, 0.089, 0.324, 0.103, 0.194, 0.309, 0.153, 0.139, 0.123]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=128390)[0m rmse: 0.20242491364479065
[2m[36m(func pid=128390)[0m mae:  0.12966927886009216
[2m[36m(func pid=128390)[0m rmse_per_class: [0.094, 0.287, 0.045, 0.383, 0.056, 0.191, 0.528, 0.155, 0.189, 0.097]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.4302 | Steps: 2 | Val loss: 0.3588 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.3536 | Steps: 2 | Val loss: 0.3082 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.7054 | Steps: 2 | Val loss: 0.5583 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.5427 | Steps: 2 | Val loss: 0.4785 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
== Status ==
Current time: 2024-01-07 08:42:06 (running for 00:10:07.38)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.717 |  0.181 |                   27 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.362 |  0.17  |                   27 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.43  |  0.169 |                    6 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.628 |  0.202 |                    3 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=127565)[0m rmse: 0.16868437826633453
[2m[36m(func pid=127565)[0m mae:  0.1182488426566124
[2m[36m(func pid=127565)[0m rmse_per_class: [0.108, 0.267, 0.073, 0.342, 0.063, 0.186, 0.258, 0.136, 0.16, 0.093]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.16917981207370758
[2m[36m(func pid=122389)[0m mae:  0.12184591591358185
[2m[36m(func pid=122389)[0m rmse_per_class: [0.106, 0.265, 0.074, 0.32, 0.076, 0.189, 0.27, 0.133, 0.149, 0.108]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=122279)[0m rmse: 0.1807941496372223
[2m[36m(func pid=122279)[0m mae:  0.1324581801891327
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.268, 0.089, 0.324, 0.104, 0.194, 0.308, 0.153, 0.139, 0.123]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=128390)[0m rmse: 0.19566017389297485
[2m[36m(func pid=128390)[0m mae:  0.1223553866147995
[2m[36m(func pid=128390)[0m rmse_per_class: [0.087, 0.278, 0.047, 0.382, 0.056, 0.171, 0.38, 0.155, 0.303, 0.097]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.4385 | Steps: 2 | Val loss: 0.3710 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.6972 | Steps: 2 | Val loss: 0.5500 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.3547 | Steps: 2 | Val loss: 0.3077 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.3898 | Steps: 2 | Val loss: 0.3989 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=127565)[0m rmse: 0.16722634434700012
[2m[36m(func pid=127565)[0m mae:  0.11539242416620255
[2m[36m(func pid=127565)[0m rmse_per_class: [0.106, 0.265, 0.062, 0.342, 0.059, 0.185, 0.262, 0.138, 0.162, 0.091]
[2m[36m(func pid=127565)[0m 
== Status ==
Current time: 2024-01-07 08:42:11 (running for 00:10:12.67)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.705 |  0.181 |                   28 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.354 |  0.169 |                   28 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.438 |  0.167 |                    7 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.543 |  0.196 |                    4 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=122279)[0m rmse: 0.18080376088619232
[2m[36m(func pid=122279)[0m mae:  0.1324489414691925
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.103, 0.194, 0.308, 0.153, 0.139, 0.123]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.1688643991947174
[2m[36m(func pid=122389)[0m mae:  0.12156683206558228
[2m[36m(func pid=122389)[0m rmse_per_class: [0.106, 0.265, 0.073, 0.32, 0.076, 0.189, 0.269, 0.133, 0.15, 0.108]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=128390)[0m rmse: 0.18818101286888123
[2m[36m(func pid=128390)[0m mae:  0.11912517249584198
[2m[36m(func pid=128390)[0m rmse_per_class: [0.084, 0.243, 0.041, 0.364, 0.056, 0.292, 0.215, 0.149, 0.341, 0.097]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.4260 | Steps: 2 | Val loss: 0.3702 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.6808 | Steps: 2 | Val loss: 0.5428 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.3472 | Steps: 2 | Val loss: 0.3069 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.3174 | Steps: 2 | Val loss: 0.3351 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 08:42:17 (running for 00:10:17.90)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.697 |  0.181 |                   29 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.355 |  0.169 |                   29 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.426 |  0.166 |                    8 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.39  |  0.188 |                    5 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=127565)[0m rmse: 0.1656234860420227
[2m[36m(func pid=127565)[0m mae:  0.11281529814004898
[2m[36m(func pid=127565)[0m rmse_per_class: [0.104, 0.262, 0.054, 0.338, 0.056, 0.183, 0.264, 0.139, 0.165, 0.09]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=122279)[0m rmse: 0.18075627088546753
[2m[36m(func pid=122279)[0m mae:  0.132389634847641
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.103, 0.194, 0.308, 0.153, 0.139, 0.123]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.16839978098869324
[2m[36m(func pid=122389)[0m mae:  0.12116936594247818
[2m[36m(func pid=122389)[0m rmse_per_class: [0.106, 0.265, 0.072, 0.319, 0.075, 0.189, 0.268, 0.133, 0.149, 0.108]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=128390)[0m rmse: 0.17137965559959412
[2m[36m(func pid=128390)[0m mae:  0.10789785534143448
[2m[36m(func pid=128390)[0m rmse_per_class: [0.084, 0.22, 0.026, 0.311, 0.056, 0.275, 0.265, 0.112, 0.269, 0.095]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.4082 | Steps: 2 | Val loss: 0.3600 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.6745 | Steps: 2 | Val loss: 0.5351 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.3499 | Steps: 2 | Val loss: 0.3061 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.3244 | Steps: 2 | Val loss: 0.3407 | Batch size: 32 | lr: 0.1 | Duration: 2.74s
== Status ==
Current time: 2024-01-07 08:42:22 (running for 00:10:23.13)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.681 |  0.181 |                   30 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.347 |  0.168 |                   30 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.408 |  0.164 |                    9 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.317 |  0.171 |                    6 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=127565)[0m rmse: 0.16389837861061096
[2m[36m(func pid=127565)[0m mae:  0.110711969435215
[2m[36m(func pid=127565)[0m rmse_per_class: [0.102, 0.258, 0.049, 0.334, 0.055, 0.181, 0.26, 0.139, 0.169, 0.09]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=122279)[0m rmse: 0.1807183027267456
[2m[36m(func pid=122279)[0m mae:  0.1323227733373642
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.103, 0.194, 0.307, 0.152, 0.139, 0.123]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.16804400086402893
[2m[36m(func pid=122389)[0m mae:  0.12088756263256073
[2m[36m(func pid=122389)[0m rmse_per_class: [0.106, 0.264, 0.071, 0.318, 0.075, 0.189, 0.268, 0.133, 0.149, 0.108]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=128390)[0m rmse: 0.16973254084587097
[2m[36m(func pid=128390)[0m mae:  0.10675780475139618
[2m[36m(func pid=128390)[0m rmse_per_class: [0.068, 0.248, 0.031, 0.302, 0.056, 0.183, 0.268, 0.139, 0.316, 0.087]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.3815 | Steps: 2 | Val loss: 0.3423 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.6691 | Steps: 2 | Val loss: 0.5275 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.3493 | Steps: 2 | Val loss: 0.3052 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.3041 | Steps: 2 | Val loss: 0.3800 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
== Status ==
Current time: 2024-01-07 08:42:27 (running for 00:10:28.25)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.675 |  0.181 |                   31 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.35  |  0.168 |                   31 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.382 |  0.161 |                   10 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.324 |  0.17  |                    7 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=127565)[0m rmse: 0.16132375597953796
[2m[36m(func pid=127565)[0m mae:  0.10850069671869278
[2m[36m(func pid=127565)[0m rmse_per_class: [0.101, 0.254, 0.046, 0.327, 0.055, 0.179, 0.249, 0.139, 0.174, 0.089]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=122279)[0m rmse: 0.1807330846786499
[2m[36m(func pid=122279)[0m mae:  0.13230964541435242
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.103, 0.194, 0.307, 0.153, 0.139, 0.123]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.16757932305335999
[2m[36m(func pid=122389)[0m mae:  0.12051907926797867
[2m[36m(func pid=122389)[0m rmse_per_class: [0.106, 0.264, 0.07, 0.317, 0.074, 0.188, 0.267, 0.133, 0.149, 0.107]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=128390)[0m rmse: 0.17954371869564056
[2m[36m(func pid=128390)[0m mae:  0.11431436240673065
[2m[36m(func pid=128390)[0m rmse_per_class: [0.074, 0.277, 0.032, 0.3, 0.054, 0.19, 0.268, 0.158, 0.348, 0.095]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.3455 | Steps: 2 | Val loss: 0.3199 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.6629 | Steps: 2 | Val loss: 0.5212 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.3473 | Steps: 2 | Val loss: 0.3041 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.3041 | Steps: 2 | Val loss: 0.3596 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
== Status ==
Current time: 2024-01-07 08:42:32 (running for 00:10:33.63)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.669 |  0.181 |                   32 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.349 |  0.168 |                   32 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.346 |  0.158 |                   11 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.304 |  0.18  |                    8 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=127565)[0m rmse: 0.15773527324199677
[2m[36m(func pid=127565)[0m mae:  0.10607953369617462
[2m[36m(func pid=127565)[0m rmse_per_class: [0.099, 0.25, 0.044, 0.316, 0.055, 0.177, 0.235, 0.137, 0.177, 0.089]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=122279)[0m rmse: 0.18070511519908905
[2m[36m(func pid=122279)[0m mae:  0.13228750228881836
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.324, 0.102, 0.194, 0.307, 0.153, 0.139, 0.123]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.16702817380428314
[2m[36m(func pid=122389)[0m mae:  0.12007524073123932
[2m[36m(func pid=122389)[0m rmse_per_class: [0.105, 0.263, 0.069, 0.316, 0.074, 0.188, 0.267, 0.133, 0.148, 0.107]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=128390)[0m rmse: 0.17881114780902863
[2m[36m(func pid=128390)[0m mae:  0.11122085154056549
[2m[36m(func pid=128390)[0m rmse_per_class: [0.071, 0.284, 0.037, 0.311, 0.051, 0.184, 0.362, 0.151, 0.241, 0.097]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.3183 | Steps: 2 | Val loss: 0.3005 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.6534 | Steps: 2 | Val loss: 0.5151 | Batch size: 32 | lr: 0.0001 | Duration: 3.07s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.3480 | Steps: 2 | Val loss: 0.3033 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.2697 | Steps: 2 | Val loss: 0.3195 | Batch size: 32 | lr: 0.1 | Duration: 2.74s
== Status ==
Current time: 2024-01-07 08:42:38 (running for 00:10:38.98)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.663 |  0.181 |                   33 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.347 |  0.167 |                   33 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.318 |  0.155 |                   12 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.304 |  0.179 |                    9 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=127565)[0m rmse: 0.15476329624652863
[2m[36m(func pid=127565)[0m mae:  0.10436347872018814
[2m[36m(func pid=127565)[0m rmse_per_class: [0.098, 0.245, 0.043, 0.306, 0.055, 0.176, 0.224, 0.134, 0.178, 0.088]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=122279)[0m rmse: 0.1807476431131363
[2m[36m(func pid=122279)[0m mae:  0.13231056928634644
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.324, 0.102, 0.194, 0.307, 0.153, 0.139, 0.123]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.16659648716449738
[2m[36m(func pid=122389)[0m mae:  0.11970952898263931
[2m[36m(func pid=122389)[0m rmse_per_class: [0.105, 0.263, 0.068, 0.315, 0.073, 0.188, 0.267, 0.133, 0.148, 0.107]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=128390)[0m rmse: 0.1634756624698639
[2m[36m(func pid=128390)[0m mae:  0.101206935942173
[2m[36m(func pid=128390)[0m rmse_per_class: [0.067, 0.265, 0.039, 0.316, 0.048, 0.164, 0.325, 0.131, 0.191, 0.088]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.2845 | Steps: 2 | Val loss: 0.2854 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.6448 | Steps: 2 | Val loss: 0.5095 | Batch size: 32 | lr: 0.0001 | Duration: 2.81s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.3400 | Steps: 2 | Val loss: 0.3028 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.2614 | Steps: 2 | Val loss: 0.2922 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
== Status ==
Current time: 2024-01-07 08:42:43 (running for 00:10:44.29)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.653 |  0.181 |                   34 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.348 |  0.167 |                   34 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.284 |  0.152 |                   13 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.27  |  0.163 |                   10 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=127565)[0m rmse: 0.15240652859210968
[2m[36m(func pid=127565)[0m mae:  0.10313472896814346
[2m[36m(func pid=127565)[0m rmse_per_class: [0.098, 0.242, 0.041, 0.297, 0.055, 0.175, 0.223, 0.129, 0.178, 0.088]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=122279)[0m rmse: 0.18067379295825958
[2m[36m(func pid=122279)[0m mae:  0.13226532936096191
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.324, 0.102, 0.194, 0.306, 0.152, 0.139, 0.123]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.16628803312778473
[2m[36m(func pid=122389)[0m mae:  0.11942596733570099
[2m[36m(func pid=122389)[0m rmse_per_class: [0.104, 0.263, 0.067, 0.315, 0.073, 0.188, 0.266, 0.133, 0.148, 0.107]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=128390)[0m rmse: 0.14915382862091064
[2m[36m(func pid=128390)[0m mae:  0.092141292989254
[2m[36m(func pid=128390)[0m rmse_per_class: [0.084, 0.239, 0.041, 0.307, 0.048, 0.185, 0.205, 0.117, 0.178, 0.088]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.2780 | Steps: 2 | Val loss: 0.2763 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.6374 | Steps: 2 | Val loss: 0.5031 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.3372 | Steps: 2 | Val loss: 0.3024 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.2540 | Steps: 2 | Val loss: 0.2945 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 08:42:48 (running for 00:10:49.47)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.645 |  0.181 |                   35 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.34  |  0.166 |                   35 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.278 |  0.15  |                   14 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.261 |  0.149 |                   11 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=127565)[0m rmse: 0.15043890476226807
[2m[36m(func pid=127565)[0m mae:  0.10216476768255234
[2m[36m(func pid=127565)[0m rmse_per_class: [0.095, 0.24, 0.04, 0.287, 0.055, 0.174, 0.227, 0.122, 0.176, 0.087]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=122279)[0m rmse: 0.18058553338050842
[2m[36m(func pid=122279)[0m mae:  0.13216331601142883
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.102, 0.194, 0.306, 0.152, 0.139, 0.123]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.1661064624786377
[2m[36m(func pid=122389)[0m mae:  0.11928500980138779
[2m[36m(func pid=122389)[0m rmse_per_class: [0.104, 0.262, 0.067, 0.315, 0.072, 0.187, 0.266, 0.132, 0.147, 0.106]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=128390)[0m rmse: 0.15521404147148132
[2m[36m(func pid=128390)[0m mae:  0.09527433663606644
[2m[36m(func pid=128390)[0m rmse_per_class: [0.075, 0.256, 0.042, 0.308, 0.048, 0.166, 0.224, 0.154, 0.19, 0.089]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.2824 | Steps: 2 | Val loss: 0.2713 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.6254 | Steps: 2 | Val loss: 0.4974 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.3457 | Steps: 2 | Val loss: 0.3021 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.2503 | Steps: 2 | Val loss: 0.2972 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
== Status ==
Current time: 2024-01-07 08:42:53 (running for 00:10:54.57)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.637 |  0.181 |                   36 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.337 |  0.166 |                   36 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.282 |  0.149 |                   15 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.254 |  0.155 |                   12 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=127565)[0m rmse: 0.1486114263534546
[2m[36m(func pid=127565)[0m mae:  0.10138732194900513
[2m[36m(func pid=127565)[0m rmse_per_class: [0.094, 0.239, 0.039, 0.279, 0.054, 0.173, 0.235, 0.116, 0.17, 0.088]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=122279)[0m rmse: 0.18060043454170227
[2m[36m(func pid=122279)[0m mae:  0.13215762376785278
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.325, 0.102, 0.194, 0.306, 0.152, 0.139, 0.123]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.16598348319530487
[2m[36m(func pid=122389)[0m mae:  0.11917511373758316
[2m[36m(func pid=122389)[0m rmse_per_class: [0.104, 0.262, 0.067, 0.314, 0.072, 0.187, 0.266, 0.132, 0.148, 0.106]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=128390)[0m rmse: 0.15776139497756958
[2m[36m(func pid=128390)[0m mae:  0.09717389941215515
[2m[36m(func pid=128390)[0m rmse_per_class: [0.072, 0.266, 0.041, 0.298, 0.048, 0.16, 0.226, 0.151, 0.228, 0.087]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.2720 | Steps: 2 | Val loss: 0.2690 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.6196 | Steps: 2 | Val loss: 0.4922 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.3423 | Steps: 2 | Val loss: 0.3014 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.2429 | Steps: 2 | Val loss: 0.2907 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
== Status ==
Current time: 2024-01-07 08:42:58 (running for 00:10:59.78)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.625 |  0.181 |                   37 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.346 |  0.166 |                   37 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.272 |  0.147 |                   16 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.25  |  0.158 |                   13 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=127565)[0m rmse: 0.1469215750694275
[2m[36m(func pid=127565)[0m mae:  0.10049253702163696
[2m[36m(func pid=127565)[0m rmse_per_class: [0.091, 0.237, 0.037, 0.274, 0.054, 0.172, 0.242, 0.112, 0.162, 0.089]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=122279)[0m rmse: 0.1806602030992508
[2m[36m(func pid=122279)[0m mae:  0.13218359649181366
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.103, 0.194, 0.306, 0.152, 0.139, 0.123]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.1655929833650589
[2m[36m(func pid=122389)[0m mae:  0.11881085485219955
[2m[36m(func pid=122389)[0m rmse_per_class: [0.104, 0.262, 0.066, 0.314, 0.072, 0.187, 0.265, 0.132, 0.148, 0.107]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=128390)[0m rmse: 0.1516716331243515
[2m[36m(func pid=128390)[0m mae:  0.0938025712966919
[2m[36m(func pid=128390)[0m rmse_per_class: [0.072, 0.247, 0.036, 0.286, 0.048, 0.171, 0.2, 0.123, 0.25, 0.085]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.2711 | Steps: 2 | Val loss: 0.2689 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.6122 | Steps: 2 | Val loss: 0.4863 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.3329 | Steps: 2 | Val loss: 0.3008 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.2484 | Steps: 2 | Val loss: 0.2844 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=127565)[0m rmse: 0.1465533822774887
[2m[36m(func pid=127565)[0m mae:  0.1004885584115982
[2m[36m(func pid=127565)[0m rmse_per_class: [0.087, 0.236, 0.036, 0.272, 0.054, 0.172, 0.247, 0.111, 0.158, 0.093]
== Status ==
Current time: 2024-01-07 08:43:04 (running for 00:11:05.11)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.62  |  0.181 |                   38 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.342 |  0.166 |                   38 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.271 |  0.147 |                   17 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.243 |  0.152 |                   14 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=122279)[0m rmse: 0.1806163489818573
[2m[36m(func pid=122279)[0m mae:  0.13212811946868896
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.103, 0.194, 0.305, 0.151, 0.139, 0.123]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.16525506973266602
[2m[36m(func pid=122389)[0m mae:  0.11851172149181366
[2m[36m(func pid=122389)[0m rmse_per_class: [0.103, 0.261, 0.066, 0.313, 0.071, 0.187, 0.265, 0.132, 0.147, 0.106]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=128390)[0m rmse: 0.1468367874622345
[2m[36m(func pid=128390)[0m mae:  0.09082317352294922
[2m[36m(func pid=128390)[0m rmse_per_class: [0.072, 0.238, 0.03, 0.282, 0.048, 0.168, 0.198, 0.114, 0.235, 0.084]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.2652 | Steps: 2 | Val loss: 0.2693 | Batch size: 32 | lr: 0.01 | Duration: 2.75s
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.6064 | Steps: 2 | Val loss: 0.4810 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.3272 | Steps: 2 | Val loss: 0.3003 | Batch size: 32 | lr: 0.001 | Duration: 3.06s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.2492 | Steps: 2 | Val loss: 0.2840 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
== Status ==
Current time: 2024-01-07 08:43:09 (running for 00:11:10.32)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.612 |  0.181 |                   39 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.333 |  0.165 |                   39 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.265 |  0.146 |                   18 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.248 |  0.147 |                   15 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=127565)[0m rmse: 0.14645680785179138
[2m[36m(func pid=127565)[0m mae:  0.10039287805557251
[2m[36m(func pid=127565)[0m rmse_per_class: [0.085, 0.237, 0.035, 0.27, 0.053, 0.171, 0.249, 0.114, 0.153, 0.097]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=122279)[0m rmse: 0.1804787665605545
[2m[36m(func pid=122279)[0m mae:  0.1320049911737442
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.102, 0.193, 0.305, 0.151, 0.14, 0.123]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.16504445672035217
[2m[36m(func pid=122389)[0m mae:  0.11835116147994995
[2m[36m(func pid=122389)[0m rmse_per_class: [0.103, 0.261, 0.066, 0.313, 0.072, 0.187, 0.265, 0.131, 0.147, 0.106]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=128390)[0m rmse: 0.14521223306655884
[2m[36m(func pid=128390)[0m mae:  0.09080328792333603
[2m[36m(func pid=128390)[0m rmse_per_class: [0.08, 0.24, 0.029, 0.294, 0.048, 0.155, 0.198, 0.111, 0.213, 0.084]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.2516 | Steps: 2 | Val loss: 0.2711 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.6007 | Steps: 2 | Val loss: 0.4764 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.3279 | Steps: 2 | Val loss: 0.2998 | Batch size: 32 | lr: 0.001 | Duration: 3.06s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.2394 | Steps: 2 | Val loss: 0.2842 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 08:43:14 (running for 00:11:15.45)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.606 |  0.18  |                   40 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.327 |  0.165 |                   40 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.252 |  0.147 |                   19 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.249 |  0.145 |                   16 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=127565)[0m rmse: 0.14716565608978271
[2m[36m(func pid=127565)[0m mae:  0.10097277164459229
[2m[36m(func pid=127565)[0m rmse_per_class: [0.083, 0.238, 0.034, 0.271, 0.054, 0.171, 0.249, 0.12, 0.149, 0.103]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=122279)[0m rmse: 0.18041101098060608
[2m[36m(func pid=122279)[0m mae:  0.1319420337677002
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.102, 0.193, 0.305, 0.151, 0.14, 0.122]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.1647796481847763
[2m[36m(func pid=122389)[0m mae:  0.11813689768314362
[2m[36m(func pid=122389)[0m rmse_per_class: [0.103, 0.261, 0.065, 0.313, 0.072, 0.186, 0.265, 0.131, 0.146, 0.106]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=128390)[0m rmse: 0.1470274180173874
[2m[36m(func pid=128390)[0m mae:  0.09234297275543213
[2m[36m(func pid=128390)[0m rmse_per_class: [0.098, 0.242, 0.032, 0.303, 0.05, 0.153, 0.205, 0.114, 0.188, 0.085]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.2537 | Steps: 2 | Val loss: 0.2734 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.5925 | Steps: 2 | Val loss: 0.4719 | Batch size: 32 | lr: 0.0001 | Duration: 2.77s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.3259 | Steps: 2 | Val loss: 0.2997 | Batch size: 32 | lr: 0.001 | Duration: 3.06s
== Status ==
Current time: 2024-01-07 08:43:19 (running for 00:11:20.59)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.601 |  0.18  |                   41 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.328 |  0.165 |                   41 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.254 |  0.148 |                   20 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.239 |  0.147 |                   17 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=127565)[0m rmse: 0.14783912897109985
[2m[36m(func pid=127565)[0m mae:  0.10144642740488052
[2m[36m(func pid=127565)[0m rmse_per_class: [0.082, 0.239, 0.034, 0.273, 0.055, 0.171, 0.247, 0.124, 0.146, 0.107]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.2465 | Steps: 2 | Val loss: 0.2888 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=122279)[0m rmse: 0.18037714064121246
[2m[36m(func pid=122279)[0m mae:  0.13191838562488556
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.102, 0.193, 0.305, 0.151, 0.14, 0.122]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.1647091656923294
[2m[36m(func pid=122389)[0m mae:  0.11807586997747421
[2m[36m(func pid=122389)[0m rmse_per_class: [0.103, 0.26, 0.065, 0.313, 0.072, 0.186, 0.264, 0.131, 0.146, 0.107]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=128390)[0m rmse: 0.15088893473148346
[2m[36m(func pid=128390)[0m mae:  0.09448239207267761
[2m[36m(func pid=128390)[0m rmse_per_class: [0.093, 0.253, 0.034, 0.316, 0.053, 0.152, 0.211, 0.123, 0.185, 0.087]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.2527 | Steps: 2 | Val loss: 0.2767 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.5868 | Steps: 2 | Val loss: 0.4675 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.3275 | Steps: 2 | Val loss: 0.2991 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=127565)[0m rmse: 0.1482965350151062
[2m[36m(func pid=127565)[0m mae:  0.10168153047561646
[2m[36m(func pid=127565)[0m rmse_per_class: [0.08, 0.241, 0.034, 0.275, 0.058, 0.171, 0.243, 0.126, 0.145, 0.11]
[2m[36m(func pid=127565)[0m 
== Status ==
Current time: 2024-01-07 08:43:25 (running for 00:11:25.90)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.592 |  0.18  |                   42 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.326 |  0.165 |                   42 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.253 |  0.148 |                   21 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.246 |  0.151 |                   18 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.2399 | Steps: 2 | Val loss: 0.2847 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=122279)[0m rmse: 0.18039673566818237
[2m[36m(func pid=122279)[0m mae:  0.13190177083015442
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.102, 0.193, 0.305, 0.151, 0.14, 0.123]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.1644415408372879
[2m[36m(func pid=122389)[0m mae:  0.11785503476858139
[2m[36m(func pid=122389)[0m rmse_per_class: [0.102, 0.26, 0.064, 0.313, 0.071, 0.186, 0.264, 0.131, 0.145, 0.107]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=128390)[0m rmse: 0.1477343887090683
[2m[36m(func pid=128390)[0m mae:  0.09217266738414764
[2m[36m(func pid=128390)[0m rmse_per_class: [0.08, 0.257, 0.032, 0.314, 0.056, 0.155, 0.196, 0.113, 0.185, 0.089]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.2473 | Steps: 2 | Val loss: 0.2791 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.5814 | Steps: 2 | Val loss: 0.4625 | Batch size: 32 | lr: 0.0001 | Duration: 2.78s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.3233 | Steps: 2 | Val loss: 0.2987 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
== Status ==
Current time: 2024-01-07 08:43:30 (running for 00:11:31.17)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.587 |  0.18  |                   43 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.327 |  0.164 |                   43 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.247 |  0.148 |                   22 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.24  |  0.148 |                   19 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=127565)[0m rmse: 0.14836063981056213
[2m[36m(func pid=127565)[0m mae:  0.1015719547867775
[2m[36m(func pid=127565)[0m rmse_per_class: [0.08, 0.242, 0.034, 0.278, 0.062, 0.171, 0.237, 0.126, 0.143, 0.111]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.2446 | Steps: 2 | Val loss: 0.2790 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=122279)[0m rmse: 0.18032343685626984
[2m[36m(func pid=122279)[0m mae:  0.13180643320083618
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.102, 0.193, 0.304, 0.15, 0.14, 0.122]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.16416725516319275
[2m[36m(func pid=122389)[0m mae:  0.11762768030166626
[2m[36m(func pid=122389)[0m rmse_per_class: [0.102, 0.26, 0.064, 0.313, 0.072, 0.186, 0.264, 0.131, 0.145, 0.107]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=128390)[0m rmse: 0.14452597498893738
[2m[36m(func pid=128390)[0m mae:  0.08960812538862228
[2m[36m(func pid=128390)[0m rmse_per_class: [0.076, 0.248, 0.029, 0.3, 0.056, 0.164, 0.194, 0.105, 0.188, 0.087]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.2433 | Steps: 2 | Val loss: 0.2814 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.5745 | Steps: 2 | Val loss: 0.4586 | Batch size: 32 | lr: 0.0001 | Duration: 2.76s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.3189 | Steps: 2 | Val loss: 0.2983 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.2463 | Steps: 2 | Val loss: 0.2756 | Batch size: 32 | lr: 0.1 | Duration: 2.78s
== Status ==
Current time: 2024-01-07 08:43:35 (running for 00:11:36.53)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.581 |  0.18  |                   44 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.323 |  0.164 |                   44 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.243 |  0.148 |                   23 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.245 |  0.145 |                   20 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=127565)[0m rmse: 0.14804144203662872
[2m[36m(func pid=127565)[0m mae:  0.101169154047966
[2m[36m(func pid=127565)[0m rmse_per_class: [0.08, 0.242, 0.035, 0.28, 0.067, 0.17, 0.231, 0.122, 0.143, 0.11]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=122279)[0m rmse: 0.1803523600101471
[2m[36m(func pid=122279)[0m mae:  0.13179545104503632
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.102, 0.193, 0.304, 0.151, 0.14, 0.122]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.16395221650600433
[2m[36m(func pid=122389)[0m mae:  0.11742925643920898
[2m[36m(func pid=122389)[0m rmse_per_class: [0.102, 0.26, 0.063, 0.312, 0.071, 0.186, 0.263, 0.131, 0.145, 0.107]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=128390)[0m rmse: 0.1420472115278244
[2m[36m(func pid=128390)[0m mae:  0.08790569007396698
[2m[36m(func pid=128390)[0m rmse_per_class: [0.078, 0.241, 0.028, 0.29, 0.053, 0.154, 0.194, 0.103, 0.193, 0.087]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.2488 | Steps: 2 | Val loss: 0.2825 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.5646 | Steps: 2 | Val loss: 0.4549 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.2330 | Steps: 2 | Val loss: 0.2714 | Batch size: 32 | lr: 0.1 | Duration: 2.78s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.3164 | Steps: 2 | Val loss: 0.2977 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
== Status ==
Current time: 2024-01-07 08:43:40 (running for 00:11:41.86)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.575 |  0.18  |                   45 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.319 |  0.164 |                   45 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.249 |  0.147 |                   24 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.246 |  0.142 |                   21 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=127565)[0m rmse: 0.1471574604511261
[2m[36m(func pid=127565)[0m mae:  0.1003488078713417
[2m[36m(func pid=127565)[0m rmse_per_class: [0.08, 0.24, 0.035, 0.283, 0.071, 0.17, 0.225, 0.119, 0.144, 0.105]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=122279)[0m rmse: 0.18028566241264343
[2m[36m(func pid=122279)[0m mae:  0.13174214959144592
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.102, 0.193, 0.304, 0.15, 0.14, 0.122]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=128390)[0m rmse: 0.14146241545677185
[2m[36m(func pid=128390)[0m mae:  0.0880390852689743
[2m[36m(func pid=128390)[0m rmse_per_class: [0.093, 0.235, 0.033, 0.279, 0.053, 0.15, 0.197, 0.105, 0.183, 0.087]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.16363507509231567
[2m[36m(func pid=122389)[0m mae:  0.11711709201335907
[2m[36m(func pid=122389)[0m rmse_per_class: [0.101, 0.259, 0.062, 0.311, 0.072, 0.185, 0.263, 0.131, 0.145, 0.107]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.2424 | Steps: 2 | Val loss: 0.2826 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.5624 | Steps: 2 | Val loss: 0.4510 | Batch size: 32 | lr: 0.0001 | Duration: 3.05s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.2329 | Steps: 2 | Val loss: 0.2738 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.3179 | Steps: 2 | Val loss: 0.2971 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
== Status ==
Current time: 2024-01-07 08:43:46 (running for 00:11:47.16)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.565 |  0.18  |                   46 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.316 |  0.164 |                   46 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.242 |  0.146 |                   25 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.233 |  0.141 |                   22 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=127565)[0m rmse: 0.14638391137123108
[2m[36m(func pid=127565)[0m mae:  0.09949325025081635
[2m[36m(func pid=127565)[0m rmse_per_class: [0.08, 0.239, 0.035, 0.285, 0.073, 0.169, 0.22, 0.116, 0.144, 0.103]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=122279)[0m rmse: 0.18027305603027344
[2m[36m(func pid=122279)[0m mae:  0.13171865046024323
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.326, 0.102, 0.193, 0.303, 0.15, 0.14, 0.122]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=128390)[0m rmse: 0.14483660459518433
[2m[36m(func pid=128390)[0m mae:  0.09053229540586472
[2m[36m(func pid=128390)[0m rmse_per_class: [0.106, 0.234, 0.035, 0.279, 0.055, 0.15, 0.207, 0.111, 0.18, 0.09]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.16331863403320312
[2m[36m(func pid=122389)[0m mae:  0.11685152351856232
[2m[36m(func pid=122389)[0m rmse_per_class: [0.101, 0.259, 0.061, 0.31, 0.071, 0.185, 0.263, 0.131, 0.145, 0.107]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.2472 | Steps: 2 | Val loss: 0.2821 | Batch size: 32 | lr: 0.01 | Duration: 2.76s
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.5580 | Steps: 2 | Val loss: 0.4469 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.2386 | Steps: 2 | Val loss: 0.2777 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.3219 | Steps: 2 | Val loss: 0.2966 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 08:43:51 (running for 00:11:52.46)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.562 |  0.18  |                   47 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.318 |  0.163 |                   47 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.247 |  0.146 |                   26 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.233 |  0.145 |                   23 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=127565)[0m rmse: 0.14560870826244354
[2m[36m(func pid=127565)[0m mae:  0.09843967109918594
[2m[36m(func pid=127565)[0m rmse_per_class: [0.08, 0.238, 0.035, 0.287, 0.074, 0.168, 0.214, 0.115, 0.144, 0.1]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=122279)[0m rmse: 0.18019911646842957
[2m[36m(func pid=122279)[0m mae:  0.13165102899074554
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.101, 0.193, 0.303, 0.15, 0.14, 0.122]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=128390)[0m rmse: 0.1466350257396698
[2m[36m(func pid=128390)[0m mae:  0.09145886451005936
[2m[36m(func pid=128390)[0m rmse_per_class: [0.102, 0.237, 0.035, 0.292, 0.056, 0.151, 0.2, 0.117, 0.187, 0.092]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.1630452424287796
[2m[36m(func pid=122389)[0m mae:  0.11656278371810913
[2m[36m(func pid=122389)[0m rmse_per_class: [0.101, 0.259, 0.061, 0.309, 0.071, 0.185, 0.262, 0.131, 0.144, 0.108]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.2444 | Steps: 2 | Val loss: 0.2818 | Batch size: 32 | lr: 0.01 | Duration: 2.77s
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.5587 | Steps: 2 | Val loss: 0.4435 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.2329 | Steps: 2 | Val loss: 0.2772 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 08:43:56 (running for 00:11:57.57)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.558 |  0.18  |                   48 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.322 |  0.163 |                   48 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.244 |  0.145 |                   27 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.239 |  0.147 |                   24 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=127565)[0m rmse: 0.14524748921394348
[2m[36m(func pid=127565)[0m mae:  0.09800132364034653
[2m[36m(func pid=127565)[0m rmse_per_class: [0.081, 0.237, 0.036, 0.289, 0.073, 0.168, 0.212, 0.113, 0.147, 0.097]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.3164 | Steps: 2 | Val loss: 0.2961 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=122279)[0m rmse: 0.18011289834976196
[2m[36m(func pid=122279)[0m mae:  0.1315884292125702
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.101, 0.193, 0.303, 0.15, 0.14, 0.122]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=128390)[0m rmse: 0.14471685886383057
[2m[36m(func pid=128390)[0m mae:  0.09028805047273636
[2m[36m(func pid=128390)[0m rmse_per_class: [0.08, 0.239, 0.032, 0.301, 0.059, 0.151, 0.193, 0.109, 0.191, 0.092]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.1627892255783081
[2m[36m(func pid=122389)[0m mae:  0.11636088788509369
[2m[36m(func pid=122389)[0m rmse_per_class: [0.101, 0.259, 0.06, 0.309, 0.071, 0.185, 0.262, 0.131, 0.144, 0.107]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.2408 | Steps: 2 | Val loss: 0.2804 | Batch size: 32 | lr: 0.01 | Duration: 2.76s
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.5555 | Steps: 2 | Val loss: 0.4404 | Batch size: 32 | lr: 0.0001 | Duration: 2.76s
[2m[36m(func pid=127565)[0m rmse: 0.14436867833137512
[2m[36m(func pid=127565)[0m mae:  0.09706108272075653
[2m[36m(func pid=127565)[0m rmse_per_class: [0.081, 0.236, 0.036, 0.289, 0.071, 0.167, 0.209, 0.113, 0.147, 0.094]
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.2323 | Steps: 2 | Val loss: 0.2752 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 08:44:01 (running for 00:12:02.79)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.559 |  0.18  |                   49 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.316 |  0.163 |                   49 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.241 |  0.144 |                   28 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.233 |  0.145 |                   25 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.3177 | Steps: 2 | Val loss: 0.2959 | Batch size: 32 | lr: 0.001 | Duration: 3.04s
[2m[36m(func pid=122279)[0m rmse: 0.18007780611515045
[2m[36m(func pid=122279)[0m mae:  0.13156895339488983
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.101, 0.193, 0.303, 0.15, 0.14, 0.121]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=128390)[0m rmse: 0.1429414600133896
[2m[36m(func pid=128390)[0m mae:  0.08918489515781403
[2m[36m(func pid=128390)[0m rmse_per_class: [0.076, 0.239, 0.029, 0.298, 0.062, 0.152, 0.189, 0.105, 0.188, 0.09]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.2394 | Steps: 2 | Val loss: 0.2785 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=122389)[0m rmse: 0.16271376609802246
[2m[36m(func pid=122389)[0m mae:  0.11628358066082001
[2m[36m(func pid=122389)[0m rmse_per_class: [0.101, 0.259, 0.06, 0.309, 0.071, 0.185, 0.261, 0.13, 0.144, 0.107]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.5516 | Steps: 2 | Val loss: 0.4361 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=127565)[0m rmse: 0.1434699296951294
[2m[36m(func pid=127565)[0m mae:  0.0961090624332428
[2m[36m(func pid=127565)[0m rmse_per_class: [0.081, 0.235, 0.036, 0.287, 0.068, 0.167, 0.208, 0.113, 0.147, 0.092]
[2m[36m(func pid=127565)[0m 
== Status ==
Current time: 2024-01-07 08:44:07 (running for 00:12:08.05)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.556 |  0.18  |                   50 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.318 |  0.163 |                   50 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.239 |  0.143 |                   29 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.232 |  0.143 |                   26 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)

[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.2421 | Steps: 2 | Val loss: 0.2729 | Batch size: 32 | lr: 0.1 | Duration: 2.89s

[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.3143 | Steps: 2 | Val loss: 0.2956 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=122279)[0m rmse: 0.18005217611789703
[2m[36m(func pid=122279)[0m mae:  0.13151223957538605
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.101, 0.193, 0.303, 0.149, 0.14, 0.121]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=128390)[0m rmse: 0.14213216304779053
[2m[36m(func pid=128390)[0m mae:  0.08893954008817673
[2m[36m(func pid=128390)[0m rmse_per_class: [0.08, 0.236, 0.028, 0.29, 0.065, 0.152, 0.193, 0.105, 0.183, 0.091]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.2459 | Steps: 2 | Val loss: 0.2765 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=122389)[0m rmse: 0.16254208981990814
[2m[36m(func pid=122389)[0m mae:  0.11616363376379013
[2m[36m(func pid=122389)[0m rmse_per_class: [0.101, 0.258, 0.06, 0.308, 0.071, 0.185, 0.262, 0.13, 0.145, 0.107]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.5417 | Steps: 2 | Val loss: 0.4328 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
== Status ==
Current time: 2024-01-07 08:44:12 (running for 00:12:13.26)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.552 |  0.18  |                   51 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.314 |  0.163 |                   51 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.246 |  0.143 |                   30 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.242 |  0.142 |                   27 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=127565)[0m rmse: 0.1427752524614334
[2m[36m(func pid=127565)[0m mae:  0.09554518759250641
[2m[36m(func pid=127565)[0m rmse_per_class: [0.081, 0.233, 0.037, 0.283, 0.066, 0.166, 0.209, 0.112, 0.149, 0.091]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.2342 | Steps: 2 | Val loss: 0.2698 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.3090 | Steps: 2 | Val loss: 0.2957 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
[2m[36m(func pid=122279)[0m rmse: 0.1800215095281601
[2m[36m(func pid=122279)[0m mae:  0.13146734237670898
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.326, 0.101, 0.193, 0.303, 0.149, 0.14, 0.121]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=128390)[0m rmse: 0.14196369051933289
[2m[36m(func pid=128390)[0m mae:  0.08902734518051147
[2m[36m(func pid=128390)[0m rmse_per_class: [0.082, 0.234, 0.028, 0.285, 0.065, 0.152, 0.2, 0.11, 0.172, 0.09]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.2441 | Steps: 2 | Val loss: 0.2749 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=122389)[0m rmse: 0.16257864236831665
[2m[36m(func pid=122389)[0m mae:  0.11620192229747772
[2m[36m(func pid=122389)[0m rmse_per_class: [0.101, 0.258, 0.06, 0.309, 0.071, 0.184, 0.262, 0.13, 0.145, 0.107]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.5382 | Steps: 2 | Val loss: 0.4296 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.2318 | Steps: 2 | Val loss: 0.2710 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
== Status ==
Current time: 2024-01-07 08:44:17 (running for 00:12:18.53)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.542 |  0.18  |                   52 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.309 |  0.163 |                   52 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.244 |  0.142 |                   31 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.234 |  0.142 |                   28 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=127565)[0m rmse: 0.14203937351703644
[2m[36m(func pid=127565)[0m mae:  0.09487734735012054
[2m[36m(func pid=127565)[0m rmse_per_class: [0.082, 0.233, 0.037, 0.278, 0.063, 0.166, 0.21, 0.112, 0.151, 0.089]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.3075 | Steps: 2 | Val loss: 0.2952 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=122279)[0m rmse: 0.17998209595680237
[2m[36m(func pid=122279)[0m mae:  0.13144519925117493
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.269, 0.092, 0.326, 0.1, 0.193, 0.302, 0.149, 0.14, 0.122]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=128390)[0m rmse: 0.14374259114265442
[2m[36m(func pid=128390)[0m mae:  0.09001617133617401
[2m[36m(func pid=128390)[0m rmse_per_class: [0.085, 0.234, 0.03, 0.286, 0.062, 0.152, 0.203, 0.122, 0.172, 0.09]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.2398 | Steps: 2 | Val loss: 0.2750 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=122389)[0m rmse: 0.162313774228096
[2m[36m(func pid=122389)[0m mae:  0.11594164371490479
[2m[36m(func pid=122389)[0m rmse_per_class: [0.1, 0.258, 0.059, 0.308, 0.071, 0.184, 0.261, 0.13, 0.145, 0.106]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.5359 | Steps: 2 | Val loss: 0.4268 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.2399 | Steps: 2 | Val loss: 0.2734 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
== Status ==
Current time: 2024-01-07 08:44:22 (running for 00:12:23.80)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.538 |  0.18  |                   53 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.308 |  0.162 |                   53 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.24  |  0.142 |                   32 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.232 |  0.144 |                   29 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=127565)[0m rmse: 0.14215074479579926
[2m[36m(func pid=127565)[0m mae:  0.0948677808046341
[2m[36m(func pid=127565)[0m rmse_per_class: [0.081, 0.233, 0.036, 0.279, 0.062, 0.166, 0.211, 0.112, 0.15, 0.09]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.3154 | Steps: 2 | Val loss: 0.2955 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=122279)[0m rmse: 0.17991167306900024
[2m[36m(func pid=122279)[0m mae:  0.13140496611595154
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.1, 0.193, 0.302, 0.149, 0.14, 0.122]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=128390)[0m rmse: 0.14551511406898499
[2m[36m(func pid=128390)[0m mae:  0.09124398976564407
[2m[36m(func pid=128390)[0m rmse_per_class: [0.079, 0.237, 0.033, 0.292, 0.06, 0.151, 0.202, 0.124, 0.187, 0.089]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.2381 | Steps: 2 | Val loss: 0.2739 | Batch size: 32 | lr: 0.01 | Duration: 2.74s
[2m[36m(func pid=122389)[0m rmse: 0.16246141493320465
[2m[36m(func pid=122389)[0m mae:  0.11602691560983658
[2m[36m(func pid=122389)[0m rmse_per_class: [0.1, 0.258, 0.06, 0.309, 0.071, 0.184, 0.26, 0.13, 0.145, 0.107]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.5325 | Steps: 2 | Val loss: 0.4240 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.2395 | Steps: 2 | Val loss: 0.2792 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 08:44:28 (running for 00:12:28.93)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.536 |  0.18  |                   54 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.315 |  0.162 |                   54 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.238 |  0.142 |                   33 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.24  |  0.146 |                   30 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=127565)[0m rmse: 0.1418006718158722
[2m[36m(func pid=127565)[0m mae:  0.09460191428661346
[2m[36m(func pid=127565)[0m rmse_per_class: [0.081, 0.233, 0.036, 0.277, 0.06, 0.167, 0.213, 0.113, 0.15, 0.089]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.3066 | Steps: 2 | Val loss: 0.2956 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=122279)[0m rmse: 0.17981287837028503
[2m[36m(func pid=122279)[0m mae:  0.13131888210773468
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.1, 0.193, 0.302, 0.149, 0.14, 0.121]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=128390)[0m rmse: 0.14757388830184937
[2m[36m(func pid=128390)[0m mae:  0.09313373267650604
[2m[36m(func pid=128390)[0m rmse_per_class: [0.073, 0.243, 0.033, 0.296, 0.057, 0.152, 0.199, 0.113, 0.221, 0.089]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.2419 | Steps: 2 | Val loss: 0.2726 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=122389)[0m rmse: 0.16245391964912415
[2m[36m(func pid=122389)[0m mae:  0.11601021140813828
[2m[36m(func pid=122389)[0m rmse_per_class: [0.1, 0.258, 0.059, 0.31, 0.071, 0.184, 0.26, 0.129, 0.146, 0.108]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.5265 | Steps: 2 | Val loss: 0.4210 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 08:44:33 (running for 00:12:34.18)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.532 |  0.18  |                   55 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.307 |  0.162 |                   55 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.242 |  0.141 |                   34 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.239 |  0.148 |                   31 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=127565)[0m rmse: 0.141233429312706
[2m[36m(func pid=127565)[0m mae:  0.09419512748718262
[2m[36m(func pid=127565)[0m rmse_per_class: [0.081, 0.232, 0.036, 0.273, 0.059, 0.166, 0.215, 0.113, 0.147, 0.089]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.2443 | Steps: 2 | Val loss: 0.2791 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.3040 | Steps: 2 | Val loss: 0.2952 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=122279)[0m rmse: 0.1798083335161209
[2m[36m(func pid=122279)[0m mae:  0.13131432235240936
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.1, 0.193, 0.302, 0.149, 0.141, 0.122]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=128390)[0m rmse: 0.1467081606388092
[2m[36m(func pid=128390)[0m mae:  0.09257592260837555
[2m[36m(func pid=128390)[0m rmse_per_class: [0.07, 0.245, 0.029, 0.299, 0.054, 0.152, 0.192, 0.109, 0.231, 0.086]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.2393 | Steps: 2 | Val loss: 0.2733 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=122389)[0m rmse: 0.16220474243164062
[2m[36m(func pid=122389)[0m mae:  0.11579076945781708
[2m[36m(func pid=122389)[0m rmse_per_class: [0.099, 0.258, 0.059, 0.309, 0.071, 0.184, 0.26, 0.129, 0.146, 0.107]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.5221 | Steps: 2 | Val loss: 0.4190 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
== Status ==
Current time: 2024-01-07 08:44:38 (running for 00:12:39.45)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.527 |  0.18  |                   56 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.304 |  0.162 |                   56 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.239 |  0.142 |                   35 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.244 |  0.147 |                   32 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=127565)[0m rmse: 0.14151649177074432
[2m[36m(func pid=127565)[0m mae:  0.09457607567310333
[2m[36m(func pid=127565)[0m rmse_per_class: [0.081, 0.233, 0.036, 0.272, 0.059, 0.166, 0.218, 0.113, 0.147, 0.09]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.2386 | Steps: 2 | Val loss: 0.2708 | Batch size: 32 | lr: 0.1 | Duration: 2.98s
[2m[36m(func pid=122279)[0m rmse: 0.17972956597805023
[2m[36m(func pid=122279)[0m mae:  0.13124185800552368
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.1, 0.193, 0.302, 0.149, 0.14, 0.122]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.3109 | Steps: 2 | Val loss: 0.2950 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=128390)[0m rmse: 0.1425950974225998
[2m[36m(func pid=128390)[0m mae:  0.08942044526338577
[2m[36m(func pid=128390)[0m rmse_per_class: [0.068, 0.241, 0.026, 0.288, 0.053, 0.151, 0.192, 0.112, 0.211, 0.085]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.2338 | Steps: 2 | Val loss: 0.2741 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=122389)[0m rmse: 0.16207578778266907
[2m[36m(func pid=122389)[0m mae:  0.11567598581314087
[2m[36m(func pid=122389)[0m rmse_per_class: [0.099, 0.258, 0.059, 0.308, 0.071, 0.184, 0.26, 0.129, 0.146, 0.107]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.5206 | Steps: 2 | Val loss: 0.4167 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
== Status ==
Current time: 2024-01-07 08:44:43 (running for 00:12:44.75)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.522 |  0.18  |                   57 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.311 |  0.162 |                   57 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.234 |  0.142 |                   36 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.239 |  0.143 |                   33 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=127565)[0m rmse: 0.1417165845632553
[2m[36m(func pid=127565)[0m mae:  0.09475933015346527
[2m[36m(func pid=127565)[0m rmse_per_class: [0.081, 0.233, 0.036, 0.273, 0.059, 0.167, 0.219, 0.113, 0.146, 0.09]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.2337 | Steps: 2 | Val loss: 0.2697 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.3108 | Steps: 2 | Val loss: 0.2946 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=122279)[0m rmse: 0.1797897219657898
[2m[36m(func pid=122279)[0m mae:  0.1312669813632965
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.1, 0.193, 0.302, 0.149, 0.141, 0.121]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=128390)[0m rmse: 0.1424666941165924
[2m[36m(func pid=128390)[0m mae:  0.08946122229099274
[2m[36m(func pid=128390)[0m rmse_per_class: [0.076, 0.24, 0.026, 0.281, 0.057, 0.15, 0.197, 0.118, 0.193, 0.086]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.2400 | Steps: 2 | Val loss: 0.2758 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=122389)[0m rmse: 0.16187891364097595
[2m[36m(func pid=122389)[0m mae:  0.11551012098789215
[2m[36m(func pid=122389)[0m rmse_per_class: [0.099, 0.258, 0.058, 0.308, 0.07, 0.184, 0.259, 0.129, 0.146, 0.107]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.5138 | Steps: 2 | Val loss: 0.4135 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
== Status ==
Current time: 2024-01-07 08:44:49 (running for 00:12:50.11)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.521 |  0.18  |                   58 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.311 |  0.162 |                   58 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.24  |  0.142 |                   37 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.234 |  0.142 |                   34 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=127565)[0m rmse: 0.14222820103168488
[2m[36m(func pid=127565)[0m mae:  0.09517570585012436
[2m[36m(func pid=127565)[0m rmse_per_class: [0.082, 0.234, 0.035, 0.276, 0.059, 0.167, 0.219, 0.114, 0.147, 0.09]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.2342 | Steps: 2 | Val loss: 0.2732 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.3009 | Steps: 2 | Val loss: 0.2942 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=122279)[0m rmse: 0.17969383299350739
[2m[36m(func pid=122279)[0m mae:  0.131166011095047
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.1, 0.193, 0.301, 0.148, 0.14, 0.121]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=128390)[0m rmse: 0.14471371471881866
[2m[36m(func pid=128390)[0m mae:  0.09110961854457855
[2m[36m(func pid=128390)[0m rmse_per_class: [0.087, 0.24, 0.027, 0.284, 0.061, 0.151, 0.203, 0.125, 0.179, 0.09]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.2505 | Steps: 2 | Val loss: 0.2769 | Batch size: 32 | lr: 0.01 | Duration: 2.73s
[2m[36m(func pid=122389)[0m rmse: 0.16161313652992249
[2m[36m(func pid=122389)[0m mae:  0.11528661102056503
[2m[36m(func pid=122389)[0m rmse_per_class: [0.099, 0.257, 0.058, 0.307, 0.071, 0.183, 0.259, 0.129, 0.146, 0.107]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.5136 | Steps: 2 | Val loss: 0.4112 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 08:44:54 (running for 00:12:55.18)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.514 |  0.18  |                   59 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.301 |  0.162 |                   59 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.25  |  0.142 |                   38 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.234 |  0.145 |                   35 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=127565)[0m rmse: 0.14228007197380066
[2m[36m(func pid=127565)[0m mae:  0.09534513205289841
[2m[36m(func pid=127565)[0m rmse_per_class: [0.082, 0.233, 0.035, 0.276, 0.058, 0.165, 0.219, 0.113, 0.147, 0.093]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.2254 | Steps: 2 | Val loss: 0.2719 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=122279)[0m rmse: 0.17963603138923645
[2m[36m(func pid=122279)[0m mae:  0.13113845884799957
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.099, 0.193, 0.301, 0.148, 0.141, 0.121]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.3044 | Steps: 2 | Val loss: 0.2937 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=128390)[0m rmse: 0.14336343109607697
[2m[36m(func pid=128390)[0m mae:  0.09046278893947601
[2m[36m(func pid=128390)[0m rmse_per_class: [0.091, 0.24, 0.028, 0.291, 0.061, 0.151, 0.196, 0.114, 0.172, 0.09]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.2359 | Steps: 2 | Val loss: 0.2769 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=122389)[0m rmse: 0.16131901741027832
[2m[36m(func pid=122389)[0m mae:  0.11500038951635361
[2m[36m(func pid=122389)[0m rmse_per_class: [0.098, 0.257, 0.057, 0.307, 0.071, 0.183, 0.259, 0.129, 0.145, 0.107]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.5083 | Steps: 2 | Val loss: 0.4082 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=127565)[0m rmse: 0.14209918677806854
[2m[36m(func pid=127565)[0m mae:  0.09523346275091171
[2m[36m(func pid=127565)[0m rmse_per_class: [0.081, 0.234, 0.034, 0.278, 0.058, 0.165, 0.217, 0.114, 0.145, 0.094]
[2m[36m(func pid=127565)[0m 
== Status ==
Current time: 2024-01-07 08:44:59 (running for 00:13:00.38)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.514 |  0.18  |                   60 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.304 |  0.161 |                   60 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.236 |  0.142 |                   39 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.225 |  0.143 |                   36 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.2303 | Steps: 2 | Val loss: 0.2695 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=122279)[0m rmse: 0.1795864701271057
[2m[36m(func pid=122279)[0m mae:  0.13106419146060944
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.326, 0.099, 0.193, 0.301, 0.148, 0.141, 0.121]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.3030 | Steps: 2 | Val loss: 0.2937 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=128390)[0m rmse: 0.14184027910232544
[2m[36m(func pid=128390)[0m mae:  0.08924131840467453
[2m[36m(func pid=128390)[0m rmse_per_class: [0.08, 0.239, 0.028, 0.293, 0.061, 0.152, 0.191, 0.112, 0.174, 0.088]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.2360 | Steps: 2 | Val loss: 0.2778 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=122389)[0m rmse: 0.16130368411540985
[2m[36m(func pid=122389)[0m mae:  0.11498536914587021
[2m[36m(func pid=122389)[0m rmse_per_class: [0.098, 0.256, 0.058, 0.307, 0.071, 0.183, 0.259, 0.129, 0.146, 0.107]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.5067 | Steps: 2 | Val loss: 0.4053 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
== Status ==
Current time: 2024-01-07 08:45:04 (running for 00:13:05.70)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.508 |  0.18  |                   61 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.303 |  0.161 |                   61 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.236 |  0.142 |                   40 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.23  |  0.142 |                   37 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=127565)[0m rmse: 0.14230917394161224
[2m[36m(func pid=127565)[0m mae:  0.09538052976131439
[2m[36m(func pid=127565)[0m rmse_per_class: [0.081, 0.234, 0.034, 0.28, 0.059, 0.165, 0.215, 0.114, 0.146, 0.094]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.2298 | Steps: 2 | Val loss: 0.2693 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=122279)[0m rmse: 0.17958781123161316
[2m[36m(func pid=122279)[0m mae:  0.13103845715522766
[2m[36m(func pid=122279)[0m rmse_per_class: [0.108, 0.269, 0.09, 0.326, 0.1, 0.193, 0.3, 0.148, 0.141, 0.121]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.2945 | Steps: 2 | Val loss: 0.2934 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=128390)[0m rmse: 0.14214368164539337
[2m[36m(func pid=128390)[0m mae:  0.08928392827510834
[2m[36m(func pid=128390)[0m rmse_per_class: [0.074, 0.241, 0.028, 0.298, 0.058, 0.152, 0.19, 0.117, 0.177, 0.086]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.2350 | Steps: 2 | Val loss: 0.2784 | Batch size: 32 | lr: 0.01 | Duration: 2.77s
[2m[36m(func pid=122389)[0m rmse: 0.16110417246818542
[2m[36m(func pid=122389)[0m mae:  0.1148180142045021
[2m[36m(func pid=122389)[0m rmse_per_class: [0.098, 0.256, 0.057, 0.307, 0.071, 0.183, 0.259, 0.128, 0.145, 0.106]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.5040 | Steps: 2 | Val loss: 0.4038 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=127565)[0m rmse: 0.1425667703151703
[2m[36m(func pid=127565)[0m mae:  0.09545348584651947
[2m[36m(func pid=127565)[0m rmse_per_class: [0.081, 0.235, 0.034, 0.283, 0.059, 0.165, 0.214, 0.115, 0.146, 0.094]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.2326 | Steps: 2 | Val loss: 0.2715 | Batch size: 32 | lr: 0.1 | Duration: 3.01s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.2954 | Steps: 2 | Val loss: 0.2932 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
== Status ==
Current time: 2024-01-07 08:45:11 (running for 00:13:12.86)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.504 |  0.179 |                   63 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.295 |  0.161 |                   62 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.235 |  0.143 |                   41 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.23  |  0.142 |                   38 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=122279)[0m rmse: 0.17946311831474304
[2m[36m(func pid=122279)[0m mae:  0.130942240357399
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.326, 0.099, 0.193, 0.3, 0.148, 0.141, 0.121]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=128390)[0m rmse: 0.1436261236667633
[2m[36m(func pid=128390)[0m mae:  0.09041287750005722
[2m[36m(func pid=128390)[0m rmse_per_class: [0.072, 0.244, 0.027, 0.303, 0.057, 0.151, 0.194, 0.119, 0.182, 0.086]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.2369 | Steps: 2 | Val loss: 0.2791 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=122389)[0m rmse: 0.1610272228717804
[2m[36m(func pid=122389)[0m mae:  0.11475007236003876
[2m[36m(func pid=122389)[0m rmse_per_class: [0.098, 0.256, 0.057, 0.307, 0.071, 0.183, 0.259, 0.128, 0.145, 0.106]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.5010 | Steps: 2 | Val loss: 0.4016 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=127565)[0m rmse: 0.1426774561405182
[2m[36m(func pid=127565)[0m mae:  0.09550181776285172
[2m[36m(func pid=127565)[0m rmse_per_class: [0.079, 0.234, 0.034, 0.284, 0.059, 0.165, 0.214, 0.116, 0.145, 0.096]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.2294 | Steps: 2 | Val loss: 0.2746 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
== Status ==
Current time: 2024-01-07 08:45:17 (running for 00:13:18.00)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.501 |  0.179 |                   64 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.295 |  0.161 |                   63 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.237 |  0.143 |                   42 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.233 |  0.144 |                   39 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=122279)[0m rmse: 0.17932386696338654
[2m[36m(func pid=122279)[0m mae:  0.13085344433784485
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.098, 0.193, 0.3, 0.148, 0.141, 0.12]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.2948 | Steps: 2 | Val loss: 0.2930 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.2428 | Steps: 2 | Val loss: 0.2800 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
[2m[36m(func pid=128390)[0m rmse: 0.14500068128108978
[2m[36m(func pid=128390)[0m mae:  0.09159392863512039
[2m[36m(func pid=128390)[0m rmse_per_class: [0.076, 0.245, 0.028, 0.304, 0.056, 0.153, 0.2, 0.119, 0.183, 0.087]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.16089390218257904
[2m[36m(func pid=122389)[0m mae:  0.11463326215744019
[2m[36m(func pid=122389)[0m rmse_per_class: [0.098, 0.256, 0.057, 0.307, 0.072, 0.182, 0.258, 0.128, 0.146, 0.106]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.4985 | Steps: 2 | Val loss: 0.3989 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=127565)[0m rmse: 0.1429877132177353
[2m[36m(func pid=127565)[0m mae:  0.09566954523324966
[2m[36m(func pid=127565)[0m rmse_per_class: [0.079, 0.234, 0.035, 0.286, 0.059, 0.165, 0.214, 0.115, 0.145, 0.098]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.2291 | Steps: 2 | Val loss: 0.2765 | Batch size: 32 | lr: 0.1 | Duration: 3.02s
== Status ==
Current time: 2024-01-07 08:45:22 (running for 00:13:23.26)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.499 |  0.179 |                   65 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.295 |  0.161 |                   64 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.243 |  0.143 |                   43 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.229 |  0.145 |                   40 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=122279)[0m rmse: 0.17925044894218445
[2m[36m(func pid=122279)[0m mae:  0.13076438009738922
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.098, 0.193, 0.3, 0.148, 0.141, 0.12]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.2970 | Steps: 2 | Val loss: 0.2930 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.2478 | Steps: 2 | Val loss: 0.2806 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=128390)[0m rmse: 0.14493650197982788
[2m[36m(func pid=128390)[0m mae:  0.09138019382953644
[2m[36m(func pid=128390)[0m rmse_per_class: [0.079, 0.244, 0.029, 0.306, 0.059, 0.152, 0.194, 0.116, 0.183, 0.087]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.1609177589416504
[2m[36m(func pid=122389)[0m mae:  0.11464359611272812
[2m[36m(func pid=122389)[0m rmse_per_class: [0.098, 0.255, 0.057, 0.307, 0.072, 0.182, 0.258, 0.128, 0.146, 0.106]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.4947 | Steps: 2 | Val loss: 0.3967 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=127565)[0m rmse: 0.1430509388446808
[2m[36m(func pid=127565)[0m mae:  0.0953991711139679
[2m[36m(func pid=127565)[0m rmse_per_class: [0.078, 0.235, 0.035, 0.287, 0.058, 0.165, 0.213, 0.118, 0.144, 0.097]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.2324 | Steps: 2 | Val loss: 0.2742 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
== Status ==
Current time: 2024-01-07 08:45:27 (running for 00:13:28.57)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.495 |  0.179 |                   66 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.297 |  0.161 |                   65 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.248 |  0.143 |                   44 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.229 |  0.145 |                   41 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=122279)[0m rmse: 0.1792440414428711
[2m[36m(func pid=122279)[0m mae:  0.13073569536209106
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.098, 0.193, 0.3, 0.148, 0.141, 0.121]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.2987 | Steps: 2 | Val loss: 0.2928 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.2354 | Steps: 2 | Val loss: 0.2798 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
[2m[36m(func pid=128390)[0m rmse: 0.14414910972118378
[2m[36m(func pid=128390)[0m mae:  0.09039671719074249
[2m[36m(func pid=128390)[0m rmse_per_class: [0.083, 0.241, 0.031, 0.3, 0.06, 0.152, 0.191, 0.117, 0.178, 0.088]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m rmse: 0.14255112409591675
[2m[36m(func pid=127565)[0m mae:  0.09520785510540009
[2m[36m(func pid=127565)[0m rmse_per_class: [0.079, 0.233, 0.034, 0.287, 0.058, 0.165, 0.213, 0.117, 0.142, 0.097]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.1607770025730133
[2m[36m(func pid=122389)[0m mae:  0.11448068916797638
[2m[36m(func pid=122389)[0m rmse_per_class: [0.098, 0.256, 0.057, 0.306, 0.072, 0.182, 0.258, 0.128, 0.147, 0.106]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.4912 | Steps: 2 | Val loss: 0.3940 | Batch size: 32 | lr: 0.0001 | Duration: 3.11s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.2315 | Steps: 2 | Val loss: 0.2698 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.2304 | Steps: 2 | Val loss: 0.2802 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 08:45:33 (running for 00:13:34.12)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.491 |  0.179 |                   67 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.299 |  0.161 |                   66 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.235 |  0.143 |                   45 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.232 |  0.144 |                   42 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=122279)[0m rmse: 0.17917031049728394
[2m[36m(func pid=122279)[0m mae:  0.13067275285720825
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.098, 0.193, 0.299, 0.147, 0.141, 0.12]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.2972 | Steps: 2 | Val loss: 0.2925 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=128390)[0m rmse: 0.14299313724040985
[2m[36m(func pid=128390)[0m mae:  0.08912767469882965
[2m[36m(func pid=128390)[0m rmse_per_class: [0.078, 0.239, 0.032, 0.295, 0.059, 0.154, 0.192, 0.123, 0.172, 0.087]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m rmse: 0.14271752536296844
[2m[36m(func pid=127565)[0m mae:  0.0954669937491417
[2m[36m(func pid=127565)[0m rmse_per_class: [0.08, 0.232, 0.034, 0.289, 0.059, 0.165, 0.213, 0.116, 0.143, 0.095]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.16057024896144867
[2m[36m(func pid=122389)[0m mae:  0.1142880916595459
[2m[36m(func pid=122389)[0m rmse_per_class: [0.097, 0.255, 0.057, 0.306, 0.072, 0.182, 0.258, 0.128, 0.146, 0.106]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.4894 | Steps: 2 | Val loss: 0.3928 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.2318 | Steps: 2 | Val loss: 0.2688 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.2340 | Steps: 2 | Val loss: 0.2798 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 08:45:38 (running for 00:13:39.42)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.489 |  0.179 |                   68 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.297 |  0.161 |                   67 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.23  |  0.143 |                   46 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.231 |  0.143 |                   43 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=122279)[0m rmse: 0.17913153767585754
[2m[36m(func pid=122279)[0m mae:  0.13064661622047424
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.098, 0.193, 0.299, 0.147, 0.141, 0.121]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.2889 | Steps: 2 | Val loss: 0.2919 | Batch size: 32 | lr: 0.001 | Duration: 3.03s
[2m[36m(func pid=128390)[0m rmse: 0.14267222583293915
[2m[36m(func pid=128390)[0m mae:  0.08899106830358505
[2m[36m(func pid=128390)[0m rmse_per_class: [0.077, 0.239, 0.031, 0.293, 0.058, 0.152, 0.193, 0.125, 0.173, 0.087]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m rmse: 0.14214733242988586
[2m[36m(func pid=127565)[0m mae:  0.09507040679454803
[2m[36m(func pid=127565)[0m rmse_per_class: [0.081, 0.232, 0.034, 0.287, 0.059, 0.164, 0.213, 0.114, 0.143, 0.094]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.1601724475622177
[2m[36m(func pid=122389)[0m mae:  0.11394818127155304
[2m[36m(func pid=122389)[0m rmse_per_class: [0.097, 0.255, 0.056, 0.305, 0.072, 0.182, 0.257, 0.127, 0.145, 0.105]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.4892 | Steps: 2 | Val loss: 0.3908 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.2308 | Steps: 2 | Val loss: 0.2695 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 08:45:43 (running for 00:13:44.66)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.489 |  0.179 |                   69 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.289 |  0.16  |                   68 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.234 |  0.142 |                   47 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.232 |  0.143 |                   44 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=122279)[0m rmse: 0.17910046875476837
[2m[36m(func pid=122279)[0m mae:  0.13059702515602112
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.098, 0.193, 0.299, 0.148, 0.141, 0.12]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.2376 | Steps: 2 | Val loss: 0.2801 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.2935 | Steps: 2 | Val loss: 0.2915 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=128390)[0m rmse: 0.1432434767484665
[2m[36m(func pid=128390)[0m mae:  0.08962201327085495
[2m[36m(func pid=128390)[0m rmse_per_class: [0.079, 0.239, 0.029, 0.292, 0.057, 0.151, 0.198, 0.127, 0.174, 0.087]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m rmse: 0.14233991503715515
[2m[36m(func pid=127565)[0m mae:  0.09519566595554352
[2m[36m(func pid=127565)[0m rmse_per_class: [0.082, 0.232, 0.034, 0.286, 0.059, 0.164, 0.213, 0.115, 0.144, 0.095]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.1599765121936798
[2m[36m(func pid=122389)[0m mae:  0.11378894746303558
[2m[36m(func pid=122389)[0m rmse_per_class: [0.096, 0.254, 0.056, 0.305, 0.072, 0.181, 0.257, 0.127, 0.146, 0.105]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.4837 | Steps: 2 | Val loss: 0.3890 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.2351 | Steps: 2 | Val loss: 0.2724 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.2384 | Steps: 2 | Val loss: 0.2800 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
== Status ==
Current time: 2024-01-07 08:45:49 (running for 00:13:50.04)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.484 |  0.179 |                   70 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.294 |  0.16  |                   69 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.238 |  0.142 |                   48 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.231 |  0.143 |                   45 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=122279)[0m rmse: 0.17908939719200134
[2m[36m(func pid=122279)[0m mae:  0.13057057559490204
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.326, 0.098, 0.193, 0.299, 0.147, 0.141, 0.12]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.2938 | Steps: 2 | Val loss: 0.2910 | Batch size: 32 | lr: 0.001 | Duration: 3.04s
[2m[36m(func pid=128390)[0m rmse: 0.1435357928276062
[2m[36m(func pid=128390)[0m mae:  0.08990506827831268
[2m[36m(func pid=128390)[0m rmse_per_class: [0.078, 0.24, 0.028, 0.295, 0.059, 0.151, 0.196, 0.119, 0.179, 0.089]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m rmse: 0.14222955703735352
[2m[36m(func pid=127565)[0m mae:  0.09501473605632782
[2m[36m(func pid=127565)[0m rmse_per_class: [0.083, 0.232, 0.034, 0.285, 0.058, 0.164, 0.213, 0.115, 0.143, 0.095]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.4826 | Steps: 2 | Val loss: 0.3870 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=122389)[0m rmse: 0.15965013206005096
[2m[36m(func pid=122389)[0m mae:  0.11348778009414673
[2m[36m(func pid=122389)[0m rmse_per_class: [0.096, 0.254, 0.056, 0.304, 0.072, 0.181, 0.256, 0.127, 0.146, 0.105]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.2302 | Steps: 2 | Val loss: 0.2738 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=122279)[0m rmse: 0.17907187342643738
[2m[36m(func pid=122279)[0m mae:  0.1305253803730011
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.326, 0.098, 0.193, 0.299, 0.147, 0.141, 0.12]
== Status ==
Current time: 2024-01-07 08:45:54 (running for 00:13:55.20)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.483 |  0.179 |                   71 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.294 |  0.16  |                   70 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.238 |  0.142 |                   49 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.235 |  0.144 |                   46 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.2359 | Steps: 2 | Val loss: 0.2807 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.2979 | Steps: 2 | Val loss: 0.2909 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=128390)[0m rmse: 0.14395944774150848
[2m[36m(func pid=128390)[0m mae:  0.09002514183521271
[2m[36m(func pid=128390)[0m rmse_per_class: [0.076, 0.239, 0.03, 0.301, 0.06, 0.152, 0.194, 0.117, 0.181, 0.09]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m rmse: 0.14253559708595276
[2m[36m(func pid=127565)[0m mae:  0.09526503086090088
[2m[36m(func pid=127565)[0m rmse_per_class: [0.084, 0.233, 0.034, 0.285, 0.058, 0.164, 0.213, 0.114, 0.145, 0.095]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.4761 | Steps: 2 | Val loss: 0.3852 | Batch size: 32 | lr: 0.0001 | Duration: 3.01s
[2m[36m(func pid=122389)[0m rmse: 0.1595230996608734
[2m[36m(func pid=122389)[0m mae:  0.11331652104854584
[2m[36m(func pid=122389)[0m rmse_per_class: [0.096, 0.254, 0.055, 0.304, 0.071, 0.181, 0.256, 0.127, 0.146, 0.105]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.2349 | Steps: 2 | Val loss: 0.2750 | Batch size: 32 | lr: 0.1 | Duration: 2.75s
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.2403 | Steps: 2 | Val loss: 0.2809 | Batch size: 32 | lr: 0.01 | Duration: 2.67s
== Status ==
Current time: 2024-01-07 08:45:59 (running for 00:14:00.62)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.476 |  0.179 |                   72 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.298 |  0.16  |                   71 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.236 |  0.143 |                   50 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.23  |  0.144 |                   47 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=122279)[0m rmse: 0.17900261282920837
[2m[36m(func pid=122279)[0m mae:  0.13047704100608826
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.326, 0.098, 0.193, 0.299, 0.147, 0.141, 0.12]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=128390)[0m rmse: 0.14451119303703308
[2m[36m(func pid=128390)[0m mae:  0.09022010862827301
[2m[36m(func pid=128390)[0m rmse_per_class: [0.078, 0.24, 0.031, 0.299, 0.059, 0.153, 0.194, 0.117, 0.183, 0.092]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.2845 | Steps: 2 | Val loss: 0.2908 | Batch size: 32 | lr: 0.001 | Duration: 3.20s
[2m[36m(func pid=127565)[0m rmse: 0.14251232147216797
[2m[36m(func pid=127565)[0m mae:  0.09526754170656204
[2m[36m(func pid=127565)[0m rmse_per_class: [0.084, 0.232, 0.034, 0.284, 0.058, 0.164, 0.214, 0.113, 0.145, 0.097]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.4766 | Steps: 2 | Val loss: 0.3838 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.2310 | Steps: 2 | Val loss: 0.2742 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=122389)[0m rmse: 0.1594427525997162
[2m[36m(func pid=122389)[0m mae:  0.11324421316385269
[2m[36m(func pid=122389)[0m rmse_per_class: [0.096, 0.254, 0.055, 0.304, 0.071, 0.181, 0.255, 0.127, 0.145, 0.105]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.2343 | Steps: 2 | Val loss: 0.2813 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
== Status ==
Current time: 2024-01-07 08:46:04 (running for 00:14:05.88)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.477 |  0.179 |                   73 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.284 |  0.159 |                   72 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.24  |  0.143 |                   51 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.235 |  0.145 |                   48 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=122279)[0m rmse: 0.1788633167743683
[2m[36m(func pid=122279)[0m mae:  0.13036450743675232
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.098, 0.193, 0.299, 0.147, 0.141, 0.12]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=128390)[0m rmse: 0.1443256437778473
[2m[36m(func pid=128390)[0m mae:  0.08999457955360413
[2m[36m(func pid=128390)[0m rmse_per_class: [0.076, 0.239, 0.031, 0.295, 0.06, 0.154, 0.194, 0.118, 0.184, 0.092]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.2876 | Steps: 2 | Val loss: 0.2904 | Batch size: 32 | lr: 0.001 | Duration: 2.72s
[2m[36m(func pid=127565)[0m rmse: 0.1428493857383728
[2m[36m(func pid=127565)[0m mae:  0.09545380622148514
[2m[36m(func pid=127565)[0m rmse_per_class: [0.083, 0.233, 0.035, 0.286, 0.058, 0.165, 0.213, 0.113, 0.145, 0.097]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.4789 | Steps: 2 | Val loss: 0.3824 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=122389)[0m rmse: 0.1591915637254715
[2m[36m(func pid=122389)[0m mae:  0.11298692226409912
[2m[36m(func pid=122389)[0m rmse_per_class: [0.096, 0.254, 0.055, 0.304, 0.071, 0.181, 0.255, 0.127, 0.145, 0.104]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.2278 | Steps: 2 | Val loss: 0.2719 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.2282 | Steps: 2 | Val loss: 0.2808 | Batch size: 32 | lr: 0.01 | Duration: 2.70s
== Status ==
Current time: 2024-01-07 08:46:10 (running for 00:14:11.18)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.479 |  0.179 |                   74 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.288 |  0.159 |                   73 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.234 |  0.143 |                   52 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.231 |  0.144 |                   49 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=122279)[0m rmse: 0.1786326766014099
[2m[36m(func pid=122279)[0m mae:  0.13019566237926483
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.269, 0.089, 0.325, 0.097, 0.193, 0.298, 0.147, 0.141, 0.12]
[2m[36m(func pid=122279)[0m 
[2m[36m(func pid=128390)[0m rmse: 0.14332684874534607
[2m[36m(func pid=128390)[0m mae:  0.08955444395542145
[2m[36m(func pid=128390)[0m rmse_per_class: [0.076, 0.238, 0.031, 0.288, 0.062, 0.153, 0.194, 0.116, 0.186, 0.09]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.2893 | Steps: 2 | Val loss: 0.2904 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=127565)[0m rmse: 0.14261344075202942
[2m[36m(func pid=127565)[0m mae:  0.09514951705932617
[2m[36m(func pid=127565)[0m rmse_per_class: [0.083, 0.233, 0.035, 0.286, 0.059, 0.165, 0.212, 0.113, 0.144, 0.096]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=122279)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.4706 | Steps: 2 | Val loss: 0.3807 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.2300 | Steps: 2 | Val loss: 0.2726 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=122389)[0m rmse: 0.15912960469722748
[2m[36m(func pid=122389)[0m mae:  0.11294271796941757
[2m[36m(func pid=122389)[0m rmse_per_class: [0.096, 0.254, 0.055, 0.304, 0.071, 0.181, 0.255, 0.127, 0.145, 0.104]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.2388 | Steps: 2 | Val loss: 0.2807 | Batch size: 32 | lr: 0.01 | Duration: 2.67s
== Status ==
Current time: 2024-01-07 08:46:15 (running for 00:14:16.48)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.1615000031888485
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00004 | RUNNING    | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.479 |  0.179 |                   74 |
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.289 |  0.159 |                   74 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.228 |  0.143 |                   53 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.23  |  0.144 |                   51 |
| train_d77f6_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=128390)[0m rmse: 0.1442311555147171
[2m[36m(func pid=128390)[0m mae:  0.09035957604646683
[2m[36m(func pid=128390)[0m rmse_per_class: [0.077, 0.239, 0.029, 0.29, 0.064, 0.153, 0.197, 0.119, 0.187, 0.088]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=122279)[0m rmse: 0.17867213487625122
[2m[36m(func pid=122279)[0m mae:  0.13022926449775696
[2m[36m(func pid=122279)[0m rmse_per_class: [0.107, 0.269, 0.089, 0.325, 0.098, 0.193, 0.298, 0.147, 0.141, 0.12]
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.2880 | Steps: 2 | Val loss: 0.2899 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=127565)[0m rmse: 0.14235058426856995
[2m[36m(func pid=127565)[0m mae:  0.09486003965139389
[2m[36m(func pid=127565)[0m rmse_per_class: [0.083, 0.234, 0.035, 0.285, 0.058, 0.164, 0.211, 0.112, 0.146, 0.095]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.2289 | Steps: 2 | Val loss: 0.2740 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
[2m[36m(func pid=122389)[0m rmse: 0.15885330736637115
[2m[36m(func pid=122389)[0m mae:  0.11269903182983398
[2m[36m(func pid=122389)[0m rmse_per_class: [0.096, 0.253, 0.055, 0.304, 0.071, 0.181, 0.255, 0.127, 0.144, 0.104]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.2321 | Steps: 2 | Val loss: 0.2793 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
[2m[36m(func pid=128390)[0m rmse: 0.1455422043800354
[2m[36m(func pid=128390)[0m mae:  0.09152043610811234
[2m[36m(func pid=128390)[0m rmse_per_class: [0.085, 0.24, 0.028, 0.298, 0.064, 0.153, 0.197, 0.117, 0.187, 0.087]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 75] | Train loss: 0.2858 | Steps: 2 | Val loss: 0.2897 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
[2m[36m(func pid=127565)[0m rmse: 0.14157752692699432
[2m[36m(func pid=127565)[0m mae:  0.09416016191244125
[2m[36m(func pid=127565)[0m rmse_per_class: [0.081, 0.232, 0.035, 0.282, 0.058, 0.164, 0.21, 0.113, 0.145, 0.095]
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.2294 | Steps: 2 | Val loss: 0.2757 | Batch size: 32 | lr: 0.1 | Duration: 2.78s
== Status ==
Current time: 2024-01-07 08:46:20 (running for 00:14:21.78)
Memory usage on this node: 22.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.1599999964237213
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.288 |  0.159 |                   75 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.239 |  0.142 |                   54 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.229 |  0.146 |                   52 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=139738)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=139738)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=139738)[0m Configuration completed!
[2m[36m(func pid=139738)[0m New optimizer parameters:
[2m[36m(func pid=139738)[0m SGD (
[2m[36m(func pid=139738)[0m Parameter Group 0
[2m[36m(func pid=139738)[0m     dampening: 0
[2m[36m(func pid=139738)[0m     differentiable: False
[2m[36m(func pid=139738)[0m     foreach: None
[2m[36m(func pid=139738)[0m     lr: 0.0001
[2m[36m(func pid=139738)[0m     maximize: False
[2m[36m(func pid=139738)[0m     momentum: 0.99
[2m[36m(func pid=139738)[0m     nesterov: False
[2m[36m(func pid=139738)[0m     weight_decay: 0.0001
[2m[36m(func pid=139738)[0m )
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.15871790051460266
[2m[36m(func pid=122389)[0m mae:  0.11255904287099838
[2m[36m(func pid=122389)[0m rmse_per_class: [0.096, 0.253, 0.054, 0.303, 0.07, 0.181, 0.254, 0.127, 0.143, 0.105]
[2m[36m(func pid=122389)[0m 
== Status ==
Current time: 2024-01-07 08:46:25 (running for 00:14:26.84)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.1599999964237213
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.286 |  0.159 |                   76 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.142 |                   55 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.229 |  0.146 |                   53 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=128390)[0m rmse: 0.14620988070964813
[2m[36m(func pid=128390)[0m mae:  0.09203602373600006
[2m[36m(func pid=128390)[0m rmse_per_class: [0.085, 0.241, 0.028, 0.309, 0.065, 0.153, 0.194, 0.118, 0.182, 0.087]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.2371 | Steps: 2 | Val loss: 0.2793 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 76] | Train loss: 0.2866 | Steps: 2 | Val loss: 0.2893 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 1.0845 | Steps: 2 | Val loss: 0.8109 | Batch size: 32 | lr: 0.0001 | Duration: 4.57s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.2353 | Steps: 2 | Val loss: 0.2783 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=127565)[0m rmse: 0.1414952278137207
[2m[36m(func pid=127565)[0m mae:  0.09405157715082169
[2m[36m(func pid=127565)[0m rmse_per_class: [0.081, 0.233, 0.035, 0.282, 0.058, 0.164, 0.209, 0.113, 0.146, 0.094]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.15845303237438202
[2m[36m(func pid=122389)[0m mae:  0.11227668821811676
[2m[36m(func pid=122389)[0m rmse_per_class: [0.096, 0.253, 0.054, 0.303, 0.07, 0.18, 0.253, 0.127, 0.143, 0.105]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.1786802113056183
[2m[36m(func pid=139738)[0m mae:  0.13118800520896912
[2m[36m(func pid=139738)[0m rmse_per_class: [0.105, 0.266, 0.087, 0.325, 0.101, 0.192, 0.304, 0.153, 0.139, 0.116]
[2m[36m(func pid=139738)[0m 
== Status ==
Current time: 2024-01-07 08:46:31 (running for 00:14:32.07)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.1599999964237213
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.287 |  0.158 |                   77 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.237 |  0.141 |                   56 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.235 |  0.147 |                   54 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  1.085 |  0.179 |                    1 |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=128390)[0m rmse: 0.14689774811267853
[2m[36m(func pid=128390)[0m mae:  0.09244564920663834
[2m[36m(func pid=128390)[0m rmse_per_class: [0.089, 0.241, 0.029, 0.316, 0.066, 0.153, 0.192, 0.115, 0.182, 0.087]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.2321 | Steps: 2 | Val loss: 0.2792 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 77] | Train loss: 0.2843 | Steps: 2 | Val loss: 0.2889 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 1.0708 | Steps: 2 | Val loss: 0.8124 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=127565)[0m rmse: 0.1414097249507904
[2m[36m(func pid=127565)[0m mae:  0.09399376809597015
[2m[36m(func pid=127565)[0m rmse_per_class: [0.08, 0.232, 0.034, 0.284, 0.058, 0.164, 0.209, 0.113, 0.145, 0.095]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.2369 | Steps: 2 | Val loss: 0.2757 | Batch size: 32 | lr: 0.1 | Duration: 3.06s
[2m[36m(func pid=122389)[0m rmse: 0.1582302749156952
[2m[36m(func pid=122389)[0m mae:  0.112112857401371
[2m[36m(func pid=122389)[0m rmse_per_class: [0.096, 0.253, 0.054, 0.302, 0.07, 0.18, 0.253, 0.126, 0.143, 0.105]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.179184690117836
[2m[36m(func pid=139738)[0m mae:  0.13159818947315216
[2m[36m(func pid=139738)[0m rmse_per_class: [0.105, 0.266, 0.088, 0.325, 0.102, 0.193, 0.306, 0.154, 0.139, 0.116]
[2m[36m(func pid=139738)[0m 
== Status ==
Current time: 2024-01-07 08:46:36 (running for 00:14:37.58)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.1599999964237213
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.284 |  0.158 |                   78 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                   57 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.237 |  0.145 |                   55 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  1.071 |  0.179 |                    2 |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=128390)[0m rmse: 0.14506784081459045
[2m[36m(func pid=128390)[0m mae:  0.091229148209095
[2m[36m(func pid=128390)[0m rmse_per_class: [0.086, 0.241, 0.029, 0.308, 0.065, 0.153, 0.191, 0.111, 0.179, 0.088]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.2301 | Steps: 2 | Val loss: 0.2789 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 78] | Train loss: 0.2778 | Steps: 2 | Val loss: 0.2890 | Batch size: 32 | lr: 0.001 | Duration: 3.03s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 1.0685 | Steps: 2 | Val loss: 0.8115 | Batch size: 32 | lr: 0.0001 | Duration: 3.01s
[2m[36m(func pid=127565)[0m rmse: 0.14123490452766418
[2m[36m(func pid=127565)[0m mae:  0.09386880695819855
[2m[36m(func pid=127565)[0m rmse_per_class: [0.08, 0.232, 0.034, 0.283, 0.058, 0.163, 0.209, 0.114, 0.144, 0.095]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.2284 | Steps: 2 | Val loss: 0.2755 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=122389)[0m rmse: 0.1581721007823944
[2m[36m(func pid=122389)[0m mae:  0.11206729710102081
[2m[36m(func pid=122389)[0m rmse_per_class: [0.096, 0.252, 0.053, 0.303, 0.07, 0.18, 0.253, 0.126, 0.143, 0.104]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.1795945018529892
[2m[36m(func pid=139738)[0m mae:  0.13190136849880219
[2m[36m(func pid=139738)[0m rmse_per_class: [0.105, 0.266, 0.089, 0.325, 0.103, 0.193, 0.307, 0.154, 0.139, 0.116]
[2m[36m(func pid=139738)[0m 
== Status ==
Current time: 2024-01-07 08:46:41 (running for 00:14:42.85)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.1599999964237213
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.278 |  0.158 |                   79 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.23  |  0.141 |                   58 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.145 |                   56 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  1.068 |  0.18  |                    3 |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=128390)[0m rmse: 0.1448695957660675
[2m[36m(func pid=128390)[0m mae:  0.09135457873344421
[2m[36m(func pid=128390)[0m rmse_per_class: [0.085, 0.24, 0.028, 0.304, 0.064, 0.153, 0.193, 0.113, 0.18, 0.088]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.2358 | Steps: 2 | Val loss: 0.2789 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 79] | Train loss: 0.2822 | Steps: 2 | Val loss: 0.2890 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 1.0548 | Steps: 2 | Val loss: 0.8069 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=127565)[0m rmse: 0.14111599326133728
[2m[36m(func pid=127565)[0m mae:  0.09368239343166351
[2m[36m(func pid=127565)[0m rmse_per_class: [0.079, 0.232, 0.034, 0.282, 0.057, 0.163, 0.209, 0.115, 0.143, 0.096]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.2242 | Steps: 2 | Val loss: 0.2741 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
[2m[36m(func pid=122389)[0m rmse: 0.15818099677562714
[2m[36m(func pid=122389)[0m mae:  0.1120891124010086
[2m[36m(func pid=122389)[0m rmse_per_class: [0.096, 0.252, 0.053, 0.303, 0.07, 0.18, 0.253, 0.126, 0.144, 0.104]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.17993301153182983
[2m[36m(func pid=139738)[0m mae:  0.13215453922748566
[2m[36m(func pid=139738)[0m rmse_per_class: [0.105, 0.266, 0.09, 0.325, 0.104, 0.193, 0.308, 0.154, 0.138, 0.117]
[2m[36m(func pid=139738)[0m 
== Status ==
Current time: 2024-01-07 08:46:47 (running for 00:14:48.27)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.1599999964237213
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.282 |  0.158 |                   80 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.236 |  0.141 |                   59 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.224 |  0.145 |                   57 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  1.055 |  0.18  |                    4 |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=128390)[0m rmse: 0.14466704428195953
[2m[36m(func pid=128390)[0m mae:  0.09132305532693863
[2m[36m(func pid=128390)[0m rmse_per_class: [0.083, 0.24, 0.029, 0.302, 0.063, 0.152, 0.196, 0.115, 0.179, 0.088]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.2357 | Steps: 2 | Val loss: 0.2788 | Batch size: 32 | lr: 0.01 | Duration: 2.74s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 80] | Train loss: 0.2835 | Steps: 2 | Val loss: 0.2887 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 1.0361 | Steps: 2 | Val loss: 0.7983 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=127565)[0m rmse: 0.14095577597618103
[2m[36m(func pid=127565)[0m mae:  0.09341953694820404
[2m[36m(func pid=127565)[0m rmse_per_class: [0.079, 0.232, 0.034, 0.281, 0.057, 0.163, 0.209, 0.116, 0.142, 0.096]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.2343 | Steps: 2 | Val loss: 0.2736 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
[2m[36m(func pid=122389)[0m rmse: 0.15799367427825928
[2m[36m(func pid=122389)[0m mae:  0.11191906034946442
[2m[36m(func pid=122389)[0m rmse_per_class: [0.096, 0.252, 0.053, 0.302, 0.07, 0.18, 0.253, 0.126, 0.144, 0.103]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.18022894859313965
[2m[36m(func pid=139738)[0m mae:  0.13237830996513367
[2m[36m(func pid=139738)[0m rmse_per_class: [0.105, 0.266, 0.09, 0.325, 0.105, 0.193, 0.308, 0.154, 0.138, 0.118]
[2m[36m(func pid=139738)[0m 
== Status ==
Current time: 2024-01-07 08:46:52 (running for 00:14:53.44)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.1599999964237213
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.283 |  0.158 |                   81 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.236 |  0.141 |                   60 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.234 |  0.146 |                   58 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  1.036 |  0.18  |                    5 |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=128390)[0m rmse: 0.14584684371948242
[2m[36m(func pid=128390)[0m mae:  0.09182916581630707
[2m[36m(func pid=128390)[0m rmse_per_class: [0.083, 0.241, 0.03, 0.3, 0.061, 0.152, 0.2, 0.122, 0.18, 0.088]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.2350 | Steps: 2 | Val loss: 0.2792 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 81] | Train loss: 0.2831 | Steps: 2 | Val loss: 0.2886 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 1.0200 | Steps: 2 | Val loss: 0.7874 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=127565)[0m rmse: 0.1412186622619629
[2m[36m(func pid=127565)[0m mae:  0.09355778992176056
[2m[36m(func pid=127565)[0m rmse_per_class: [0.079, 0.232, 0.034, 0.281, 0.057, 0.163, 0.21, 0.118, 0.141, 0.097]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.2271 | Steps: 2 | Val loss: 0.2723 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=122389)[0m rmse: 0.15788483619689941
[2m[36m(func pid=122389)[0m mae:  0.11176633834838867
[2m[36m(func pid=122389)[0m rmse_per_class: [0.096, 0.252, 0.053, 0.302, 0.07, 0.18, 0.253, 0.126, 0.144, 0.103]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.18046505749225616
[2m[36m(func pid=139738)[0m mae:  0.13254563510417938
[2m[36m(func pid=139738)[0m rmse_per_class: [0.105, 0.266, 0.09, 0.325, 0.105, 0.194, 0.309, 0.154, 0.138, 0.118]
[2m[36m(func pid=139738)[0m 
== Status ==
Current time: 2024-01-07 08:46:57 (running for 00:14:58.85)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.1599999964237213
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.283 |  0.158 |                   82 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.235 |  0.141 |                   61 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.227 |  0.145 |                   59 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  1.02  |  0.18  |                    6 |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.2319 | Steps: 2 | Val loss: 0.2788 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=128390)[0m rmse: 0.14523527026176453
[2m[36m(func pid=128390)[0m mae:  0.09134186804294586
[2m[36m(func pid=128390)[0m rmse_per_class: [0.078, 0.24, 0.03, 0.302, 0.061, 0.153, 0.196, 0.122, 0.182, 0.089]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 82] | Train loss: 0.2831 | Steps: 2 | Val loss: 0.2879 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.9920 | Steps: 2 | Val loss: 0.7710 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=127565)[0m rmse: 0.14090612530708313
[2m[36m(func pid=127565)[0m mae:  0.0933225154876709
[2m[36m(func pid=127565)[0m rmse_per_class: [0.08, 0.232, 0.034, 0.278, 0.057, 0.163, 0.21, 0.118, 0.14, 0.097]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.2326 | Steps: 2 | Val loss: 0.2739 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=122389)[0m rmse: 0.15743158757686615
[2m[36m(func pid=122389)[0m mae:  0.11136579513549805
[2m[36m(func pid=122389)[0m rmse_per_class: [0.096, 0.252, 0.052, 0.3, 0.07, 0.18, 0.253, 0.126, 0.143, 0.103]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.1806456446647644
[2m[36m(func pid=139738)[0m mae:  0.13268132507801056
[2m[36m(func pid=139738)[0m rmse_per_class: [0.105, 0.266, 0.09, 0.324, 0.105, 0.194, 0.309, 0.154, 0.138, 0.119]
[2m[36m(func pid=139738)[0m 
== Status ==
Current time: 2024-01-07 08:47:03 (running for 00:15:04.07)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.1599999964237213
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.283 |  0.157 |                   83 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                   62 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.233 |  0.145 |                   60 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.992 |  0.181 |                    7 |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.2350 | Steps: 2 | Val loss: 0.2794 | Batch size: 32 | lr: 0.01 | Duration: 2.70s
[2m[36m(func pid=128390)[0m rmse: 0.14542938768863678
[2m[36m(func pid=128390)[0m mae:  0.09130646288394928
[2m[36m(func pid=128390)[0m rmse_per_class: [0.078, 0.241, 0.03, 0.304, 0.062, 0.154, 0.192, 0.118, 0.187, 0.089]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 83] | Train loss: 0.2771 | Steps: 2 | Val loss: 0.2880 | Batch size: 32 | lr: 0.001 | Duration: 3.11s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.9660 | Steps: 2 | Val loss: 0.7514 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
[2m[36m(func pid=127565)[0m rmse: 0.14091822504997253
[2m[36m(func pid=127565)[0m mae:  0.09351266920566559
[2m[36m(func pid=127565)[0m rmse_per_class: [0.082, 0.233, 0.034, 0.276, 0.057, 0.163, 0.211, 0.115, 0.142, 0.097]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.2325 | Steps: 2 | Val loss: 0.2758 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=122389)[0m rmse: 0.1574561595916748
[2m[36m(func pid=122389)[0m mae:  0.11136232316493988
[2m[36m(func pid=122389)[0m rmse_per_class: [0.095, 0.252, 0.052, 0.301, 0.07, 0.18, 0.252, 0.126, 0.143, 0.103]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.18074704706668854
[2m[36m(func pid=139738)[0m mae:  0.1327226758003235
[2m[36m(func pid=139738)[0m rmse_per_class: [0.106, 0.266, 0.09, 0.324, 0.106, 0.194, 0.31, 0.154, 0.138, 0.12]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.2297 | Steps: 2 | Val loss: 0.2796 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
== Status ==
Current time: 2024-01-07 08:47:08 (running for 00:15:09.46)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.1599999964237213
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.277 |  0.157 |                   84 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.235 |  0.141 |                   63 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.232 |  0.146 |                   61 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.966 |  0.181 |                    8 |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=128390)[0m rmse: 0.14572152495384216
[2m[36m(func pid=128390)[0m mae:  0.09149164706468582
[2m[36m(func pid=128390)[0m rmse_per_class: [0.079, 0.241, 0.029, 0.305, 0.066, 0.155, 0.191, 0.112, 0.191, 0.089]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m rmse: 0.14124973118305206
[2m[36m(func pid=127565)[0m mae:  0.09389439225196838
[2m[36m(func pid=127565)[0m rmse_per_class: [0.083, 0.232, 0.033, 0.279, 0.056, 0.163, 0.211, 0.115, 0.143, 0.096]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 84] | Train loss: 0.2864 | Steps: 2 | Val loss: 0.2882 | Batch size: 32 | lr: 0.001 | Duration: 3.03s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.9358 | Steps: 2 | Val loss: 0.7294 | Batch size: 32 | lr: 0.0001 | Duration: 3.04s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.2262 | Steps: 2 | Val loss: 0.2760 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=122389)[0m rmse: 0.15753670036792755
[2m[36m(func pid=122389)[0m mae:  0.11138387769460678
[2m[36m(func pid=122389)[0m rmse_per_class: [0.095, 0.253, 0.052, 0.301, 0.071, 0.18, 0.251, 0.126, 0.143, 0.103]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.2315 | Steps: 2 | Val loss: 0.2802 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=139738)[0m rmse: 0.18084260821342468
[2m[36m(func pid=139738)[0m mae:  0.1327706277370453
[2m[36m(func pid=139738)[0m rmse_per_class: [0.106, 0.266, 0.09, 0.324, 0.106, 0.194, 0.31, 0.155, 0.138, 0.12]
[2m[36m(func pid=139738)[0m 
== Status ==
Current time: 2024-01-07 08:47:13 (running for 00:15:14.70)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.1599999964237213
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.286 |  0.158 |                   85 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.23  |  0.141 |                   64 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.226 |  0.146 |                   62 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.936 |  0.181 |                    9 |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=128390)[0m rmse: 0.14581747353076935
[2m[36m(func pid=128390)[0m mae:  0.09173958003520966
[2m[36m(func pid=128390)[0m rmse_per_class: [0.082, 0.24, 0.03, 0.305, 0.067, 0.155, 0.193, 0.111, 0.186, 0.088]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m rmse: 0.14178025722503662
[2m[36m(func pid=127565)[0m mae:  0.09426511824131012
[2m[36m(func pid=127565)[0m rmse_per_class: [0.083, 0.233, 0.034, 0.281, 0.057, 0.164, 0.211, 0.114, 0.144, 0.096]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 85] | Train loss: 0.2793 | Steps: 2 | Val loss: 0.2877 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.9013 | Steps: 2 | Val loss: 0.7032 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.2306 | Steps: 2 | Val loss: 0.2742 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
[2m[36m(func pid=122389)[0m rmse: 0.15725089609622955
[2m[36m(func pid=122389)[0m mae:  0.11109181493520737
[2m[36m(func pid=122389)[0m rmse_per_class: [0.094, 0.252, 0.052, 0.301, 0.07, 0.18, 0.251, 0.126, 0.143, 0.104]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.18082673847675323
[2m[36m(func pid=139738)[0m mae:  0.13270582258701324
[2m[36m(func pid=139738)[0m rmse_per_class: [0.106, 0.267, 0.09, 0.324, 0.105, 0.194, 0.309, 0.155, 0.138, 0.121]
== Status ==
Current time: 2024-01-07 08:47:18 (running for 00:15:19.73)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.1599999964237213
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.279 |  0.157 |                   86 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.142 |                   65 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.226 |  0.146 |                   62 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.901 |  0.181 |                   10 |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.2304 | Steps: 2 | Val loss: 0.2803 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=128390)[0m rmse: 0.14545033872127533
[2m[36m(func pid=128390)[0m mae:  0.09147494286298752
[2m[36m(func pid=128390)[0m rmse_per_class: [0.084, 0.239, 0.03, 0.3, 0.065, 0.155, 0.195, 0.116, 0.182, 0.087]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m rmse: 0.14168688654899597
[2m[36m(func pid=127565)[0m mae:  0.09418980032205582
[2m[36m(func pid=127565)[0m rmse_per_class: [0.083, 0.233, 0.034, 0.281, 0.057, 0.165, 0.211, 0.113, 0.144, 0.097]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 86] | Train loss: 0.2889 | Steps: 2 | Val loss: 0.2874 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.8711 | Steps: 2 | Val loss: 0.6767 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.2276 | Steps: 2 | Val loss: 0.2744 | Batch size: 32 | lr: 0.1 | Duration: 2.76s
[2m[36m(func pid=122389)[0m rmse: 0.15698760747909546
[2m[36m(func pid=122389)[0m mae:  0.11084163188934326
[2m[36m(func pid=122389)[0m rmse_per_class: [0.094, 0.252, 0.052, 0.3, 0.07, 0.18, 0.25, 0.126, 0.143, 0.104]
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.2315 | Steps: 2 | Val loss: 0.2804 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
== Status ==
Current time: 2024-01-07 08:47:24 (running for 00:15:25.01)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.1599999964237213
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.289 |  0.157 |                   87 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.23  |  0.142 |                   66 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.231 |  0.145 |                   63 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.901 |  0.181 |                   10 |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=128390)[0m rmse: 0.14611147344112396
[2m[36m(func pid=128390)[0m mae:  0.09204678982496262
[2m[36m(func pid=128390)[0m rmse_per_class: [0.086, 0.239, 0.03, 0.302, 0.065, 0.156, 0.198, 0.119, 0.18, 0.087]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.1808122843503952
[2m[36m(func pid=139738)[0m mae:  0.1326344907283783
[2m[36m(func pid=139738)[0m rmse_per_class: [0.106, 0.267, 0.09, 0.324, 0.105, 0.194, 0.309, 0.155, 0.138, 0.121]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=127565)[0m rmse: 0.14161096513271332
[2m[36m(func pid=127565)[0m mae:  0.09407837688922882
[2m[36m(func pid=127565)[0m rmse_per_class: [0.081, 0.233, 0.034, 0.281, 0.057, 0.165, 0.211, 0.113, 0.144, 0.098]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 87] | Train loss: 0.2743 | Steps: 2 | Val loss: 0.2874 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.2276 | Steps: 2 | Val loss: 0.2730 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.8395 | Steps: 2 | Val loss: 0.6499 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.2298 | Steps: 2 | Val loss: 0.2809 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=122389)[0m rmse: 0.15700377523899078
[2m[36m(func pid=122389)[0m mae:  0.11084549129009247
[2m[36m(func pid=122389)[0m rmse_per_class: [0.094, 0.252, 0.052, 0.3, 0.071, 0.18, 0.25, 0.126, 0.143, 0.104]
== Status ==
Current time: 2024-01-07 08:47:29 (running for 00:15:30.50)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.1599999964237213
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.274 |  0.157 |                   88 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.142 |                   67 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                   64 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.871 |  0.181 |                   11 |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=128390)[0m rmse: 0.14520612359046936
[2m[36m(func pid=128390)[0m mae:  0.09145179390907288
[2m[36m(func pid=128390)[0m rmse_per_class: [0.085, 0.238, 0.03, 0.303, 0.063, 0.154, 0.195, 0.117, 0.179, 0.087]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.18092072010040283
[2m[36m(func pid=139738)[0m mae:  0.1326664239168167
[2m[36m(func pid=139738)[0m rmse_per_class: [0.106, 0.267, 0.09, 0.324, 0.105, 0.194, 0.309, 0.155, 0.138, 0.121]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=127565)[0m rmse: 0.141672283411026
[2m[36m(func pid=127565)[0m mae:  0.09406284987926483
[2m[36m(func pid=127565)[0m rmse_per_class: [0.082, 0.233, 0.034, 0.282, 0.056, 0.164, 0.21, 0.113, 0.146, 0.097]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 88] | Train loss: 0.2800 | Steps: 2 | Val loss: 0.2873 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.2323 | Steps: 2 | Val loss: 0.2714 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.8020 | Steps: 2 | Val loss: 0.6213 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.2341 | Steps: 2 | Val loss: 0.2819 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=122389)[0m rmse: 0.1568542718887329
[2m[36m(func pid=122389)[0m mae:  0.11069725453853607
[2m[36m(func pid=122389)[0m rmse_per_class: [0.094, 0.252, 0.051, 0.3, 0.071, 0.179, 0.25, 0.125, 0.142, 0.104]
[2m[36m(func pid=122389)[0m 
== Status ==
Current time: 2024-01-07 08:47:34 (running for 00:15:35.88)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.1599999964237213
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.28  |  0.157 |                   89 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.23  |  0.142 |                   68 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.145 |                   65 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.84  |  0.181 |                   12 |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=128390)[0m rmse: 0.14446692168712616
[2m[36m(func pid=128390)[0m mae:  0.09087777137756348
[2m[36m(func pid=128390)[0m rmse_per_class: [0.082, 0.238, 0.029, 0.301, 0.064, 0.154, 0.193, 0.115, 0.181, 0.088]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.18091410398483276
[2m[36m(func pid=139738)[0m mae:  0.1326065957546234
[2m[36m(func pid=139738)[0m rmse_per_class: [0.106, 0.267, 0.09, 0.324, 0.104, 0.194, 0.308, 0.155, 0.138, 0.122]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=127565)[0m rmse: 0.14192071557044983
[2m[36m(func pid=127565)[0m mae:  0.09408010542392731
[2m[36m(func pid=127565)[0m rmse_per_class: [0.081, 0.233, 0.034, 0.284, 0.056, 0.164, 0.209, 0.114, 0.146, 0.098]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 89] | Train loss: 0.2729 | Steps: 2 | Val loss: 0.2873 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.2292 | Steps: 2 | Val loss: 0.2708 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.7623 | Steps: 2 | Val loss: 0.5933 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.2373 | Steps: 2 | Val loss: 0.2824 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
== Status ==
Current time: 2024-01-07 08:47:40 (running for 00:15:41.19)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.1599999964237213
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.28  |  0.157 |                   89 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.234 |  0.142 |                   69 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.232 |  0.144 |                   66 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.762 |  0.181 |                   14 |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=139738)[0m rmse: 0.18084187805652618
[2m[36m(func pid=139738)[0m mae:  0.13250352442264557
[2m[36m(func pid=139738)[0m rmse_per_class: [0.106, 0.268, 0.09, 0.324, 0.103, 0.194, 0.308, 0.155, 0.138, 0.122]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.1568625420331955
[2m[36m(func pid=122389)[0m mae:  0.11071674525737762
[2m[36m(func pid=122389)[0m rmse_per_class: [0.094, 0.251, 0.051, 0.301, 0.071, 0.179, 0.25, 0.125, 0.142, 0.104]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=128390)[0m rmse: 0.14435450732707977
[2m[36m(func pid=128390)[0m mae:  0.0905495136976242
[2m[36m(func pid=128390)[0m rmse_per_class: [0.08, 0.237, 0.029, 0.297, 0.066, 0.155, 0.192, 0.115, 0.186, 0.087]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m rmse: 0.14177021384239197
[2m[36m(func pid=127565)[0m mae:  0.09389747679233551
[2m[36m(func pid=127565)[0m rmse_per_class: [0.082, 0.233, 0.034, 0.283, 0.056, 0.164, 0.208, 0.113, 0.148, 0.097]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.7294 | Steps: 2 | Val loss: 0.5657 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.2312 | Steps: 2 | Val loss: 0.2727 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 90] | Train loss: 0.2848 | Steps: 2 | Val loss: 0.2873 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.2303 | Steps: 2 | Val loss: 0.2829 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 08:47:45 (running for 00:15:46.49)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.1599999964237213
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.157 |                   90 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.237 |  0.142 |                   70 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.229 |  0.144 |                   67 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.729 |  0.181 |                   15 |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=139738)[0m rmse: 0.18085867166519165
[2m[36m(func pid=139738)[0m mae:  0.1324448138475418
[2m[36m(func pid=139738)[0m rmse_per_class: [0.106, 0.268, 0.09, 0.324, 0.103, 0.194, 0.307, 0.154, 0.138, 0.122]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.15684378147125244
[2m[36m(func pid=122389)[0m mae:  0.11067710071802139
[2m[36m(func pid=122389)[0m rmse_per_class: [0.094, 0.251, 0.051, 0.301, 0.07, 0.179, 0.25, 0.125, 0.142, 0.105]
[2m[36m(func pid=128390)[0m rmse: 0.1447368562221527
[2m[36m(func pid=128390)[0m mae:  0.09089414030313492
[2m[36m(func pid=128390)[0m rmse_per_class: [0.077, 0.239, 0.029, 0.3, 0.065, 0.154, 0.192, 0.115, 0.19, 0.087]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=127565)[0m rmse: 0.14215269684791565
[2m[36m(func pid=127565)[0m mae:  0.09417273849248886
[2m[36m(func pid=127565)[0m rmse_per_class: [0.081, 0.234, 0.034, 0.285, 0.056, 0.164, 0.209, 0.113, 0.147, 0.098]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.7012 | Steps: 2 | Val loss: 0.5381 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.2298 | Steps: 2 | Val loss: 0.2753 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 91] | Train loss: 0.2709 | Steps: 2 | Val loss: 0.2870 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.2336 | Steps: 2 | Val loss: 0.2828 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
== Status ==
Current time: 2024-01-07 08:47:51 (running for 00:15:51.98)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.1599999964237213
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.285 |  0.157 |                   91 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.23  |  0.142 |                   71 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.23  |  0.145 |                   69 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.729 |  0.181 |                   15 |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=128390)[0m rmse: 0.14523257315158844
[2m[36m(func pid=128390)[0m mae:  0.09144864231348038
[2m[36m(func pid=128390)[0m rmse_per_class: [0.079, 0.241, 0.029, 0.303, 0.066, 0.153, 0.193, 0.111, 0.191, 0.088]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.18067915737628937
[2m[36m(func pid=139738)[0m mae:  0.1322590559720993
[2m[36m(func pid=139738)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.103, 0.194, 0.307, 0.154, 0.138, 0.122]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.15666022896766663
[2m[36m(func pid=122389)[0m mae:  0.11058755218982697
[2m[36m(func pid=122389)[0m rmse_per_class: [0.094, 0.25, 0.051, 0.301, 0.07, 0.179, 0.25, 0.124, 0.142, 0.105]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=127565)[0m rmse: 0.14175334572792053
[2m[36m(func pid=127565)[0m mae:  0.09372080862522125
[2m[36m(func pid=127565)[0m rmse_per_class: [0.081, 0.233, 0.034, 0.283, 0.056, 0.163, 0.208, 0.114, 0.148, 0.098]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.2318 | Steps: 2 | Val loss: 0.2759 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 92] | Train loss: 0.2693 | Steps: 2 | Val loss: 0.2869 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.6618 | Steps: 2 | Val loss: 0.5125 | Batch size: 32 | lr: 0.0001 | Duration: 3.09s
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.2334 | Steps: 2 | Val loss: 0.2819 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
== Status ==
Current time: 2024-01-07 08:47:56 (running for 00:15:57.43)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.1599999964237213
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.271 |  0.157 |                   92 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.234 |  0.142 |                   72 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.232 |  0.146 |                   70 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.701 |  0.181 |                   16 |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=128390)[0m rmse: 0.1456698477268219
[2m[36m(func pid=128390)[0m mae:  0.09172841161489487
[2m[36m(func pid=128390)[0m rmse_per_class: [0.086, 0.242, 0.03, 0.304, 0.065, 0.153, 0.192, 0.11, 0.188, 0.087]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.15658336877822876
[2m[36m(func pid=122389)[0m mae:  0.11051509529352188
[2m[36m(func pid=122389)[0m rmse_per_class: [0.094, 0.25, 0.051, 0.302, 0.071, 0.179, 0.249, 0.124, 0.141, 0.104]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.18060564994812012
[2m[36m(func pid=139738)[0m mae:  0.13214699923992157
[2m[36m(func pid=139738)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.325, 0.102, 0.194, 0.306, 0.154, 0.139, 0.122]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=127565)[0m rmse: 0.1413109451532364
[2m[36m(func pid=127565)[0m mae:  0.09334246814250946
[2m[36m(func pid=127565)[0m rmse_per_class: [0.081, 0.233, 0.034, 0.281, 0.055, 0.163, 0.208, 0.114, 0.147, 0.097]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.2309 | Steps: 2 | Val loss: 0.2761 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 93] | Train loss: 0.2769 | Steps: 2 | Val loss: 0.2872 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.6297 | Steps: 2 | Val loss: 0.4871 | Batch size: 32 | lr: 0.0001 | Duration: 3.04s
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.2407 | Steps: 2 | Val loss: 0.2810 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
== Status ==
Current time: 2024-01-07 08:48:01 (running for 00:16:02.86)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.1599999964237213
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.269 |  0.157 |                   93 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.233 |  0.141 |                   73 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.231 |  0.147 |                   71 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.662 |  0.181 |                   17 |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=128390)[0m rmse: 0.14659252762794495
[2m[36m(func pid=128390)[0m mae:  0.09222390502691269
[2m[36m(func pid=128390)[0m rmse_per_class: [0.091, 0.242, 0.03, 0.305, 0.066, 0.153, 0.192, 0.113, 0.188, 0.087]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.15664109587669373
[2m[36m(func pid=122389)[0m mae:  0.11055505275726318
[2m[36m(func pid=122389)[0m rmse_per_class: [0.094, 0.25, 0.051, 0.301, 0.071, 0.179, 0.249, 0.124, 0.142, 0.105]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.18045446276664734
[2m[36m(func pid=139738)[0m mae:  0.13197217881679535
[2m[36m(func pid=139738)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.102, 0.194, 0.305, 0.153, 0.139, 0.122]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=127565)[0m rmse: 0.1408652812242508
[2m[36m(func pid=127565)[0m mae:  0.09285029023885727
[2m[36m(func pid=127565)[0m rmse_per_class: [0.08, 0.232, 0.034, 0.279, 0.056, 0.163, 0.207, 0.115, 0.145, 0.096]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.2289 | Steps: 2 | Val loss: 0.2726 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 94] | Train loss: 0.2721 | Steps: 2 | Val loss: 0.2868 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.6025 | Steps: 2 | Val loss: 0.4644 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.2297 | Steps: 2 | Val loss: 0.2805 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 08:48:07 (running for 00:16:08.05)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.1599999964237213
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.277 |  0.157 |                   94 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.241 |  0.141 |                   74 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.229 |  0.146 |                   72 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.63  |  0.18  |                   18 |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=128390)[0m rmse: 0.1456572562456131
[2m[36m(func pid=128390)[0m mae:  0.09173467010259628
[2m[36m(func pid=128390)[0m rmse_per_class: [0.084, 0.242, 0.029, 0.298, 0.064, 0.153, 0.194, 0.117, 0.185, 0.089]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.15641018748283386
[2m[36m(func pid=122389)[0m mae:  0.11031891405582428
[2m[36m(func pid=122389)[0m rmse_per_class: [0.094, 0.25, 0.051, 0.301, 0.071, 0.179, 0.249, 0.124, 0.142, 0.104]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.18028730154037476
[2m[36m(func pid=139738)[0m mae:  0.13177941739559174
[2m[36m(func pid=139738)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.101, 0.194, 0.304, 0.152, 0.14, 0.122]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=127565)[0m rmse: 0.14102517068386078
[2m[36m(func pid=127565)[0m mae:  0.09298265725374222
[2m[36m(func pid=127565)[0m rmse_per_class: [0.08, 0.233, 0.034, 0.281, 0.056, 0.164, 0.207, 0.115, 0.144, 0.098]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.2256 | Steps: 2 | Val loss: 0.2707 | Batch size: 32 | lr: 0.1 | Duration: 2.78s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 95] | Train loss: 0.2671 | Steps: 2 | Val loss: 0.2866 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.5747 | Steps: 2 | Val loss: 0.4433 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 75] | Train loss: 0.2334 | Steps: 2 | Val loss: 0.2811 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 08:48:12 (running for 00:16:13.28)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.15799999982118607
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.272 |  0.156 |                   95 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.23  |  0.141 |                   75 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.226 |  0.145 |                   73 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.602 |  0.18  |                   19 |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=128390)[0m rmse: 0.14473024010658264
[2m[36m(func pid=128390)[0m mae:  0.09118658304214478
[2m[36m(func pid=128390)[0m rmse_per_class: [0.077, 0.242, 0.029, 0.295, 0.061, 0.153, 0.194, 0.117, 0.19, 0.09]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.1562645137310028
[2m[36m(func pid=122389)[0m mae:  0.11022824048995972
[2m[36m(func pid=122389)[0m rmse_per_class: [0.094, 0.25, 0.051, 0.3, 0.071, 0.178, 0.249, 0.124, 0.142, 0.104]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.18006698787212372
[2m[36m(func pid=139738)[0m mae:  0.131575807929039
[2m[36m(func pid=139738)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.1, 0.194, 0.303, 0.151, 0.14, 0.122]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=127565)[0m rmse: 0.1412515938282013
[2m[36m(func pid=127565)[0m mae:  0.09309645742177963
[2m[36m(func pid=127565)[0m rmse_per_class: [0.08, 0.233, 0.033, 0.283, 0.056, 0.163, 0.206, 0.116, 0.144, 0.099]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.2290 | Steps: 2 | Val loss: 0.2699 | Batch size: 32 | lr: 0.1 | Duration: 2.98s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 96] | Train loss: 0.2731 | Steps: 2 | Val loss: 0.2863 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.5542 | Steps: 2 | Val loss: 0.4244 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 76] | Train loss: 0.2290 | Steps: 2 | Val loss: 0.2803 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
== Status ==
Current time: 2024-01-07 08:48:17 (running for 00:16:18.61)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.15799999982118607
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.267 |  0.156 |                   96 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.233 |  0.141 |                   76 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.229 |  0.144 |                   74 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.575 |  0.18  |                   20 |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=128390)[0m rmse: 0.1437370479106903
[2m[36m(func pid=128390)[0m mae:  0.09046117216348648
[2m[36m(func pid=128390)[0m rmse_per_class: [0.073, 0.243, 0.029, 0.294, 0.06, 0.153, 0.191, 0.113, 0.192, 0.09]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.15602196753025055
[2m[36m(func pid=122389)[0m mae:  0.10997877269983292
[2m[36m(func pid=122389)[0m rmse_per_class: [0.094, 0.25, 0.05, 0.299, 0.07, 0.178, 0.249, 0.124, 0.142, 0.104]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.17991679906845093
[2m[36m(func pid=139738)[0m mae:  0.1313970983028412
[2m[36m(func pid=139738)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.099, 0.194, 0.302, 0.151, 0.14, 0.121]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=127565)[0m rmse: 0.14090396463871002
[2m[36m(func pid=127565)[0m mae:  0.09295224398374557
[2m[36m(func pid=127565)[0m rmse_per_class: [0.081, 0.232, 0.033, 0.283, 0.057, 0.163, 0.205, 0.116, 0.142, 0.097]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.2300 | Steps: 2 | Val loss: 0.2727 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 97] | Train loss: 0.2699 | Steps: 2 | Val loss: 0.2864 | Batch size: 32 | lr: 0.001 | Duration: 3.04s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.5255 | Steps: 2 | Val loss: 0.4071 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 77] | Train loss: 0.2310 | Steps: 2 | Val loss: 0.2798 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
== Status ==
Current time: 2024-01-07 08:48:23 (running for 00:16:23.89)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                   97 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.229 |  0.141 |                   77 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.23  |  0.144 |                   75 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.554 |  0.18  |                   21 |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=128390)[0m rmse: 0.14431653916835785
[2m[36m(func pid=128390)[0m mae:  0.09098924696445465
[2m[36m(func pid=128390)[0m rmse_per_class: [0.075, 0.244, 0.029, 0.299, 0.06, 0.152, 0.191, 0.109, 0.194, 0.09]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.15601933002471924
[2m[36m(func pid=122389)[0m mae:  0.10990770906209946
[2m[36m(func pid=122389)[0m rmse_per_class: [0.094, 0.25, 0.05, 0.3, 0.07, 0.178, 0.248, 0.124, 0.143, 0.103]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.1796584129333496
[2m[36m(func pid=139738)[0m mae:  0.1311240792274475
[2m[36m(func pid=139738)[0m rmse_per_class: [0.107, 0.269, 0.092, 0.326, 0.098, 0.194, 0.3, 0.149, 0.141, 0.121]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=127565)[0m rmse: 0.14078184962272644
[2m[36m(func pid=127565)[0m mae:  0.09286415576934814
[2m[36m(func pid=127565)[0m rmse_per_class: [0.083, 0.231, 0.033, 0.283, 0.057, 0.162, 0.205, 0.115, 0.142, 0.097]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 75] | Train loss: 0.2422 | Steps: 2 | Val loss: 0.2765 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 98] | Train loss: 0.2760 | Steps: 2 | Val loss: 0.2867 | Batch size: 32 | lr: 0.001 | Duration: 3.06s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.5082 | Steps: 2 | Val loss: 0.3903 | Batch size: 32 | lr: 0.0001 | Duration: 3.04s
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 78] | Train loss: 0.2345 | Steps: 2 | Val loss: 0.2807 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=128390)[0m rmse: 0.1459481418132782
[2m[36m(func pid=128390)[0m mae:  0.0920235812664032
[2m[36m(func pid=128390)[0m rmse_per_class: [0.082, 0.245, 0.029, 0.306, 0.06, 0.153, 0.191, 0.109, 0.194, 0.09]
== Status ==
Current time: 2024-01-07 08:48:28 (running for 00:16:29.09)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.27  |  0.156 |                   98 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.231 |  0.141 |                   78 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.242 |  0.146 |                   76 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.526 |  0.18  |                   22 |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.1562025099992752
[2m[36m(func pid=122389)[0m mae:  0.11006920039653778
[2m[36m(func pid=122389)[0m rmse_per_class: [0.093, 0.25, 0.05, 0.3, 0.071, 0.178, 0.248, 0.124, 0.143, 0.104]
[2m[36m(func pid=122389)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.1793140470981598
[2m[36m(func pid=139738)[0m mae:  0.1307559609413147
[2m[36m(func pid=139738)[0m rmse_per_class: [0.107, 0.269, 0.093, 0.326, 0.098, 0.193, 0.298, 0.148, 0.141, 0.12]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=127565)[0m rmse: 0.1409951001405716
[2m[36m(func pid=127565)[0m mae:  0.09298433363437653
[2m[36m(func pid=127565)[0m rmse_per_class: [0.083, 0.231, 0.033, 0.285, 0.057, 0.162, 0.205, 0.115, 0.143, 0.097]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 76] | Train loss: 0.2281 | Steps: 2 | Val loss: 0.2764 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=122389)[0m [N0-GPU0] | [Epoch: 99] | Train loss: 0.2733 | Steps: 2 | Val loss: 0.2867 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.4895 | Steps: 2 | Val loss: 0.3769 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 79] | Train loss: 0.2369 | Steps: 2 | Val loss: 0.2821 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
== Status ==
Current time: 2024-01-07 08:48:33 (running for 00:16:34.21)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00005 | RUNNING    | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.276 |  0.156 |                   99 |
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.234 |  0.141 |                   79 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                   77 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.508 |  0.179 |                   23 |
| train_d77f6_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=128390)[0m rmse: 0.14640380442142487
[2m[36m(func pid=128390)[0m mae:  0.09222759306430817
[2m[36m(func pid=128390)[0m rmse_per_class: [0.083, 0.244, 0.029, 0.312, 0.064, 0.154, 0.192, 0.112, 0.185, 0.089]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=122389)[0m rmse: 0.15603280067443848
[2m[36m(func pid=122389)[0m mae:  0.10990108549594879
[2m[36m(func pid=122389)[0m rmse_per_class: [0.093, 0.25, 0.05, 0.299, 0.071, 0.178, 0.248, 0.124, 0.144, 0.103]
[2m[36m(func pid=139738)[0m rmse: 0.17914140224456787
[2m[36m(func pid=139738)[0m mae:  0.13054503500461578
[2m[36m(func pid=139738)[0m rmse_per_class: [0.107, 0.27, 0.093, 0.326, 0.098, 0.193, 0.297, 0.146, 0.142, 0.119]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=127565)[0m rmse: 0.14160510897636414
[2m[36m(func pid=127565)[0m mae:  0.09351514279842377
[2m[36m(func pid=127565)[0m rmse_per_class: [0.085, 0.231, 0.033, 0.287, 0.057, 0.162, 0.205, 0.114, 0.145, 0.097]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 77] | Train loss: 0.2317 | Steps: 2 | Val loss: 0.2740 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.4680 | Steps: 2 | Val loss: 0.3657 | Batch size: 32 | lr: 0.0001 | Duration: 3.15s
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 80] | Train loss: 0.2330 | Steps: 2 | Val loss: 0.2825 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
[2m[36m(func pid=128390)[0m rmse: 0.1462051272392273
[2m[36m(func pid=128390)[0m mae:  0.09206578135490417
[2m[36m(func pid=128390)[0m rmse_per_class: [0.085, 0.243, 0.029, 0.309, 0.065, 0.154, 0.194, 0.118, 0.177, 0.089]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.17892451584339142
[2m[36m(func pid=139738)[0m mae:  0.1303217113018036
[2m[36m(func pid=139738)[0m rmse_per_class: [0.108, 0.27, 0.093, 0.327, 0.097, 0.193, 0.295, 0.145, 0.143, 0.118]
[2m[36m(func pid=127565)[0m rmse: 0.14149951934814453
[2m[36m(func pid=127565)[0m mae:  0.09346212446689606
[2m[36m(func pid=127565)[0m rmse_per_class: [0.085, 0.232, 0.033, 0.286, 0.057, 0.162, 0.205, 0.114, 0.144, 0.099]
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 78] | Train loss: 0.2300 | Steps: 2 | Val loss: 0.2689 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 08:48:38 (running for 00:16:39.55)
Memory usage on this node: 22.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.237 |  0.142 |                   80 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.232 |  0.146 |                   78 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.489 |  0.179 |                   24 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=145749)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=145749)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=145749)[0m Configuration completed!
[2m[36m(func pid=145749)[0m New optimizer parameters:
[2m[36m(func pid=145749)[0m SGD (
[2m[36m(func pid=145749)[0m Parameter Group 0
[2m[36m(func pid=145749)[0m     dampening: 0
[2m[36m(func pid=145749)[0m     differentiable: False
[2m[36m(func pid=145749)[0m     foreach: None
[2m[36m(func pid=145749)[0m     lr: 0.001
[2m[36m(func pid=145749)[0m     maximize: False
[2m[36m(func pid=145749)[0m     momentum: 0.99
[2m[36m(func pid=145749)[0m     nesterov: False
[2m[36m(func pid=145749)[0m     weight_decay: 0.0001
[2m[36m(func pid=145749)[0m )
[2m[36m(func pid=145749)[0m 
== Status ==
Current time: 2024-01-07 08:48:44 (running for 00:16:44.97)
Memory usage on this node: 24.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.233 |  0.141 |                   81 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.23  |  0.144 |                   79 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.468 |  0.179 |                   25 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=128390)[0m rmse: 0.14437255263328552
[2m[36m(func pid=128390)[0m mae:  0.09080352634191513
[2m[36m(func pid=128390)[0m rmse_per_class: [0.085, 0.241, 0.03, 0.295, 0.066, 0.154, 0.196, 0.117, 0.174, 0.088]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 81] | Train loss: 0.2347 | Steps: 2 | Val loss: 0.2828 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.4540 | Steps: 2 | Val loss: 0.3558 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 79] | Train loss: 0.2283 | Steps: 2 | Val loss: 0.2672 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 1.0765 | Steps: 2 | Val loss: 0.7929 | Batch size: 32 | lr: 0.001 | Duration: 4.71s
[2m[36m(func pid=127565)[0m rmse: 0.14155122637748718
[2m[36m(func pid=127565)[0m mae:  0.093498095870018
[2m[36m(func pid=127565)[0m rmse_per_class: [0.085, 0.231, 0.033, 0.286, 0.056, 0.162, 0.205, 0.114, 0.145, 0.099]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.17861658334732056
[2m[36m(func pid=139738)[0m mae:  0.13000503182411194
[2m[36m(func pid=139738)[0m rmse_per_class: [0.108, 0.27, 0.093, 0.328, 0.097, 0.193, 0.293, 0.144, 0.144, 0.117]
[2m[36m(func pid=139738)[0m 
== Status ==
Current time: 2024-01-07 08:48:49 (running for 00:16:50.46)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.235 |  0.142 |                   82 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.143 |                   80 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.454 |  0.179 |                   26 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=128390)[0m rmse: 0.14275100827217102
[2m[36m(func pid=128390)[0m mae:  0.08983591943979263
[2m[36m(func pid=128390)[0m rmse_per_class: [0.081, 0.239, 0.03, 0.288, 0.062, 0.153, 0.193, 0.113, 0.178, 0.09]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.1786373257637024
[2m[36m(func pid=145749)[0m mae:  0.131159245967865
[2m[36m(func pid=145749)[0m rmse_per_class: [0.105, 0.266, 0.087, 0.325, 0.1, 0.192, 0.304, 0.153, 0.139, 0.116]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 82] | Train loss: 0.2286 | Steps: 2 | Val loss: 0.2832 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.4427 | Steps: 2 | Val loss: 0.3471 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 80] | Train loss: 0.2309 | Steps: 2 | Val loss: 0.2704 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 1.0298 | Steps: 2 | Val loss: 0.7553 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=127565)[0m rmse: 0.1416931450366974
[2m[36m(func pid=127565)[0m mae:  0.0936821848154068
[2m[36m(func pid=127565)[0m rmse_per_class: [0.083, 0.231, 0.033, 0.288, 0.056, 0.163, 0.206, 0.113, 0.145, 0.099]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.17849208414554596
[2m[36m(func pid=139738)[0m mae:  0.12981221079826355
[2m[36m(func pid=139738)[0m rmse_per_class: [0.108, 0.27, 0.094, 0.328, 0.096, 0.193, 0.292, 0.142, 0.144, 0.117]
[2m[36m(func pid=139738)[0m 
== Status ==
Current time: 2024-01-07 08:48:54 (running for 00:16:55.83)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.229 |  0.142 |                   83 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.231 |  0.143 |                   81 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.443 |  0.178 |                   27 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  1.077 |  0.179 |                    1 |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=128390)[0m rmse: 0.14328566193580627
[2m[36m(func pid=128390)[0m mae:  0.09032567590475082
[2m[36m(func pid=128390)[0m rmse_per_class: [0.08, 0.241, 0.029, 0.292, 0.06, 0.153, 0.191, 0.109, 0.185, 0.092]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.17902235686779022
[2m[36m(func pid=145749)[0m mae:  0.131403848528862
[2m[36m(func pid=145749)[0m rmse_per_class: [0.105, 0.266, 0.088, 0.325, 0.101, 0.193, 0.305, 0.154, 0.139, 0.116]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 83] | Train loss: 0.2283 | Steps: 2 | Val loss: 0.2833 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.4299 | Steps: 2 | Val loss: 0.3401 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 81] | Train loss: 0.2352 | Steps: 2 | Val loss: 0.2737 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.9510 | Steps: 2 | Val loss: 0.6934 | Batch size: 32 | lr: 0.001 | Duration: 3.07s
[2m[36m(func pid=127565)[0m rmse: 0.14152303338050842
[2m[36m(func pid=127565)[0m mae:  0.0936230719089508
[2m[36m(func pid=127565)[0m rmse_per_class: [0.083, 0.23, 0.033, 0.289, 0.056, 0.163, 0.206, 0.113, 0.144, 0.099]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.1781468689441681
[2m[36m(func pid=139738)[0m mae:  0.12947824597358704
[2m[36m(func pid=139738)[0m rmse_per_class: [0.109, 0.27, 0.094, 0.329, 0.095, 0.193, 0.29, 0.141, 0.145, 0.116]
[2m[36m(func pid=139738)[0m 
== Status ==
Current time: 2024-01-07 08:49:00 (running for 00:17:01.15)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.228 |  0.142 |                   84 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.235 |  0.145 |                   82 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.43  |  0.178 |                   28 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  1.03  |  0.179 |                    2 |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=128390)[0m rmse: 0.1445930153131485
[2m[36m(func pid=128390)[0m mae:  0.0912158340215683
[2m[36m(func pid=128390)[0m rmse_per_class: [0.078, 0.242, 0.029, 0.301, 0.061, 0.152, 0.191, 0.109, 0.192, 0.091]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.17925748229026794
[2m[36m(func pid=145749)[0m mae:  0.13148808479309082
[2m[36m(func pid=145749)[0m rmse_per_class: [0.104, 0.267, 0.089, 0.324, 0.101, 0.193, 0.305, 0.155, 0.139, 0.115]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 84] | Train loss: 0.2335 | Steps: 2 | Val loss: 0.2840 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.4268 | Steps: 2 | Val loss: 0.3341 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 82] | Train loss: 0.2256 | Steps: 2 | Val loss: 0.2721 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=127565)[0m rmse: 0.14146891236305237
[2m[36m(func pid=127565)[0m mae:  0.09345375001430511
[2m[36m(func pid=127565)[0m rmse_per_class: [0.082, 0.23, 0.034, 0.288, 0.056, 0.163, 0.206, 0.114, 0.144, 0.098]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.8410 | Steps: 2 | Val loss: 0.6141 | Batch size: 32 | lr: 0.001 | Duration: 3.08s
[2m[36m(func pid=139738)[0m rmse: 0.1779511421918869
[2m[36m(func pid=139738)[0m mae:  0.1292302906513214
[2m[36m(func pid=139738)[0m rmse_per_class: [0.109, 0.271, 0.095, 0.33, 0.094, 0.193, 0.288, 0.14, 0.146, 0.115]
[2m[36m(func pid=139738)[0m 
== Status ==
Current time: 2024-01-07 08:49:05 (running for 00:17:06.37)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.233 |  0.141 |                   85 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.226 |  0.144 |                   83 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.427 |  0.178 |                   29 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.951 |  0.179 |                    3 |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=128390)[0m rmse: 0.1442919671535492
[2m[36m(func pid=128390)[0m mae:  0.09109047800302505
[2m[36m(func pid=128390)[0m rmse_per_class: [0.075, 0.241, 0.029, 0.308, 0.059, 0.152, 0.192, 0.112, 0.187, 0.088]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.17931978404521942
[2m[36m(func pid=145749)[0m mae:  0.13139456510543823
[2m[36m(func pid=145749)[0m rmse_per_class: [0.104, 0.267, 0.089, 0.324, 0.101, 0.193, 0.304, 0.156, 0.139, 0.115]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 85] | Train loss: 0.2353 | Steps: 2 | Val loss: 0.2847 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.4181 | Steps: 2 | Val loss: 0.3300 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 83] | Train loss: 0.2241 | Steps: 2 | Val loss: 0.2707 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
[2m[36m(func pid=127565)[0m rmse: 0.14162170886993408
[2m[36m(func pid=127565)[0m mae:  0.09354039281606674
[2m[36m(func pid=127565)[0m rmse_per_class: [0.082, 0.231, 0.033, 0.288, 0.056, 0.163, 0.205, 0.114, 0.143, 0.1]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.7226 | Steps: 2 | Val loss: 0.5290 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=139738)[0m rmse: 0.17774920165538788
[2m[36m(func pid=139738)[0m mae:  0.12898758053779602
[2m[36m(func pid=139738)[0m rmse_per_class: [0.109, 0.271, 0.096, 0.33, 0.092, 0.193, 0.286, 0.139, 0.147, 0.114]
[2m[36m(func pid=139738)[0m 
== Status ==
Current time: 2024-01-07 08:49:10 (running for 00:17:11.57)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.235 |  0.142 |                   86 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.224 |  0.145 |                   84 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.418 |  0.178 |                   30 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.841 |  0.179 |                    4 |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=128390)[0m rmse: 0.14461322128772736
[2m[36m(func pid=128390)[0m mae:  0.09118442237377167
[2m[36m(func pid=128390)[0m rmse_per_class: [0.08, 0.24, 0.029, 0.305, 0.061, 0.152, 0.194, 0.114, 0.184, 0.086]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 86] | Train loss: 0.2332 | Steps: 2 | Val loss: 0.2834 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=145749)[0m rmse: 0.17918166518211365
[2m[36m(func pid=145749)[0m mae:  0.13110770285129547
[2m[36m(func pid=145749)[0m rmse_per_class: [0.104, 0.268, 0.09, 0.324, 0.1, 0.193, 0.303, 0.156, 0.139, 0.114]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.4070 | Steps: 2 | Val loss: 0.3267 | Batch size: 32 | lr: 0.0001 | Duration: 2.81s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 84] | Train loss: 0.2268 | Steps: 2 | Val loss: 0.2702 | Batch size: 32 | lr: 0.1 | Duration: 2.75s
[2m[36m(func pid=127565)[0m rmse: 0.14100995659828186
[2m[36m(func pid=127565)[0m mae:  0.0930059552192688
[2m[36m(func pid=127565)[0m rmse_per_class: [0.081, 0.23, 0.034, 0.284, 0.056, 0.163, 0.206, 0.114, 0.143, 0.1]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.17749033868312836
[2m[36m(func pid=139738)[0m mae:  0.1287166327238083
[2m[36m(func pid=139738)[0m rmse_per_class: [0.109, 0.271, 0.097, 0.331, 0.091, 0.193, 0.284, 0.138, 0.148, 0.113]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.6116 | Steps: 2 | Val loss: 0.4501 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
== Status ==
Current time: 2024-01-07 08:49:15 (running for 00:17:16.74)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.233 |  0.141 |                   87 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.227 |  0.144 |                   85 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.407 |  0.177 |                   31 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.723 |  0.179 |                    5 |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=128390)[0m rmse: 0.1444971114397049
[2m[36m(func pid=128390)[0m mae:  0.090911865234375
[2m[36m(func pid=128390)[0m rmse_per_class: [0.086, 0.239, 0.03, 0.298, 0.064, 0.152, 0.193, 0.114, 0.184, 0.086]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 87] | Train loss: 0.2332 | Steps: 2 | Val loss: 0.2820 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=145749)[0m rmse: 0.1788465976715088
[2m[36m(func pid=145749)[0m mae:  0.13063381612300873
[2m[36m(func pid=145749)[0m rmse_per_class: [0.105, 0.269, 0.091, 0.325, 0.099, 0.193, 0.3, 0.154, 0.14, 0.114]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.4031 | Steps: 2 | Val loss: 0.3241 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 85] | Train loss: 0.2347 | Steps: 2 | Val loss: 0.2723 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=127565)[0m rmse: 0.1406700164079666
[2m[36m(func pid=127565)[0m mae:  0.09278848022222519
[2m[36m(func pid=127565)[0m rmse_per_class: [0.083, 0.23, 0.034, 0.282, 0.055, 0.163, 0.206, 0.113, 0.143, 0.098]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.17722252011299133
[2m[36m(func pid=139738)[0m mae:  0.12838950753211975
[2m[36m(func pid=139738)[0m rmse_per_class: [0.11, 0.271, 0.097, 0.332, 0.09, 0.193, 0.282, 0.137, 0.148, 0.112]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.5193 | Steps: 2 | Val loss: 0.3887 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 08:49:21 (running for 00:17:22.07)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.233 |  0.141 |                   88 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.235 |  0.145 |                   86 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.403 |  0.177 |                   32 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.612 |  0.179 |                    6 |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=128390)[0m rmse: 0.1451428234577179
[2m[36m(func pid=128390)[0m mae:  0.09126408398151398
[2m[36m(func pid=128390)[0m rmse_per_class: [0.091, 0.239, 0.029, 0.3, 0.065, 0.154, 0.191, 0.113, 0.183, 0.087]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 88] | Train loss: 0.2326 | Steps: 2 | Val loss: 0.2812 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
[2m[36m(func pid=145749)[0m rmse: 0.17812806367874146
[2m[36m(func pid=145749)[0m mae:  0.12987692654132843
[2m[36m(func pid=145749)[0m rmse_per_class: [0.106, 0.27, 0.092, 0.326, 0.096, 0.193, 0.295, 0.15, 0.141, 0.112]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.3954 | Steps: 2 | Val loss: 0.3222 | Batch size: 32 | lr: 0.0001 | Duration: 3.03s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 86] | Train loss: 0.2312 | Steps: 2 | Val loss: 0.2736 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=127565)[0m rmse: 0.140190988779068
[2m[36m(func pid=127565)[0m mae:  0.09231571853160858
[2m[36m(func pid=127565)[0m rmse_per_class: [0.084, 0.23, 0.034, 0.278, 0.055, 0.162, 0.206, 0.113, 0.143, 0.097]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.17673653364181519
[2m[36m(func pid=139738)[0m mae:  0.12788523733615875
[2m[36m(func pid=139738)[0m rmse_per_class: [0.11, 0.271, 0.096, 0.333, 0.089, 0.193, 0.28, 0.137, 0.149, 0.111]
[2m[36m(func pid=139738)[0m 
== Status ==
Current time: 2024-01-07 08:49:26 (running for 00:17:27.23)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.233 |  0.14  |                   89 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.231 |  0.145 |                   87 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.395 |  0.177 |                   33 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.519 |  0.178 |                    7 |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=128390)[0m rmse: 0.14493979513645172
[2m[36m(func pid=128390)[0m mae:  0.09127716720104218
[2m[36m(func pid=128390)[0m rmse_per_class: [0.09, 0.239, 0.028, 0.306, 0.065, 0.154, 0.189, 0.109, 0.183, 0.087]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.4591 | Steps: 2 | Val loss: 0.3474 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 89] | Train loss: 0.2350 | Steps: 2 | Val loss: 0.2807 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
[2m[36m(func pid=145749)[0m rmse: 0.17716695368289948
[2m[36m(func pid=145749)[0m mae:  0.12886714935302734
[2m[36m(func pid=145749)[0m rmse_per_class: [0.107, 0.27, 0.093, 0.328, 0.094, 0.192, 0.289, 0.145, 0.143, 0.11]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.3934 | Steps: 2 | Val loss: 0.3216 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 87] | Train loss: 0.2301 | Steps: 2 | Val loss: 0.2734 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=127565)[0m rmse: 0.14018937945365906
[2m[36m(func pid=127565)[0m mae:  0.09221218526363373
[2m[36m(func pid=127565)[0m rmse_per_class: [0.085, 0.231, 0.034, 0.277, 0.054, 0.162, 0.205, 0.114, 0.144, 0.096]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.17651374638080597
[2m[36m(func pid=139738)[0m mae:  0.127619206905365
[2m[36m(func pid=139738)[0m rmse_per_class: [0.11, 0.271, 0.096, 0.333, 0.088, 0.192, 0.278, 0.136, 0.15, 0.111]
[2m[36m(func pid=139738)[0m 
== Status ==
Current time: 2024-01-07 08:49:31 (running for 00:17:32.50)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.235 |  0.14  |                   90 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.23  |  0.145 |                   88 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.393 |  0.177 |                   34 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.459 |  0.177 |                    8 |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=128390)[0m rmse: 0.14453046023845673
[2m[36m(func pid=128390)[0m mae:  0.09122364223003387
[2m[36m(func pid=128390)[0m rmse_per_class: [0.083, 0.239, 0.028, 0.307, 0.063, 0.153, 0.191, 0.112, 0.181, 0.087]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.4179 | Steps: 2 | Val loss: 0.3257 | Batch size: 32 | lr: 0.001 | Duration: 3.07s
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 90] | Train loss: 0.2353 | Steps: 2 | Val loss: 0.2815 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.3945 | Steps: 2 | Val loss: 0.3217 | Batch size: 32 | lr: 0.0001 | Duration: 2.81s
[2m[36m(func pid=145749)[0m rmse: 0.17617711424827576
[2m[36m(func pid=145749)[0m mae:  0.1277436912059784
[2m[36m(func pid=145749)[0m rmse_per_class: [0.108, 0.271, 0.096, 0.33, 0.09, 0.192, 0.282, 0.14, 0.146, 0.108]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 88] | Train loss: 0.2313 | Steps: 2 | Val loss: 0.2743 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
[2m[36m(func pid=127565)[0m rmse: 0.1408415138721466
[2m[36m(func pid=127565)[0m mae:  0.09260381758213043
[2m[36m(func pid=127565)[0m rmse_per_class: [0.085, 0.232, 0.034, 0.281, 0.054, 0.163, 0.205, 0.115, 0.143, 0.098]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.1762373149394989
[2m[36m(func pid=139738)[0m mae:  0.12731143832206726
[2m[36m(func pid=139738)[0m rmse_per_class: [0.11, 0.271, 0.096, 0.334, 0.087, 0.192, 0.276, 0.136, 0.151, 0.11]
[2m[36m(func pid=139738)[0m 
== Status ==
Current time: 2024-01-07 08:49:36 (running for 00:17:37.85)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.235 |  0.141 |                   91 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.231 |  0.146 |                   89 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.395 |  0.176 |                   35 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.418 |  0.176 |                    9 |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=128390)[0m rmse: 0.14553526043891907
[2m[36m(func pid=128390)[0m mae:  0.09209545701742172
[2m[36m(func pid=128390)[0m rmse_per_class: [0.081, 0.241, 0.029, 0.308, 0.061, 0.154, 0.198, 0.116, 0.181, 0.087]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.4026 | Steps: 2 | Val loss: 0.3199 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 91] | Train loss: 0.2336 | Steps: 2 | Val loss: 0.2808 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.3923 | Steps: 2 | Val loss: 0.3224 | Batch size: 32 | lr: 0.0001 | Duration: 3.05s
[2m[36m(func pid=145749)[0m rmse: 0.17517569661140442
[2m[36m(func pid=145749)[0m mae:  0.12658755481243134
[2m[36m(func pid=145749)[0m rmse_per_class: [0.109, 0.271, 0.096, 0.333, 0.085, 0.192, 0.275, 0.136, 0.149, 0.105]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 89] | Train loss: 0.2306 | Steps: 2 | Val loss: 0.2723 | Batch size: 32 | lr: 0.1 | Duration: 2.78s
[2m[36m(func pid=127565)[0m rmse: 0.1406944841146469
[2m[36m(func pid=127565)[0m mae:  0.0925951674580574
[2m[36m(func pid=127565)[0m rmse_per_class: [0.087, 0.231, 0.033, 0.28, 0.054, 0.162, 0.206, 0.113, 0.144, 0.096]
[2m[36m(func pid=127565)[0m 
== Status ==
Current time: 2024-01-07 08:49:42 (running for 00:17:42.94)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.234 |  0.141 |                   92 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.231 |  0.146 |                   89 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.392 |  0.176 |                   36 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.403 |  0.175 |                   10 |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=139738)[0m rmse: 0.176029771566391
[2m[36m(func pid=139738)[0m mae:  0.12705448269844055
[2m[36m(func pid=139738)[0m rmse_per_class: [0.111, 0.271, 0.096, 0.335, 0.086, 0.192, 0.275, 0.135, 0.151, 0.109]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=128390)[0m rmse: 0.14448964595794678
[2m[36m(func pid=128390)[0m mae:  0.09134341031312943
[2m[36m(func pid=128390)[0m rmse_per_class: [0.079, 0.241, 0.03, 0.305, 0.061, 0.154, 0.198, 0.113, 0.178, 0.088]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.3943 | Steps: 2 | Val loss: 0.3252 | Batch size: 32 | lr: 0.001 | Duration: 3.15s
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 92] | Train loss: 0.2335 | Steps: 2 | Val loss: 0.2803 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=145749)[0m rmse: 0.17431038618087769
[2m[36m(func pid=145749)[0m mae:  0.12542679905891418
[2m[36m(func pid=145749)[0m rmse_per_class: [0.11, 0.271, 0.096, 0.336, 0.081, 0.191, 0.269, 0.134, 0.152, 0.102]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 90] | Train loss: 0.2267 | Steps: 2 | Val loss: 0.2692 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.3916 | Steps: 2 | Val loss: 0.3230 | Batch size: 32 | lr: 0.0001 | Duration: 3.01s
[2m[36m(func pid=127565)[0m rmse: 0.14061982929706573
[2m[36m(func pid=127565)[0m mae:  0.09258409589529037
[2m[36m(func pid=127565)[0m rmse_per_class: [0.086, 0.231, 0.033, 0.28, 0.055, 0.162, 0.205, 0.113, 0.145, 0.095]
[2m[36m(func pid=127565)[0m 
== Status ==
Current time: 2024-01-07 08:49:47 (running for 00:17:48.35)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.234 |  0.141 |                   93 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.231 |  0.144 |                   90 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.392 |  0.176 |                   37 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.394 |  0.174 |                   11 |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=139738)[0m rmse: 0.17561736702919006
[2m[36m(func pid=139738)[0m mae:  0.1266322135925293
[2m[36m(func pid=139738)[0m rmse_per_class: [0.11, 0.271, 0.095, 0.336, 0.085, 0.192, 0.273, 0.134, 0.152, 0.108]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=128390)[0m rmse: 0.14314961433410645
[2m[36m(func pid=128390)[0m mae:  0.09020546078681946
[2m[36m(func pid=128390)[0m rmse_per_class: [0.078, 0.239, 0.031, 0.302, 0.061, 0.153, 0.191, 0.11, 0.179, 0.086]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.4005 | Steps: 2 | Val loss: 0.3377 | Batch size: 32 | lr: 0.001 | Duration: 3.05s
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 93] | Train loss: 0.2286 | Steps: 2 | Val loss: 0.2807 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 91] | Train loss: 0.2327 | Steps: 2 | Val loss: 0.2688 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.3905 | Steps: 2 | Val loss: 0.3244 | Batch size: 32 | lr: 0.0001 | Duration: 3.01s
[2m[36m(func pid=145749)[0m rmse: 0.1735314279794693
[2m[36m(func pid=145749)[0m mae:  0.12417205423116684
[2m[36m(func pid=145749)[0m rmse_per_class: [0.11, 0.271, 0.094, 0.339, 0.076, 0.191, 0.265, 0.134, 0.155, 0.1]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=127565)[0m rmse: 0.1408202350139618
[2m[36m(func pid=127565)[0m mae:  0.09283386915922165
[2m[36m(func pid=127565)[0m rmse_per_class: [0.085, 0.231, 0.033, 0.283, 0.055, 0.163, 0.205, 0.112, 0.145, 0.096]
[2m[36m(func pid=127565)[0m 
== Status ==
Current time: 2024-01-07 08:49:52 (running for 00:17:53.62)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.229 |  0.141 |                   94 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.233 |  0.143 |                   92 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.392 |  0.176 |                   37 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.4   |  0.174 |                   12 |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=128390)[0m rmse: 0.14331082999706268
[2m[36m(func pid=128390)[0m mae:  0.09006498008966446
[2m[36m(func pid=128390)[0m rmse_per_class: [0.079, 0.237, 0.031, 0.301, 0.062, 0.156, 0.19, 0.112, 0.18, 0.086]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.1753213107585907
[2m[36m(func pid=139738)[0m mae:  0.12628021836280823
[2m[36m(func pid=139738)[0m rmse_per_class: [0.11, 0.271, 0.095, 0.337, 0.084, 0.192, 0.272, 0.134, 0.152, 0.107]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 94] | Train loss: 0.2302 | Steps: 2 | Val loss: 0.2803 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.4115 | Steps: 2 | Val loss: 0.3548 | Batch size: 32 | lr: 0.001 | Duration: 3.03s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 92] | Train loss: 0.2320 | Steps: 2 | Val loss: 0.2696 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.3952 | Steps: 2 | Val loss: 0.3262 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=127565)[0m rmse: 0.14066655933856964
[2m[36m(func pid=127565)[0m mae:  0.09282691776752472
[2m[36m(func pid=127565)[0m rmse_per_class: [0.085, 0.23, 0.033, 0.282, 0.055, 0.163, 0.206, 0.112, 0.144, 0.097]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.1729045957326889
[2m[36m(func pid=145749)[0m mae:  0.1228424534201622
[2m[36m(func pid=145749)[0m rmse_per_class: [0.111, 0.271, 0.09, 0.342, 0.072, 0.191, 0.262, 0.135, 0.157, 0.098]
[2m[36m(func pid=145749)[0m 
== Status ==
Current time: 2024-01-07 08:49:58 (running for 00:17:58.90)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.23  |  0.141 |                   95 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.232 |  0.144 |                   93 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.39  |  0.175 |                   38 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.412 |  0.173 |                   13 |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=128390)[0m rmse: 0.14380158483982086
[2m[36m(func pid=128390)[0m mae:  0.09037956595420837
[2m[36m(func pid=128390)[0m rmse_per_class: [0.08, 0.236, 0.03, 0.299, 0.064, 0.155, 0.193, 0.114, 0.181, 0.086]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.1750396490097046
[2m[36m(func pid=139738)[0m mae:  0.12592127919197083
[2m[36m(func pid=139738)[0m rmse_per_class: [0.111, 0.271, 0.094, 0.337, 0.083, 0.192, 0.27, 0.134, 0.153, 0.106]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 95] | Train loss: 0.2423 | Steps: 2 | Val loss: 0.2803 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.4326 | Steps: 2 | Val loss: 0.3743 | Batch size: 32 | lr: 0.001 | Duration: 3.06s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 93] | Train loss: 0.2284 | Steps: 2 | Val loss: 0.2722 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.3981 | Steps: 2 | Val loss: 0.3285 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=127565)[0m rmse: 0.14030501246452332
[2m[36m(func pid=127565)[0m mae:  0.09251079708337784
[2m[36m(func pid=127565)[0m rmse_per_class: [0.084, 0.231, 0.033, 0.278, 0.055, 0.162, 0.206, 0.111, 0.146, 0.097]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.17265407741069794
[2m[36m(func pid=145749)[0m mae:  0.12165407091379166
[2m[36m(func pid=145749)[0m rmse_per_class: [0.11, 0.271, 0.087, 0.346, 0.068, 0.19, 0.263, 0.136, 0.159, 0.095]
[2m[36m(func pid=145749)[0m 
== Status ==
Current time: 2024-01-07 08:50:03 (running for 00:18:04.18)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.242 |  0.14  |                   96 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.145 |                   94 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.395 |  0.175 |                   39 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.433 |  0.173 |                   14 |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=128390)[0m rmse: 0.1449374407529831
[2m[36m(func pid=128390)[0m mae:  0.0914958119392395
[2m[36m(func pid=128390)[0m rmse_per_class: [0.08, 0.237, 0.03, 0.303, 0.063, 0.155, 0.197, 0.118, 0.18, 0.085]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.17501190304756165
[2m[36m(func pid=139738)[0m mae:  0.12580378353595734
[2m[36m(func pid=139738)[0m rmse_per_class: [0.111, 0.271, 0.095, 0.337, 0.082, 0.192, 0.268, 0.134, 0.154, 0.105]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 96] | Train loss: 0.2294 | Steps: 2 | Val loss: 0.2803 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.4555 | Steps: 2 | Val loss: 0.3952 | Batch size: 32 | lr: 0.001 | Duration: 3.11s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 94] | Train loss: 0.2314 | Steps: 2 | Val loss: 0.2737 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.3940 | Steps: 2 | Val loss: 0.3309 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=127565)[0m rmse: 0.14058497548103333
[2m[36m(func pid=127565)[0m mae:  0.09272356331348419
[2m[36m(func pid=127565)[0m rmse_per_class: [0.083, 0.23, 0.033, 0.281, 0.055, 0.162, 0.207, 0.113, 0.145, 0.098]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.17258310317993164
[2m[36m(func pid=145749)[0m mae:  0.12043161690235138
[2m[36m(func pid=145749)[0m rmse_per_class: [0.11, 0.271, 0.082, 0.348, 0.065, 0.19, 0.267, 0.138, 0.16, 0.094]
[2m[36m(func pid=145749)[0m 
== Status ==
Current time: 2024-01-07 08:50:08 (running for 00:18:09.33)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.229 |  0.141 |                   97 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.231 |  0.146 |                   95 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.398 |  0.175 |                   40 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.455 |  0.173 |                   15 |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=128390)[0m rmse: 0.14586946368217468
[2m[36m(func pid=128390)[0m mae:  0.09228860586881638
[2m[36m(func pid=128390)[0m rmse_per_class: [0.088, 0.238, 0.029, 0.304, 0.066, 0.156, 0.198, 0.113, 0.18, 0.086]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.174729585647583
[2m[36m(func pid=139738)[0m mae:  0.1254613995552063
[2m[36m(func pid=139738)[0m rmse_per_class: [0.111, 0.271, 0.094, 0.338, 0.081, 0.192, 0.267, 0.134, 0.155, 0.104]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 97] | Train loss: 0.2289 | Steps: 2 | Val loss: 0.2812 | Batch size: 32 | lr: 0.01 | Duration: 2.74s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.4706 | Steps: 2 | Val loss: 0.4157 | Batch size: 32 | lr: 0.001 | Duration: 3.23s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.3947 | Steps: 2 | Val loss: 0.3336 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 95] | Train loss: 0.2318 | Steps: 2 | Val loss: 0.2720 | Batch size: 32 | lr: 0.1 | Duration: 3.14s
[2m[36m(func pid=127565)[0m rmse: 0.1409434676170349
[2m[36m(func pid=127565)[0m mae:  0.09299404919147491
[2m[36m(func pid=127565)[0m rmse_per_class: [0.083, 0.231, 0.033, 0.282, 0.055, 0.163, 0.207, 0.113, 0.146, 0.097]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.17280074954032898
[2m[36m(func pid=145749)[0m mae:  0.11946006864309311
[2m[36m(func pid=145749)[0m rmse_per_class: [0.109, 0.271, 0.077, 0.351, 0.062, 0.189, 0.275, 0.141, 0.161, 0.093]
[2m[36m(func pid=145749)[0m 
== Status ==
Current time: 2024-01-07 08:50:14 (running for 00:18:14.90)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.229 |  0.141 |                   98 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.231 |  0.146 |                   95 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.395 |  0.175 |                   42 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.471 |  0.173 |                   16 |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=139738)[0m rmse: 0.1745300590991974
[2m[36m(func pid=139738)[0m mae:  0.1251789778470993
[2m[36m(func pid=139738)[0m rmse_per_class: [0.112, 0.271, 0.094, 0.338, 0.081, 0.192, 0.266, 0.134, 0.155, 0.104]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=128390)[0m rmse: 0.14464972913265228
[2m[36m(func pid=128390)[0m mae:  0.09133405983448029
[2m[36m(func pid=128390)[0m rmse_per_class: [0.082, 0.239, 0.029, 0.306, 0.065, 0.155, 0.192, 0.11, 0.181, 0.088]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 98] | Train loss: 0.2402 | Steps: 2 | Val loss: 0.2822 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.4916 | Steps: 2 | Val loss: 0.4343 | Batch size: 32 | lr: 0.001 | Duration: 3.09s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 96] | Train loss: 0.2332 | Steps: 2 | Val loss: 0.2733 | Batch size: 32 | lr: 0.1 | Duration: 2.99s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.4000 | Steps: 2 | Val loss: 0.3362 | Batch size: 32 | lr: 0.0001 | Duration: 3.07s
[2m[36m(func pid=127565)[0m rmse: 0.1411026418209076
[2m[36m(func pid=127565)[0m mae:  0.09307800978422165
[2m[36m(func pid=127565)[0m rmse_per_class: [0.082, 0.232, 0.033, 0.282, 0.055, 0.163, 0.206, 0.112, 0.148, 0.097]
[2m[36m(func pid=127565)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.1733936369419098
[2m[36m(func pid=145749)[0m mae:  0.11880644410848618
[2m[36m(func pid=145749)[0m rmse_per_class: [0.107, 0.27, 0.073, 0.354, 0.06, 0.189, 0.285, 0.142, 0.162, 0.092]
[2m[36m(func pid=145749)[0m 
== Status ==
Current time: 2024-01-07 08:50:19 (running for 00:18:20.30)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00006 | RUNNING    | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.24  |  0.141 |                   99 |
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.232 |  0.145 |                   96 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.4   |  0.174 |                   43 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.492 |  0.173 |                   17 |
| train_d77f6_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=139738)[0m rmse: 0.17431499063968658
[2m[36m(func pid=139738)[0m mae:  0.12489088624715805
[2m[36m(func pid=139738)[0m rmse_per_class: [0.112, 0.271, 0.093, 0.339, 0.079, 0.191, 0.265, 0.134, 0.156, 0.103]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=128390)[0m rmse: 0.14584313333034515
[2m[36m(func pid=128390)[0m mae:  0.09185115247964859
[2m[36m(func pid=128390)[0m rmse_per_class: [0.079, 0.241, 0.03, 0.306, 0.063, 0.157, 0.19, 0.111, 0.193, 0.09]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=127565)[0m [N0-GPU0] | [Epoch: 99] | Train loss: 0.2321 | Steps: 2 | Val loss: 0.2822 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.5115 | Steps: 2 | Val loss: 0.4535 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.3978 | Steps: 2 | Val loss: 0.3392 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=127565)[0m rmse: 0.1410493552684784
[2m[36m(func pid=127565)[0m mae:  0.09296891838312149
[2m[36m(func pid=127565)[0m rmse_per_class: [0.082, 0.232, 0.033, 0.283, 0.055, 0.163, 0.206, 0.112, 0.148, 0.098]
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 97] | Train loss: 0.2277 | Steps: 2 | Val loss: 0.2710 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=145749)[0m rmse: 0.17432987689971924
[2m[36m(func pid=145749)[0m mae:  0.1182546466588974
[2m[36m(func pid=145749)[0m rmse_per_class: [0.106, 0.271, 0.067, 0.356, 0.058, 0.188, 0.298, 0.144, 0.164, 0.091]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.17411254346370697
[2m[36m(func pid=139738)[0m mae:  0.12457875162363052
[2m[36m(func pid=139738)[0m rmse_per_class: [0.112, 0.271, 0.092, 0.34, 0.079, 0.191, 0.264, 0.134, 0.157, 0.102]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=128390)[0m rmse: 0.14510829746723175
[2m[36m(func pid=128390)[0m mae:  0.09125839173793793
[2m[36m(func pid=128390)[0m rmse_per_class: [0.075, 0.24, 0.03, 0.299, 0.06, 0.156, 0.192, 0.114, 0.195, 0.088]
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.5171 | Steps: 2 | Val loss: 0.4698 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.4070 | Steps: 2 | Val loss: 0.3417 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=145749)[0m rmse: 0.17531850934028625
[2m[36m(func pid=145749)[0m mae:  0.11795121431350708
[2m[36m(func pid=145749)[0m rmse_per_class: [0.104, 0.27, 0.063, 0.358, 0.057, 0.188, 0.311, 0.146, 0.165, 0.091]
[2m[36m(func pid=139738)[0m rmse: 0.17377693951129913
[2m[36m(func pid=139738)[0m mae:  0.12421784549951553
[2m[36m(func pid=139738)[0m rmse_per_class: [0.111, 0.271, 0.091, 0.34, 0.077, 0.191, 0.263, 0.134, 0.157, 0.101]
== Status ==
Current time: 2024-01-07 08:50:24 (running for 00:18:25.60)
Memory usage on this node: 22.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (13 PENDING, 4 RUNNING, 7 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.233 |  0.146 |                   97 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.398 |  0.174 |                   44 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.511 |  0.174 |                   18 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


== Status ==
Current time: 2024-01-07 08:50:30 (running for 00:18:31.85)
Memory usage on this node: 23.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (13 PENDING, 4 RUNNING, 7 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.233 |  0.146 |                   97 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.398 |  0.174 |                   44 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.517 |  0.175 |                   19 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=150254)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=150254)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=150254)[0m Configuration completed!
[2m[36m(func pid=150254)[0m New optimizer parameters:
[2m[36m(func pid=150254)[0m SGD (
[2m[36m(func pid=150254)[0m Parameter Group 0
[2m[36m(func pid=150254)[0m     dampening: 0
[2m[36m(func pid=150254)[0m     differentiable: False
[2m[36m(func pid=150254)[0m     foreach: None
[2m[36m(func pid=150254)[0m     lr: 0.01
[2m[36m(func pid=150254)[0m     maximize: False
[2m[36m(func pid=150254)[0m     momentum: 0.99
[2m[36m(func pid=150254)[0m     nesterov: False
[2m[36m(func pid=150254)[0m     weight_decay: 0.0001
[2m[36m(func pid=150254)[0m )
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.4067 | Steps: 2 | Val loss: 0.3444 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.5311 | Steps: 2 | Val loss: 0.4859 | Batch size: 32 | lr: 0.001 | Duration: 3.31s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 98] | Train loss: 0.2326 | Steps: 2 | Val loss: 0.2720 | Batch size: 32 | lr: 0.1 | Duration: 3.33s
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 1.0250 | Steps: 2 | Val loss: 0.6445 | Batch size: 32 | lr: 0.01 | Duration: 4.82s
== Status ==
Current time: 2024-01-07 08:50:35 (running for 00:18:36.87)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (13 PENDING, 4 RUNNING, 7 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.145 |                   98 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.407 |  0.174 |                   45 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.517 |  0.175 |                   19 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=139738)[0m rmse: 0.17356440424919128
[2m[36m(func pid=139738)[0m mae:  0.12390638887882233
[2m[36m(func pid=139738)[0m rmse_per_class: [0.111, 0.271, 0.091, 0.34, 0.076, 0.191, 0.262, 0.134, 0.158, 0.101]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.17656032741069794
[2m[36m(func pid=145749)[0m mae:  0.11773161590099335
[2m[36m(func pid=145749)[0m rmse_per_class: [0.103, 0.27, 0.059, 0.36, 0.056, 0.188, 0.327, 0.147, 0.165, 0.091]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=128390)[0m rmse: 0.14606693387031555
[2m[36m(func pid=128390)[0m mae:  0.09172157198190689
[2m[36m(func pid=128390)[0m rmse_per_class: [0.076, 0.241, 0.03, 0.298, 0.062, 0.155, 0.197, 0.119, 0.196, 0.087]
[2m[36m(func pid=128390)[0m 
[2m[36m(func pid=150254)[0m rmse: 0.17791661620140076
[2m[36m(func pid=150254)[0m mae:  0.1303977221250534
[2m[36m(func pid=150254)[0m rmse_per_class: [0.104, 0.267, 0.085, 0.325, 0.097, 0.192, 0.301, 0.155, 0.139, 0.114]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.4064 | Steps: 2 | Val loss: 0.3476 | Batch size: 32 | lr: 0.0001 | Duration: 3.05s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.5653 | Steps: 2 | Val loss: 0.5003 | Batch size: 32 | lr: 0.001 | Duration: 3.03s
[2m[36m(func pid=128390)[0m [N0-GPU0] | [Epoch: 99] | Train loss: 0.2278 | Steps: 2 | Val loss: 0.2736 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.6922 | Steps: 2 | Val loss: 0.4170 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=139738)[0m rmse: 0.17337898910045624
[2m[36m(func pid=139738)[0m mae:  0.12362686544656754
[2m[36m(func pid=139738)[0m rmse_per_class: [0.111, 0.271, 0.09, 0.341, 0.075, 0.191, 0.262, 0.134, 0.158, 0.101]
[2m[36m(func pid=139738)[0m 
== Status ==
Current time: 2024-01-07 08:50:41 (running for 00:18:42.79)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (13 PENDING, 4 RUNNING, 7 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00007 | RUNNING    | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.233 |  0.146 |                   99 |
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.406 |  0.173 |                   47 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.531 |  0.177 |                   20 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  1.025 |  0.178 |                    1 |
| train_d77f6_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=128390)[0m rmse: 0.14574365317821503
[2m[36m(func pid=128390)[0m mae:  0.09167035669088364
[2m[36m(func pid=128390)[0m rmse_per_class: [0.077, 0.24, 0.03, 0.303, 0.063, 0.155, 0.195, 0.115, 0.193, 0.087]
[2m[36m(func pid=145749)[0m rmse: 0.17792923748493195
[2m[36m(func pid=145749)[0m mae:  0.11775447428226471
[2m[36m(func pid=145749)[0m rmse_per_class: [0.101, 0.27, 0.055, 0.362, 0.056, 0.187, 0.343, 0.149, 0.166, 0.091]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=150254)[0m rmse: 0.17623934149742126
[2m[36m(func pid=150254)[0m mae:  0.1286574751138687
[2m[36m(func pid=150254)[0m rmse_per_class: [0.104, 0.269, 0.087, 0.326, 0.091, 0.192, 0.292, 0.153, 0.141, 0.108]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.4136 | Steps: 2 | Val loss: 0.3512 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.5601 | Steps: 2 | Val loss: 0.5118 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.4349 | Steps: 2 | Val loss: 0.3200 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=139738)[0m rmse: 0.17317228019237518
[2m[36m(func pid=139738)[0m mae:  0.12331652641296387
[2m[36m(func pid=139738)[0m rmse_per_class: [0.111, 0.271, 0.089, 0.341, 0.074, 0.191, 0.26, 0.134, 0.159, 0.1]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.1792396605014801
[2m[36m(func pid=145749)[0m mae:  0.11782206594944
[2m[36m(func pid=145749)[0m rmse_per_class: [0.1, 0.269, 0.052, 0.363, 0.055, 0.187, 0.359, 0.15, 0.165, 0.091]
[2m[36m(func pid=150254)[0m rmse: 0.17316317558288574
[2m[36m(func pid=150254)[0m mae:  0.12553101778030396
[2m[36m(func pid=150254)[0m rmse_per_class: [0.105, 0.27, 0.091, 0.332, 0.082, 0.19, 0.275, 0.138, 0.146, 0.101]
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.4107 | Steps: 2 | Val loss: 0.3536 | Batch size: 32 | lr: 0.0001 | Duration: 2.78s
== Status ==
Current time: 2024-01-07 08:50:47 (running for 00:18:47.93)
Memory usage on this node: 22.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.414 |  0.173 |                   48 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.565 |  0.178 |                   21 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.692 |  0.176 |                    2 |
| train_d77f6_00011 | RUNNING    | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=151230)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=151230)[0m 
[2m[36m(func pid=151230)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=151230)[0m Configuration completed!
[2m[36m(func pid=151230)[0m New optimizer parameters:
[2m[36m(func pid=151230)[0m SGD (
[2m[36m(func pid=151230)[0m Parameter Group 0
[2m[36m(func pid=151230)[0m     dampening: 0
[2m[36m(func pid=151230)[0m     differentiable: False
[2m[36m(func pid=151230)[0m     foreach: None
[2m[36m(func pid=151230)[0m     lr: 0.1
[2m[36m(func pid=151230)[0m     maximize: False
[2m[36m(func pid=151230)[0m     momentum: 0.99
[2m[36m(func pid=151230)[0m     nesterov: False
[2m[36m(func pid=151230)[0m     weight_decay: 0.0001
[2m[36m(func pid=151230)[0m )
[2m[36m(func pid=151230)[0m 
== Status ==
Current time: 2024-01-07 08:50:52 (running for 00:18:53.48)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.411 |  0.173 |                   49 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.56  |  0.179 |                   22 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.435 |  0.173 |                    3 |
| train_d77f6_00011 | RUNNING    | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=139738)[0m rmse: 0.17290061712265015
[2m[36m(func pid=139738)[0m mae:  0.12298603355884552
[2m[36m(func pid=139738)[0m rmse_per_class: [0.111, 0.271, 0.088, 0.341, 0.073, 0.191, 0.26, 0.135, 0.16, 0.1]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.4027 | Steps: 2 | Val loss: 0.3424 | Batch size: 32 | lr: 0.01 | Duration: 3.13s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.5754 | Steps: 2 | Val loss: 0.5201 | Batch size: 32 | lr: 0.001 | Duration: 3.15s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.4206 | Steps: 2 | Val loss: 0.3570 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
[2m[36m(func pid=151230)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 0.7711 | Steps: 2 | Val loss: 0.3235 | Batch size: 32 | lr: 0.1 | Duration: 4.84s
[2m[36m(func pid=150254)[0m rmse: 0.1715216040611267
[2m[36m(func pid=150254)[0m mae:  0.12204995006322861
[2m[36m(func pid=150254)[0m rmse_per_class: [0.106, 0.272, 0.089, 0.343, 0.071, 0.189, 0.264, 0.134, 0.154, 0.095]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.18062981963157654
[2m[36m(func pid=145749)[0m mae:  0.11805373430252075
[2m[36m(func pid=145749)[0m rmse_per_class: [0.098, 0.269, 0.05, 0.365, 0.055, 0.187, 0.375, 0.151, 0.166, 0.092]
[2m[36m(func pid=145749)[0m 
== Status ==
Current time: 2024-01-07 08:50:57 (running for 00:18:58.62)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.421 |  0.173 |                   50 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.575 |  0.181 |                   23 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.403 |  0.172 |                    4 |
| train_d77f6_00011 | RUNNING    | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=139738)[0m rmse: 0.17271938920021057
[2m[36m(func pid=139738)[0m mae:  0.12270376831293106
[2m[36m(func pid=139738)[0m rmse_per_class: [0.111, 0.271, 0.087, 0.342, 0.072, 0.191, 0.259, 0.135, 0.161, 0.099]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=151230)[0m rmse: 0.17111049592494965
[2m[36m(func pid=151230)[0m mae:  0.123257115483284
[2m[36m(func pid=151230)[0m rmse_per_class: [0.106, 0.272, 0.085, 0.336, 0.071, 0.189, 0.269, 0.132, 0.153, 0.098]
[2m[36m(func pid=151230)[0m 
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.4627 | Steps: 2 | Val loss: 0.4115 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.5709 | Steps: 2 | Val loss: 0.5255 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.4210 | Steps: 2 | Val loss: 0.3595 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=151230)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.5384 | Steps: 2 | Val loss: 0.5024 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
[2m[36m(func pid=150254)[0m rmse: 0.17334921658039093
[2m[36m(func pid=150254)[0m mae:  0.11945146322250366
[2m[36m(func pid=150254)[0m rmse_per_class: [0.105, 0.272, 0.075, 0.355, 0.061, 0.187, 0.284, 0.141, 0.162, 0.092]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.18204551935195923
[2m[36m(func pid=145749)[0m mae:  0.11841341108083725
[2m[36m(func pid=145749)[0m rmse_per_class: [0.097, 0.27, 0.048, 0.366, 0.055, 0.186, 0.389, 0.151, 0.166, 0.092]
[2m[36m(func pid=145749)[0m 
== Status ==
Current time: 2024-01-07 08:51:03 (running for 00:19:03.97)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.421 |  0.173 |                   50 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.571 |  0.182 |                   24 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.463 |  0.173 |                    5 |
| train_d77f6_00011 | RUNNING    | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.538 |  0.182 |                    2 |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=139738)[0m rmse: 0.17257460951805115
[2m[36m(func pid=139738)[0m mae:  0.12247087806463242
[2m[36m(func pid=139738)[0m rmse_per_class: [0.111, 0.271, 0.086, 0.342, 0.072, 0.191, 0.259, 0.135, 0.162, 0.098]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=151230)[0m rmse: 0.1821099817752838
[2m[36m(func pid=151230)[0m mae:  0.1212182492017746
[2m[36m(func pid=151230)[0m rmse_per_class: [0.096, 0.275, 0.05, 0.363, 0.055, 0.189, 0.347, 0.149, 0.204, 0.093]
[2m[36m(func pid=151230)[0m 
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.5568 | Steps: 2 | Val loss: 0.4879 | Batch size: 32 | lr: 0.01 | Duration: 3.09s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.5679 | Steps: 2 | Val loss: 0.5311 | Batch size: 32 | lr: 0.001 | Duration: 3.07s
[2m[36m(func pid=151230)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.7595 | Steps: 2 | Val loss: 0.6471 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.4205 | Steps: 2 | Val loss: 0.3615 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=150254)[0m rmse: 0.17877569794654846
[2m[36m(func pid=150254)[0m mae:  0.11924202740192413
[2m[36m(func pid=150254)[0m rmse_per_class: [0.101, 0.273, 0.059, 0.365, 0.056, 0.187, 0.34, 0.148, 0.166, 0.092]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.18339775502681732
[2m[36m(func pid=145749)[0m mae:  0.11884918063879013
[2m[36m(func pid=145749)[0m rmse_per_class: [0.096, 0.269, 0.047, 0.368, 0.055, 0.186, 0.401, 0.152, 0.167, 0.092]
[2m[36m(func pid=145749)[0m 
== Status ==
Current time: 2024-01-07 08:51:08 (running for 00:19:09.28)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.421 |  0.173 |                   51 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.568 |  0.183 |                   25 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.557 |  0.179 |                    6 |
| train_d77f6_00011 | RUNNING    | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.76  |  0.208 |                    3 |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=151230)[0m rmse: 0.20783455669879913
[2m[36m(func pid=151230)[0m mae:  0.13260740041732788
[2m[36m(func pid=151230)[0m rmse_per_class: [0.091, 0.289, 0.047, 0.383, 0.056, 0.209, 0.499, 0.155, 0.253, 0.097]
[2m[36m(func pid=151230)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.17223592102527618
[2m[36m(func pid=139738)[0m mae:  0.12204758822917938
[2m[36m(func pid=139738)[0m rmse_per_class: [0.111, 0.27, 0.085, 0.342, 0.071, 0.19, 0.258, 0.135, 0.161, 0.098]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.6098 | Steps: 2 | Val loss: 0.5536 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.5734 | Steps: 2 | Val loss: 0.5335 | Batch size: 32 | lr: 0.001 | Duration: 3.07s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.4202 | Steps: 2 | Val loss: 0.3640 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=151230)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.7297 | Steps: 2 | Val loss: 0.6864 | Batch size: 32 | lr: 0.1 | Duration: 2.98s
[2m[36m(func pid=150254)[0m rmse: 0.18689389526844025
[2m[36m(func pid=150254)[0m mae:  0.12166349589824677
[2m[36m(func pid=150254)[0m rmse_per_class: [0.096, 0.275, 0.048, 0.373, 0.055, 0.189, 0.421, 0.152, 0.166, 0.094]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.18498241901397705
[2m[36m(func pid=145749)[0m mae:  0.11931473016738892
[2m[36m(func pid=145749)[0m rmse_per_class: [0.094, 0.27, 0.046, 0.369, 0.055, 0.186, 0.418, 0.152, 0.167, 0.093]
[2m[36m(func pid=145749)[0m 
== Status ==
Current time: 2024-01-07 08:51:13 (running for 00:19:14.66)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.42  |  0.172 |                   52 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.573 |  0.185 |                   26 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.61  |  0.187 |                    7 |
| train_d77f6_00011 | RUNNING    | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.73  |  0.225 |                    4 |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=151230)[0m rmse: 0.22471503913402557
[2m[36m(func pid=151230)[0m mae:  0.14033770561218262
[2m[36m(func pid=151230)[0m rmse_per_class: [0.097, 0.298, 0.049, 0.388, 0.056, 0.221, 0.538, 0.156, 0.347, 0.097]
[2m[36m(func pid=151230)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.17192170023918152
[2m[36m(func pid=139738)[0m mae:  0.12163574993610382
[2m[36m(func pid=139738)[0m rmse_per_class: [0.111, 0.27, 0.084, 0.342, 0.07, 0.19, 0.259, 0.135, 0.16, 0.097]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.6351 | Steps: 2 | Val loss: 0.5987 | Batch size: 32 | lr: 0.01 | Duration: 3.34s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.5728 | Steps: 2 | Val loss: 0.5338 | Batch size: 32 | lr: 0.001 | Duration: 3.35s
[2m[36m(func pid=151230)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.5509 | Steps: 2 | Val loss: 0.6641 | Batch size: 32 | lr: 0.1 | Duration: 3.05s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.4293 | Steps: 2 | Val loss: 0.3670 | Batch size: 32 | lr: 0.0001 | Duration: 3.33s
[2m[36m(func pid=150254)[0m rmse: 0.19511911273002625
[2m[36m(func pid=150254)[0m mae:  0.1254274547100067
[2m[36m(func pid=150254)[0m rmse_per_class: [0.092, 0.278, 0.044, 0.378, 0.056, 0.193, 0.498, 0.154, 0.162, 0.095]
[2m[36m(func pid=150254)[0m 
== Status ==
Current time: 2024-01-07 08:51:19 (running for 00:19:19.89)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.42  |  0.172 |                   53 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.573 |  0.186 |                   27 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.635 |  0.195 |                    8 |
| train_d77f6_00011 | RUNNING    | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.73  |  0.225 |                    4 |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=145749)[0m rmse: 0.18622514605522156
[2m[36m(func pid=145749)[0m mae:  0.11966145038604736
[2m[36m(func pid=145749)[0m rmse_per_class: [0.093, 0.27, 0.045, 0.37, 0.055, 0.186, 0.431, 0.153, 0.167, 0.093]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=151230)[0m rmse: 0.2144525796175003
[2m[36m(func pid=151230)[0m mae:  0.13198210299015045
[2m[36m(func pid=151230)[0m rmse_per_class: [0.096, 0.281, 0.048, 0.382, 0.056, 0.199, 0.346, 0.156, 0.482, 0.097]
[2m[36m(func pid=151230)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.17167364060878754
[2m[36m(func pid=139738)[0m mae:  0.12121742963790894
[2m[36m(func pid=139738)[0m rmse_per_class: [0.11, 0.27, 0.083, 0.343, 0.069, 0.19, 0.258, 0.136, 0.161, 0.097]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.6703 | Steps: 2 | Val loss: 0.6244 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.5654 | Steps: 2 | Val loss: 0.5325 | Batch size: 32 | lr: 0.001 | Duration: 3.08s
[2m[36m(func pid=151230)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.3932 | Steps: 2 | Val loss: 0.7801 | Batch size: 32 | lr: 0.1 | Duration: 3.02s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.4219 | Steps: 2 | Val loss: 0.3691 | Batch size: 32 | lr: 0.0001 | Duration: 2.79s
[2m[36m(func pid=150254)[0m rmse: 0.20210933685302734
[2m[36m(func pid=150254)[0m mae:  0.1292869746685028
[2m[36m(func pid=150254)[0m rmse_per_class: [0.09, 0.281, 0.045, 0.382, 0.056, 0.197, 0.559, 0.155, 0.16, 0.096]
== Status ==
Current time: 2024-01-07 08:51:24 (running for 00:19:25.09)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.429 |  0.172 |                   54 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.573 |  0.186 |                   27 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.67  |  0.202 |                    9 |
| train_d77f6_00011 | RUNNING    | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.551 |  0.214 |                    5 |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.1873505562543869
[2m[36m(func pid=145749)[0m mae:  0.120073102414608
[2m[36m(func pid=145749)[0m rmse_per_class: [0.092, 0.27, 0.045, 0.37, 0.055, 0.185, 0.441, 0.153, 0.169, 0.093]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=151230)[0m rmse: 0.2085570991039276
[2m[36m(func pid=151230)[0m mae:  0.13136352598667145
[2m[36m(func pid=151230)[0m rmse_per_class: [0.138, 0.258, 0.034, 0.359, 0.056, 0.232, 0.242, 0.155, 0.515, 0.096]
[2m[36m(func pid=151230)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.17136718332767487
[2m[36m(func pid=139738)[0m mae:  0.12084084749221802
[2m[36m(func pid=139738)[0m rmse_per_class: [0.11, 0.27, 0.081, 0.343, 0.069, 0.19, 0.258, 0.136, 0.161, 0.096]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.6648 | Steps: 2 | Val loss: 0.6325 | Batch size: 32 | lr: 0.01 | Duration: 3.16s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.4270 | Steps: 2 | Val loss: 0.3717 | Batch size: 32 | lr: 0.0001 | Duration: 2.75s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.5762 | Steps: 2 | Val loss: 0.5329 | Batch size: 32 | lr: 0.001 | Duration: 3.04s
[2m[36m(func pid=151230)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.3949 | Steps: 2 | Val loss: 0.8160 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 08:51:29 (running for 00:19:30.72)
Memory usage on this node: 25.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.422 |  0.171 |                   55 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.565 |  0.187 |                   28 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.67  |  0.202 |                    9 |
| train_d77f6_00011 | RUNNING    | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.393 |  0.209 |                    6 |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=150254)[0m rmse: 0.20771491527557373
[2m[36m(func pid=150254)[0m mae:  0.132786363363266
[2m[36m(func pid=150254)[0m rmse_per_class: [0.09, 0.284, 0.047, 0.384, 0.056, 0.201, 0.603, 0.156, 0.16, 0.096]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=151230)[0m rmse: 0.2082333117723465
[2m[36m(func pid=151230)[0m mae:  0.12926316261291504
[2m[36m(func pid=151230)[0m rmse_per_class: [0.09, 0.262, 0.035, 0.343, 0.056, 0.339, 0.308, 0.147, 0.411, 0.09]
[2m[36m(func pid=139738)[0m rmse: 0.17124579846858978
[2m[36m(func pid=139738)[0m mae:  0.12060555070638657
[2m[36m(func pid=139738)[0m rmse_per_class: [0.11, 0.27, 0.081, 0.343, 0.068, 0.19, 0.258, 0.136, 0.162, 0.096]
[2m[36m(func pid=151230)[0m 
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.18818964064121246
[2m[36m(func pid=145749)[0m mae:  0.12031836807727814
[2m[36m(func pid=145749)[0m rmse_per_class: [0.091, 0.269, 0.045, 0.371, 0.056, 0.185, 0.445, 0.154, 0.173, 0.093]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.6223 | Steps: 2 | Val loss: 0.6208 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.4274 | Steps: 2 | Val loss: 0.3747 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=151230)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.3883 | Steps: 2 | Val loss: 0.9156 | Batch size: 32 | lr: 0.1 | Duration: 3.01s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.5473 | Steps: 2 | Val loss: 0.5280 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
== Status ==
Current time: 2024-01-07 08:51:35 (running for 00:19:35.99)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.427 |  0.171 |                   56 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.576 |  0.188 |                   29 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.665 |  0.208 |                   10 |
| train_d77f6_00011 | RUNNING    | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.395 |  0.208 |                    7 |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=150254)[0m rmse: 0.21071434020996094
[2m[36m(func pid=150254)[0m mae:  0.1345570683479309
[2m[36m(func pid=150254)[0m rmse_per_class: [0.09, 0.284, 0.048, 0.386, 0.056, 0.201, 0.626, 0.156, 0.163, 0.097]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=151230)[0m rmse: 0.22117368876934052
[2m[36m(func pid=151230)[0m mae:  0.13941992819309235
[2m[36m(func pid=151230)[0m rmse_per_class: [0.08, 0.263, 0.044, 0.358, 0.056, 0.428, 0.326, 0.155, 0.391, 0.11]
[2m[36m(func pid=151230)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.1710444837808609
[2m[36m(func pid=139738)[0m mae:  0.12028072774410248
[2m[36m(func pid=139738)[0m rmse_per_class: [0.11, 0.269, 0.08, 0.343, 0.067, 0.19, 0.258, 0.136, 0.162, 0.096]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.18865399062633514
[2m[36m(func pid=145749)[0m mae:  0.1203668937087059
[2m[36m(func pid=145749)[0m rmse_per_class: [0.09, 0.268, 0.045, 0.372, 0.056, 0.185, 0.451, 0.154, 0.173, 0.094]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.5792 | Steps: 2 | Val loss: 0.5922 | Batch size: 32 | lr: 0.01 | Duration: 3.07s
[2m[36m(func pid=151230)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.3483 | Steps: 2 | Val loss: 0.9112 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.4297 | Steps: 2 | Val loss: 0.3768 | Batch size: 32 | lr: 0.0001 | Duration: 3.11s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.5452 | Steps: 2 | Val loss: 0.5229 | Batch size: 32 | lr: 0.001 | Duration: 3.10s
== Status ==
Current time: 2024-01-07 08:51:40 (running for 00:19:41.38)
Memory usage on this node: 25.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.427 |  0.171 |                   57 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.547 |  0.189 |                   30 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.622 |  0.211 |                   11 |
| train_d77f6_00011 | RUNNING    | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.388 |  0.221 |                    8 |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=150254)[0m rmse: 0.21057745814323425
[2m[36m(func pid=150254)[0m mae:  0.13386043906211853
[2m[36m(func pid=150254)[0m rmse_per_class: [0.087, 0.281, 0.048, 0.386, 0.056, 0.198, 0.622, 0.156, 0.175, 0.097]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=151230)[0m rmse: 0.23261268436908722
[2m[36m(func pid=151230)[0m mae:  0.14226259291172028
[2m[36m(func pid=151230)[0m rmse_per_class: [0.099, 0.278, 0.046, 0.364, 0.056, 0.386, 0.329, 0.167, 0.395, 0.207]
[2m[36m(func pid=151230)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.1706487238407135
[2m[36m(func pid=139738)[0m mae:  0.11973843723535538
[2m[36m(func pid=139738)[0m rmse_per_class: [0.109, 0.269, 0.078, 0.343, 0.066, 0.19, 0.259, 0.137, 0.161, 0.095]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.18922631442546844
[2m[36m(func pid=145749)[0m mae:  0.12049095332622528
[2m[36m(func pid=145749)[0m rmse_per_class: [0.09, 0.268, 0.045, 0.372, 0.056, 0.184, 0.454, 0.154, 0.176, 0.094]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.5296 | Steps: 2 | Val loss: 0.5502 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=151230)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.3753 | Steps: 2 | Val loss: 1.2429 | Batch size: 32 | lr: 0.1 | Duration: 3.10s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.4299 | Steps: 2 | Val loss: 0.3783 | Batch size: 32 | lr: 0.0001 | Duration: 3.09s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.5193 | Steps: 2 | Val loss: 0.5135 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
== Status ==
Current time: 2024-01-07 08:51:46 (running for 00:19:47.01)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.43  |  0.171 |                   58 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.545 |  0.189 |                   31 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.579 |  0.211 |                   12 |
| train_d77f6_00011 | RUNNING    | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.375 |  0.242 |                   10 |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=151230)[0m rmse: 0.24183163046836853
[2m[36m(func pid=151230)[0m mae:  0.14803257584571838
[2m[36m(func pid=151230)[0m rmse_per_class: [0.109, 0.289, 0.049, 0.432, 0.055, 0.229, 0.33, 0.182, 0.268, 0.475]
[2m[36m(func pid=151230)[0m 
[2m[36m(func pid=150254)[0m rmse: 0.20590023696422577
[2m[36m(func pid=150254)[0m mae:  0.12955746054649353
[2m[36m(func pid=150254)[0m rmse_per_class: [0.081, 0.272, 0.048, 0.385, 0.056, 0.187, 0.58, 0.156, 0.196, 0.097]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.17046737670898438
[2m[36m(func pid=139738)[0m mae:  0.11947516351938248
[2m[36m(func pid=139738)[0m rmse_per_class: [0.109, 0.269, 0.077, 0.343, 0.065, 0.189, 0.259, 0.137, 0.161, 0.095]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.18970349431037903
[2m[36m(func pid=145749)[0m mae:  0.12053593248128891
[2m[36m(func pid=145749)[0m rmse_per_class: [0.088, 0.267, 0.045, 0.372, 0.056, 0.184, 0.46, 0.154, 0.176, 0.094]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=151230)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.3236 | Steps: 2 | Val loss: 2.1088 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.4689 | Steps: 2 | Val loss: 0.5002 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.4376 | Steps: 2 | Val loss: 0.3798 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.5085 | Steps: 2 | Val loss: 0.5011 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
== Status ==
Current time: 2024-01-07 08:51:51 (running for 00:19:52.40)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.43  |  0.17  |                   59 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.519 |  0.19  |                   32 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.53  |  0.206 |                   13 |
| train_d77f6_00011 | RUNNING    | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.324 |  0.252 |                   11 |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=151230)[0m rmse: 0.25237351655960083
[2m[36m(func pid=151230)[0m mae:  0.16381888091564178
[2m[36m(func pid=151230)[0m rmse_per_class: [0.111, 0.295, 0.049, 0.395, 0.054, 0.214, 0.332, 0.195, 0.154, 0.725]
[2m[36m(func pid=151230)[0m 
[2m[36m(func pid=150254)[0m rmse: 0.19597287476062775
[2m[36m(func pid=150254)[0m mae:  0.12123726308345795
[2m[36m(func pid=150254)[0m rmse_per_class: [0.075, 0.256, 0.047, 0.381, 0.056, 0.171, 0.495, 0.156, 0.226, 0.097]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.17043815553188324
[2m[36m(func pid=139738)[0m mae:  0.11928755044937134
[2m[36m(func pid=139738)[0m rmse_per_class: [0.109, 0.269, 0.076, 0.343, 0.065, 0.189, 0.259, 0.137, 0.162, 0.094]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.18939463794231415
[2m[36m(func pid=145749)[0m mae:  0.12012557685375214
[2m[36m(func pid=145749)[0m rmse_per_class: [0.088, 0.265, 0.046, 0.372, 0.056, 0.183, 0.46, 0.154, 0.177, 0.094]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=151230)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.3501 | Steps: 2 | Val loss: 1.9616 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.4146 | Steps: 2 | Val loss: 0.4514 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.4340 | Steps: 2 | Val loss: 0.3815 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.4996 | Steps: 2 | Val loss: 0.4893 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=151230)[0m rmse: 0.248320072889328
[2m[36m(func pid=151230)[0m mae:  0.15945279598236084
[2m[36m(func pid=151230)[0m rmse_per_class: [0.101, 0.291, 0.049, 0.358, 0.053, 0.22, 0.319, 0.212, 0.237, 0.644]
[2m[36m(func pid=151230)[0m 
== Status ==
Current time: 2024-01-07 08:51:56 (running for 00:19:57.66)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.438 |  0.17  |                   60 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.509 |  0.189 |                   33 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.469 |  0.196 |                   14 |
| train_d77f6_00011 | RUNNING    | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.35  |  0.248 |                   12 |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=150254)[0m rmse: 0.18432599306106567
[2m[36m(func pid=150254)[0m mae:  0.11183537542819977
[2m[36m(func pid=150254)[0m rmse_per_class: [0.078, 0.244, 0.046, 0.373, 0.056, 0.163, 0.374, 0.156, 0.257, 0.096]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.17013712227344513
[2m[36m(func pid=139738)[0m mae:  0.11888419091701508
[2m[36m(func pid=139738)[0m rmse_per_class: [0.108, 0.269, 0.075, 0.343, 0.064, 0.189, 0.26, 0.137, 0.162, 0.094]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.1888696700334549
[2m[36m(func pid=145749)[0m mae:  0.11964087188243866
[2m[36m(func pid=145749)[0m rmse_per_class: [0.086, 0.263, 0.046, 0.371, 0.056, 0.182, 0.457, 0.154, 0.18, 0.094]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=151230)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.3138 | Steps: 2 | Val loss: 1.7220 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.3745 | Steps: 2 | Val loss: 0.4091 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.4345 | Steps: 2 | Val loss: 0.3835 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.4838 | Steps: 2 | Val loss: 0.4762 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
== Status ==
Current time: 2024-01-07 08:52:02 (running for 00:20:02.92)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.434 |  0.17  |                   61 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.5   |  0.189 |                   34 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.415 |  0.184 |                   15 |
| train_d77f6_00011 | RUNNING    | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.314 |  0.23  |                   13 |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=151230)[0m rmse: 0.23025640845298767
[2m[36m(func pid=151230)[0m mae:  0.14700469374656677
[2m[36m(func pid=151230)[0m rmse_per_class: [0.095, 0.281, 0.049, 0.332, 0.051, 0.223, 0.306, 0.228, 0.412, 0.326]
[2m[36m(func pid=151230)[0m 
[2m[36m(func pid=150254)[0m rmse: 0.17508670687675476
[2m[36m(func pid=150254)[0m mae:  0.10536762326955795
[2m[36m(func pid=150254)[0m rmse_per_class: [0.086, 0.24, 0.042, 0.358, 0.056, 0.192, 0.255, 0.155, 0.27, 0.096]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.1699749082326889
[2m[36m(func pid=139738)[0m mae:  0.11862455308437347
[2m[36m(func pid=139738)[0m rmse_per_class: [0.108, 0.268, 0.074, 0.343, 0.063, 0.189, 0.26, 0.137, 0.162, 0.094]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.18806904554367065
[2m[36m(func pid=145749)[0m mae:  0.11891307681798935
[2m[36m(func pid=145749)[0m rmse_per_class: [0.085, 0.26, 0.046, 0.37, 0.056, 0.18, 0.452, 0.154, 0.182, 0.094]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=151230)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.3195 | Steps: 2 | Val loss: 1.6567 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.3503 | Steps: 2 | Val loss: 0.3838 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.4351 | Steps: 2 | Val loss: 0.3849 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.4625 | Steps: 2 | Val loss: 0.4637 | Batch size: 32 | lr: 0.001 | Duration: 3.13s
== Status ==
Current time: 2024-01-07 08:52:07 (running for 00:20:08.26)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.435 |  0.17  |                   62 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.484 |  0.188 |                   35 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.374 |  0.175 |                   16 |
| train_d77f6_00011 | RUNNING    | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.32  |  0.219 |                   14 |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=151230)[0m rmse: 0.21875932812690735
[2m[36m(func pid=151230)[0m mae:  0.13987961411476135
[2m[36m(func pid=151230)[0m rmse_per_class: [0.094, 0.258, 0.049, 0.316, 0.053, 0.223, 0.311, 0.212, 0.581, 0.09]
[2m[36m(func pid=151230)[0m 
[2m[36m(func pid=150254)[0m rmse: 0.17190979421138763
[2m[36m(func pid=150254)[0m mae:  0.10412198305130005
[2m[36m(func pid=150254)[0m rmse_per_class: [0.089, 0.238, 0.035, 0.339, 0.056, 0.241, 0.198, 0.154, 0.274, 0.094]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.16972610354423523
[2m[36m(func pid=139738)[0m mae:  0.11830560863018036
[2m[36m(func pid=139738)[0m rmse_per_class: [0.108, 0.268, 0.073, 0.343, 0.063, 0.189, 0.26, 0.138, 0.162, 0.094]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.18701620399951935
[2m[36m(func pid=145749)[0m mae:  0.11800309270620346
[2m[36m(func pid=145749)[0m rmse_per_class: [0.085, 0.258, 0.046, 0.37, 0.056, 0.178, 0.441, 0.154, 0.188, 0.094]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=151230)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.3913 | Steps: 2 | Val loss: 2.9946 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.3538 | Steps: 2 | Val loss: 0.3702 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.4392 | Steps: 2 | Val loss: 0.3859 | Batch size: 32 | lr: 0.0001 | Duration: 3.01s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.4505 | Steps: 2 | Val loss: 0.4503 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
== Status ==
Current time: 2024-01-07 08:52:12 (running for 00:20:13.52)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.435 |  0.17  |                   63 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.462 |  0.187 |                   36 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.35  |  0.172 |                   17 |
| train_d77f6_00011 | RUNNING    | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.391 |  0.215 |                   15 |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=151230)[0m rmse: 0.21492543816566467
[2m[36m(func pid=151230)[0m mae:  0.14051292836666107
[2m[36m(func pid=151230)[0m rmse_per_class: [0.093, 0.251, 0.049, 0.415, 0.055, 0.226, 0.332, 0.179, 0.456, 0.093]
[2m[36m(func pid=151230)[0m 
[2m[36m(func pid=150254)[0m rmse: 0.1716843843460083
[2m[36m(func pid=150254)[0m mae:  0.1048554927110672
[2m[36m(func pid=150254)[0m rmse_per_class: [0.087, 0.234, 0.029, 0.317, 0.056, 0.274, 0.205, 0.151, 0.271, 0.093]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.16962455213069916
[2m[36m(func pid=139738)[0m mae:  0.11807988584041595
[2m[36m(func pid=139738)[0m rmse_per_class: [0.108, 0.268, 0.072, 0.343, 0.062, 0.189, 0.261, 0.138, 0.162, 0.093]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.1858253926038742
[2m[36m(func pid=145749)[0m mae:  0.11701591312885284
[2m[36m(func pid=145749)[0m rmse_per_class: [0.083, 0.256, 0.047, 0.368, 0.056, 0.176, 0.432, 0.154, 0.192, 0.094]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=151230)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.3488 | Steps: 2 | Val loss: 0.8141 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.3649 | Steps: 2 | Val loss: 0.3598 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.4403 | Steps: 2 | Val loss: 0.3867 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.4460 | Steps: 2 | Val loss: 0.4377 | Batch size: 32 | lr: 0.001 | Duration: 3.06s
[2m[36m(func pid=151230)[0m rmse: 0.19783328473567963
[2m[36m(func pid=151230)[0m mae:  0.11874936521053314
[2m[36m(func pid=151230)[0m rmse_per_class: [0.14, 0.244, 0.088, 0.405, 0.048, 0.224, 0.257, 0.327, 0.146, 0.1]
[2m[36m(func pid=151230)[0m 
== Status ==
Current time: 2024-01-07 08:52:18 (running for 00:20:18.92)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.439 |  0.17  |                   64 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.451 |  0.186 |                   37 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.354 |  0.172 |                   18 |
| train_d77f6_00011 | RUNNING    | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.349 |  0.198 |                   16 |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=150254)[0m rmse: 0.16972431540489197
[2m[36m(func pid=150254)[0m mae:  0.10451678186655045
[2m[36m(func pid=150254)[0m rmse_per_class: [0.079, 0.226, 0.027, 0.296, 0.056, 0.281, 0.231, 0.142, 0.267, 0.091]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.1693158745765686
[2m[36m(func pid=139738)[0m mae:  0.11763308942317963
[2m[36m(func pid=139738)[0m rmse_per_class: [0.107, 0.268, 0.07, 0.343, 0.062, 0.189, 0.262, 0.138, 0.162, 0.093]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.18501731753349304
[2m[36m(func pid=145749)[0m mae:  0.11629146337509155
[2m[36m(func pid=145749)[0m rmse_per_class: [0.082, 0.255, 0.047, 0.367, 0.056, 0.175, 0.424, 0.154, 0.196, 0.094]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=151230)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.3822 | Steps: 2 | Val loss: 0.9188 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.3650 | Steps: 2 | Val loss: 0.3485 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.4432 | Steps: 2 | Val loss: 0.3884 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.4199 | Steps: 2 | Val loss: 0.4242 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
== Status ==
Current time: 2024-01-07 08:52:23 (running for 00:20:24.26)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.44  |  0.169 |                   65 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.446 |  0.185 |                   38 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.365 |  0.17  |                   19 |
| train_d77f6_00011 | RUNNING    | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.382 |  0.226 |                   17 |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=151230)[0m rmse: 0.2259361296892166
[2m[36m(func pid=151230)[0m mae:  0.12663055956363678
[2m[36m(func pid=151230)[0m rmse_per_class: [0.24, 0.251, 0.186, 0.402, 0.054, 0.218, 0.225, 0.346, 0.141, 0.197]
[2m[36m(func pid=151230)[0m 
[2m[36m(func pid=150254)[0m rmse: 0.16528882086277008
[2m[36m(func pid=150254)[0m mae:  0.10277199745178223
[2m[36m(func pid=150254)[0m rmse_per_class: [0.071, 0.219, 0.025, 0.287, 0.056, 0.265, 0.253, 0.124, 0.263, 0.089]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.16923458874225616
[2m[36m(func pid=139738)[0m mae:  0.11739823967218399
[2m[36m(func pid=139738)[0m rmse_per_class: [0.107, 0.268, 0.069, 0.343, 0.061, 0.189, 0.262, 0.138, 0.162, 0.093]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.18308721482753754
[2m[36m(func pid=145749)[0m mae:  0.1148282140493393
[2m[36m(func pid=145749)[0m rmse_per_class: [0.081, 0.251, 0.047, 0.365, 0.056, 0.173, 0.409, 0.154, 0.201, 0.094]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=151230)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.3713 | Steps: 2 | Val loss: 0.7780 | Batch size: 32 | lr: 0.1 | Duration: 2.98s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.4357 | Steps: 2 | Val loss: 0.3879 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.3637 | Steps: 2 | Val loss: 0.3456 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.3971 | Steps: 2 | Val loss: 0.4093 | Batch size: 32 | lr: 0.001 | Duration: 3.04s
== Status ==
Current time: 2024-01-07 08:52:28 (running for 00:20:29.55)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.443 |  0.169 |                   66 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.42  |  0.183 |                   39 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.365 |  0.165 |                   20 |
| train_d77f6_00011 | RUNNING    | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.371 |  0.222 |                   18 |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=151230)[0m rmse: 0.22235484421253204
[2m[36m(func pid=151230)[0m mae:  0.13297756016254425
[2m[36m(func pid=151230)[0m rmse_per_class: [0.141, 0.255, 0.084, 0.385, 0.055, 0.208, 0.263, 0.415, 0.146, 0.271]
[2m[36m(func pid=151230)[0m 
[2m[36m(func pid=150254)[0m rmse: 0.1625557243824005
[2m[36m(func pid=150254)[0m mae:  0.10196256637573242
[2m[36m(func pid=150254)[0m rmse_per_class: [0.064, 0.214, 0.026, 0.289, 0.056, 0.233, 0.271, 0.112, 0.273, 0.088]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.1690451055765152
[2m[36m(func pid=139738)[0m mae:  0.1171141043305397
[2m[36m(func pid=139738)[0m rmse_per_class: [0.107, 0.267, 0.068, 0.343, 0.061, 0.189, 0.262, 0.138, 0.162, 0.093]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.18100762367248535
[2m[36m(func pid=145749)[0m mae:  0.11331798881292343
[2m[36m(func pid=145749)[0m rmse_per_class: [0.081, 0.248, 0.047, 0.363, 0.056, 0.171, 0.391, 0.154, 0.206, 0.094]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=151230)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.3080 | Steps: 2 | Val loss: 1.5930 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.4359 | Steps: 2 | Val loss: 0.3882 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.3565 | Steps: 2 | Val loss: 0.3447 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.3871 | Steps: 2 | Val loss: 0.3947 | Batch size: 32 | lr: 0.001 | Duration: 3.05s
== Status ==
Current time: 2024-01-07 08:52:34 (running for 00:20:34.98)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.436 |  0.169 |                   67 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.397 |  0.181 |                   40 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.364 |  0.163 |                   21 |
| train_d77f6_00011 | RUNNING    | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.308 |  0.228 |                   19 |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=151230)[0m rmse: 0.22758162021636963
[2m[36m(func pid=151230)[0m mae:  0.13679200410842896
[2m[36m(func pid=151230)[0m rmse_per_class: [0.111, 0.235, 0.051, 0.388, 0.056, 0.217, 0.223, 0.306, 0.414, 0.274]
[2m[36m(func pid=151230)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.1689639836549759
[2m[36m(func pid=139738)[0m mae:  0.1168958991765976
[2m[36m(func pid=139738)[0m rmse_per_class: [0.107, 0.267, 0.067, 0.343, 0.061, 0.188, 0.264, 0.138, 0.162, 0.092]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=150254)[0m rmse: 0.16234901547431946
[2m[36m(func pid=150254)[0m mae:  0.10178734362125397
[2m[36m(func pid=150254)[0m rmse_per_class: [0.061, 0.215, 0.029, 0.301, 0.056, 0.202, 0.282, 0.113, 0.276, 0.088]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.17819854617118835
[2m[36m(func pid=145749)[0m mae:  0.11137226969003677
[2m[36m(func pid=145749)[0m rmse_per_class: [0.08, 0.244, 0.047, 0.359, 0.056, 0.169, 0.373, 0.154, 0.207, 0.094]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=151230)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.3103 | Steps: 2 | Val loss: 2.9963 | Batch size: 32 | lr: 0.1 | Duration: 3.04s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.4362 | Steps: 2 | Val loss: 0.3887 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.3591 | Steps: 2 | Val loss: 0.3495 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.3799 | Steps: 2 | Val loss: 0.3801 | Batch size: 32 | lr: 0.001 | Duration: 3.06s
== Status ==
Current time: 2024-01-07 08:52:39 (running for 00:20:40.55)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.436 |  0.169 |                   68 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.387 |  0.178 |                   41 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.356 |  0.162 |                   22 |
| train_d77f6_00011 | RUNNING    | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.31  |  0.221 |                   20 |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=151230)[0m rmse: 0.22117920219898224
[2m[36m(func pid=151230)[0m mae:  0.14109490811824799
[2m[36m(func pid=151230)[0m rmse_per_class: [0.113, 0.249, 0.049, 0.388, 0.056, 0.223, 0.273, 0.212, 0.384, 0.264]
[2m[36m(func pid=151230)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.16879531741142273
[2m[36m(func pid=139738)[0m mae:  0.11665469408035278
[2m[36m(func pid=139738)[0m rmse_per_class: [0.106, 0.267, 0.066, 0.343, 0.06, 0.188, 0.264, 0.138, 0.163, 0.092]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=150254)[0m rmse: 0.1665484756231308
[2m[36m(func pid=150254)[0m mae:  0.10357923805713654
[2m[36m(func pid=150254)[0m rmse_per_class: [0.064, 0.219, 0.03, 0.314, 0.056, 0.19, 0.289, 0.124, 0.285, 0.096]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.1751774251461029
[2m[36m(func pid=145749)[0m mae:  0.10929366201162338
[2m[36m(func pid=145749)[0m rmse_per_class: [0.079, 0.24, 0.047, 0.355, 0.056, 0.167, 0.35, 0.153, 0.211, 0.094]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=151230)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.4411 | Steps: 2 | Val loss: 14.4839 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.4395 | Steps: 2 | Val loss: 0.3904 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.3401 | Steps: 2 | Val loss: 0.3532 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.3700 | Steps: 2 | Val loss: 0.3681 | Batch size: 32 | lr: 0.001 | Duration: 3.07s
== Status ==
Current time: 2024-01-07 08:52:45 (running for 00:20:45.98)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.436 |  0.169 |                   69 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.38  |  0.175 |                   42 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.359 |  0.167 |                   23 |
| train_d77f6_00011 | RUNNING    | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.441 |  0.242 |                   21 |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=151230)[0m rmse: 0.2416723221540451
[2m[36m(func pid=151230)[0m mae:  0.16232815384864807
[2m[36m(func pid=151230)[0m rmse_per_class: [0.112, 0.286, 0.049, 0.389, 0.054, 0.227, 0.306, 0.374, 0.401, 0.218]
[2m[36m(func pid=151230)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.16868971288204193
[2m[36m(func pid=139738)[0m mae:  0.11636219173669815
[2m[36m(func pid=139738)[0m rmse_per_class: [0.106, 0.267, 0.065, 0.343, 0.06, 0.188, 0.265, 0.139, 0.162, 0.092]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=150254)[0m rmse: 0.17105522751808167
[2m[36m(func pid=150254)[0m mae:  0.10571350902318954
[2m[36m(func pid=150254)[0m rmse_per_class: [0.069, 0.224, 0.029, 0.32, 0.055, 0.189, 0.293, 0.139, 0.285, 0.105]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.1720774918794632
[2m[36m(func pid=145749)[0m mae:  0.10731247812509537
[2m[36m(func pid=145749)[0m rmse_per_class: [0.08, 0.236, 0.046, 0.352, 0.056, 0.166, 0.323, 0.153, 0.215, 0.093]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=151230)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.5482 | Steps: 2 | Val loss: 0.7043 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.4379 | Steps: 2 | Val loss: 0.3912 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.3662 | Steps: 2 | Val loss: 0.3613 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.3580 | Steps: 2 | Val loss: 0.3582 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 08:52:50 (running for 00:20:51.30)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.439 |  0.169 |                   70 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.37  |  0.172 |                   43 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.34  |  0.171 |                   24 |
| train_d77f6_00011 | RUNNING    | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.548 |  0.251 |                   22 |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=151230)[0m rmse: 0.25097981095314026
[2m[36m(func pid=151230)[0m mae:  0.15883110463619232
[2m[36m(func pid=151230)[0m rmse_per_class: [0.21, 0.298, 0.436, 0.373, 0.055, 0.22, 0.301, 0.149, 0.146, 0.321]
[2m[36m(func pid=151230)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.1685599386692047
[2m[36m(func pid=139738)[0m mae:  0.11611592769622803
[2m[36m(func pid=139738)[0m rmse_per_class: [0.106, 0.266, 0.065, 0.343, 0.06, 0.188, 0.265, 0.139, 0.162, 0.092]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=150254)[0m rmse: 0.17742183804512024
[2m[36m(func pid=150254)[0m mae:  0.10853562504053116
[2m[36m(func pid=150254)[0m rmse_per_class: [0.075, 0.235, 0.036, 0.326, 0.055, 0.189, 0.299, 0.155, 0.282, 0.121]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.1698935478925705
[2m[36m(func pid=145749)[0m mae:  0.10592423379421234
[2m[36m(func pid=145749)[0m rmse_per_class: [0.079, 0.235, 0.046, 0.35, 0.056, 0.165, 0.304, 0.153, 0.217, 0.093]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=151230)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.9015 | Steps: 2 | Val loss: 1.3058 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.4424 | Steps: 2 | Val loss: 0.3919 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.3473 | Steps: 2 | Val loss: 0.3706 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.3582 | Steps: 2 | Val loss: 0.3473 | Batch size: 32 | lr: 0.001 | Duration: 3.13s
== Status ==
Current time: 2024-01-07 08:52:55 (running for 00:20:56.59)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.438 |  0.169 |                   71 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.358 |  0.17  |                   44 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.366 |  0.177 |                   25 |
| train_d77f6_00011 | RUNNING    | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.901 |  0.264 |                   23 |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=151230)[0m rmse: 0.26370394229888916
[2m[36m(func pid=151230)[0m mae:  0.1690351814031601
[2m[36m(func pid=151230)[0m rmse_per_class: [0.344, 0.284, 0.552, 0.393, 0.056, 0.23, 0.309, 0.171, 0.14, 0.158]
[2m[36m(func pid=151230)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.16853246092796326
[2m[36m(func pid=139738)[0m mae:  0.11591725051403046
[2m[36m(func pid=139738)[0m rmse_per_class: [0.106, 0.266, 0.064, 0.343, 0.059, 0.188, 0.265, 0.139, 0.162, 0.092]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=150254)[0m rmse: 0.18438687920570374
[2m[36m(func pid=150254)[0m mae:  0.11210355907678604
[2m[36m(func pid=150254)[0m rmse_per_class: [0.079, 0.248, 0.041, 0.325, 0.055, 0.19, 0.305, 0.175, 0.284, 0.141]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.16732892394065857
[2m[36m(func pid=145749)[0m mae:  0.10438303649425507
[2m[36m(func pid=145749)[0m rmse_per_class: [0.08, 0.233, 0.046, 0.345, 0.056, 0.165, 0.281, 0.153, 0.222, 0.093]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=151230)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.5301 | Steps: 2 | Val loss: 5.2756 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.4350 | Steps: 2 | Val loss: 0.3914 | Batch size: 32 | lr: 0.0001 | Duration: 3.05s
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.3656 | Steps: 2 | Val loss: 0.3818 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.3342 | Steps: 2 | Val loss: 0.3350 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
== Status ==
Current time: 2024-01-07 08:53:01 (running for 00:21:01.97)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.442 |  0.169 |                   72 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.358 |  0.167 |                   45 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.347 |  0.184 |                   26 |
| train_d77f6_00011 | RUNNING    | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.53  |  0.278 |                   24 |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=151230)[0m rmse: 0.2780497670173645
[2m[36m(func pid=151230)[0m mae:  0.17228148877620697
[2m[36m(func pid=151230)[0m rmse_per_class: [0.217, 0.617, 0.514, 0.389, 0.056, 0.232, 0.352, 0.164, 0.14, 0.098]
[2m[36m(func pid=151230)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.16842812299728394
[2m[36m(func pid=139738)[0m mae:  0.11568806320428848
[2m[36m(func pid=139738)[0m rmse_per_class: [0.106, 0.266, 0.063, 0.343, 0.059, 0.188, 0.267, 0.139, 0.162, 0.092]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=150254)[0m rmse: 0.18988199532032013
[2m[36m(func pid=150254)[0m mae:  0.11577467620372772
[2m[36m(func pid=150254)[0m rmse_per_class: [0.083, 0.261, 0.039, 0.325, 0.054, 0.191, 0.314, 0.191, 0.29, 0.15]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.16412809491157532
[2m[36m(func pid=145749)[0m mae:  0.10239418596029282
[2m[36m(func pid=145749)[0m rmse_per_class: [0.08, 0.231, 0.046, 0.337, 0.056, 0.167, 0.259, 0.152, 0.22, 0.093]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=151230)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.4749 | Steps: 2 | Val loss: 8.2920 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.4364 | Steps: 2 | Val loss: 0.3919 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.3323 | Steps: 2 | Val loss: 0.3770 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.3182 | Steps: 2 | Val loss: 0.3240 | Batch size: 32 | lr: 0.001 | Duration: 3.03s
== Status ==
Current time: 2024-01-07 08:53:06 (running for 00:21:07.36)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.435 |  0.168 |                   73 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.334 |  0.164 |                   46 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.366 |  0.19  |                   27 |
| train_d77f6_00011 | RUNNING    | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.475 |  0.289 |                   25 |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=151230)[0m rmse: 0.2893124222755432
[2m[36m(func pid=151230)[0m mae:  0.1753385066986084
[2m[36m(func pid=151230)[0m rmse_per_class: [0.123, 0.492, 0.627, 0.389, 0.056, 0.434, 0.352, 0.175, 0.14, 0.105]
[2m[36m(func pid=151230)[0m 
[2m[36m(func pid=139738)[0m rmse: 0.16825827956199646
[2m[36m(func pid=139738)[0m mae:  0.11545532941818237
[2m[36m(func pid=139738)[0m rmse_per_class: [0.105, 0.266, 0.062, 0.343, 0.059, 0.188, 0.266, 0.14, 0.163, 0.091]
[2m[36m(func pid=139738)[0m 
[2m[36m(func pid=150254)[0m rmse: 0.19047647714614868
[2m[36m(func pid=150254)[0m mae:  0.11682063341140747
[2m[36m(func pid=150254)[0m rmse_per_class: [0.085, 0.267, 0.036, 0.322, 0.054, 0.193, 0.314, 0.211, 0.274, 0.149]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.16119185090065002
[2m[36m(func pid=145749)[0m mae:  0.10064293444156647
[2m[36m(func pid=145749)[0m rmse_per_class: [0.081, 0.228, 0.045, 0.331, 0.056, 0.17, 0.242, 0.151, 0.213, 0.092]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=151230)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.4538 | Steps: 2 | Val loss: 8.4020 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=139738)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.4307 | Steps: 2 | Val loss: 0.3922 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.3269 | Steps: 2 | Val loss: 0.3717 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.3069 | Steps: 2 | Val loss: 0.3156 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=151230)[0m rmse: 0.2833946645259857
[2m[36m(func pid=151230)[0m mae:  0.18361341953277588
[2m[36m(func pid=151230)[0m rmse_per_class: [0.115, 0.309, 0.291, 0.389, 0.056, 0.229, 0.336, 0.83, 0.14, 0.139]
[2m[36m(func pid=151230)[0m 
== Status ==
Current time: 2024-01-07 08:53:11 (running for 00:21:12.73)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1537500023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00008 | RUNNING    | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.436 |  0.168 |                   74 |
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.318 |  0.161 |                   47 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.332 |  0.19  |                   28 |
| train_d77f6_00011 | RUNNING    | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.454 |  0.283 |                   26 |
| train_d77f6_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=150254)[0m rmse: 0.18987157940864563
[2m[36m(func pid=150254)[0m mae:  0.11725465953350067
[2m[36m(func pid=150254)[0m rmse_per_class: [0.085, 0.27, 0.033, 0.321, 0.053, 0.194, 0.311, 0.226, 0.262, 0.144]
[2m[36m(func pid=139738)[0m rmse: 0.16807399690151215
[2m[36m(func pid=139738)[0m mae:  0.11520353704690933
[2m[36m(func pid=139738)[0m rmse_per_class: [0.105, 0.265, 0.061, 0.342, 0.058, 0.188, 0.265, 0.14, 0.164, 0.091]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.1590384989976883
[2m[36m(func pid=145749)[0m mae:  0.0994267612695694
[2m[36m(func pid=145749)[0m rmse_per_class: [0.081, 0.227, 0.045, 0.326, 0.056, 0.175, 0.226, 0.15, 0.212, 0.092]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=151230)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.4669 | Steps: 2 | Val loss: 8.8561 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.3325 | Steps: 2 | Val loss: 0.3701 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.3117 | Steps: 2 | Val loss: 0.3071 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=151230)[0m rmse: 0.2655952572822571
[2m[36m(func pid=151230)[0m mae:  0.18057781457901
[2m[36m(func pid=151230)[0m rmse_per_class: [0.113, 0.32, 0.086, 0.389, 0.056, 0.232, 0.338, 0.87, 0.14, 0.113]
[2m[36m(func pid=151230)[0m 
[2m[36m(func pid=150254)[0m rmse: 0.18966348469257355
[2m[36m(func pid=150254)[0m mae:  0.11759962141513824
[2m[36m(func pid=150254)[0m rmse_per_class: [0.083, 0.273, 0.033, 0.321, 0.053, 0.196, 0.305, 0.236, 0.257, 0.139]
[2m[36m(func pid=145749)[0m rmse: 0.15650255978107452
[2m[36m(func pid=145749)[0m mae:  0.09799467027187347
[2m[36m(func pid=145749)[0m rmse_per_class: [0.083, 0.225, 0.044, 0.319, 0.056, 0.178, 0.212, 0.149, 0.207, 0.092]
[2m[36m(func pid=151230)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.4033 | Steps: 2 | Val loss: 12.2755 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 08:53:17 (running for 00:21:17.91)
Memory usage on this node: 22.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.307 |  0.159 |                   48 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.327 |  0.19  |                   29 |
| train_d77f6_00011 | RUNNING    | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.467 |  0.266 |                   27 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=157328)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=157328)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=157328)[0m Configuration completed!
[2m[36m(func pid=157328)[0m New optimizer parameters:
[2m[36m(func pid=157328)[0m SGD (
[2m[36m(func pid=157328)[0m Parameter Group 0
[2m[36m(func pid=157328)[0m     dampening: 0
[2m[36m(func pid=157328)[0m     differentiable: False
[2m[36m(func pid=157328)[0m     foreach: None
[2m[36m(func pid=157328)[0m     lr: 0.0001
[2m[36m(func pid=157328)[0m     maximize: False
[2m[36m(func pid=157328)[0m     momentum: 0.9
[2m[36m(func pid=157328)[0m     nesterov: False
[2m[36m(func pid=157328)[0m     weight_decay: 0.0001
[2m[36m(func pid=157328)[0m )
[2m[36m(func pid=157328)[0m 
== Status ==
Current time: 2024-01-07 08:53:22 (running for 00:21:23.22)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.312 |  0.157 |                   49 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.332 |  0.19  |                   30 |
| train_d77f6_00011 | RUNNING    | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.403 |  0.254 |                   28 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=151230)[0m rmse: 0.253621906042099
[2m[36m(func pid=151230)[0m mae:  0.15155871212482452
[2m[36m(func pid=151230)[0m rmse_per_class: [0.336, 0.372, 0.256, 0.389, 0.057, 0.232, 0.486, 0.17, 0.14, 0.099]
[2m[36m(func pid=151230)[0m 
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.3176 | Steps: 2 | Val loss: 0.3618 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.3094 | Steps: 2 | Val loss: 0.3002 | Batch size: 32 | lr: 0.001 | Duration: 3.12s
[2m[36m(func pid=151230)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.4916 | Steps: 2 | Val loss: 33.7383 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 1.0859 | Steps: 2 | Val loss: 0.8088 | Batch size: 32 | lr: 0.0001 | Duration: 4.76s
[2m[36m(func pid=150254)[0m rmse: 0.18708990514278412
[2m[36m(func pid=150254)[0m mae:  0.11682788282632828
[2m[36m(func pid=150254)[0m rmse_per_class: [0.082, 0.273, 0.036, 0.321, 0.052, 0.196, 0.302, 0.243, 0.241, 0.126]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.15459798276424408
[2m[36m(func pid=145749)[0m mae:  0.09716351330280304
[2m[36m(func pid=145749)[0m rmse_per_class: [0.083, 0.224, 0.044, 0.313, 0.056, 0.183, 0.199, 0.147, 0.206, 0.091]
[2m[36m(func pid=145749)[0m 
== Status ==
Current time: 2024-01-07 08:53:27 (running for 00:21:28.47)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.309 |  0.155 |                   50 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.318 |  0.187 |                   31 |
| train_d77f6_00011 | RUNNING    | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.492 |  0.254 |                   29 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=151230)[0m rmse: 0.2539699673652649
[2m[36m(func pid=151230)[0m mae:  0.15363247692584991
[2m[36m(func pid=151230)[0m rmse_per_class: [0.196, 0.342, 0.299, 0.389, 0.06, 0.231, 0.618, 0.161, 0.14, 0.105]
[2m[36m(func pid=151230)[0m 
[2m[36m(func pid=157328)[0m rmse: 0.178719162940979
[2m[36m(func pid=157328)[0m mae:  0.13121409714221954
[2m[36m(func pid=157328)[0m rmse_per_class: [0.105, 0.266, 0.087, 0.325, 0.101, 0.192, 0.304, 0.153, 0.139, 0.116]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.3103 | Steps: 2 | Val loss: 0.3545 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.3131 | Steps: 2 | Val loss: 0.2948 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=151230)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.4018 | Steps: 2 | Val loss: 129.3999 | Batch size: 32 | lr: 0.1 | Duration: 2.71s
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 1.0769 | Steps: 2 | Val loss: 0.8109 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
[2m[36m(func pid=150254)[0m rmse: 0.18465039134025574
[2m[36m(func pid=150254)[0m mae:  0.116061270236969
[2m[36m(func pid=150254)[0m rmse_per_class: [0.082, 0.271, 0.038, 0.323, 0.052, 0.196, 0.296, 0.246, 0.223, 0.118]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.15331417322158813
[2m[36m(func pid=145749)[0m mae:  0.09664259105920792
[2m[36m(func pid=145749)[0m rmse_per_class: [0.084, 0.223, 0.043, 0.306, 0.056, 0.187, 0.194, 0.145, 0.205, 0.091]
[2m[36m(func pid=145749)[0m 
== Status ==
Current time: 2024-01-07 08:53:32 (running for 00:21:33.47)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.313 |  0.153 |                   51 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.31  |  0.185 |                   32 |
| train_d77f6_00011 | RUNNING    | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.402 |  0.277 |                   30 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  1.086 |  0.179 |                    1 |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=151230)[0m rmse: 0.27685245871543884
[2m[36m(func pid=151230)[0m mae:  0.17983856797218323
[2m[36m(func pid=151230)[0m rmse_per_class: [0.126, 0.291, 0.207, 0.389, 0.056, 0.233, 0.353, 0.875, 0.14, 0.097]
[2m[36m(func pid=151230)[0m 
[2m[36m(func pid=157328)[0m rmse: 0.1791744828224182
[2m[36m(func pid=157328)[0m mae:  0.131583109498024
[2m[36m(func pid=157328)[0m rmse_per_class: [0.104, 0.266, 0.088, 0.325, 0.102, 0.193, 0.305, 0.154, 0.139, 0.116]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.2977 | Steps: 2 | Val loss: 0.3480 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.3133 | Steps: 2 | Val loss: 0.2901 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
[2m[36m(func pid=151230)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.3891 | Steps: 2 | Val loss: 204.7197 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 1.0682 | Steps: 2 | Val loss: 0.8131 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=150254)[0m rmse: 0.18258115649223328
[2m[36m(func pid=150254)[0m mae:  0.11489470303058624
[2m[36m(func pid=150254)[0m rmse_per_class: [0.086, 0.269, 0.04, 0.328, 0.053, 0.194, 0.293, 0.24, 0.208, 0.116]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.15207703411579132
[2m[36m(func pid=145749)[0m mae:  0.09611956030130386
[2m[36m(func pid=145749)[0m rmse_per_class: [0.083, 0.222, 0.043, 0.298, 0.056, 0.191, 0.193, 0.143, 0.201, 0.09]
[2m[36m(func pid=145749)[0m 
== Status ==
Current time: 2024-01-07 08:53:37 (running for 00:21:38.57)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.313 |  0.152 |                   52 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.298 |  0.183 |                   33 |
| train_d77f6_00011 | RUNNING    | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.389 |  0.197 |                   31 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  1.077 |  0.179 |                    2 |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=151230)[0m rmse: 0.1968517005443573
[2m[36m(func pid=151230)[0m mae:  0.13144321739673615
[2m[36m(func pid=151230)[0m rmse_per_class: [0.113, 0.339, 0.049, 0.389, 0.056, 0.233, 0.259, 0.293, 0.14, 0.097]
[2m[36m(func pid=151230)[0m 
[2m[36m(func pid=157328)[0m rmse: 0.17960020899772644
[2m[36m(func pid=157328)[0m mae:  0.13190630078315735
[2m[36m(func pid=157328)[0m rmse_per_class: [0.105, 0.266, 0.089, 0.325, 0.103, 0.193, 0.307, 0.154, 0.139, 0.116]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.2924 | Steps: 2 | Val loss: 0.3431 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.3012 | Steps: 2 | Val loss: 0.2867 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=151230)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.5083 | Steps: 2 | Val loss: 200.5965 | Batch size: 32 | lr: 0.1 | Duration: 2.76s
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 1.0600 | Steps: 2 | Val loss: 0.8136 | Batch size: 32 | lr: 0.0001 | Duration: 2.81s
[2m[36m(func pid=150254)[0m rmse: 0.18061189353466034
[2m[36m(func pid=150254)[0m mae:  0.11373132467269897
[2m[36m(func pid=150254)[0m rmse_per_class: [0.088, 0.264, 0.043, 0.334, 0.054, 0.192, 0.29, 0.235, 0.199, 0.107]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=151230)[0m rmse: 0.19954541325569153
[2m[36m(func pid=151230)[0m mae:  0.12918545305728912
[2m[36m(func pid=151230)[0m rmse_per_class: [0.164, 0.363, 0.049, 0.389, 0.056, 0.233, 0.255, 0.249, 0.14, 0.097]
[2m[36m(func pid=151230)[0m 
== Status ==
Current time: 2024-01-07 08:53:42 (running for 00:21:43.71)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.313 |  0.152 |                   52 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.292 |  0.181 |                   34 |
| train_d77f6_00011 | RUNNING    | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  1.068 |  0.18  |                    3 |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=145749)[0m rmse: 0.1511843353509903
[2m[36m(func pid=145749)[0m mae:  0.09591801464557648
[2m[36m(func pid=145749)[0m rmse_per_class: [0.083, 0.222, 0.042, 0.294, 0.056, 0.195, 0.195, 0.14, 0.196, 0.089]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=157328)[0m rmse: 0.1799512356519699
[2m[36m(func pid=157328)[0m mae:  0.13217110931873322
[2m[36m(func pid=157328)[0m rmse_per_class: [0.105, 0.266, 0.09, 0.325, 0.104, 0.193, 0.307, 0.154, 0.138, 0.117]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.2901 | Steps: 2 | Val loss: 0.3355 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=151230)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.3859 | Steps: 2 | Val loss: 145.1450 | Batch size: 32 | lr: 0.1 | Duration: 2.76s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.3089 | Steps: 2 | Val loss: 0.2826 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 1.0494 | Steps: 2 | Val loss: 0.8102 | Batch size: 32 | lr: 0.0001 | Duration: 2.81s
[2m[36m(func pid=150254)[0m rmse: 0.1771748811006546
[2m[36m(func pid=150254)[0m mae:  0.11171485483646393
[2m[36m(func pid=150254)[0m rmse_per_class: [0.091, 0.258, 0.045, 0.34, 0.058, 0.187, 0.286, 0.217, 0.187, 0.103]
[2m[36m(func pid=150254)[0m 
2024-01-07 08:53:48,107	ERROR trial_runner.py:1062 -- Trial train_d77f6_00011: Error processing event.
ray.exceptions.RayTaskError(ValueError): [36mray::ImplicitFunc.train()[39m (pid=151230, ip=192.168.7.53, repr=func)
  File "/home/ajsanchez/anaconda3/envs/ssl-bsu-conda/lib/python3.10/site-packages/ray/tune/trainable/trainable.py", line 368, in train
    raise skipped from exception_cause(skipped)
  File "/home/ajsanchez/anaconda3/envs/ssl-bsu-conda/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py", line 337, in entrypoint
    return self._trainable_func(
  File "/home/ajsanchez/anaconda3/envs/ssl-bsu-conda/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py", line 654, in _trainable_func
    output = fn()
  File "/home/ajsanchez/GitHub/ssl-bsu/trainer.py", line 447, in train
    acc_results = accuracy(self.model,
  File "/home/ajsanchez/GitHub/ssl-bsu/trainer.py", line 104, in accuracy
    rmse = mean_squared_error(y_true_cpu, y_pred_cpu, squared=False)
  File "/home/ajsanchez/anaconda3/envs/ssl-bsu-conda/lib/python3.10/site-packages/sklearn/metrics/_regression.py", line 442, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/ajsanchez/anaconda3/envs/ssl-bsu-conda/lib/python3.10/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/ajsanchez/anaconda3/envs/ssl-bsu-conda/lib/python3.10/site-packages/sklearn/utils/validation.py", line 919, in check_array
    _assert_all_finite(
  File "/home/ajsanchez/anaconda3/envs/ssl-bsu-conda/lib/python3.10/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.
== Status ==
Current time: 2024-01-07 08:53:48 (running for 00:21:49.00)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 11 PENDING, 3 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.301 |  0.151 |                   53 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.29  |  0.177 |                   35 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  1.06  |  0.18  |                    4 |
| train_d77f6_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=145749)[0m rmse: 0.14963476359844208
[2m[36m(func pid=145749)[0m mae:  0.09501950442790985
[2m[36m(func pid=145749)[0m rmse_per_class: [0.082, 0.22, 0.041, 0.285, 0.056, 0.199, 0.199, 0.136, 0.189, 0.088]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=157328)[0m rmse: 0.18019556999206543
[2m[36m(func pid=157328)[0m mae:  0.13234910368919373
[2m[36m(func pid=157328)[0m rmse_per_class: [0.105, 0.266, 0.09, 0.325, 0.104, 0.194, 0.308, 0.154, 0.138, 0.118]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.2947 | Steps: 2 | Val loss: 0.3292 | Batch size: 32 | lr: 0.01 | Duration: 3.09s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.3083 | Steps: 2 | Val loss: 0.2807 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 1.0373 | Steps: 2 | Val loss: 0.8045 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=150254)[0m rmse: 0.17313596606254578
[2m[36m(func pid=150254)[0m mae:  0.10888395458459854
[2m[36m(func pid=150254)[0m rmse_per_class: [0.091, 0.25, 0.046, 0.343, 0.062, 0.18, 0.281, 0.198, 0.182, 0.098]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.1490151435136795
[2m[36m(func pid=145749)[0m mae:  0.09483249485492706
[2m[36m(func pid=145749)[0m rmse_per_class: [0.082, 0.219, 0.041, 0.281, 0.056, 0.199, 0.204, 0.131, 0.189, 0.088]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=157328)[0m rmse: 0.18046019971370697
[2m[36m(func pid=157328)[0m mae:  0.13251057267189026
[2m[36m(func pid=157328)[0m rmse_per_class: [0.105, 0.266, 0.091, 0.325, 0.105, 0.194, 0.309, 0.154, 0.138, 0.119]
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.2775 | Steps: 2 | Val loss: 0.3197 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
== Status ==
Current time: 2024-01-07 08:53:53 (running for 00:21:54.68)
Memory usage on this node: 22.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 10 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.308 |  0.149 |                   55 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.295 |  0.173 |                   36 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  1.049 |  0.18  |                    5 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 1 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=158989)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=158989)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=158989)[0m Configuration completed!
[2m[36m(func pid=158989)[0m New optimizer parameters:
[2m[36m(func pid=158989)[0m SGD (
[2m[36m(func pid=158989)[0m Parameter Group 0
[2m[36m(func pid=158989)[0m     dampening: 0
[2m[36m(func pid=158989)[0m     differentiable: False
[2m[36m(func pid=158989)[0m     foreach: None
[2m[36m(func pid=158989)[0m     lr: 0.001
[2m[36m(func pid=158989)[0m     maximize: False
[2m[36m(func pid=158989)[0m     momentum: 0.9
[2m[36m(func pid=158989)[0m     nesterov: False
[2m[36m(func pid=158989)[0m     weight_decay: 0.0001
[2m[36m(func pid=158989)[0m )
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.3245 | Steps: 2 | Val loss: 0.2788 | Batch size: 32 | lr: 0.001 | Duration: 3.08s
[2m[36m(func pid=150254)[0m rmse: 0.16807284951210022
[2m[36m(func pid=150254)[0m mae:  0.10566586256027222
[2m[36m(func pid=150254)[0m rmse_per_class: [0.091, 0.241, 0.047, 0.344, 0.066, 0.174, 0.268, 0.182, 0.174, 0.095]
[2m[36m(func pid=150254)[0m 
== Status ==
Current time: 2024-01-07 08:53:59 (running for 00:22:00.37)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 10 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.324 |  0.148 |                   56 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.277 |  0.168 |                   37 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  1.037 |  0.18  |                    6 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 1 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=145749)[0m rmse: 0.14796943962574005
[2m[36m(func pid=145749)[0m mae:  0.09414240717887878
[2m[36m(func pid=145749)[0m rmse_per_class: [0.081, 0.218, 0.04, 0.276, 0.056, 0.2, 0.21, 0.125, 0.187, 0.087]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 1.0159 | Steps: 2 | Val loss: 0.7955 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 1.0775 | Steps: 2 | Val loss: 0.7940 | Batch size: 32 | lr: 0.001 | Duration: 4.37s
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.2779 | Steps: 2 | Val loss: 0.3120 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=157328)[0m rmse: 0.18064790964126587
[2m[36m(func pid=157328)[0m mae:  0.13267387449741364
[2m[36m(func pid=157328)[0m rmse_per_class: [0.105, 0.266, 0.091, 0.325, 0.105, 0.194, 0.309, 0.154, 0.138, 0.119]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.3098 | Steps: 2 | Val loss: 0.2781 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
[2m[36m(func pid=158989)[0m rmse: 0.1786898970603943
[2m[36m(func pid=158989)[0m mae:  0.13118502497673035
[2m[36m(func pid=158989)[0m rmse_per_class: [0.105, 0.266, 0.087, 0.325, 0.101, 0.192, 0.304, 0.153, 0.139, 0.116]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=150254)[0m rmse: 0.16344444453716278
[2m[36m(func pid=150254)[0m mae:  0.10248695313930511
[2m[36m(func pid=150254)[0m rmse_per_class: [0.09, 0.233, 0.048, 0.345, 0.07, 0.167, 0.252, 0.165, 0.171, 0.094]
[2m[36m(func pid=150254)[0m 
== Status ==
Current time: 2024-01-07 08:54:05 (running for 00:22:05.90)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 10 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.31  |  0.147 |                   57 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.278 |  0.163 |                   38 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  1.016 |  0.181 |                    7 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  1.078 |  0.179 |                    1 |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 1 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=145749)[0m rmse: 0.14735175669193268
[2m[36m(func pid=145749)[0m mae:  0.09420651197433472
[2m[36m(func pid=145749)[0m rmse_per_class: [0.081, 0.217, 0.039, 0.274, 0.056, 0.198, 0.218, 0.121, 0.184, 0.086]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 1.0021 | Steps: 2 | Val loss: 0.7839 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 1.0371 | Steps: 2 | Val loss: 0.7605 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.2754 | Steps: 2 | Val loss: 0.3063 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=157328)[0m rmse: 0.18078799545764923
[2m[36m(func pid=157328)[0m mae:  0.13277240097522736
[2m[36m(func pid=157328)[0m rmse_per_class: [0.105, 0.266, 0.091, 0.324, 0.106, 0.194, 0.31, 0.154, 0.138, 0.12]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.3090 | Steps: 2 | Val loss: 0.2774 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=158989)[0m rmse: 0.17903462052345276
[2m[36m(func pid=158989)[0m mae:  0.1313900649547577
[2m[36m(func pid=158989)[0m rmse_per_class: [0.104, 0.266, 0.088, 0.325, 0.101, 0.193, 0.305, 0.154, 0.139, 0.115]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=150254)[0m rmse: 0.15991270542144775
[2m[36m(func pid=150254)[0m mae:  0.09940186142921448
[2m[36m(func pid=150254)[0m rmse_per_class: [0.087, 0.228, 0.048, 0.342, 0.073, 0.162, 0.237, 0.156, 0.175, 0.09]
[2m[36m(func pid=150254)[0m 
== Status ==
Current time: 2024-01-07 08:54:10 (running for 00:22:11.07)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 10 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.309 |  0.147 |                   58 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.275 |  0.16  |                   39 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  1.002 |  0.181 |                    8 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  1.037 |  0.179 |                    2 |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 1 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=145749)[0m rmse: 0.14661863446235657
[2m[36m(func pid=145749)[0m mae:  0.09405912458896637
[2m[36m(func pid=145749)[0m rmse_per_class: [0.078, 0.217, 0.037, 0.272, 0.056, 0.197, 0.225, 0.116, 0.183, 0.086]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.9849 | Steps: 2 | Val loss: 0.7717 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.9624 | Steps: 2 | Val loss: 0.7104 | Batch size: 32 | lr: 0.001 | Duration: 2.73s
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.2688 | Steps: 2 | Val loss: 0.3011 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=157328)[0m rmse: 0.18085604906082153
[2m[36m(func pid=157328)[0m mae:  0.13280734419822693
[2m[36m(func pid=157328)[0m rmse_per_class: [0.106, 0.266, 0.091, 0.324, 0.106, 0.194, 0.31, 0.154, 0.138, 0.12]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.3118 | Steps: 2 | Val loss: 0.2769 | Batch size: 32 | lr: 0.001 | Duration: 3.05s
[2m[36m(func pid=158989)[0m rmse: 0.17924579977989197
[2m[36m(func pid=158989)[0m mae:  0.13146242499351501
[2m[36m(func pid=158989)[0m rmse_per_class: [0.104, 0.267, 0.089, 0.324, 0.101, 0.193, 0.305, 0.156, 0.139, 0.116]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=150254)[0m rmse: 0.15711569786071777
[2m[36m(func pid=150254)[0m mae:  0.09710697829723358
[2m[36m(func pid=150254)[0m rmse_per_class: [0.088, 0.225, 0.049, 0.34, 0.074, 0.161, 0.22, 0.149, 0.176, 0.09]
[2m[36m(func pid=150254)[0m 
== Status ==
Current time: 2024-01-07 08:54:15 (running for 00:22:16.51)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 10 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.312 |  0.146 |                   59 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.269 |  0.157 |                   40 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.985 |  0.181 |                    9 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.962 |  0.179 |                    3 |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 1 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=145749)[0m rmse: 0.14589840173721313
[2m[36m(func pid=145749)[0m mae:  0.09389014542102814
[2m[36m(func pid=145749)[0m rmse_per_class: [0.077, 0.216, 0.037, 0.269, 0.056, 0.194, 0.232, 0.112, 0.181, 0.085]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.9620 | Steps: 2 | Val loss: 0.7592 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.8734 | Steps: 2 | Val loss: 0.6497 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.2879 | Steps: 2 | Val loss: 0.2972 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=157328)[0m rmse: 0.18090280890464783
[2m[36m(func pid=157328)[0m mae:  0.13283896446228027
[2m[36m(func pid=157328)[0m rmse_per_class: [0.106, 0.267, 0.091, 0.324, 0.105, 0.194, 0.31, 0.154, 0.138, 0.121]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.3157 | Steps: 2 | Val loss: 0.2762 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=158989)[0m rmse: 0.17943605780601501
[2m[36m(func pid=158989)[0m mae:  0.1315271407365799
[2m[36m(func pid=158989)[0m rmse_per_class: [0.104, 0.267, 0.089, 0.324, 0.101, 0.193, 0.305, 0.156, 0.139, 0.115]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=150254)[0m rmse: 0.1555851250886917
[2m[36m(func pid=150254)[0m mae:  0.09520166367292404
[2m[36m(func pid=150254)[0m rmse_per_class: [0.089, 0.225, 0.05, 0.335, 0.073, 0.164, 0.207, 0.145, 0.179, 0.089]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.9483 | Steps: 2 | Val loss: 0.7454 | Batch size: 32 | lr: 0.0001 | Duration: 2.78s
== Status ==
Current time: 2024-01-07 08:54:20 (running for 00:22:21.78)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 10 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.316 |  0.145 |                   60 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.288 |  0.156 |                   41 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.962 |  0.181 |                   10 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.873 |  0.179 |                    4 |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 1 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=145749)[0m rmse: 0.14504963159561157
[2m[36m(func pid=145749)[0m mae:  0.09371688216924667
[2m[36m(func pid=145749)[0m rmse_per_class: [0.075, 0.216, 0.035, 0.267, 0.056, 0.189, 0.24, 0.109, 0.179, 0.085]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.7751 | Steps: 2 | Val loss: 0.5843 | Batch size: 32 | lr: 0.001 | Duration: 2.74s
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.2785 | Steps: 2 | Val loss: 0.2945 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=157328)[0m rmse: 0.18101903796195984
[2m[36m(func pid=157328)[0m mae:  0.13293235003948212
[2m[36m(func pid=157328)[0m rmse_per_class: [0.106, 0.267, 0.091, 0.324, 0.106, 0.194, 0.31, 0.154, 0.138, 0.121]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.3129 | Steps: 2 | Val loss: 0.2759 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=158989)[0m rmse: 0.17944708466529846
[2m[36m(func pid=158989)[0m mae:  0.13141515851020813
[2m[36m(func pid=158989)[0m rmse_per_class: [0.104, 0.268, 0.089, 0.324, 0.101, 0.193, 0.304, 0.157, 0.139, 0.115]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=150254)[0m rmse: 0.1552540361881256
[2m[36m(func pid=150254)[0m mae:  0.09404473006725311
[2m[36m(func pid=150254)[0m rmse_per_class: [0.09, 0.226, 0.05, 0.33, 0.072, 0.168, 0.201, 0.143, 0.181, 0.089]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.9305 | Steps: 2 | Val loss: 0.7315 | Batch size: 32 | lr: 0.0001 | Duration: 2.76s
== Status ==
Current time: 2024-01-07 08:54:26 (running for 00:22:27.16)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 10 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.313 |  0.145 |                   61 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.278 |  0.155 |                   42 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.948 |  0.181 |                   11 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.775 |  0.179 |                    5 |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 1 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=145749)[0m rmse: 0.144646555185318
[2m[36m(func pid=145749)[0m mae:  0.09367381036281586
[2m[36m(func pid=145749)[0m rmse_per_class: [0.074, 0.215, 0.035, 0.266, 0.055, 0.186, 0.247, 0.106, 0.178, 0.084]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.6938 | Steps: 2 | Val loss: 0.5229 | Batch size: 32 | lr: 0.001 | Duration: 2.71s
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.2881 | Steps: 2 | Val loss: 0.2945 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
[2m[36m(func pid=157328)[0m rmse: 0.18102410435676575
[2m[36m(func pid=157328)[0m mae:  0.13292211294174194
[2m[36m(func pid=157328)[0m rmse_per_class: [0.106, 0.267, 0.09, 0.324, 0.106, 0.194, 0.31, 0.154, 0.138, 0.122]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.3132 | Steps: 2 | Val loss: 0.2754 | Batch size: 32 | lr: 0.001 | Duration: 2.76s
[2m[36m(func pid=158989)[0m rmse: 0.17932885885238647
[2m[36m(func pid=158989)[0m mae:  0.13118597865104675
[2m[36m(func pid=158989)[0m rmse_per_class: [0.104, 0.268, 0.089, 0.324, 0.1, 0.193, 0.303, 0.156, 0.139, 0.115]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=150254)[0m rmse: 0.1563354879617691
[2m[36m(func pid=150254)[0m mae:  0.09399779140949249
[2m[36m(func pid=150254)[0m rmse_per_class: [0.092, 0.228, 0.052, 0.328, 0.071, 0.173, 0.2, 0.147, 0.185, 0.089]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.9107 | Steps: 2 | Val loss: 0.7188 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
== Status ==
Current time: 2024-01-07 08:54:31 (running for 00:22:32.24)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 10 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.313 |  0.144 |                   62 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.288 |  0.156 |                   43 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.931 |  0.181 |                   12 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.694 |  0.179 |                    6 |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 1 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=145749)[0m rmse: 0.14406026899814606
[2m[36m(func pid=145749)[0m mae:  0.09349919855594635
[2m[36m(func pid=145749)[0m rmse_per_class: [0.071, 0.214, 0.033, 0.264, 0.055, 0.183, 0.253, 0.104, 0.178, 0.084]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.6172 | Steps: 2 | Val loss: 0.4690 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.2850 | Steps: 2 | Val loss: 0.2940 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=157328)[0m rmse: 0.18104377388954163
[2m[36m(func pid=157328)[0m mae:  0.13292774558067322
[2m[36m(func pid=157328)[0m rmse_per_class: [0.106, 0.267, 0.09, 0.324, 0.105, 0.194, 0.31, 0.154, 0.138, 0.122]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.3118 | Steps: 2 | Val loss: 0.2748 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=158989)[0m rmse: 0.17913977801799774
[2m[36m(func pid=158989)[0m mae:  0.13088330626487732
[2m[36m(func pid=158989)[0m rmse_per_class: [0.105, 0.268, 0.09, 0.325, 0.1, 0.193, 0.301, 0.155, 0.139, 0.115]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=150254)[0m rmse: 0.15723659098148346
[2m[36m(func pid=150254)[0m mae:  0.0940328985452652
[2m[36m(func pid=150254)[0m rmse_per_class: [0.093, 0.229, 0.055, 0.324, 0.07, 0.176, 0.202, 0.148, 0.187, 0.09]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.8962 | Steps: 2 | Val loss: 0.7066 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
== Status ==
Current time: 2024-01-07 08:54:36 (running for 00:22:37.57)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 10 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.312 |  0.144 |                   63 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.285 |  0.157 |                   44 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.911 |  0.181 |                   13 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.617 |  0.179 |                    7 |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 1 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=145749)[0m rmse: 0.14371100068092346
[2m[36m(func pid=145749)[0m mae:  0.09338726848363876
[2m[36m(func pid=145749)[0m rmse_per_class: [0.07, 0.213, 0.033, 0.263, 0.055, 0.179, 0.259, 0.104, 0.176, 0.085]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.5588 | Steps: 2 | Val loss: 0.4259 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.2791 | Steps: 2 | Val loss: 0.2972 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=157328)[0m rmse: 0.1811372935771942
[2m[36m(func pid=157328)[0m mae:  0.13297055661678314
[2m[36m(func pid=157328)[0m rmse_per_class: [0.106, 0.267, 0.091, 0.324, 0.105, 0.194, 0.31, 0.154, 0.138, 0.122]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.3090 | Steps: 2 | Val loss: 0.2742 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=158989)[0m rmse: 0.1787651926279068
[2m[36m(func pid=158989)[0m mae:  0.13047118484973907
[2m[36m(func pid=158989)[0m rmse_per_class: [0.106, 0.269, 0.09, 0.325, 0.099, 0.193, 0.299, 0.153, 0.14, 0.115]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=150254)[0m rmse: 0.1592140942811966
[2m[36m(func pid=150254)[0m mae:  0.09489616751670837
[2m[36m(func pid=150254)[0m rmse_per_class: [0.093, 0.232, 0.057, 0.325, 0.069, 0.176, 0.204, 0.155, 0.187, 0.093]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.8816 | Steps: 2 | Val loss: 0.6944 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=145749)[0m rmse: 0.14332762360572815
[2m[36m(func pid=145749)[0m mae:  0.09317059814929962
[2m[36m(func pid=145749)[0m rmse_per_class: [0.069, 0.212, 0.032, 0.262, 0.055, 0.174, 0.263, 0.106, 0.173, 0.087]
== Status ==
Current time: 2024-01-07 08:54:41 (running for 00:22:42.72)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 10 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.309 |  0.143 |                   64 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.279 |  0.159 |                   45 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.896 |  0.181 |                   14 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.559 |  0.179 |                    8 |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 1 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.5118 | Steps: 2 | Val loss: 0.3934 | Batch size: 32 | lr: 0.001 | Duration: 2.74s
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.2761 | Steps: 2 | Val loss: 0.2984 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=157328)[0m rmse: 0.1811094433069229
[2m[36m(func pid=157328)[0m mae:  0.1329195350408554
[2m[36m(func pid=157328)[0m rmse_per_class: [0.106, 0.267, 0.09, 0.324, 0.105, 0.194, 0.31, 0.154, 0.138, 0.122]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=158989)[0m rmse: 0.17850281298160553
[2m[36m(func pid=158989)[0m mae:  0.13010898232460022
[2m[36m(func pid=158989)[0m rmse_per_class: [0.106, 0.269, 0.091, 0.326, 0.098, 0.193, 0.296, 0.151, 0.14, 0.114]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.3073 | Steps: 2 | Val loss: 0.2742 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=150254)[0m rmse: 0.16036662459373474
[2m[36m(func pid=150254)[0m mae:  0.09563170373439789
[2m[36m(func pid=150254)[0m rmse_per_class: [0.093, 0.235, 0.06, 0.328, 0.07, 0.174, 0.207, 0.156, 0.184, 0.098]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.8659 | Steps: 2 | Val loss: 0.6830 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
== Status ==
Current time: 2024-01-07 08:54:47 (running for 00:22:48.22)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 10 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.307 |  0.143 |                   65 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.276 |  0.16  |                   46 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.882 |  0.181 |                   15 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.512 |  0.179 |                    9 |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 1 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=145749)[0m rmse: 0.1433200240135193
[2m[36m(func pid=145749)[0m mae:  0.09303931891918182
[2m[36m(func pid=145749)[0m rmse_per_class: [0.068, 0.211, 0.031, 0.262, 0.055, 0.171, 0.268, 0.108, 0.173, 0.087]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.4732 | Steps: 2 | Val loss: 0.3693 | Batch size: 32 | lr: 0.001 | Duration: 2.78s
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.2918 | Steps: 2 | Val loss: 0.3029 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=157328)[0m rmse: 0.18111646175384521
[2m[36m(func pid=157328)[0m mae:  0.1329077035188675
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.267, 0.09, 0.324, 0.105, 0.194, 0.31, 0.154, 0.138, 0.122]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=158989)[0m rmse: 0.17818917334079742
[2m[36m(func pid=158989)[0m mae:  0.12975263595581055
[2m[36m(func pid=158989)[0m rmse_per_class: [0.107, 0.27, 0.092, 0.327, 0.097, 0.193, 0.293, 0.148, 0.141, 0.114]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.3216 | Steps: 2 | Val loss: 0.2759 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=150254)[0m rmse: 0.16153699159622192
[2m[36m(func pid=150254)[0m mae:  0.09627486765384674
[2m[36m(func pid=150254)[0m rmse_per_class: [0.093, 0.24, 0.061, 0.331, 0.071, 0.168, 0.208, 0.153, 0.186, 0.104]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.8505 | Steps: 2 | Val loss: 0.6709 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.4487 | Steps: 2 | Val loss: 0.3523 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 08:54:52 (running for 00:22:53.70)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 10 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.322 |  0.145 |                   66 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.292 |  0.162 |                   47 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.866 |  0.181 |                   16 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.473 |  0.178 |                   10 |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 1 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
[2m[36m(func pid=145749)[0m rmse: 0.14486871659755707

[2m[36m(func pid=145749)[0m mae:  0.09402196109294891
[2m[36m(func pid=145749)[0m rmse_per_class: [0.067, 0.212, 0.03, 0.264, 0.055, 0.168, 0.272, 0.111, 0.179, 0.09]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=157328)[0m rmse: 0.18112054467201233
[2m[36m(func pid=157328)[0m mae:  0.13289742171764374
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.267, 0.09, 0.324, 0.105, 0.194, 0.31, 0.154, 0.138, 0.123]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.2793 | Steps: 2 | Val loss: 0.3106 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=158989)[0m rmse: 0.1776849329471588
[2m[36m(func pid=158989)[0m mae:  0.1292724907398224
[2m[36m(func pid=158989)[0m rmse_per_class: [0.107, 0.27, 0.092, 0.328, 0.095, 0.193, 0.291, 0.146, 0.142, 0.113]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.3028 | Steps: 2 | Val loss: 0.2765 | Batch size: 32 | lr: 0.001 | Duration: 3.09s
[2m[36m(func pid=150254)[0m rmse: 0.16382154822349548
[2m[36m(func pid=150254)[0m mae:  0.09790894389152527
[2m[36m(func pid=150254)[0m rmse_per_class: [0.095, 0.247, 0.064, 0.338, 0.071, 0.165, 0.209, 0.151, 0.188, 0.111]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.8353 | Steps: 2 | Val loss: 0.6596 | Batch size: 32 | lr: 0.0001 | Duration: 2.75s
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.4284 | Steps: 2 | Val loss: 0.3405 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 08:54:58 (running for 00:22:59.30)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 10 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.303 |  0.146 |                   67 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.279 |  0.164 |                   48 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.85  |  0.181 |                   17 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.449 |  0.178 |                   11 |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 1 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=145749)[0m rmse: 0.1456131637096405
[2m[36m(func pid=145749)[0m mae:  0.09436796605587006
[2m[36m(func pid=145749)[0m rmse_per_class: [0.066, 0.212, 0.029, 0.264, 0.055, 0.168, 0.275, 0.114, 0.18, 0.093]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=157328)[0m rmse: 0.1810559332370758
[2m[36m(func pid=157328)[0m mae:  0.13284331560134888
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.267, 0.089, 0.324, 0.105, 0.194, 0.31, 0.154, 0.138, 0.123]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.2717 | Steps: 2 | Val loss: 0.3208 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
[2m[36m(func pid=158989)[0m rmse: 0.1772906482219696
[2m[36m(func pid=158989)[0m mae:  0.12886252999305725
[2m[36m(func pid=158989)[0m rmse_per_class: [0.108, 0.27, 0.092, 0.328, 0.094, 0.193, 0.289, 0.144, 0.143, 0.113]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.2970 | Steps: 2 | Val loss: 0.2771 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.8190 | Steps: 2 | Val loss: 0.6486 | Batch size: 32 | lr: 0.0001 | Duration: 2.74s
[2m[36m(func pid=150254)[0m rmse: 0.16682414710521698
[2m[36m(func pid=150254)[0m mae:  0.09981924295425415
[2m[36m(func pid=150254)[0m rmse_per_class: [0.099, 0.255, 0.068, 0.345, 0.072, 0.163, 0.209, 0.146, 0.19, 0.122]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.4144 | Steps: 2 | Val loss: 0.3321 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
== Status ==
Current time: 2024-01-07 08:55:03 (running for 00:23:04.67)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 10 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.297 |  0.146 |                   68 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.272 |  0.167 |                   49 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.835 |  0.181 |                   18 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.428 |  0.177 |                   12 |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 1 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=145749)[0m rmse: 0.1464816778898239
[2m[36m(func pid=145749)[0m mae:  0.09472957998514175
[2m[36m(func pid=145749)[0m rmse_per_class: [0.066, 0.212, 0.029, 0.264, 0.054, 0.166, 0.277, 0.12, 0.181, 0.095]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=157328)[0m rmse: 0.1810762584209442
[2m[36m(func pid=157328)[0m mae:  0.13284417986869812
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.268, 0.089, 0.324, 0.105, 0.194, 0.31, 0.154, 0.138, 0.123]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=158989)[0m rmse: 0.17676730453968048
[2m[36m(func pid=158989)[0m mae:  0.12835270166397095
[2m[36m(func pid=158989)[0m rmse_per_class: [0.109, 0.269, 0.092, 0.329, 0.092, 0.192, 0.286, 0.142, 0.144, 0.113]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.2612 | Steps: 2 | Val loss: 0.3293 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.3044 | Steps: 2 | Val loss: 0.2782 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.8023 | Steps: 2 | Val loss: 0.6356 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=150254)[0m rmse: 0.16954071819782257
[2m[36m(func pid=150254)[0m mae:  0.10160525143146515
[2m[36m(func pid=150254)[0m rmse_per_class: [0.107, 0.264, 0.072, 0.35, 0.072, 0.165, 0.208, 0.142, 0.193, 0.123]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.4042 | Steps: 2 | Val loss: 0.3267 | Batch size: 32 | lr: 0.001 | Duration: 2.71s
== Status ==
Current time: 2024-01-07 08:55:09 (running for 00:23:10.12)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 10 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.304 |  0.147 |                   69 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.261 |  0.17  |                   50 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.819 |  0.181 |                   19 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.414 |  0.177 |                   13 |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 1 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=145749)[0m rmse: 0.14714714884757996
[2m[36m(func pid=145749)[0m mae:  0.09502078592777252
[2m[36m(func pid=145749)[0m rmse_per_class: [0.064, 0.213, 0.028, 0.267, 0.054, 0.165, 0.28, 0.122, 0.182, 0.097]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=157328)[0m rmse: 0.18104353547096252
[2m[36m(func pid=157328)[0m mae:  0.13279657065868378
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.268, 0.089, 0.324, 0.105, 0.194, 0.31, 0.154, 0.138, 0.123]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=158989)[0m rmse: 0.1763520985841751
[2m[36m(func pid=158989)[0m mae:  0.1279509961605072
[2m[36m(func pid=158989)[0m rmse_per_class: [0.109, 0.269, 0.092, 0.329, 0.091, 0.192, 0.284, 0.14, 0.145, 0.112]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.2517 | Steps: 2 | Val loss: 0.3347 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.2938 | Steps: 2 | Val loss: 0.2793 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.7854 | Steps: 2 | Val loss: 0.6241 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.3953 | Steps: 2 | Val loss: 0.3229 | Batch size: 32 | lr: 0.001 | Duration: 2.75s
[2m[36m(func pid=150254)[0m rmse: 0.172003835439682
[2m[36m(func pid=150254)[0m mae:  0.10343434661626816
[2m[36m(func pid=150254)[0m rmse_per_class: [0.119, 0.267, 0.074, 0.353, 0.075, 0.17, 0.207, 0.138, 0.19, 0.127]
[2m[36m(func pid=150254)[0m 
== Status ==
Current time: 2024-01-07 08:55:14 (running for 00:23:15.56)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 10 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.294 |  0.148 |                   70 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.252 |  0.172 |                   51 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.802 |  0.181 |                   20 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.404 |  0.176 |                   14 |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 1 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=145749)[0m rmse: 0.14840392768383026
[2m[36m(func pid=145749)[0m mae:  0.09566081315279007
[2m[36m(func pid=145749)[0m rmse_per_class: [0.064, 0.214, 0.028, 0.267, 0.054, 0.164, 0.281, 0.129, 0.182, 0.101]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=157328)[0m rmse: 0.1810021698474884
[2m[36m(func pid=157328)[0m mae:  0.13276240229606628
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.268, 0.089, 0.324, 0.105, 0.194, 0.31, 0.154, 0.138, 0.123]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=158989)[0m rmse: 0.17582610249519348
[2m[36m(func pid=158989)[0m mae:  0.12748582661151886
[2m[36m(func pid=158989)[0m rmse_per_class: [0.109, 0.269, 0.091, 0.329, 0.089, 0.192, 0.283, 0.139, 0.145, 0.112]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.2578 | Steps: 2 | Val loss: 0.3372 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.3147 | Steps: 2 | Val loss: 0.2821 | Batch size: 32 | lr: 0.001 | Duration: 3.10s
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.7770 | Steps: 2 | Val loss: 0.6142 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.3924 | Steps: 2 | Val loss: 0.3202 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=150254)[0m rmse: 0.17293313145637512
[2m[36m(func pid=150254)[0m mae:  0.10412649810314178
[2m[36m(func pid=150254)[0m rmse_per_class: [0.127, 0.267, 0.07, 0.354, 0.079, 0.175, 0.206, 0.137, 0.188, 0.126]
[2m[36m(func pid=150254)[0m 
== Status ==
Current time: 2024-01-07 08:55:20 (running for 00:23:21.13)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 10 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.315 |  0.151 |                   71 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.258 |  0.173 |                   52 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.785 |  0.181 |                   21 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.395 |  0.176 |                   15 |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 1 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=145749)[0m rmse: 0.1506287306547165
[2m[36m(func pid=145749)[0m mae:  0.09681360423564911
[2m[36m(func pid=145749)[0m rmse_per_class: [0.063, 0.217, 0.028, 0.268, 0.054, 0.165, 0.282, 0.134, 0.186, 0.109]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=157328)[0m rmse: 0.18099181354045868
[2m[36m(func pid=157328)[0m mae:  0.13273189961910248
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.268, 0.089, 0.324, 0.104, 0.194, 0.31, 0.154, 0.138, 0.123]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=158989)[0m rmse: 0.1752864122390747
[2m[36m(func pid=158989)[0m mae:  0.12700751423835754
[2m[36m(func pid=158989)[0m rmse_per_class: [0.11, 0.269, 0.09, 0.329, 0.088, 0.192, 0.281, 0.138, 0.145, 0.112]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.2570 | Steps: 2 | Val loss: 0.3390 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.2870 | Steps: 2 | Val loss: 0.2833 | Batch size: 32 | lr: 0.001 | Duration: 3.07s
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.3904 | Steps: 2 | Val loss: 0.3184 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=150254)[0m rmse: 0.1740291714668274
[2m[36m(func pid=150254)[0m mae:  0.10475947707891464
[2m[36m(func pid=150254)[0m rmse_per_class: [0.142, 0.269, 0.068, 0.355, 0.081, 0.178, 0.205, 0.135, 0.183, 0.124]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.7607 | Steps: 2 | Val loss: 0.6037 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=145749)[0m rmse: 0.1515338122844696
[2m[36m(func pid=145749)[0m mae:  0.09734117984771729
[2m[36m(func pid=145749)[0m rmse_per_class: [0.063, 0.219, 0.027, 0.269, 0.054, 0.165, 0.282, 0.138, 0.185, 0.114]
== Status ==
Current time: 2024-01-07 08:55:25 (running for 00:23:26.77)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 10 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.287 |  0.152 |                   72 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.257 |  0.174 |                   53 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.777 |  0.181 |                   22 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.392 |  0.175 |                   16 |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 1 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=157328)[0m rmse: 0.1810004562139511
[2m[36m(func pid=157328)[0m mae:  0.1327119618654251
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.268, 0.089, 0.324, 0.104, 0.194, 0.309, 0.154, 0.138, 0.123]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=158989)[0m rmse: 0.17476323246955872
[2m[36m(func pid=158989)[0m mae:  0.12657523155212402
[2m[36m(func pid=158989)[0m rmse_per_class: [0.109, 0.268, 0.089, 0.328, 0.086, 0.192, 0.28, 0.138, 0.145, 0.112]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.2717 | Steps: 2 | Val loss: 0.3391 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.2848 | Steps: 2 | Val loss: 0.2855 | Batch size: 32 | lr: 0.001 | Duration: 3.04s
[2m[36m(func pid=150254)[0m rmse: 0.17442935705184937
[2m[36m(func pid=150254)[0m mae:  0.10497947782278061
[2m[36m(func pid=150254)[0m rmse_per_class: [0.159, 0.267, 0.069, 0.354, 0.081, 0.181, 0.204, 0.134, 0.184, 0.112]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.3881 | Steps: 2 | Val loss: 0.3173 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.7527 | Steps: 2 | Val loss: 0.5932 | Batch size: 32 | lr: 0.0001 | Duration: 3.04s
== Status ==
Current time: 2024-01-07 08:55:31 (running for 00:23:32.28)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 10 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.287 |  0.152 |                   72 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.272 |  0.174 |                   54 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.761 |  0.181 |                   23 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.388 |  0.174 |                   18 |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 1 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=158989)[0m rmse: 0.1744406670331955
[2m[36m(func pid=158989)[0m mae:  0.12627945840358734
[2m[36m(func pid=158989)[0m rmse_per_class: [0.11, 0.268, 0.088, 0.328, 0.086, 0.191, 0.279, 0.137, 0.146, 0.112]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.15340876579284668
[2m[36m(func pid=145749)[0m mae:  0.09815140813589096
[2m[36m(func pid=145749)[0m rmse_per_class: [0.063, 0.22, 0.027, 0.268, 0.053, 0.166, 0.282, 0.148, 0.18, 0.127]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=157328)[0m rmse: 0.180907741189003
[2m[36m(func pid=157328)[0m mae:  0.13260525465011597
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.104, 0.194, 0.309, 0.154, 0.138, 0.123]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.2675 | Steps: 2 | Val loss: 0.3368 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.3794 | Steps: 2 | Val loss: 0.3163 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=150254)[0m rmse: 0.17285463213920593
[2m[36m(func pid=150254)[0m mae:  0.10396857559680939
[2m[36m(func pid=150254)[0m rmse_per_class: [0.162, 0.265, 0.063, 0.352, 0.08, 0.182, 0.203, 0.135, 0.186, 0.101]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.7393 | Steps: 2 | Val loss: 0.5836 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.2901 | Steps: 2 | Val loss: 0.2873 | Batch size: 32 | lr: 0.001 | Duration: 3.18s
== Status ==
Current time: 2024-01-07 08:55:36 (running for 00:23:37.50)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 10 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.285 |  0.153 |                   73 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.268 |  0.173 |                   55 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.753 |  0.181 |                   24 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.379 |  0.174 |                   19 |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 1 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=158989)[0m rmse: 0.17397814989089966
[2m[36m(func pid=158989)[0m mae:  0.12588131427764893
[2m[36m(func pid=158989)[0m rmse_per_class: [0.11, 0.268, 0.086, 0.327, 0.084, 0.191, 0.278, 0.136, 0.147, 0.112]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=157328)[0m rmse: 0.18090559542179108
[2m[36m(func pid=157328)[0m mae:  0.13256695866584778
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.268, 0.089, 0.324, 0.104, 0.194, 0.309, 0.153, 0.138, 0.123]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.15488770604133606
[2m[36m(func pid=145749)[0m mae:  0.09886593371629715
[2m[36m(func pid=145749)[0m rmse_per_class: [0.063, 0.222, 0.028, 0.268, 0.053, 0.167, 0.281, 0.155, 0.182, 0.13]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.2576 | Steps: 2 | Val loss: 0.3350 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.3765 | Steps: 2 | Val loss: 0.3153 | Batch size: 32 | lr: 0.001 | Duration: 3.11s
[2m[36m(func pid=150254)[0m rmse: 0.1710422933101654
[2m[36m(func pid=150254)[0m mae:  0.10302410274744034
[2m[36m(func pid=150254)[0m rmse_per_class: [0.16, 0.265, 0.055, 0.351, 0.083, 0.182, 0.202, 0.134, 0.188, 0.091]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.7278 | Steps: 2 | Val loss: 0.5744 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.2952 | Steps: 2 | Val loss: 0.2895 | Batch size: 32 | lr: 0.001 | Duration: 3.05s
== Status ==
Current time: 2024-01-07 08:55:42 (running for 00:23:43.02)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 10 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.29  |  0.155 |                   74 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.258 |  0.171 |                   56 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.739 |  0.181 |                   25 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.377 |  0.173 |                   20 |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 1 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=158989)[0m rmse: 0.17345738410949707
[2m[36m(func pid=158989)[0m mae:  0.12544794380664825
[2m[36m(func pid=158989)[0m rmse_per_class: [0.11, 0.268, 0.085, 0.326, 0.083, 0.191, 0.277, 0.136, 0.147, 0.111]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=157328)[0m rmse: 0.18089072406291962
[2m[36m(func pid=157328)[0m mae:  0.1325352042913437
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.104, 0.193, 0.309, 0.153, 0.138, 0.123]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.1564534455537796
[2m[36m(func pid=145749)[0m mae:  0.09949551522731781
[2m[36m(func pid=145749)[0m rmse_per_class: [0.063, 0.224, 0.029, 0.268, 0.053, 0.168, 0.28, 0.161, 0.179, 0.138]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.2565 | Steps: 2 | Val loss: 0.3331 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.3739 | Steps: 2 | Val loss: 0.3143 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=150254)[0m rmse: 0.1695147454738617
[2m[36m(func pid=150254)[0m mae:  0.10210718959569931
[2m[36m(func pid=150254)[0m rmse_per_class: [0.153, 0.265, 0.05, 0.349, 0.084, 0.181, 0.2, 0.135, 0.19, 0.088]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.7192 | Steps: 2 | Val loss: 0.5648 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 75] | Train loss: 0.2973 | Steps: 2 | Val loss: 0.2930 | Batch size: 32 | lr: 0.001 | Duration: 3.08s
== Status ==
Current time: 2024-01-07 08:55:47 (running for 00:23:48.24)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.1562500037252903
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 10 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.295 |  0.156 |                   75 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.256 |  0.17  |                   57 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.728 |  0.181 |                   26 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.374 |  0.173 |                   21 |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 1 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=158989)[0m rmse: 0.17280957102775574
[2m[36m(func pid=158989)[0m mae:  0.1248924508690834
[2m[36m(func pid=158989)[0m rmse_per_class: [0.109, 0.268, 0.083, 0.325, 0.082, 0.191, 0.276, 0.136, 0.147, 0.111]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=157328)[0m rmse: 0.1808813214302063
[2m[36m(func pid=157328)[0m mae:  0.1325131356716156
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.103, 0.193, 0.309, 0.153, 0.139, 0.123]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.2539 | Steps: 2 | Val loss: 0.3312 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=145749)[0m rmse: 0.1587725579738617
[2m[36m(func pid=145749)[0m mae:  0.10068000853061676
[2m[36m(func pid=145749)[0m rmse_per_class: [0.064, 0.228, 0.029, 0.269, 0.053, 0.17, 0.279, 0.167, 0.183, 0.146]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.3710 | Steps: 2 | Val loss: 0.3134 | Batch size: 32 | lr: 0.001 | Duration: 3.05s
[2m[36m(func pid=150254)[0m rmse: 0.16777734458446503
[2m[36m(func pid=150254)[0m mae:  0.10128005594015121
[2m[36m(func pid=150254)[0m rmse_per_class: [0.147, 0.266, 0.047, 0.345, 0.081, 0.177, 0.199, 0.135, 0.193, 0.086]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.7095 | Steps: 2 | Val loss: 0.5555 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 76] | Train loss: 0.2870 | Steps: 2 | Val loss: 0.2954 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 08:55:52 (running for 00:23:53.69)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.1562500037252903
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 10 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.297 |  0.159 |                   76 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.254 |  0.168 |                   58 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.71  |  0.181 |                   28 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.374 |  0.173 |                   21 |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 1 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=157328)[0m rmse: 0.18077808618545532
[2m[36m(func pid=157328)[0m mae:  0.13243362307548523
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.103, 0.194, 0.308, 0.153, 0.139, 0.123]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=158989)[0m rmse: 0.17226114869117737
[2m[36m(func pid=158989)[0m mae:  0.12441682815551758
[2m[36m(func pid=158989)[0m rmse_per_class: [0.109, 0.267, 0.082, 0.324, 0.081, 0.19, 0.276, 0.135, 0.147, 0.11]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.2537 | Steps: 2 | Val loss: 0.3284 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=145749)[0m rmse: 0.16043034195899963
[2m[36m(func pid=145749)[0m mae:  0.10162381827831268
[2m[36m(func pid=145749)[0m rmse_per_class: [0.065, 0.231, 0.03, 0.27, 0.052, 0.171, 0.277, 0.173, 0.181, 0.154]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.6952 | Steps: 2 | Val loss: 0.5486 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.3675 | Steps: 2 | Val loss: 0.3125 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=150254)[0m rmse: 0.1662188470363617
[2m[36m(func pid=150254)[0m mae:  0.10030224174261093
[2m[36m(func pid=150254)[0m rmse_per_class: [0.134, 0.269, 0.046, 0.344, 0.085, 0.173, 0.198, 0.134, 0.195, 0.085]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 77] | Train loss: 0.2917 | Steps: 2 | Val loss: 0.2968 | Batch size: 32 | lr: 0.001 | Duration: 3.03s
== Status ==
Current time: 2024-01-07 08:55:58 (running for 00:23:59.00)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.1562500037252903
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 10 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.287 |  0.16  |                   77 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.254 |  0.166 |                   59 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.71  |  0.181 |                   28 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.367 |  0.172 |                   23 |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 1 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=157328)[0m rmse: 0.1807454526424408
[2m[36m(func pid=157328)[0m mae:  0.1323796957731247
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.268, 0.089, 0.324, 0.103, 0.194, 0.308, 0.153, 0.139, 0.123]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=158989)[0m rmse: 0.17171648144721985
[2m[36m(func pid=158989)[0m mae:  0.12396563589572906
[2m[36m(func pid=158989)[0m rmse_per_class: [0.109, 0.267, 0.081, 0.323, 0.08, 0.19, 0.275, 0.135, 0.148, 0.11]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.2499 | Steps: 2 | Val loss: 0.3257 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=145749)[0m rmse: 0.16110743582248688
[2m[36m(func pid=145749)[0m mae:  0.10181117057800293
[2m[36m(func pid=145749)[0m rmse_per_class: [0.065, 0.232, 0.031, 0.27, 0.052, 0.173, 0.275, 0.176, 0.179, 0.157]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.3705 | Steps: 2 | Val loss: 0.3118 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.6851 | Steps: 2 | Val loss: 0.5416 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=150254)[0m rmse: 0.16489487886428833
[2m[36m(func pid=150254)[0m mae:  0.09963497519493103
[2m[36m(func pid=150254)[0m rmse_per_class: [0.123, 0.271, 0.047, 0.342, 0.085, 0.169, 0.198, 0.132, 0.197, 0.085]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 78] | Train loss: 0.2846 | Steps: 2 | Val loss: 0.2999 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
== Status ==
Current time: 2024-01-07 08:56:03 (running for 00:24:04.02)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.1562500037252903
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 10 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.292 |  0.161 |                   78 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.25  |  0.165 |                   60 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.695 |  0.181 |                   29 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.371 |  0.171 |                   24 |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 1 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=158989)[0m rmse: 0.1712784618139267
[2m[36m(func pid=158989)[0m mae:  0.12362971156835556
[2m[36m(func pid=158989)[0m rmse_per_class: [0.109, 0.267, 0.079, 0.322, 0.079, 0.19, 0.274, 0.134, 0.148, 0.11]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=157328)[0m rmse: 0.18078403174877167
[2m[36m(func pid=157328)[0m mae:  0.13239189982414246
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.103, 0.194, 0.308, 0.153, 0.139, 0.123]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.2613 | Steps: 2 | Val loss: 0.3249 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=145749)[0m rmse: 0.1628313511610031
[2m[36m(func pid=145749)[0m mae:  0.10292444378137589
[2m[36m(func pid=145749)[0m rmse_per_class: [0.066, 0.236, 0.031, 0.271, 0.052, 0.174, 0.273, 0.182, 0.184, 0.159]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.3655 | Steps: 2 | Val loss: 0.3111 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.6752 | Steps: 2 | Val loss: 0.5339 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=150254)[0m rmse: 0.16407039761543274
[2m[36m(func pid=150254)[0m mae:  0.09931833297014236
[2m[36m(func pid=150254)[0m rmse_per_class: [0.116, 0.274, 0.048, 0.34, 0.082, 0.166, 0.2, 0.128, 0.201, 0.085]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 79] | Train loss: 0.2819 | Steps: 2 | Val loss: 0.3021 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
== Status ==
Current time: 2024-01-07 08:56:08 (running for 00:24:09.27)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.1562500037252903
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 10 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.285 |  0.163 |                   79 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.261 |  0.164 |                   61 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.685 |  0.181 |                   30 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.365 |  0.171 |                   25 |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 1 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=158989)[0m rmse: 0.17080971598625183
[2m[36m(func pid=158989)[0m mae:  0.12320947647094727
[2m[36m(func pid=158989)[0m rmse_per_class: [0.108, 0.266, 0.078, 0.321, 0.079, 0.19, 0.273, 0.134, 0.148, 0.11]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=157328)[0m rmse: 0.18076331913471222
[2m[36m(func pid=157328)[0m mae:  0.1323595941066742
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.103, 0.194, 0.307, 0.153, 0.139, 0.123]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.2447 | Steps: 2 | Val loss: 0.3238 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=145749)[0m rmse: 0.16383324563503265
[2m[36m(func pid=145749)[0m mae:  0.10367834568023682
[2m[36m(func pid=145749)[0m rmse_per_class: [0.066, 0.238, 0.032, 0.273, 0.052, 0.175, 0.271, 0.186, 0.181, 0.164]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.3610 | Steps: 2 | Val loss: 0.3101 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.6659 | Steps: 2 | Val loss: 0.5264 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
[2m[36m(func pid=150254)[0m rmse: 0.1637355089187622
[2m[36m(func pid=150254)[0m mae:  0.0994034856557846
[2m[36m(func pid=150254)[0m rmse_per_class: [0.106, 0.277, 0.049, 0.341, 0.082, 0.163, 0.205, 0.127, 0.203, 0.085]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 80] | Train loss: 0.2830 | Steps: 2 | Val loss: 0.3043 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
== Status ==
Current time: 2024-01-07 08:56:13 (running for 00:24:14.62)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.1562500037252903
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 10 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.282 |  0.164 |                   80 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.245 |  0.164 |                   62 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.675 |  0.181 |                   31 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.361 |  0.17  |                   26 |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 1 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=158989)[0m rmse: 0.17025862634181976
[2m[36m(func pid=158989)[0m mae:  0.12276344001293182
[2m[36m(func pid=158989)[0m rmse_per_class: [0.108, 0.266, 0.077, 0.321, 0.078, 0.189, 0.272, 0.134, 0.148, 0.109]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=157328)[0m rmse: 0.18074481189250946
[2m[36m(func pid=157328)[0m mae:  0.1323150247335434
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.324, 0.103, 0.194, 0.307, 0.152, 0.139, 0.123]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.2431 | Steps: 2 | Val loss: 0.3241 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=145749)[0m rmse: 0.16464325785636902
[2m[36m(func pid=145749)[0m mae:  0.10421860218048096
[2m[36m(func pid=145749)[0m rmse_per_class: [0.066, 0.24, 0.033, 0.275, 0.052, 0.176, 0.269, 0.19, 0.181, 0.166]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.3587 | Steps: 2 | Val loss: 0.3090 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.6577 | Steps: 2 | Val loss: 0.5201 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=150254)[0m rmse: 0.16353461146354675
[2m[36m(func pid=150254)[0m mae:  0.09953363984823227
[2m[36m(func pid=150254)[0m rmse_per_class: [0.098, 0.278, 0.048, 0.341, 0.081, 0.161, 0.21, 0.125, 0.208, 0.085]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 81] | Train loss: 0.2782 | Steps: 2 | Val loss: 0.3072 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 08:56:19 (running for 00:24:19.94)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.1562500037252903
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 10 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.283 |  0.165 |                   81 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.243 |  0.164 |                   63 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.666 |  0.181 |                   32 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.359 |  0.17  |                   27 |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 1 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=158989)[0m rmse: 0.16965371370315552
[2m[36m(func pid=158989)[0m mae:  0.12225908041000366
[2m[36m(func pid=158989)[0m rmse_per_class: [0.107, 0.265, 0.076, 0.32, 0.078, 0.189, 0.271, 0.133, 0.148, 0.109]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=157328)[0m rmse: 0.18067088723182678
[2m[36m(func pid=157328)[0m mae:  0.13224133849143982
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.268, 0.089, 0.324, 0.103, 0.194, 0.307, 0.152, 0.139, 0.123]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.2699 | Steps: 2 | Val loss: 0.3278 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=145749)[0m rmse: 0.16584636270999908
[2m[36m(func pid=145749)[0m mae:  0.1050482839345932
[2m[36m(func pid=145749)[0m rmse_per_class: [0.066, 0.243, 0.033, 0.278, 0.052, 0.178, 0.266, 0.192, 0.179, 0.172]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.3562 | Steps: 2 | Val loss: 0.3082 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.6533 | Steps: 2 | Val loss: 0.5134 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=150254)[0m rmse: 0.16448576748371124
[2m[36m(func pid=150254)[0m mae:  0.10000850260257721
[2m[36m(func pid=150254)[0m rmse_per_class: [0.093, 0.284, 0.047, 0.341, 0.078, 0.161, 0.216, 0.124, 0.214, 0.085]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=158989)[0m rmse: 0.1692207306623459
[2m[36m(func pid=158989)[0m mae:  0.1218927726149559
[2m[36m(func pid=158989)[0m rmse_per_class: [0.107, 0.265, 0.075, 0.319, 0.077, 0.189, 0.271, 0.133, 0.148, 0.109]
== Status ==
Current time: 2024-01-07 08:56:24 (running for 00:24:25.07)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.1562500037252903
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 10 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.166 |                   82 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.27  |  0.164 |                   64 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.658 |  0.181 |                   33 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.356 |  0.169 |                   28 |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 1 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 82] | Train loss: 0.2912 | Steps: 2 | Val loss: 0.3110 | Batch size: 32 | lr: 0.001 | Duration: 3.13s
[2m[36m(func pid=157328)[0m rmse: 0.18058964610099792
[2m[36m(func pid=157328)[0m mae:  0.13217630982398987
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.268, 0.089, 0.325, 0.102, 0.193, 0.306, 0.152, 0.139, 0.123]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.2537 | Steps: 2 | Val loss: 0.3281 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=145749)[0m rmse: 0.16764964163303375
[2m[36m(func pid=145749)[0m mae:  0.10610024631023407
[2m[36m(func pid=145749)[0m rmse_per_class: [0.067, 0.246, 0.034, 0.281, 0.053, 0.179, 0.264, 0.193, 0.18, 0.181]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.3560 | Steps: 2 | Val loss: 0.3077 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.6443 | Steps: 2 | Val loss: 0.5069 | Batch size: 32 | lr: 0.0001 | Duration: 3.07s
[2m[36m(func pid=150254)[0m rmse: 0.16480591893196106
[2m[36m(func pid=150254)[0m mae:  0.10032014548778534
[2m[36m(func pid=150254)[0m rmse_per_class: [0.09, 0.284, 0.046, 0.341, 0.077, 0.163, 0.22, 0.123, 0.218, 0.085]
[2m[36m(func pid=150254)[0m 
== Status ==
Current time: 2024-01-07 08:56:29 (running for 00:24:30.22)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.1562500037252903
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 10 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.291 |  0.168 |                   83 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.254 |  0.165 |                   65 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.653 |  0.181 |                   34 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.356 |  0.169 |                   29 |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 1 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=158989)[0m rmse: 0.1689276248216629
[2m[36m(func pid=158989)[0m mae:  0.12163557857275009
[2m[36m(func pid=158989)[0m rmse_per_class: [0.107, 0.265, 0.074, 0.319, 0.076, 0.189, 0.27, 0.133, 0.148, 0.109]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 83] | Train loss: 0.2817 | Steps: 2 | Val loss: 0.3124 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=157328)[0m rmse: 0.18058523535728455
[2m[36m(func pid=157328)[0m mae:  0.1321488618850708
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.325, 0.102, 0.193, 0.306, 0.152, 0.139, 0.123]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.2504 | Steps: 2 | Val loss: 0.3250 | Batch size: 32 | lr: 0.01 | Duration: 2.77s
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.3495 | Steps: 2 | Val loss: 0.3070 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=145749)[0m rmse: 0.16815528273582458
[2m[36m(func pid=145749)[0m mae:  0.10646359622478485
[2m[36m(func pid=145749)[0m rmse_per_class: [0.067, 0.248, 0.035, 0.283, 0.053, 0.179, 0.262, 0.193, 0.177, 0.185]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.6345 | Steps: 2 | Val loss: 0.5016 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=150254)[0m rmse: 0.16480012238025665
[2m[36m(func pid=150254)[0m mae:  0.10086246579885483
[2m[36m(func pid=150254)[0m rmse_per_class: [0.089, 0.282, 0.045, 0.342, 0.075, 0.166, 0.225, 0.121, 0.217, 0.086]
[2m[36m(func pid=150254)[0m 
== Status ==
Current time: 2024-01-07 08:56:34 (running for 00:24:35.45)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.1562500037252903
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 10 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.282 |  0.168 |                   84 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.25  |  0.165 |                   66 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.644 |  0.181 |                   35 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.349 |  0.169 |                   30 |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 1 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=158989)[0m rmse: 0.1685788780450821
[2m[36m(func pid=158989)[0m mae:  0.12134142220020294
[2m[36m(func pid=158989)[0m rmse_per_class: [0.106, 0.265, 0.073, 0.318, 0.076, 0.189, 0.269, 0.133, 0.148, 0.109]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=157328)[0m rmse: 0.18052984774112701
[2m[36m(func pid=157328)[0m mae:  0.13209731876850128
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.102, 0.193, 0.306, 0.152, 0.139, 0.123]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 84] | Train loss: 0.2869 | Steps: 2 | Val loss: 0.3143 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.2417 | Steps: 2 | Val loss: 0.3240 | Batch size: 32 | lr: 0.01 | Duration: 3.05s
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.3481 | Steps: 2 | Val loss: 0.3066 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=145749)[0m rmse: 0.16900335252285004
[2m[36m(func pid=145749)[0m mae:  0.10692264139652252
[2m[36m(func pid=145749)[0m rmse_per_class: [0.068, 0.249, 0.036, 0.287, 0.053, 0.18, 0.26, 0.195, 0.172, 0.191]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.6277 | Steps: 2 | Val loss: 0.4964 | Batch size: 32 | lr: 0.0001 | Duration: 2.73s
[2m[36m(func pid=150254)[0m rmse: 0.16511091589927673
[2m[36m(func pid=150254)[0m mae:  0.10138358920812607
[2m[36m(func pid=150254)[0m rmse_per_class: [0.09, 0.277, 0.048, 0.343, 0.074, 0.168, 0.227, 0.119, 0.219, 0.087]
[2m[36m(func pid=150254)[0m 
== Status ==
Current time: 2024-01-07 08:56:39 (running for 00:24:40.61)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.1562500037252903
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 10 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.287 |  0.169 |                   85 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.242 |  0.165 |                   67 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.634 |  0.181 |                   36 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.348 |  0.168 |                   31 |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 1 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=158989)[0m rmse: 0.16834396123886108
[2m[36m(func pid=158989)[0m mae:  0.12117666006088257
[2m[36m(func pid=158989)[0m rmse_per_class: [0.106, 0.264, 0.072, 0.318, 0.076, 0.188, 0.269, 0.133, 0.149, 0.109]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=157328)[0m rmse: 0.18047231435775757
[2m[36m(func pid=157328)[0m mae:  0.13204777240753174
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.102, 0.193, 0.306, 0.152, 0.139, 0.123]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 85] | Train loss: 0.2817 | Steps: 2 | Val loss: 0.3165 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.2449 | Steps: 2 | Val loss: 0.3209 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.3462 | Steps: 2 | Val loss: 0.3058 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.6176 | Steps: 2 | Val loss: 0.4898 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=145749)[0m rmse: 0.1697670966386795
[2m[36m(func pid=145749)[0m mae:  0.10723624378442764
[2m[36m(func pid=145749)[0m rmse_per_class: [0.068, 0.25, 0.036, 0.29, 0.053, 0.181, 0.258, 0.194, 0.169, 0.2]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=150254)[0m rmse: 0.16433891654014587
[2m[36m(func pid=150254)[0m mae:  0.10125210136175156
[2m[36m(func pid=150254)[0m rmse_per_class: [0.09, 0.271, 0.046, 0.343, 0.073, 0.167, 0.227, 0.118, 0.219, 0.088]
[2m[36m(func pid=150254)[0m 
== Status ==
Current time: 2024-01-07 08:56:45 (running for 00:24:45.97)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.1562500037252903
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 10 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.282 |  0.17  |                   86 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.245 |  0.164 |                   68 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.628 |  0.18  |                   37 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.346 |  0.168 |                   32 |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 1 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=158989)[0m rmse: 0.16794165968894958
[2m[36m(func pid=158989)[0m mae:  0.12084077298641205
[2m[36m(func pid=158989)[0m rmse_per_class: [0.105, 0.264, 0.071, 0.317, 0.075, 0.188, 0.268, 0.132, 0.149, 0.109]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=157328)[0m rmse: 0.18038344383239746
[2m[36m(func pid=157328)[0m mae:  0.13196209073066711
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.101, 0.193, 0.305, 0.151, 0.139, 0.123]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 86] | Train loss: 0.2924 | Steps: 2 | Val loss: 0.3177 | Batch size: 32 | lr: 0.001 | Duration: 3.11s
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.2545 | Steps: 2 | Val loss: 0.3171 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.3419 | Steps: 2 | Val loss: 0.3049 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.6088 | Steps: 2 | Val loss: 0.4863 | Batch size: 32 | lr: 0.0001 | Duration: 3.15s
[2m[36m(func pid=145749)[0m rmse: 0.16988664865493774
[2m[36m(func pid=145749)[0m mae:  0.1072002425789833
[2m[36m(func pid=145749)[0m rmse_per_class: [0.068, 0.252, 0.036, 0.291, 0.054, 0.181, 0.256, 0.188, 0.17, 0.201]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=150254)[0m rmse: 0.1632518172264099
[2m[36m(func pid=150254)[0m mae:  0.1009611114859581
[2m[36m(func pid=150254)[0m rmse_per_class: [0.089, 0.266, 0.044, 0.341, 0.073, 0.166, 0.227, 0.117, 0.218, 0.091]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=158989)[0m rmse: 0.1674622744321823
[2m[36m(func pid=158989)[0m mae:  0.12040290981531143
[2m[36m(func pid=158989)[0m rmse_per_class: [0.105, 0.264, 0.07, 0.317, 0.075, 0.188, 0.267, 0.132, 0.148, 0.109]
[2m[36m(func pid=158989)[0m 
== Status ==
Current time: 2024-01-07 08:56:50 (running for 00:24:51.16)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.1562500037252903
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 10 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.292 |  0.17  |                   87 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.255 |  0.163 |                   69 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.618 |  0.18  |                   38 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.342 |  0.167 |                   33 |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 1 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=157328)[0m rmse: 0.18038560450077057
[2m[36m(func pid=157328)[0m mae:  0.13196831941604614
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.325, 0.102, 0.193, 0.305, 0.151, 0.139, 0.123]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 87] | Train loss: 0.2830 | Steps: 2 | Val loss: 0.3178 | Batch size: 32 | lr: 0.001 | Duration: 3.04s
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.2406 | Steps: 2 | Val loss: 0.3129 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.3446 | Steps: 2 | Val loss: 0.3042 | Batch size: 32 | lr: 0.001 | Duration: 2.74s
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.6066 | Steps: 2 | Val loss: 0.4813 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=145749)[0m rmse: 0.16950395703315735
[2m[36m(func pid=145749)[0m mae:  0.10675898939371109
[2m[36m(func pid=145749)[0m rmse_per_class: [0.068, 0.252, 0.036, 0.293, 0.054, 0.181, 0.255, 0.186, 0.172, 0.197]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=150254)[0m rmse: 0.16176030039787292
[2m[36m(func pid=150254)[0m mae:  0.10034060478210449
[2m[36m(func pid=150254)[0m rmse_per_class: [0.09, 0.26, 0.043, 0.341, 0.075, 0.162, 0.223, 0.118, 0.213, 0.093]
[2m[36m(func pid=150254)[0m 
== Status ==
Current time: 2024-01-07 08:56:55 (running for 00:24:56.37)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.1562500037252903
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 10 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.283 |  0.17  |                   88 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.241 |  0.162 |                   70 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.609 |  0.18  |                   39 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.345 |  0.167 |                   34 |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 1 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=158989)[0m rmse: 0.1670495569705963
[2m[36m(func pid=158989)[0m mae:  0.12007224559783936
[2m[36m(func pid=158989)[0m rmse_per_class: [0.104, 0.263, 0.069, 0.316, 0.074, 0.188, 0.267, 0.132, 0.148, 0.109]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=157328)[0m rmse: 0.18038953840732574
[2m[36m(func pid=157328)[0m mae:  0.13196182250976562
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.325, 0.102, 0.193, 0.305, 0.151, 0.14, 0.122]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 88] | Train loss: 0.2847 | Steps: 2 | Val loss: 0.3169 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.2492 | Steps: 2 | Val loss: 0.3102 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.3404 | Steps: 2 | Val loss: 0.3035 | Batch size: 32 | lr: 0.001 | Duration: 2.74s
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.6000 | Steps: 2 | Val loss: 0.4763 | Batch size: 32 | lr: 0.0001 | Duration: 2.72s
[2m[36m(func pid=145749)[0m rmse: 0.16844023764133453
[2m[36m(func pid=145749)[0m mae:  0.1059025302529335
[2m[36m(func pid=145749)[0m rmse_per_class: [0.068, 0.252, 0.036, 0.294, 0.055, 0.181, 0.254, 0.183, 0.169, 0.193]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=150254)[0m rmse: 0.1606970727443695
[2m[36m(func pid=150254)[0m mae:  0.09964066743850708
[2m[36m(func pid=150254)[0m rmse_per_class: [0.089, 0.257, 0.044, 0.34, 0.077, 0.158, 0.218, 0.118, 0.21, 0.096]
[2m[36m(func pid=150254)[0m 
== Status ==
Current time: 2024-01-07 08:57:00 (running for 00:25:01.50)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.1562500037252903
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 10 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.285 |  0.168 |                   89 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.249 |  0.161 |                   71 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.607 |  0.18  |                   40 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.34  |  0.167 |                   35 |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 1 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=158989)[0m rmse: 0.16675147414207458
[2m[36m(func pid=158989)[0m mae:  0.11983652412891388
[2m[36m(func pid=158989)[0m rmse_per_class: [0.104, 0.263, 0.069, 0.315, 0.073, 0.188, 0.267, 0.132, 0.148, 0.109]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=157328)[0m rmse: 0.18032971024513245
[2m[36m(func pid=157328)[0m mae:  0.1318977177143097
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.102, 0.193, 0.305, 0.151, 0.14, 0.122]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 89] | Train loss: 0.2655 | Steps: 2 | Val loss: 0.3165 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.2626 | Steps: 2 | Val loss: 0.3112 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.3405 | Steps: 2 | Val loss: 0.3026 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.5952 | Steps: 2 | Val loss: 0.4712 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=150254)[0m rmse: 0.16045239567756653
[2m[36m(func pid=150254)[0m mae:  0.09908019751310349
[2m[36m(func pid=150254)[0m rmse_per_class: [0.09, 0.253, 0.046, 0.341, 0.083, 0.156, 0.213, 0.118, 0.207, 0.098]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.16762325167655945
[2m[36m(func pid=145749)[0m mae:  0.1055426225066185
[2m[36m(func pid=145749)[0m rmse_per_class: [0.067, 0.252, 0.035, 0.298, 0.056, 0.181, 0.254, 0.177, 0.165, 0.19]
[2m[36m(func pid=145749)[0m 
== Status ==
Current time: 2024-01-07 08:57:05 (running for 00:25:06.72)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.1562500037252903
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 10 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.265 |  0.168 |                   90 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.263 |  0.16  |                   72 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.6   |  0.18  |                   41 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.341 |  0.166 |                   36 |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 1 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=158989)[0m rmse: 0.1662367880344391
[2m[36m(func pid=158989)[0m mae:  0.1193932518362999
[2m[36m(func pid=158989)[0m rmse_per_class: [0.104, 0.263, 0.068, 0.314, 0.072, 0.188, 0.267, 0.132, 0.148, 0.108]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=157328)[0m rmse: 0.18029822409152985
[2m[36m(func pid=157328)[0m mae:  0.13186457753181458
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.102, 0.193, 0.305, 0.151, 0.14, 0.122]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.2555 | Steps: 2 | Val loss: 0.3077 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 90] | Train loss: 0.2715 | Steps: 2 | Val loss: 0.3172 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.3363 | Steps: 2 | Val loss: 0.3018 | Batch size: 32 | lr: 0.001 | Duration: 2.67s
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.5876 | Steps: 2 | Val loss: 0.4673 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=150254)[0m rmse: 0.15925341844558716
[2m[36m(func pid=150254)[0m mae:  0.09844813495874405
[2m[36m(func pid=150254)[0m rmse_per_class: [0.093, 0.251, 0.046, 0.34, 0.083, 0.155, 0.207, 0.119, 0.197, 0.101]
[2m[36m(func pid=150254)[0m 
== Status ==
Current time: 2024-01-07 08:57:10 (running for 00:25:11.77)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.1562500037252903
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 10 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.265 |  0.168 |                   90 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.256 |  0.159 |                   73 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.595 |  0.18  |                   42 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.336 |  0.166 |                   37 |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 1 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=145749)[0m rmse: 0.16739149391651154
[2m[36m(func pid=145749)[0m mae:  0.10534244775772095
[2m[36m(func pid=145749)[0m rmse_per_class: [0.068, 0.251, 0.035, 0.304, 0.057, 0.181, 0.254, 0.172, 0.163, 0.19]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=158989)[0m rmse: 0.16585615277290344
[2m[36m(func pid=158989)[0m mae:  0.11907428503036499
[2m[36m(func pid=158989)[0m rmse_per_class: [0.103, 0.262, 0.067, 0.313, 0.072, 0.187, 0.266, 0.132, 0.147, 0.108]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=157328)[0m rmse: 0.18029919266700745
[2m[36m(func pid=157328)[0m mae:  0.1318424493074417
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.102, 0.193, 0.304, 0.151, 0.14, 0.122]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.2484 | Steps: 2 | Val loss: 0.3056 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.3351 | Steps: 2 | Val loss: 0.3015 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 91] | Train loss: 0.2693 | Steps: 2 | Val loss: 0.3165 | Batch size: 32 | lr: 0.001 | Duration: 3.11s
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.5854 | Steps: 2 | Val loss: 0.4621 | Batch size: 32 | lr: 0.0001 | Duration: 2.75s
== Status ==
Current time: 2024-01-07 08:57:15 (running for 00:25:16.86)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.1562500037252903
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 10 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.271 |  0.167 |                   91 |
| train_d77f6_00010 | RUNNING    | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.248 |  0.158 |                   74 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.588 |  0.18  |                   43 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.336 |  0.166 |                   37 |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 1 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=150254)[0m rmse: 0.15803644061088562
[2m[36m(func pid=150254)[0m mae:  0.09776876866817474
[2m[36m(func pid=150254)[0m rmse_per_class: [0.095, 0.246, 0.046, 0.339, 0.086, 0.155, 0.202, 0.12, 0.191, 0.101]
[2m[36m(func pid=150254)[0m 
[2m[36m(func pid=158989)[0m rmse: 0.16570761799812317
[2m[36m(func pid=158989)[0m mae:  0.11894392967224121
[2m[36m(func pid=158989)[0m rmse_per_class: [0.103, 0.262, 0.066, 0.313, 0.072, 0.187, 0.266, 0.131, 0.148, 0.109]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.16682767868041992
[2m[36m(func pid=145749)[0m mae:  0.10511106252670288
[2m[36m(func pid=145749)[0m rmse_per_class: [0.068, 0.251, 0.034, 0.309, 0.058, 0.181, 0.256, 0.167, 0.16, 0.184]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=157328)[0m rmse: 0.18019641935825348
[2m[36m(func pid=157328)[0m mae:  0.13173335790634155
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.102, 0.193, 0.304, 0.15, 0.14, 0.122]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=150254)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.2513 | Steps: 2 | Val loss: 0.3053 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.3361 | Steps: 2 | Val loss: 0.3009 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 92] | Train loss: 0.2655 | Steps: 2 | Val loss: 0.3153 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.5782 | Steps: 2 | Val loss: 0.4588 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=150254)[0m rmse: 0.15739747881889343
[2m[36m(func pid=150254)[0m mae:  0.09706370532512665
[2m[36m(func pid=150254)[0m rmse_per_class: [0.096, 0.244, 0.045, 0.337, 0.09, 0.156, 0.198, 0.121, 0.189, 0.1]
== Status ==
Current time: 2024-01-07 08:57:21 (running for 00:25:22.19)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=10
Bracket: Iter 75.000: -0.15650000423192978
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 10 PENDING, 3 RUNNING, 10 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.269 |  0.167 |                   92 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.585 |  0.18  |                   44 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.335 |  0.166 |                   38 |
| train_d77f6_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 2 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=158989)[0m rmse: 0.16538631916046143
[2m[36m(func pid=158989)[0m mae:  0.11867216974496841
[2m[36m(func pid=158989)[0m rmse_per_class: [0.103, 0.262, 0.066, 0.313, 0.072, 0.187, 0.266, 0.131, 0.147, 0.108]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.16568927466869354
[2m[36m(func pid=145749)[0m mae:  0.10440464317798615
[2m[36m(func pid=145749)[0m rmse_per_class: [0.068, 0.25, 0.034, 0.313, 0.06, 0.18, 0.259, 0.159, 0.16, 0.175]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=157328)[0m rmse: 0.1801060140132904
[2m[36m(func pid=157328)[0m mae:  0.13165661692619324
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.101, 0.193, 0.303, 0.15, 0.14, 0.122]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.3320 | Steps: 2 | Val loss: 0.3005 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 93] | Train loss: 0.2675 | Steps: 2 | Val loss: 0.3141 | Batch size: 32 | lr: 0.001 | Duration: 3.08s
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.5733 | Steps: 2 | Val loss: 0.4546 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
[2m[36m(func pid=158989)[0m rmse: 0.1652282476425171
[2m[36m(func pid=158989)[0m mae:  0.11852742731571198
[2m[36m(func pid=158989)[0m rmse_per_class: [0.103, 0.261, 0.065, 0.312, 0.072, 0.187, 0.265, 0.131, 0.147, 0.109]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.16470520198345184
[2m[36m(func pid=145749)[0m mae:  0.10360739380121231
[2m[36m(func pid=145749)[0m rmse_per_class: [0.068, 0.248, 0.033, 0.316, 0.061, 0.179, 0.261, 0.155, 0.161, 0.164]
[2m[36m(func pid=157328)[0m rmse: 0.17999853193759918
[2m[36m(func pid=157328)[0m mae:  0.13155855238437653
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.101, 0.193, 0.303, 0.15, 0.14, 0.121]
== Status ==
Current time: 2024-01-07 08:57:26 (running for 00:25:27.73)
Memory usage on this node: 22.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=10
Bracket: Iter 75.000: -0.15650000423192978
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 9 PENDING, 4 RUNNING, 10 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.266 |  0.166 |                   93 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.578 |  0.18  |                   45 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.332 |  0.165 |                   40 |
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (1 PENDING, 2 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.3270 | Steps: 2 | Val loss: 0.2999 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=167906)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=167906)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=167906)[0m Configuration completed!
[2m[36m(func pid=167906)[0m New optimizer parameters:
[2m[36m(func pid=167906)[0m SGD (
[2m[36m(func pid=167906)[0m Parameter Group 0
[2m[36m(func pid=167906)[0m     dampening: 0
[2m[36m(func pid=167906)[0m     differentiable: False
[2m[36m(func pid=167906)[0m     foreach: None
[2m[36m(func pid=167906)[0m     lr: 0.01
[2m[36m(func pid=167906)[0m     maximize: False
[2m[36m(func pid=167906)[0m     momentum: 0.9
[2m[36m(func pid=167906)[0m     nesterov: False
[2m[36m(func pid=167906)[0m     weight_decay: 0.0001
[2m[36m(func pid=167906)[0m )
[2m[36m(func pid=167906)[0m 
== Status ==
Current time: 2024-01-07 08:57:32 (running for 00:25:33.15)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=10
Bracket: Iter 75.000: -0.15650000423192978
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 9 PENDING, 4 RUNNING, 10 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.267 |  0.165 |                   94 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.573 |  0.18  |                   46 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.327 |  0.165 |                   41 |
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (1 PENDING, 2 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=158989)[0m rmse: 0.16487953066825867
[2m[36m(func pid=158989)[0m mae:  0.11824169009923935
[2m[36m(func pid=158989)[0m rmse_per_class: [0.103, 0.261, 0.065, 0.312, 0.071, 0.186, 0.265, 0.131, 0.147, 0.108]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.5642 | Steps: 2 | Val loss: 0.4505 | Batch size: 32 | lr: 0.0001 | Duration: 2.77s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 94] | Train loss: 0.2772 | Steps: 2 | Val loss: 0.3152 | Batch size: 32 | lr: 0.001 | Duration: 3.05s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 1.0291 | Steps: 2 | Val loss: 0.6497 | Batch size: 32 | lr: 0.01 | Duration: 4.52s
[2m[36m(func pid=157328)[0m rmse: 0.1799374669790268
[2m[36m(func pid=157328)[0m mae:  0.1315229833126068
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.101, 0.193, 0.303, 0.15, 0.14, 0.121]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.3280 | Steps: 2 | Val loss: 0.2994 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=145749)[0m rmse: 0.16503378748893738
[2m[36m(func pid=145749)[0m mae:  0.10356570780277252
[2m[36m(func pid=145749)[0m rmse_per_class: [0.068, 0.249, 0.033, 0.32, 0.062, 0.179, 0.264, 0.152, 0.163, 0.161]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.17799633741378784
[2m[36m(func pid=167906)[0m mae:  0.13045331835746765
[2m[36m(func pid=167906)[0m rmse_per_class: [0.104, 0.267, 0.085, 0.325, 0.097, 0.192, 0.301, 0.155, 0.139, 0.115]
[2m[36m(func pid=167906)[0m 
== Status ==
Current time: 2024-01-07 08:57:37 (running for 00:25:38.37)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=10
Bracket: Iter 75.000: -0.15650000423192978
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 9 PENDING, 4 RUNNING, 10 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.277 |  0.165 |                   95 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.564 |  0.18  |                   47 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.328 |  0.165 |                   42 |
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  1.029 |  0.178 |                    1 |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (1 PENDING, 2 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=158989)[0m rmse: 0.16465775668621063
[2m[36m(func pid=158989)[0m mae:  0.11805573850870132
[2m[36m(func pid=158989)[0m rmse_per_class: [0.102, 0.261, 0.065, 0.311, 0.071, 0.186, 0.265, 0.131, 0.147, 0.108]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.5639 | Steps: 2 | Val loss: 0.4469 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 95] | Train loss: 0.2593 | Steps: 2 | Val loss: 0.3145 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.7081 | Steps: 2 | Val loss: 0.4357 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.3271 | Steps: 2 | Val loss: 0.2991 | Batch size: 32 | lr: 0.001 | Duration: 2.76s
[2m[36m(func pid=157328)[0m rmse: 0.17998185753822327
[2m[36m(func pid=157328)[0m mae:  0.13153265416622162
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.101, 0.193, 0.303, 0.15, 0.14, 0.121]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.16422805190086365
[2m[36m(func pid=145749)[0m mae:  0.10293503105640411
[2m[36m(func pid=145749)[0m rmse_per_class: [0.069, 0.247, 0.033, 0.324, 0.062, 0.177, 0.265, 0.145, 0.161, 0.159]
[2m[36m(func pid=145749)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.17668236792087555
[2m[36m(func pid=167906)[0m mae:  0.12901709973812103
[2m[36m(func pid=167906)[0m rmse_per_class: [0.104, 0.269, 0.086, 0.326, 0.092, 0.192, 0.293, 0.154, 0.141, 0.11]
[2m[36m(func pid=167906)[0m 
== Status ==
Current time: 2024-01-07 08:57:42 (running for 00:25:43.56)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=10
Bracket: Iter 75.000: -0.15650000423192978
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 9 PENDING, 4 RUNNING, 10 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.259 |  0.164 |                   96 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.564 |  0.18  |                   48 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.327 |  0.165 |                   43 |
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.708 |  0.177 |                    2 |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (1 PENDING, 2 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=158989)[0m rmse: 0.16451697051525116
[2m[36m(func pid=158989)[0m mae:  0.1179184690117836
[2m[36m(func pid=158989)[0m rmse_per_class: [0.102, 0.261, 0.064, 0.311, 0.071, 0.186, 0.264, 0.131, 0.147, 0.108]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.5589 | Steps: 2 | Val loss: 0.4431 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 96] | Train loss: 0.2710 | Steps: 2 | Val loss: 0.3136 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.4590 | Steps: 2 | Val loss: 0.3327 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.3192 | Steps: 2 | Val loss: 0.2986 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=157328)[0m rmse: 0.17992793023586273
[2m[36m(func pid=157328)[0m mae:  0.1314835250377655
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.101, 0.193, 0.303, 0.15, 0.14, 0.121]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.16296552121639252
[2m[36m(func pid=145749)[0m mae:  0.10185950994491577
[2m[36m(func pid=145749)[0m rmse_per_class: [0.07, 0.245, 0.032, 0.325, 0.063, 0.177, 0.265, 0.139, 0.165, 0.148]
[2m[36m(func pid=145749)[0m 
== Status ==
Current time: 2024-01-07 08:57:47 (running for 00:25:48.64)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=10
Bracket: Iter 75.000: -0.15650000423192978
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 9 PENDING, 4 RUNNING, 10 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.271 |  0.163 |                   97 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.559 |  0.18  |                   49 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.327 |  0.165 |                   43 |
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.459 |  0.174 |                    3 |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (1 PENDING, 2 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=167906)[0m rmse: 0.17448996007442474
[2m[36m(func pid=167906)[0m mae:  0.12680506706237793
[2m[36m(func pid=167906)[0m rmse_per_class: [0.105, 0.271, 0.09, 0.331, 0.086, 0.191, 0.28, 0.143, 0.144, 0.104]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=158989)[0m rmse: 0.16421084105968475
[2m[36m(func pid=158989)[0m mae:  0.11762993037700653
[2m[36m(func pid=158989)[0m rmse_per_class: [0.102, 0.26, 0.064, 0.31, 0.071, 0.186, 0.264, 0.131, 0.146, 0.108]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.5556 | Steps: 2 | Val loss: 0.4390 | Batch size: 32 | lr: 0.0001 | Duration: 2.76s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 97] | Train loss: 0.2546 | Steps: 2 | Val loss: 0.3114 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.3244 | Steps: 2 | Val loss: 0.2984 | Batch size: 32 | lr: 0.001 | Duration: 2.75s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.3923 | Steps: 2 | Val loss: 0.3195 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=157328)[0m rmse: 0.17988744378089905
[2m[36m(func pid=157328)[0m mae:  0.13140542805194855
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.101, 0.193, 0.303, 0.149, 0.14, 0.121]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=145749)[0m rmse: 0.16170617938041687
[2m[36m(func pid=145749)[0m mae:  0.10091272741556168
[2m[36m(func pid=145749)[0m rmse_per_class: [0.072, 0.243, 0.032, 0.327, 0.064, 0.176, 0.266, 0.134, 0.165, 0.138]
[2m[36m(func pid=145749)[0m 
== Status ==
Current time: 2024-01-07 08:57:53 (running for 00:25:53.92)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=10
Bracket: Iter 75.000: -0.15650000423192978
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 9 PENDING, 4 RUNNING, 10 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.255 |  0.162 |                   98 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.556 |  0.18  |                   50 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.324 |  0.164 |                   45 |
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.459 |  0.174 |                    3 |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (1 PENDING, 2 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=158989)[0m rmse: 0.1640670895576477
[2m[36m(func pid=158989)[0m mae:  0.11748166382312775
[2m[36m(func pid=158989)[0m rmse_per_class: [0.102, 0.26, 0.063, 0.31, 0.071, 0.186, 0.263, 0.131, 0.146, 0.108]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.1719539314508438
[2m[36m(func pid=167906)[0m mae:  0.12377849966287613
[2m[36m(func pid=167906)[0m rmse_per_class: [0.105, 0.271, 0.09, 0.337, 0.079, 0.189, 0.268, 0.135, 0.149, 0.098]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.5474 | Steps: 2 | Val loss: 0.4359 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 98] | Train loss: 0.2581 | Steps: 2 | Val loss: 0.3100 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.3207 | Steps: 2 | Val loss: 0.2976 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=157328)[0m rmse: 0.17984157800674438
[2m[36m(func pid=157328)[0m mae:  0.13134542107582092
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.101, 0.193, 0.302, 0.149, 0.14, 0.12]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.4068 | Steps: 2 | Val loss: 0.3399 | Batch size: 32 | lr: 0.01 | Duration: 3.13s
[2m[36m(func pid=145749)[0m rmse: 0.16092903912067413
[2m[36m(func pid=145749)[0m mae:  0.1004759892821312
[2m[36m(func pid=145749)[0m rmse_per_class: [0.073, 0.241, 0.032, 0.329, 0.064, 0.174, 0.267, 0.131, 0.164, 0.133]
[2m[36m(func pid=145749)[0m 
== Status ==
Current time: 2024-01-07 08:57:58 (running for 00:25:59.15)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=10
Bracket: Iter 75.000: -0.15650000423192978
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 9 PENDING, 4 RUNNING, 10 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00009 | RUNNING    | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.161 |                   99 |
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.547 |  0.18  |                   51 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.321 |  0.164 |                   46 |
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.392 |  0.172 |                    4 |
| train_d77f6_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (1 PENDING, 2 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=158989)[0m rmse: 0.16365285217761993
[2m[36m(func pid=158989)[0m mae:  0.11715105921030045
[2m[36m(func pid=158989)[0m rmse_per_class: [0.102, 0.26, 0.063, 0.309, 0.07, 0.186, 0.263, 0.131, 0.145, 0.108]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.1700841337442398
[2m[36m(func pid=167906)[0m mae:  0.12078598886728287
[2m[36m(func pid=167906)[0m rmse_per_class: [0.106, 0.27, 0.083, 0.341, 0.071, 0.188, 0.261, 0.134, 0.153, 0.095]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.5420 | Steps: 2 | Val loss: 0.4329 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=145749)[0m [N0-GPU0] | [Epoch: 99] | Train loss: 0.2578 | Steps: 2 | Val loss: 0.3088 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.3201 | Steps: 2 | Val loss: 0.2973 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=157328)[0m rmse: 0.179781973361969
[2m[36m(func pid=157328)[0m mae:  0.1313026398420334
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.101, 0.193, 0.302, 0.149, 0.14, 0.12]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.4324 | Steps: 2 | Val loss: 0.3623 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=145749)[0m rmse: 0.16023047268390656
[2m[36m(func pid=145749)[0m mae:  0.09985406696796417
[2m[36m(func pid=145749)[0m rmse_per_class: [0.073, 0.241, 0.032, 0.33, 0.065, 0.173, 0.264, 0.127, 0.165, 0.134]
[2m[36m(func pid=158989)[0m rmse: 0.1634860336780548
[2m[36m(func pid=158989)[0m mae:  0.11700310558080673
[2m[36m(func pid=158989)[0m rmse_per_class: [0.101, 0.26, 0.062, 0.309, 0.07, 0.186, 0.263, 0.131, 0.145, 0.108]
[2m[36m(func pid=167906)[0m rmse: 0.1688443422317505
[2m[36m(func pid=167906)[0m mae:  0.11821931600570679
[2m[36m(func pid=167906)[0m rmse_per_class: [0.106, 0.267, 0.072, 0.343, 0.064, 0.186, 0.26, 0.136, 0.161, 0.093]
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.5386 | Steps: 2 | Val loss: 0.4291 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=157328)[0m rmse: 0.17966851592063904
[2m[36m(func pid=157328)[0m mae:  0.13119202852249146
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.1, 0.193, 0.302, 0.149, 0.14, 0.121]
== Status ==
Current time: 2024-01-07 08:58:03 (running for 00:26:04.35)
Memory usage on this node: 22.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: -0.15650000423192978
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 8 PENDING, 4 RUNNING, 11 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.542 |  0.18  |                   52 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.321 |  0.164 |                   46 |
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.407 |  0.17  |                    5 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

== Status ==
Current time: 2024-01-07 08:58:10 (running for 00:26:11.70)
Memory usage on this node: 23.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: -0.15650000423192978
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 8 PENDING, 4 RUNNING, 11 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.542 |  0.18  |                   52 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.321 |  0.164 |                   46 |
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.432 |  0.169 |                    6 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=169734)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=169734)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=169734)[0m Configuration completed!
[2m[36m(func pid=169734)[0m New optimizer parameters:
[2m[36m(func pid=169734)[0m SGD (
[2m[36m(func pid=169734)[0m Parameter Group 0
[2m[36m(func pid=169734)[0m     dampening: 0
[2m[36m(func pid=169734)[0m     differentiable: False
[2m[36m(func pid=169734)[0m     foreach: None
[2m[36m(func pid=169734)[0m     lr: 0.1
[2m[36m(func pid=169734)[0m     maximize: False
[2m[36m(func pid=169734)[0m     momentum: 0.9
[2m[36m(func pid=169734)[0m     nesterov: False
[2m[36m(func pid=169734)[0m     weight_decay: 0.0001
[2m[36m(func pid=169734)[0m )
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.5342 | Steps: 2 | Val loss: 0.4266 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.3162 | Steps: 2 | Val loss: 0.2973 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.4386 | Steps: 2 | Val loss: 0.3732 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
== Status ==
Current time: 2024-01-07 08:58:15 (running for 00:26:16.75)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: -0.15650000423192978
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 8 PENDING, 4 RUNNING, 11 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.539 |  0.18  |                   53 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.32  |  0.163 |                   47 |
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.432 |  0.169 |                    6 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 0.7640 | Steps: 2 | Val loss: 0.3203 | Batch size: 32 | lr: 0.1 | Duration: 4.97s
[2m[36m(func pid=157328)[0m rmse: 0.17967841029167175
[2m[36m(func pid=157328)[0m mae:  0.13119514286518097
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.1, 0.193, 0.302, 0.149, 0.14, 0.121]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=158989)[0m rmse: 0.16344252228736877
[2m[36m(func pid=158989)[0m mae:  0.1169770210981369
[2m[36m(func pid=158989)[0m rmse_per_class: [0.101, 0.26, 0.062, 0.309, 0.07, 0.186, 0.263, 0.13, 0.145, 0.108]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.1673555076122284
[2m[36m(func pid=167906)[0m mae:  0.1157107725739479
[2m[36m(func pid=167906)[0m rmse_per_class: [0.104, 0.264, 0.062, 0.342, 0.06, 0.185, 0.26, 0.138, 0.166, 0.091]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=169734)[0m rmse: 0.17041510343551636
[2m[36m(func pid=169734)[0m mae:  0.12212856113910675
[2m[36m(func pid=169734)[0m rmse_per_class: [0.106, 0.272, 0.085, 0.338, 0.071, 0.188, 0.266, 0.132, 0.149, 0.096]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.5265 | Steps: 2 | Val loss: 0.4234 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.3144 | Steps: 2 | Val loss: 0.2969 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.4343 | Steps: 2 | Val loss: 0.3725 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
== Status ==
Current time: 2024-01-07 08:58:21 (running for 00:26:22.21)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: -0.15650000423192978
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 8 PENDING, 4 RUNNING, 11 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.534 |  0.18  |                   54 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.314 |  0.163 |                   49 |
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.439 |  0.167 |                    7 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.764 |  0.17  |                    1 |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=158989)[0m rmse: 0.16321727633476257
[2m[36m(func pid=158989)[0m mae:  0.11679168045520782
[2m[36m(func pid=158989)[0m rmse_per_class: [0.101, 0.26, 0.061, 0.309, 0.07, 0.185, 0.263, 0.13, 0.145, 0.108]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.5070 | Steps: 2 | Val loss: 0.4518 | Batch size: 32 | lr: 0.1 | Duration: 3.05s
[2m[36m(func pid=157328)[0m rmse: 0.17965790629386902
[2m[36m(func pid=157328)[0m mae:  0.13117177784442902
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.1, 0.193, 0.302, 0.149, 0.14, 0.121]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.16596665978431702
[2m[36m(func pid=167906)[0m mae:  0.11347611248493195
[2m[36m(func pid=167906)[0m rmse_per_class: [0.103, 0.261, 0.054, 0.34, 0.057, 0.183, 0.26, 0.14, 0.17, 0.091]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.3136 | Steps: 2 | Val loss: 0.2966 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=169734)[0m rmse: 0.1841501146554947
[2m[36m(func pid=169734)[0m mae:  0.1206759437918663
[2m[36m(func pid=169734)[0m rmse_per_class: [0.096, 0.275, 0.052, 0.363, 0.055, 0.191, 0.421, 0.147, 0.146, 0.094]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.5303 | Steps: 2 | Val loss: 0.4210 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.4149 | Steps: 2 | Val loss: 0.3613 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 08:58:26 (running for 00:26:27.49)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: -0.15650000423192978
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 8 PENDING, 4 RUNNING, 11 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.527 |  0.18  |                   55 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.314 |  0.163 |                   50 |
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.434 |  0.166 |                    8 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.507 |  0.184 |                    2 |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=158989)[0m rmse: 0.16299261152744293
[2m[36m(func pid=158989)[0m mae:  0.11657420545816422
[2m[36m(func pid=158989)[0m rmse_per_class: [0.1, 0.259, 0.061, 0.309, 0.071, 0.185, 0.262, 0.13, 0.145, 0.108]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=157328)[0m rmse: 0.17965549230575562
[2m[36m(func pid=157328)[0m mae:  0.13115420937538147
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.099, 0.193, 0.302, 0.149, 0.14, 0.121]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.16375935077667236
[2m[36m(func pid=167906)[0m mae:  0.111017607152462
[2m[36m(func pid=167906)[0m rmse_per_class: [0.102, 0.256, 0.049, 0.336, 0.056, 0.181, 0.255, 0.141, 0.172, 0.09]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.6331 | Steps: 2 | Val loss: 0.4975 | Batch size: 32 | lr: 0.1 | Duration: 3.15s
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.3112 | Steps: 2 | Val loss: 0.2963 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.5250 | Steps: 2 | Val loss: 0.4188 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=169734)[0m rmse: 0.1980045735836029
[2m[36m(func pid=169734)[0m mae:  0.12665431201457977
[2m[36m(func pid=169734)[0m rmse_per_class: [0.086, 0.276, 0.042, 0.374, 0.056, 0.194, 0.564, 0.154, 0.139, 0.097]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.3829 | Steps: 2 | Val loss: 0.3416 | Batch size: 32 | lr: 0.01 | Duration: 3.07s
== Status ==
Current time: 2024-01-07 08:58:31 (running for 00:26:32.63)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: -0.15650000423192978
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 8 PENDING, 4 RUNNING, 11 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.53  |  0.18  |                   56 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.311 |  0.163 |                   51 |
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.415 |  0.164 |                    9 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.633 |  0.198 |                    3 |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=158989)[0m rmse: 0.16284358501434326
[2m[36m(func pid=158989)[0m mae:  0.11642658710479736
[2m[36m(func pid=158989)[0m rmse_per_class: [0.1, 0.259, 0.06, 0.309, 0.071, 0.185, 0.262, 0.13, 0.145, 0.108]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=157328)[0m rmse: 0.17963510751724243
[2m[36m(func pid=157328)[0m mae:  0.131122425198555
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.099, 0.193, 0.301, 0.15, 0.14, 0.121]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.16075953841209412
[2m[36m(func pid=167906)[0m mae:  0.10826871544122696
[2m[36m(func pid=167906)[0m rmse_per_class: [0.1, 0.252, 0.046, 0.327, 0.055, 0.18, 0.247, 0.141, 0.17, 0.09]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.5517 | Steps: 2 | Val loss: 0.4155 | Batch size: 32 | lr: 0.1 | Duration: 3.07s
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.3100 | Steps: 2 | Val loss: 0.2959 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.5207 | Steps: 2 | Val loss: 0.4155 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=169734)[0m rmse: 0.1792120486497879
[2m[36m(func pid=169734)[0m mae:  0.11216463148593903
[2m[36m(func pid=169734)[0m rmse_per_class: [0.09, 0.238, 0.044, 0.359, 0.056, 0.166, 0.432, 0.155, 0.155, 0.097]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.3440 | Steps: 2 | Val loss: 0.3205 | Batch size: 32 | lr: 0.01 | Duration: 3.10s
== Status ==
Current time: 2024-01-07 08:58:36 (running for 00:26:37.81)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: -0.15650000423192978
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 8 PENDING, 4 RUNNING, 11 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.525 |  0.18  |                   57 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.31  |  0.163 |                   52 |
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.383 |  0.161 |                   10 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.552 |  0.179 |                    4 |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=158989)[0m rmse: 0.1626395881175995
[2m[36m(func pid=158989)[0m mae:  0.11626052856445312
[2m[36m(func pid=158989)[0m rmse_per_class: [0.1, 0.259, 0.06, 0.309, 0.071, 0.185, 0.261, 0.13, 0.144, 0.108]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=157328)[0m rmse: 0.17948493361473083
[2m[36m(func pid=157328)[0m mae:  0.1309889853000641
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.099, 0.193, 0.301, 0.149, 0.14, 0.12]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.15790027379989624
[2m[36m(func pid=167906)[0m mae:  0.10615984350442886
[2m[36m(func pid=167906)[0m rmse_per_class: [0.1, 0.247, 0.043, 0.32, 0.055, 0.178, 0.236, 0.139, 0.171, 0.089]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.3716 | Steps: 2 | Val loss: 0.3302 | Batch size: 32 | lr: 0.1 | Duration: 3.11s
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.3100 | Steps: 2 | Val loss: 0.2957 | Batch size: 32 | lr: 0.001 | Duration: 2.71s
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.5184 | Steps: 2 | Val loss: 0.4134 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.3205 | Steps: 2 | Val loss: 0.3013 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=169734)[0m rmse: 0.16175103187561035
[2m[36m(func pid=169734)[0m mae:  0.10058508813381195
[2m[36m(func pid=169734)[0m rmse_per_class: [0.108, 0.222, 0.032, 0.299, 0.056, 0.241, 0.209, 0.153, 0.201, 0.097]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=158989)[0m rmse: 0.16251111030578613
[2m[36m(func pid=158989)[0m mae:  0.11615191400051117
[2m[36m(func pid=158989)[0m rmse_per_class: [0.1, 0.258, 0.059, 0.309, 0.071, 0.184, 0.261, 0.13, 0.145, 0.107]
[2m[36m(func pid=158989)[0m 
== Status ==
Current time: 2024-01-07 08:58:42 (running for 00:26:43.74)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: -0.15650000423192978
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 8 PENDING, 4 RUNNING, 11 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.518 |  0.18  |                   59 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.31  |  0.163 |                   53 |
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.344 |  0.158 |                   11 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.372 |  0.162 |                    5 |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=157328)[0m rmse: 0.1795666664838791
[2m[36m(func pid=157328)[0m mae:  0.13105569779872894
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.1, 0.193, 0.301, 0.149, 0.141, 0.121]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.15506389737129211
[2m[36m(func pid=167906)[0m mae:  0.10433705151081085
[2m[36m(func pid=167906)[0m rmse_per_class: [0.099, 0.243, 0.042, 0.311, 0.054, 0.178, 0.225, 0.135, 0.173, 0.089]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.3323 | Steps: 2 | Val loss: 0.3143 | Batch size: 32 | lr: 0.1 | Duration: 3.07s
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.3084 | Steps: 2 | Val loss: 0.2956 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.5110 | Steps: 2 | Val loss: 0.4110 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.2930 | Steps: 2 | Val loss: 0.2864 | Batch size: 32 | lr: 0.01 | Duration: 3.12s
[2m[36m(func pid=158989)[0m rmse: 0.16240859031677246
[2m[36m(func pid=158989)[0m mae:  0.11603154987096786
[2m[36m(func pid=158989)[0m rmse_per_class: [0.1, 0.258, 0.059, 0.308, 0.071, 0.184, 0.261, 0.13, 0.145, 0.108]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=169734)[0m rmse: 0.15849696099758148
[2m[36m(func pid=169734)[0m mae:  0.09902898967266083
[2m[36m(func pid=169734)[0m rmse_per_class: [0.066, 0.204, 0.025, 0.272, 0.056, 0.216, 0.273, 0.128, 0.25, 0.093]
[2m[36m(func pid=169734)[0m 
== Status ==
Current time: 2024-01-07 08:58:48 (running for 00:26:48.99)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: -0.15650000423192978
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 8 PENDING, 4 RUNNING, 11 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.511 |  0.179 |                   60 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.308 |  0.162 |                   54 |
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.321 |  0.155 |                   12 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.332 |  0.158 |                    6 |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=157328)[0m rmse: 0.1794772446155548
[2m[36m(func pid=157328)[0m mae:  0.13100562989711761
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.099, 0.193, 0.301, 0.148, 0.141, 0.121]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.15245530009269714
[2m[36m(func pid=167906)[0m mae:  0.10297390073537827
[2m[36m(func pid=167906)[0m rmse_per_class: [0.099, 0.239, 0.041, 0.302, 0.054, 0.178, 0.22, 0.13, 0.172, 0.088]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.3098 | Steps: 2 | Val loss: 0.2954 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.3160 | Steps: 2 | Val loss: 0.3104 | Batch size: 32 | lr: 0.1 | Duration: 3.25s
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.5090 | Steps: 2 | Val loss: 0.4080 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=158989)[0m rmse: 0.162313312292099
[2m[36m(func pid=158989)[0m mae:  0.11594714224338531
[2m[36m(func pid=158989)[0m rmse_per_class: [0.1, 0.258, 0.059, 0.308, 0.071, 0.184, 0.26, 0.129, 0.146, 0.108]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.2781 | Steps: 2 | Val loss: 0.2769 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=169734)[0m rmse: 0.16462531685829163
[2m[36m(func pid=169734)[0m mae:  0.09801431745290756
[2m[36m(func pid=169734)[0m rmse_per_class: [0.086, 0.238, 0.031, 0.351, 0.056, 0.157, 0.262, 0.132, 0.246, 0.087]
== Status ==
Current time: 2024-01-07 08:58:53 (running for 00:26:54.04)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: -0.15650000423192978
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 8 PENDING, 4 RUNNING, 11 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.511 |  0.179 |                   60 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.31  |  0.162 |                   55 |
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.293 |  0.152 |                   13 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.316 |  0.165 |                    7 |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=157328)[0m rmse: 0.17945249378681183
[2m[36m(func pid=157328)[0m mae:  0.13096320629119873
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.099, 0.193, 0.301, 0.148, 0.141, 0.121]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.15051910281181335
[2m[36m(func pid=167906)[0m mae:  0.10215155780315399
[2m[36m(func pid=167906)[0m rmse_per_class: [0.097, 0.236, 0.04, 0.293, 0.054, 0.177, 0.224, 0.124, 0.172, 0.087]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.2963 | Steps: 2 | Val loss: 0.2952 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.2916 | Steps: 2 | Val loss: 0.3195 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.5072 | Steps: 2 | Val loss: 0.4054 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=158989)[0m rmse: 0.16219140589237213
[2m[36m(func pid=158989)[0m mae:  0.11582187563180923
[2m[36m(func pid=158989)[0m rmse_per_class: [0.1, 0.258, 0.058, 0.309, 0.071, 0.184, 0.26, 0.129, 0.145, 0.107]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.2684 | Steps: 2 | Val loss: 0.2710 | Batch size: 32 | lr: 0.01 | Duration: 3.17s
== Status ==
Current time: 2024-01-07 08:58:58 (running for 00:26:59.58)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: -0.15650000423192978
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 8 PENDING, 4 RUNNING, 11 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.509 |  0.179 |                   61 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.296 |  0.162 |                   56 |
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.278 |  0.151 |                   14 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.292 |  0.164 |                    8 |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=169734)[0m rmse: 0.16422542929649353
[2m[36m(func pid=169734)[0m mae:  0.09690525382757187
[2m[36m(func pid=169734)[0m rmse_per_class: [0.091, 0.274, 0.039, 0.3, 0.054, 0.187, 0.244, 0.136, 0.198, 0.121]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=157328)[0m rmse: 0.17945852875709534
[2m[36m(func pid=157328)[0m mae:  0.1309598982334137
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.1, 0.193, 0.3, 0.148, 0.141, 0.121]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.3190 | Steps: 2 | Val loss: 0.2949 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=167906)[0m rmse: 0.14817164838314056
[2m[36m(func pid=167906)[0m mae:  0.10100338608026505
[2m[36m(func pid=167906)[0m rmse_per_class: [0.095, 0.234, 0.038, 0.284, 0.054, 0.175, 0.233, 0.117, 0.164, 0.087]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.5021 | Steps: 2 | Val loss: 0.4032 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.3061 | Steps: 2 | Val loss: 0.3207 | Batch size: 32 | lr: 0.1 | Duration: 3.19s
[2m[36m(func pid=158989)[0m rmse: 0.1620272397994995
[2m[36m(func pid=158989)[0m mae:  0.11568991094827652
[2m[36m(func pid=158989)[0m rmse_per_class: [0.1, 0.257, 0.059, 0.308, 0.071, 0.184, 0.26, 0.129, 0.146, 0.107]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.2686 | Steps: 2 | Val loss: 0.2688 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
== Status ==
Current time: 2024-01-07 08:59:04 (running for 00:27:05.09)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: -0.15650000423192978
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 8 PENDING, 4 RUNNING, 11 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.502 |  0.179 |                   63 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.319 |  0.162 |                   57 |
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.268 |  0.148 |                   15 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.292 |  0.164 |                    8 |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=157328)[0m rmse: 0.17945705354213715
[2m[36m(func pid=157328)[0m mae:  0.1309516280889511
[2m[36m(func pid=157328)[0m rmse_per_class: [0.108, 0.269, 0.091, 0.326, 0.099, 0.193, 0.3, 0.148, 0.141, 0.121]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=169734)[0m rmse: 0.16880255937576294
[2m[36m(func pid=169734)[0m mae:  0.10228681564331055
[2m[36m(func pid=169734)[0m rmse_per_class: [0.075, 0.274, 0.04, 0.273, 0.051, 0.192, 0.344, 0.125, 0.181, 0.133]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.3098 | Steps: 2 | Val loss: 0.2947 | Batch size: 32 | lr: 0.001 | Duration: 2.67s
[2m[36m(func pid=167906)[0m rmse: 0.1467152088880539
[2m[36m(func pid=167906)[0m mae:  0.10052677243947983
[2m[36m(func pid=167906)[0m rmse_per_class: [0.091, 0.232, 0.037, 0.278, 0.054, 0.172, 0.243, 0.112, 0.16, 0.088]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.5003 | Steps: 2 | Val loss: 0.4010 | Batch size: 32 | lr: 0.0001 | Duration: 3.07s
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.2725 | Steps: 2 | Val loss: 0.2998 | Batch size: 32 | lr: 0.1 | Duration: 3.13s
[2m[36m(func pid=158989)[0m rmse: 0.16190829873085022
[2m[36m(func pid=158989)[0m mae:  0.11556875705718994
[2m[36m(func pid=158989)[0m rmse_per_class: [0.099, 0.257, 0.058, 0.309, 0.071, 0.184, 0.26, 0.129, 0.146, 0.107]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.2634 | Steps: 2 | Val loss: 0.2683 | Batch size: 32 | lr: 0.01 | Duration: 3.06s
== Status ==
Current time: 2024-01-07 08:59:09 (running for 00:27:10.63)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: -0.15650000423192978
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 8 PENDING, 4 RUNNING, 11 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.5   |  0.179 |                   64 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.31  |  0.162 |                   58 |
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.269 |  0.147 |                   16 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.306 |  0.169 |                    9 |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=157328)[0m rmse: 0.17933523654937744
[2m[36m(func pid=157328)[0m mae:  0.130855992436409
[2m[36m(func pid=157328)[0m rmse_per_class: [0.108, 0.269, 0.09, 0.326, 0.099, 0.193, 0.3, 0.148, 0.141, 0.121]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=169734)[0m rmse: 0.1597636640071869
[2m[36m(func pid=169734)[0m mae:  0.09889865666627884
[2m[36m(func pid=169734)[0m rmse_per_class: [0.092, 0.251, 0.035, 0.306, 0.049, 0.174, 0.287, 0.122, 0.183, 0.099]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.3016 | Steps: 2 | Val loss: 0.2941 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=167906)[0m rmse: 0.1459622085094452
[2m[36m(func pid=167906)[0m mae:  0.10021766275167465
[2m[36m(func pid=167906)[0m rmse_per_class: [0.086, 0.231, 0.036, 0.273, 0.053, 0.171, 0.251, 0.111, 0.156, 0.091]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.4993 | Steps: 2 | Val loss: 0.3989 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=158989)[0m rmse: 0.16157811880111694
[2m[36m(func pid=158989)[0m mae:  0.11527486890554428
[2m[36m(func pid=158989)[0m rmse_per_class: [0.099, 0.257, 0.058, 0.308, 0.071, 0.184, 0.259, 0.129, 0.145, 0.107]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.2551 | Steps: 2 | Val loss: 0.2832 | Batch size: 32 | lr: 0.1 | Duration: 3.11s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.2583 | Steps: 2 | Val loss: 0.2700 | Batch size: 32 | lr: 0.01 | Duration: 3.10s
== Status ==
Current time: 2024-01-07 08:59:15 (running for 00:27:15.93)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: -0.15650000423192978
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 8 PENDING, 4 RUNNING, 11 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.499 |  0.179 |                   65 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.302 |  0.162 |                   59 |
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.263 |  0.146 |                   17 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.272 |  0.16  |                   10 |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=157328)[0m rmse: 0.17923834919929504
[2m[36m(func pid=157328)[0m mae:  0.1307615488767624
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.099, 0.193, 0.299, 0.148, 0.141, 0.12]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.3026 | Steps: 2 | Val loss: 0.2939 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=169734)[0m rmse: 0.1490439623594284
[2m[36m(func pid=169734)[0m mae:  0.09306995570659637
[2m[36m(func pid=169734)[0m rmse_per_class: [0.117, 0.227, 0.038, 0.314, 0.049, 0.156, 0.195, 0.117, 0.19, 0.088]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.14674440026283264
[2m[36m(func pid=167906)[0m mae:  0.10101719945669174
[2m[36m(func pid=167906)[0m rmse_per_class: [0.084, 0.232, 0.035, 0.272, 0.053, 0.17, 0.255, 0.114, 0.155, 0.097]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.4941 | Steps: 2 | Val loss: 0.3971 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=158989)[0m rmse: 0.16142037510871887
[2m[36m(func pid=158989)[0m mae:  0.11512410640716553
[2m[36m(func pid=158989)[0m rmse_per_class: [0.099, 0.257, 0.057, 0.308, 0.071, 0.183, 0.259, 0.128, 0.146, 0.106]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.2501 | Steps: 2 | Val loss: 0.2805 | Batch size: 32 | lr: 0.1 | Duration: 3.18s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.2597 | Steps: 2 | Val loss: 0.2722 | Batch size: 32 | lr: 0.01 | Duration: 3.05s
== Status ==
Current time: 2024-01-07 08:59:20 (running for 00:27:21.33)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: -0.15650000423192978
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 8 PENDING, 4 RUNNING, 11 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.494 |  0.179 |                   66 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.303 |  0.161 |                   60 |
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.258 |  0.147 |                   18 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.255 |  0.149 |                   11 |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=157328)[0m rmse: 0.1791965812444687
[2m[36m(func pid=157328)[0m mae:  0.13070984184741974
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.099, 0.193, 0.299, 0.148, 0.141, 0.12]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.3032 | Steps: 2 | Val loss: 0.2939 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=169734)[0m rmse: 0.15035954117774963
[2m[36m(func pid=169734)[0m mae:  0.09453131258487701
[2m[36m(func pid=169734)[0m rmse_per_class: [0.085, 0.223, 0.04, 0.311, 0.05, 0.161, 0.216, 0.124, 0.205, 0.088]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.14779751002788544
[2m[36m(func pid=167906)[0m mae:  0.1017933338880539
[2m[36m(func pid=167906)[0m rmse_per_class: [0.082, 0.233, 0.035, 0.272, 0.054, 0.17, 0.257, 0.119, 0.152, 0.105]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.4929 | Steps: 2 | Val loss: 0.3949 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=158989)[0m rmse: 0.16135895252227783
[2m[36m(func pid=158989)[0m mae:  0.1150466576218605
[2m[36m(func pid=158989)[0m rmse_per_class: [0.099, 0.257, 0.057, 0.308, 0.071, 0.183, 0.259, 0.128, 0.146, 0.106]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.2617 | Steps: 2 | Val loss: 0.2798 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.2658 | Steps: 2 | Val loss: 0.2731 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
== Status ==
Current time: 2024-01-07 08:59:25 (running for 00:27:26.51)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: -0.15650000423192978
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 8 PENDING, 4 RUNNING, 11 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.179 |                   67 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.303 |  0.161 |                   61 |
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.26  |  0.148 |                   19 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.25  |  0.15  |                   12 |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=157328)[0m rmse: 0.17917343974113464
[2m[36m(func pid=157328)[0m mae:  0.130691796541214
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.099, 0.193, 0.299, 0.148, 0.141, 0.12]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.3033 | Steps: 2 | Val loss: 0.2935 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=169734)[0m rmse: 0.15154005587100983
[2m[36m(func pid=169734)[0m mae:  0.09464435279369354
[2m[36m(func pid=169734)[0m rmse_per_class: [0.083, 0.23, 0.041, 0.306, 0.051, 0.15, 0.221, 0.128, 0.217, 0.089]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.14788761734962463
[2m[36m(func pid=167906)[0m mae:  0.10140347480773926
[2m[36m(func pid=167906)[0m rmse_per_class: [0.08, 0.234, 0.034, 0.27, 0.055, 0.17, 0.252, 0.124, 0.148, 0.111]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.4892 | Steps: 2 | Val loss: 0.3932 | Batch size: 32 | lr: 0.0001 | Duration: 2.81s
[2m[36m(func pid=158989)[0m rmse: 0.16118422150611877
[2m[36m(func pid=158989)[0m mae:  0.11492379009723663
[2m[36m(func pid=158989)[0m rmse_per_class: [0.099, 0.257, 0.057, 0.307, 0.071, 0.183, 0.259, 0.128, 0.146, 0.106]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.2563 | Steps: 2 | Val loss: 0.2741 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 08:59:30 (running for 00:27:31.63)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: -0.15650000423192978
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 8 PENDING, 4 RUNNING, 11 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.489 |  0.179 |                   68 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.303 |  0.161 |                   62 |
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.148 |                   20 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.262 |  0.152 |                   13 |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=157328)[0m rmse: 0.17914070188999176
[2m[36m(func pid=157328)[0m mae:  0.13068632781505585
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.098, 0.193, 0.3, 0.148, 0.141, 0.12]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.2539 | Steps: 2 | Val loss: 0.2756 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.2974 | Steps: 2 | Val loss: 0.2926 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=169734)[0m rmse: 0.14757567644119263
[2m[36m(func pid=169734)[0m mae:  0.0909648910164833
[2m[36m(func pid=169734)[0m rmse_per_class: [0.083, 0.227, 0.038, 0.291, 0.051, 0.161, 0.195, 0.122, 0.218, 0.091]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.14859387278556824
[2m[36m(func pid=167906)[0m mae:  0.10185800492763519
[2m[36m(func pid=167906)[0m rmse_per_class: [0.08, 0.236, 0.034, 0.273, 0.058, 0.17, 0.247, 0.125, 0.147, 0.115]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.4859 | Steps: 2 | Val loss: 0.3909 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=158989)[0m rmse: 0.16061437129974365
[2m[36m(func pid=158989)[0m mae:  0.11435268819332123
[2m[36m(func pid=158989)[0m rmse_per_class: [0.098, 0.256, 0.056, 0.306, 0.07, 0.183, 0.258, 0.129, 0.145, 0.106]
[2m[36m(func pid=158989)[0m 
== Status ==
Current time: 2024-01-07 08:59:36 (running for 00:27:36.96)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: -0.15650000423192978
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 8 PENDING, 4 RUNNING, 11 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.486 |  0.179 |                   69 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.297 |  0.161 |                   63 |
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.254 |  0.149 |                   21 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.256 |  0.148 |                   14 |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=157328)[0m rmse: 0.1790061593055725
[2m[36m(func pid=157328)[0m mae:  0.13056537508964539
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.269, 0.089, 0.325, 0.098, 0.193, 0.299, 0.148, 0.141, 0.12]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.2496 | Steps: 2 | Val loss: 0.2741 | Batch size: 32 | lr: 0.1 | Duration: 3.05s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.2492 | Steps: 2 | Val loss: 0.2779 | Batch size: 32 | lr: 0.01 | Duration: 3.09s
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.2953 | Steps: 2 | Val loss: 0.2925 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=169734)[0m rmse: 0.14694678783416748
[2m[36m(func pid=169734)[0m mae:  0.09050954878330231
[2m[36m(func pid=169734)[0m rmse_per_class: [0.111, 0.227, 0.034, 0.288, 0.051, 0.163, 0.19, 0.114, 0.195, 0.097]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.4854 | Steps: 2 | Val loss: 0.3892 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=167906)[0m rmse: 0.14851242303848267
[2m[36m(func pid=167906)[0m mae:  0.10168471187353134
[2m[36m(func pid=167906)[0m rmse_per_class: [0.081, 0.237, 0.034, 0.277, 0.061, 0.17, 0.239, 0.122, 0.146, 0.118]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=158989)[0m rmse: 0.16051554679870605
[2m[36m(func pid=158989)[0m mae:  0.11427278816699982
[2m[36m(func pid=158989)[0m rmse_per_class: [0.098, 0.256, 0.056, 0.306, 0.07, 0.183, 0.257, 0.128, 0.145, 0.105]
[2m[36m(func pid=158989)[0m 
== Status ==
Current time: 2024-01-07 08:59:41 (running for 00:27:42.33)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: -0.15650000423192978
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 8 PENDING, 4 RUNNING, 11 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.485 |  0.179 |                   70 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.295 |  0.161 |                   64 |
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.249 |  0.149 |                   22 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.25  |  0.147 |                   15 |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=157328)[0m rmse: 0.17898401618003845
[2m[36m(func pid=157328)[0m mae:  0.13053329288959503
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.269, 0.089, 0.325, 0.098, 0.193, 0.299, 0.147, 0.141, 0.12]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.2446 | Steps: 2 | Val loss: 0.2749 | Batch size: 32 | lr: 0.1 | Duration: 3.20s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.2512 | Steps: 2 | Val loss: 0.2795 | Batch size: 32 | lr: 0.01 | Duration: 3.16s
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.2982 | Steps: 2 | Val loss: 0.2926 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.4835 | Steps: 2 | Val loss: 0.3876 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=158989)[0m rmse: 0.16059096157550812
[2m[36m(func pid=158989)[0m mae:  0.1143142431974411
[2m[36m(func pid=158989)[0m rmse_per_class: [0.098, 0.256, 0.056, 0.307, 0.071, 0.183, 0.257, 0.128, 0.146, 0.105]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=169734)[0m rmse: 0.14714035391807556
[2m[36m(func pid=169734)[0m mae:  0.09055516123771667
[2m[36m(func pid=169734)[0m rmse_per_class: [0.127, 0.228, 0.03, 0.291, 0.052, 0.153, 0.189, 0.114, 0.179, 0.108]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.14795038104057312
[2m[36m(func pid=167906)[0m mae:  0.10091346502304077
[2m[36m(func pid=167906)[0m rmse_per_class: [0.081, 0.238, 0.035, 0.28, 0.065, 0.17, 0.231, 0.121, 0.145, 0.114]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=157328)[0m rmse: 0.1789073348045349
[2m[36m(func pid=157328)[0m mae:  0.13047298789024353
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.269, 0.089, 0.325, 0.098, 0.193, 0.299, 0.147, 0.141, 0.119]
== Status ==
Current time: 2024-01-07 08:59:46 (running for 00:27:47.84)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: -0.15650000423192978
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 8 PENDING, 4 RUNNING, 11 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.483 |  0.179 |                   71 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.298 |  0.161 |                   65 |
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.251 |  0.148 |                   23 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.245 |  0.147 |                   16 |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.2990 | Steps: 2 | Val loss: 0.2923 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.2436 | Steps: 2 | Val loss: 0.2683 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.2434 | Steps: 2 | Val loss: 0.2808 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.4817 | Steps: 2 | Val loss: 0.3857 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=158989)[0m rmse: 0.16033890843391418
[2m[36m(func pid=158989)[0m mae:  0.11409275233745575
[2m[36m(func pid=158989)[0m rmse_per_class: [0.098, 0.256, 0.056, 0.306, 0.07, 0.182, 0.257, 0.128, 0.146, 0.105]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.14720186591148376
[2m[36m(func pid=167906)[0m mae:  0.10025294870138168
[2m[36m(func pid=167906)[0m rmse_per_class: [0.081, 0.238, 0.035, 0.285, 0.069, 0.169, 0.224, 0.117, 0.144, 0.109]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=169734)[0m rmse: 0.14272916316986084
[2m[36m(func pid=169734)[0m mae:  0.08807237446308136
[2m[36m(func pid=169734)[0m rmse_per_class: [0.102, 0.224, 0.029, 0.278, 0.054, 0.144, 0.198, 0.115, 0.177, 0.107]
[2m[36m(func pid=169734)[0m 
== Status ==
Current time: 2024-01-07 08:59:52 (running for 00:27:53.29)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: -0.15650000423192978
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 8 PENDING, 4 RUNNING, 11 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.482 |  0.179 |                   72 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.299 |  0.16  |                   66 |
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.243 |  0.147 |                   24 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.244 |  0.143 |                   17 |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=157328)[0m rmse: 0.1788969486951828
[2m[36m(func pid=157328)[0m mae:  0.13044586777687073
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.269, 0.089, 0.325, 0.098, 0.193, 0.298, 0.147, 0.141, 0.119]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.2938 | Steps: 2 | Val loss: 0.2922 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.2450 | Steps: 2 | Val loss: 0.2808 | Batch size: 32 | lr: 0.01 | Duration: 3.13s
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.2380 | Steps: 2 | Val loss: 0.2657 | Batch size: 32 | lr: 0.1 | Duration: 3.20s
[2m[36m(func pid=158989)[0m rmse: 0.1602710783481598
[2m[36m(func pid=158989)[0m mae:  0.11398486793041229
[2m[36m(func pid=158989)[0m rmse_per_class: [0.098, 0.256, 0.056, 0.306, 0.07, 0.182, 0.256, 0.128, 0.145, 0.105]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.4779 | Steps: 2 | Val loss: 0.3838 | Batch size: 32 | lr: 0.0001 | Duration: 2.81s
[2m[36m(func pid=167906)[0m rmse: 0.14604803919792175
[2m[36m(func pid=167906)[0m mae:  0.09913347661495209
[2m[36m(func pid=167906)[0m rmse_per_class: [0.081, 0.237, 0.036, 0.287, 0.071, 0.168, 0.219, 0.115, 0.143, 0.104]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=169734)[0m rmse: 0.14232417941093445
[2m[36m(func pid=169734)[0m mae:  0.08749266713857651
[2m[36m(func pid=169734)[0m rmse_per_class: [0.077, 0.222, 0.032, 0.265, 0.061, 0.146, 0.217, 0.119, 0.186, 0.099]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=157328)[0m rmse: 0.17889317870140076
[2m[36m(func pid=157328)[0m mae:  0.13041679561138153
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.27, 0.089, 0.325, 0.099, 0.193, 0.298, 0.147, 0.141, 0.119]
== Status ==
Current time: 2024-01-07 08:59:57 (running for 00:27:58.55)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: -0.15650000423192978
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 8 PENDING, 4 RUNNING, 11 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.478 |  0.179 |                   73 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.294 |  0.16  |                   67 |
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.245 |  0.146 |                   25 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.238 |  0.142 |                   18 |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.3005 | Steps: 2 | Val loss: 0.2917 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.2524 | Steps: 2 | Val loss: 0.2818 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.2397 | Steps: 2 | Val loss: 0.2640 | Batch size: 32 | lr: 0.1 | Duration: 3.18s
[2m[36m(func pid=158989)[0m rmse: 0.16000236570835114
[2m[36m(func pid=158989)[0m mae:  0.11369781196117401
[2m[36m(func pid=158989)[0m rmse_per_class: [0.097, 0.256, 0.055, 0.306, 0.07, 0.182, 0.256, 0.128, 0.145, 0.105]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.4751 | Steps: 2 | Val loss: 0.3821 | Batch size: 32 | lr: 0.0001 | Duration: 2.78s
[2m[36m(func pid=167906)[0m rmse: 0.1456155627965927
[2m[36m(func pid=167906)[0m mae:  0.09857586026191711
[2m[36m(func pid=167906)[0m rmse_per_class: [0.083, 0.236, 0.036, 0.289, 0.071, 0.168, 0.215, 0.113, 0.145, 0.101]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=169734)[0m rmse: 0.14209774136543274
[2m[36m(func pid=169734)[0m mae:  0.08656620979309082
[2m[36m(func pid=169734)[0m rmse_per_class: [0.073, 0.22, 0.034, 0.259, 0.068, 0.149, 0.215, 0.119, 0.194, 0.089]
[2m[36m(func pid=169734)[0m 
== Status ==
Current time: 2024-01-07 09:00:02 (running for 00:28:03.68)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: -0.15650000423192978
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 8 PENDING, 4 RUNNING, 11 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.475 |  0.179 |                   74 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.301 |  0.16  |                   68 |
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.252 |  0.146 |                   26 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.24  |  0.142 |                   19 |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=157328)[0m rmse: 0.17883779108524323
[2m[36m(func pid=157328)[0m mae:  0.1303582489490509
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.098, 0.193, 0.298, 0.147, 0.142, 0.119]
[2m[36m(func pid=157328)[0m 
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.2916 | Steps: 2 | Val loss: 0.2912 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.2437 | Steps: 2 | Val loss: 0.2819 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.2326 | Steps: 2 | Val loss: 0.2585 | Batch size: 32 | lr: 0.1 | Duration: 3.16s
[2m[36m(func pid=158989)[0m rmse: 0.15968060493469238
[2m[36m(func pid=158989)[0m mae:  0.11340762674808502
[2m[36m(func pid=158989)[0m rmse_per_class: [0.097, 0.255, 0.055, 0.305, 0.07, 0.182, 0.255, 0.128, 0.145, 0.105]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=157328)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.4719 | Steps: 2 | Val loss: 0.3803 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=167906)[0m rmse: 0.14506366848945618
[2m[36m(func pid=167906)[0m mae:  0.09786180406808853
[2m[36m(func pid=167906)[0m rmse_per_class: [0.083, 0.235, 0.036, 0.293, 0.07, 0.167, 0.212, 0.113, 0.145, 0.097]
[2m[36m(func pid=167906)[0m 
== Status ==
Current time: 2024-01-07 09:00:07 (running for 00:28:08.77)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: -0.15650000423192978
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 8 PENDING, 4 RUNNING, 11 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00012 | RUNNING    | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.475 |  0.179 |                   74 |
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.292 |  0.16  |                   69 |
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.244 |  0.145 |                   27 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.233 |  0.139 |                   20 |
| train_d77f6_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=169734)[0m rmse: 0.138607919216156
[2m[36m(func pid=169734)[0m mae:  0.08407549560070038
[2m[36m(func pid=169734)[0m rmse_per_class: [0.072, 0.218, 0.034, 0.256, 0.069, 0.151, 0.197, 0.115, 0.187, 0.086]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=157328)[0m rmse: 0.1787732094526291
[2m[36m(func pid=157328)[0m mae:  0.13028603792190552
[2m[36m(func pid=157328)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.326, 0.098, 0.193, 0.298, 0.147, 0.142, 0.119]
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.2899 | Steps: 2 | Val loss: 0.2911 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.2414 | Steps: 2 | Val loss: 0.2810 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=158989)[0m rmse: 0.15958337485790253
[2m[36m(func pid=158989)[0m mae:  0.1133531928062439
[2m[36m(func pid=158989)[0m rmse_per_class: [0.097, 0.255, 0.055, 0.305, 0.07, 0.182, 0.255, 0.128, 0.145, 0.105]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.2378 | Steps: 2 | Val loss: 0.2581 | Batch size: 32 | lr: 0.1 | Duration: 3.24s
[2m[36m(func pid=167906)[0m rmse: 0.14436694979667664
[2m[36m(func pid=167906)[0m mae:  0.09716896712779999
[2m[36m(func pid=167906)[0m rmse_per_class: [0.085, 0.234, 0.036, 0.293, 0.067, 0.167, 0.21, 0.112, 0.145, 0.094]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.2961 | Steps: 2 | Val loss: 0.2907 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=169734)[0m rmse: 0.13795919716358185
[2m[36m(func pid=169734)[0m mae:  0.08412420004606247
[2m[36m(func pid=169734)[0m rmse_per_class: [0.078, 0.218, 0.031, 0.259, 0.07, 0.152, 0.19, 0.115, 0.18, 0.087]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.2382 | Steps: 2 | Val loss: 0.2797 | Batch size: 32 | lr: 0.01 | Duration: 3.19s
[2m[36m(func pid=158989)[0m rmse: 0.15937206149101257
[2m[36m(func pid=158989)[0m mae:  0.11319991201162338
[2m[36m(func pid=158989)[0m rmse_per_class: [0.097, 0.254, 0.055, 0.305, 0.07, 0.182, 0.255, 0.128, 0.145, 0.105]
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.2412 | Steps: 2 | Val loss: 0.2610 | Batch size: 32 | lr: 0.1 | Duration: 3.21s
== Status ==
Current time: 2024-01-07 09:00:13 (running for 00:28:14.65)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 7 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.29  |  0.16  |                   70 |
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.241 |  0.144 |                   28 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.238 |  0.138 |                   21 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=174732)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=174732)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=174732)[0m Configuration completed!
[2m[36m(func pid=174732)[0m New optimizer parameters:
[2m[36m(func pid=174732)[0m SGD (
[2m[36m(func pid=174732)[0m Parameter Group 0
[2m[36m(func pid=174732)[0m     dampening: 0
[2m[36m(func pid=174732)[0m     differentiable: False
[2m[36m(func pid=174732)[0m     foreach: None
[2m[36m(func pid=174732)[0m     lr: 0.0001
[2m[36m(func pid=174732)[0m     maximize: False
[2m[36m(func pid=174732)[0m     momentum: 0.99
[2m[36m(func pid=174732)[0m     nesterov: False
[2m[36m(func pid=174732)[0m     weight_decay: 1e-05
[2m[36m(func pid=174732)[0m )
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.1437692642211914
[2m[36m(func pid=167906)[0m mae:  0.09663833677768707
[2m[36m(func pid=167906)[0m rmse_per_class: [0.085, 0.232, 0.036, 0.293, 0.066, 0.167, 0.209, 0.112, 0.146, 0.092]
[2m[36m(func pid=167906)[0m 
== Status ==
Current time: 2024-01-07 09:00:19 (running for 00:28:20.60)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 7 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.296 |  0.159 |                   71 |
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.238 |  0.144 |                   29 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.241 |  0.139 |                   22 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=169734)[0m rmse: 0.13936935365200043
[2m[36m(func pid=169734)[0m mae:  0.08576877415180206
[2m[36m(func pid=169734)[0m rmse_per_class: [0.086, 0.22, 0.027, 0.268, 0.068, 0.147, 0.192, 0.115, 0.178, 0.091]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.2912 | Steps: 2 | Val loss: 0.2902 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.2406 | Steps: 2 | Val loss: 0.2788 | Batch size: 32 | lr: 0.01 | Duration: 3.09s
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 1.0857 | Steps: 2 | Val loss: 0.8103 | Batch size: 32 | lr: 0.0001 | Duration: 4.73s
[2m[36m(func pid=158989)[0m rmse: 0.15905669331550598
[2m[36m(func pid=158989)[0m mae:  0.11290297657251358
[2m[36m(func pid=158989)[0m rmse_per_class: [0.096, 0.254, 0.055, 0.304, 0.07, 0.181, 0.255, 0.127, 0.144, 0.104]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.2377 | Steps: 2 | Val loss: 0.2624 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=167906)[0m rmse: 0.14327123761177063
[2m[36m(func pid=167906)[0m mae:  0.09617339074611664
[2m[36m(func pid=167906)[0m rmse_per_class: [0.084, 0.231, 0.036, 0.293, 0.064, 0.167, 0.209, 0.112, 0.145, 0.091]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=174732)[0m rmse: 0.17862114310264587
[2m[36m(func pid=174732)[0m mae:  0.13115194439888
[2m[36m(func pid=174732)[0m rmse_per_class: [0.105, 0.266, 0.086, 0.325, 0.1, 0.192, 0.304, 0.153, 0.139, 0.116]
[2m[36m(func pid=174732)[0m 
== Status ==
Current time: 2024-01-07 09:00:25 (running for 00:28:26.16)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 7 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.291 |  0.159 |                   72 |
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.241 |  0.143 |                   30 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.238 |  0.14  |                   23 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  1.086 |  0.179 |                    1 |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=169734)[0m rmse: 0.14047789573669434
[2m[36m(func pid=169734)[0m mae:  0.08726423233747482
[2m[36m(func pid=169734)[0m rmse_per_class: [0.082, 0.221, 0.026, 0.275, 0.064, 0.147, 0.198, 0.121, 0.172, 0.099]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.2870 | Steps: 2 | Val loss: 0.2899 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.2409 | Steps: 2 | Val loss: 0.2773 | Batch size: 32 | lr: 0.01 | Duration: 3.13s
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 1.0809 | Steps: 2 | Val loss: 0.8107 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=158989)[0m rmse: 0.15885794162750244
[2m[36m(func pid=158989)[0m mae:  0.11272527277469635
[2m[36m(func pid=158989)[0m rmse_per_class: [0.096, 0.253, 0.055, 0.304, 0.07, 0.181, 0.254, 0.127, 0.144, 0.103]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.2355 | Steps: 2 | Val loss: 0.2625 | Batch size: 32 | lr: 0.1 | Duration: 3.16s
[2m[36m(func pid=167906)[0m rmse: 0.14253540337085724
[2m[36m(func pid=167906)[0m mae:  0.09554363787174225
[2m[36m(func pid=167906)[0m rmse_per_class: [0.084, 0.23, 0.037, 0.288, 0.063, 0.166, 0.211, 0.112, 0.145, 0.09]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=174732)[0m rmse: 0.1790522038936615
[2m[36m(func pid=174732)[0m mae:  0.13148853182792664
[2m[36m(func pid=174732)[0m rmse_per_class: [0.104, 0.266, 0.088, 0.325, 0.102, 0.193, 0.305, 0.154, 0.139, 0.116]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.2864 | Steps: 2 | Val loss: 0.2895 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 09:00:31 (running for 00:28:32.01)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 7 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.287 |  0.159 |                   73 |
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.241 |  0.143 |                   31 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.236 |  0.141 |                   24 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  1.081 |  0.179 |                    2 |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=169734)[0m rmse: 0.14083200693130493
[2m[36m(func pid=169734)[0m mae:  0.08792625367641449
[2m[36m(func pid=169734)[0m rmse_per_class: [0.08, 0.219, 0.028, 0.28, 0.064, 0.147, 0.199, 0.123, 0.167, 0.102]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.2369 | Steps: 2 | Val loss: 0.2770 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 1.0703 | Steps: 2 | Val loss: 0.8116 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=158989)[0m rmse: 0.15862610936164856
[2m[36m(func pid=158989)[0m mae:  0.11252205073833466
[2m[36m(func pid=158989)[0m rmse_per_class: [0.096, 0.253, 0.054, 0.304, 0.07, 0.181, 0.254, 0.127, 0.143, 0.104]
[2m[36m(func pid=158989)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.2430 | Steps: 2 | Val loss: 0.2603 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
[2m[36m(func pid=167906)[0m rmse: 0.1423352062702179
[2m[36m(func pid=167906)[0m mae:  0.09533240646123886
[2m[36m(func pid=167906)[0m rmse_per_class: [0.083, 0.23, 0.037, 0.286, 0.062, 0.167, 0.212, 0.112, 0.145, 0.089]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=174732)[0m rmse: 0.17950120568275452
[2m[36m(func pid=174732)[0m mae:  0.13180474936962128
[2m[36m(func pid=174732)[0m rmse_per_class: [0.104, 0.266, 0.089, 0.325, 0.103, 0.193, 0.307, 0.154, 0.139, 0.117]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=158989)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.2878 | Steps: 2 | Val loss: 0.2892 | Batch size: 32 | lr: 0.001 | Duration: 2.74s
== Status ==
Current time: 2024-01-07 09:00:36 (running for 00:28:37.57)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 7 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00013 | RUNNING    | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.286 |  0.159 |                   74 |
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.237 |  0.142 |                   32 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.243 |  0.139 |                   25 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  1.07  |  0.18  |                    3 |
| train_d77f6_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=169734)[0m rmse: 0.139483243227005
[2m[36m(func pid=169734)[0m mae:  0.08682220429182053
[2m[36m(func pid=169734)[0m rmse_per_class: [0.078, 0.217, 0.03, 0.28, 0.064, 0.148, 0.191, 0.123, 0.167, 0.096]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.2359 | Steps: 2 | Val loss: 0.2762 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 1.0538 | Steps: 2 | Val loss: 0.8071 | Batch size: 32 | lr: 0.0001 | Duration: 2.69s
[2m[36m(func pid=158989)[0m rmse: 0.1584090292453766
[2m[36m(func pid=158989)[0m mae:  0.11231652647256851
[2m[36m(func pid=158989)[0m rmse_per_class: [0.096, 0.252, 0.054, 0.304, 0.07, 0.181, 0.254, 0.127, 0.143, 0.104]
[2m[36m(func pid=167906)[0m rmse: 0.14174731075763702
[2m[36m(func pid=167906)[0m mae:  0.09488416463136673
[2m[36m(func pid=167906)[0m rmse_per_class: [0.084, 0.229, 0.036, 0.282, 0.06, 0.166, 0.215, 0.112, 0.144, 0.089]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=174732)[0m rmse: 0.17986713349819183
[2m[36m(func pid=174732)[0m mae:  0.13209426403045654
[2m[36m(func pid=174732)[0m rmse_per_class: [0.105, 0.266, 0.089, 0.325, 0.104, 0.193, 0.308, 0.154, 0.138, 0.117]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.2330 | Steps: 2 | Val loss: 0.2596 | Batch size: 32 | lr: 0.1 | Duration: 3.31s
[2m[36m(func pid=169734)[0m rmse: 0.13864269852638245
[2m[36m(func pid=169734)[0m mae:  0.08605922013521194
[2m[36m(func pid=169734)[0m rmse_per_class: [0.076, 0.214, 0.03, 0.283, 0.061, 0.151, 0.186, 0.127, 0.167, 0.09]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 1.0423 | Steps: 2 | Val loss: 0.8000 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.2415 | Steps: 2 | Val loss: 0.2758 | Batch size: 32 | lr: 0.01 | Duration: 3.09s
[2m[36m(func pid=167906)[0m rmse: 0.141514390707016
[2m[36m(func pid=167906)[0m mae:  0.09454163908958435
[2m[36m(func pid=167906)[0m rmse_per_class: [0.083, 0.23, 0.036, 0.277, 0.059, 0.166, 0.216, 0.113, 0.146, 0.089]
[2m[36m(func pid=174732)[0m rmse: 0.180129736661911
[2m[36m(func pid=174732)[0m mae:  0.13227979838848114
[2m[36m(func pid=174732)[0m rmse_per_class: [0.105, 0.266, 0.09, 0.324, 0.104, 0.193, 0.308, 0.154, 0.138, 0.118]
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.2321 | Steps: 2 | Val loss: 0.2597 | Batch size: 32 | lr: 0.1 | Duration: 3.23s
== Status ==
Current time: 2024-01-07 09:00:42 (running for 00:28:43.55)
Memory usage on this node: 22.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.236 |  0.142 |                   33 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.233 |  0.139 |                   26 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  1.054 |  0.18  |                    4 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=176115)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=176115)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=176115)[0m Configuration completed!
[2m[36m(func pid=176115)[0m New optimizer parameters:
[2m[36m(func pid=176115)[0m SGD (
[2m[36m(func pid=176115)[0m Parameter Group 0
[2m[36m(func pid=176115)[0m     dampening: 0
[2m[36m(func pid=176115)[0m     differentiable: False
[2m[36m(func pid=176115)[0m     foreach: None
[2m[36m(func pid=176115)[0m     lr: 0.001
[2m[36m(func pid=176115)[0m     maximize: False
[2m[36m(func pid=176115)[0m     momentum: 0.99
[2m[36m(func pid=176115)[0m     nesterov: False
[2m[36m(func pid=176115)[0m     weight_decay: 1e-05
[2m[36m(func pid=176115)[0m )
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=169734)[0m rmse: 0.13827195763587952
[2m[36m(func pid=169734)[0m mae:  0.08620192110538483
[2m[36m(func pid=169734)[0m rmse_per_class: [0.079, 0.211, 0.029, 0.284, 0.061, 0.149, 0.189, 0.129, 0.167, 0.086]
== Status ==
Current time: 2024-01-07 09:00:48 (running for 00:28:49.44)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.241 |  0.142 |                   34 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.232 |  0.138 |                   27 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  1.042 |  0.18  |                    5 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 1.0198 | Steps: 2 | Val loss: 0.7878 | Batch size: 32 | lr: 0.0001 | Duration: 3.01s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.2388 | Steps: 2 | Val loss: 0.2764 | Batch size: 32 | lr: 0.01 | Duration: 3.10s
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.2337 | Steps: 2 | Val loss: 0.2601 | Batch size: 32 | lr: 0.1 | Duration: 3.11s
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 1.0775 | Steps: 2 | Val loss: 0.7930 | Batch size: 32 | lr: 0.001 | Duration: 4.51s
[2m[36m(func pid=174732)[0m rmse: 0.1804317682981491
[2m[36m(func pid=174732)[0m mae:  0.13250069320201874
[2m[36m(func pid=174732)[0m rmse_per_class: [0.105, 0.266, 0.091, 0.324, 0.105, 0.194, 0.309, 0.154, 0.138, 0.119]
[2m[36m(func pid=167906)[0m rmse: 0.14186349511146545
[2m[36m(func pid=167906)[0m mae:  0.09481588006019592
[2m[36m(func pid=167906)[0m rmse_per_class: [0.082, 0.23, 0.036, 0.279, 0.059, 0.166, 0.217, 0.114, 0.147, 0.09]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=174732)[0m 
== Status ==
Current time: 2024-01-07 09:00:54 (running for 00:28:55.23)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.239 |  0.142 |                   35 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.234 |  0.138 |                   28 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  1.02  |  0.18  |                    6 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=169734)[0m rmse: 0.13806305825710297
[2m[36m(func pid=169734)[0m mae:  0.08651770651340485
[2m[36m(func pid=169734)[0m rmse_per_class: [0.079, 0.211, 0.028, 0.282, 0.061, 0.149, 0.192, 0.127, 0.166, 0.086]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=176115)[0m rmse: 0.1786540150642395
[2m[36m(func pid=176115)[0m mae:  0.13117387890815735
[2m[36m(func pid=176115)[0m rmse_per_class: [0.105, 0.266, 0.087, 0.325, 0.1, 0.192, 0.304, 0.153, 0.139, 0.116]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.9928 | Steps: 2 | Val loss: 0.7726 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.2448 | Steps: 2 | Val loss: 0.2768 | Batch size: 32 | lr: 0.01 | Duration: 3.11s
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 1.0325 | Steps: 2 | Val loss: 0.7540 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.2305 | Steps: 2 | Val loss: 0.2612 | Batch size: 32 | lr: 0.1 | Duration: 3.23s
[2m[36m(func pid=174732)[0m rmse: 0.18061266839504242
[2m[36m(func pid=174732)[0m mae:  0.13261637091636658
[2m[36m(func pid=174732)[0m rmse_per_class: [0.105, 0.266, 0.091, 0.324, 0.106, 0.194, 0.309, 0.154, 0.138, 0.119]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.1418830305337906
[2m[36m(func pid=167906)[0m mae:  0.09477037191390991
[2m[36m(func pid=167906)[0m rmse_per_class: [0.081, 0.23, 0.036, 0.279, 0.058, 0.166, 0.216, 0.115, 0.147, 0.092]
[2m[36m(func pid=167906)[0m 
== Status ==
Current time: 2024-01-07 09:00:59 (running for 00:29:00.73)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.245 |  0.142 |                   36 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.234 |  0.138 |                   28 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.993 |  0.181 |                    7 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  1.033 |  0.179 |                    2 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=176115)[0m rmse: 0.17894642055034637
[2m[36m(func pid=176115)[0m mae:  0.13133464753627777
[2m[36m(func pid=176115)[0m rmse_per_class: [0.104, 0.266, 0.087, 0.325, 0.101, 0.192, 0.305, 0.154, 0.139, 0.116]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=169734)[0m rmse: 0.1389976143836975
[2m[36m(func pid=169734)[0m mae:  0.08743453025817871
[2m[36m(func pid=169734)[0m rmse_per_class: [0.08, 0.213, 0.027, 0.282, 0.062, 0.15, 0.194, 0.129, 0.166, 0.087]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.9637 | Steps: 2 | Val loss: 0.7518 | Batch size: 32 | lr: 0.0001 | Duration: 2.77s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.2354 | Steps: 2 | Val loss: 0.2772 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.9508 | Steps: 2 | Val loss: 0.6909 | Batch size: 32 | lr: 0.001 | Duration: 3.09s
[2m[36m(func pid=174732)[0m rmse: 0.18072707951068878
[2m[36m(func pid=174732)[0m mae:  0.13269804418087006
[2m[36m(func pid=174732)[0m rmse_per_class: [0.106, 0.267, 0.091, 0.324, 0.105, 0.194, 0.309, 0.154, 0.138, 0.12]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.2320 | Steps: 2 | Val loss: 0.2645 | Batch size: 32 | lr: 0.1 | Duration: 3.16s
[2m[36m(func pid=167906)[0m rmse: 0.1422746777534485
[2m[36m(func pid=167906)[0m mae:  0.09509964287281036
[2m[36m(func pid=167906)[0m rmse_per_class: [0.081, 0.231, 0.036, 0.281, 0.058, 0.166, 0.216, 0.114, 0.148, 0.092]
[2m[36m(func pid=167906)[0m 
== Status ==
Current time: 2024-01-07 09:01:05 (running for 00:29:06.25)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.235 |  0.142 |                   37 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.23  |  0.139 |                   29 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.964 |  0.181 |                    8 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.951 |  0.179 |                    3 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=176115)[0m rmse: 0.17913594841957092
[2m[36m(func pid=176115)[0m mae:  0.13137343525886536
[2m[36m(func pid=176115)[0m rmse_per_class: [0.104, 0.266, 0.088, 0.324, 0.101, 0.193, 0.305, 0.156, 0.139, 0.115]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=169734)[0m rmse: 0.1416226327419281
[2m[36m(func pid=169734)[0m mae:  0.08924674242734909
[2m[36m(func pid=169734)[0m rmse_per_class: [0.079, 0.22, 0.028, 0.287, 0.061, 0.154, 0.193, 0.135, 0.168, 0.091]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.9353 | Steps: 2 | Val loss: 0.7282 | Batch size: 32 | lr: 0.0001 | Duration: 2.81s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.2363 | Steps: 2 | Val loss: 0.2771 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.8398 | Steps: 2 | Val loss: 0.6110 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
[2m[36m(func pid=174732)[0m rmse: 0.180718794465065
[2m[36m(func pid=174732)[0m mae:  0.13268671929836273
[2m[36m(func pid=174732)[0m rmse_per_class: [0.106, 0.267, 0.09, 0.324, 0.105, 0.194, 0.31, 0.154, 0.138, 0.12]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.14213576912879944
[2m[36m(func pid=167906)[0m mae:  0.09494240581989288
[2m[36m(func pid=167906)[0m rmse_per_class: [0.082, 0.231, 0.036, 0.28, 0.058, 0.166, 0.215, 0.114, 0.147, 0.092]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.2387 | Steps: 2 | Val loss: 0.2650 | Batch size: 32 | lr: 0.1 | Duration: 3.19s
== Status ==
Current time: 2024-01-07 09:01:10 (running for 00:29:11.78)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.236 |  0.142 |                   38 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.232 |  0.142 |                   30 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.935 |  0.181 |                    9 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.84  |  0.179 |                    4 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=176115)[0m rmse: 0.17914795875549316
[2m[36m(func pid=176115)[0m mae:  0.1312500387430191
[2m[36m(func pid=176115)[0m rmse_per_class: [0.104, 0.267, 0.088, 0.324, 0.1, 0.193, 0.304, 0.157, 0.138, 0.115]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.9040 | Steps: 2 | Val loss: 0.7032 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=169734)[0m rmse: 0.14207673072814941
[2m[36m(func pid=169734)[0m mae:  0.08942309767007828
[2m[36m(func pid=169734)[0m rmse_per_class: [0.078, 0.22, 0.029, 0.289, 0.06, 0.156, 0.192, 0.135, 0.169, 0.093]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.2390 | Steps: 2 | Val loss: 0.2776 | Batch size: 32 | lr: 0.01 | Duration: 2.77s
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.7224 | Steps: 2 | Val loss: 0.5261 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
[2m[36m(func pid=174732)[0m rmse: 0.1807876080274582
[2m[36m(func pid=174732)[0m mae:  0.1326923370361328
[2m[36m(func pid=174732)[0m rmse_per_class: [0.106, 0.267, 0.09, 0.324, 0.105, 0.194, 0.309, 0.154, 0.138, 0.121]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.142322838306427
[2m[36m(func pid=167906)[0m mae:  0.09506939351558685
[2m[36m(func pid=167906)[0m rmse_per_class: [0.081, 0.232, 0.035, 0.281, 0.058, 0.165, 0.214, 0.115, 0.148, 0.093]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.2348 | Steps: 2 | Val loss: 0.2630 | Batch size: 32 | lr: 0.1 | Duration: 3.21s
== Status ==
Current time: 2024-01-07 09:01:16 (running for 00:29:17.37)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.239 |  0.142 |                   39 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.239 |  0.142 |                   31 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.904 |  0.181 |                   10 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.722 |  0.179 |                    5 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=176115)[0m rmse: 0.17907282710075378
[2m[36m(func pid=176115)[0m mae:  0.13098594546318054
[2m[36m(func pid=176115)[0m rmse_per_class: [0.104, 0.268, 0.089, 0.324, 0.1, 0.193, 0.303, 0.157, 0.139, 0.115]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.8709 | Steps: 2 | Val loss: 0.6773 | Batch size: 32 | lr: 0.0001 | Duration: 3.33s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.2349 | Steps: 2 | Val loss: 0.2792 | Batch size: 32 | lr: 0.01 | Duration: 3.09s
[2m[36m(func pid=169734)[0m rmse: 0.14074575901031494
[2m[36m(func pid=169734)[0m mae:  0.08840825408697128
[2m[36m(func pid=169734)[0m rmse_per_class: [0.078, 0.217, 0.03, 0.288, 0.062, 0.15, 0.191, 0.128, 0.17, 0.093]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.6121 | Steps: 2 | Val loss: 0.4490 | Batch size: 32 | lr: 0.001 | Duration: 3.09s
[2m[36m(func pid=174732)[0m rmse: 0.18082982301712036
[2m[36m(func pid=174732)[0m mae:  0.1326771080493927
[2m[36m(func pid=174732)[0m rmse_per_class: [0.106, 0.267, 0.09, 0.324, 0.104, 0.194, 0.309, 0.155, 0.138, 0.121]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.14292655885219574
[2m[36m(func pid=167906)[0m mae:  0.09561990201473236
[2m[36m(func pid=167906)[0m rmse_per_class: [0.083, 0.232, 0.035, 0.284, 0.059, 0.165, 0.214, 0.114, 0.149, 0.094]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.2287 | Steps: 2 | Val loss: 0.2640 | Batch size: 32 | lr: 0.1 | Duration: 3.12s
[2m[36m(func pid=176115)[0m rmse: 0.17872455716133118
[2m[36m(func pid=176115)[0m mae:  0.1305558979511261
[2m[36m(func pid=176115)[0m rmse_per_class: [0.105, 0.268, 0.09, 0.325, 0.098, 0.193, 0.3, 0.154, 0.139, 0.114]
== Status ==
Current time: 2024-01-07 09:01:22 (running for 00:29:23.09)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.235 |  0.143 |                   40 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.235 |  0.141 |                   32 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.871 |  0.181 |                   11 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.612 |  0.179 |                    6 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.8342 | Steps: 2 | Val loss: 0.6499 | Batch size: 32 | lr: 0.0001 | Duration: 3.01s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.2347 | Steps: 2 | Val loss: 0.2785 | Batch size: 32 | lr: 0.01 | Duration: 3.06s
[2m[36m(func pid=169734)[0m rmse: 0.1414630115032196
[2m[36m(func pid=169734)[0m mae:  0.08883843570947647
[2m[36m(func pid=169734)[0m rmse_per_class: [0.08, 0.218, 0.03, 0.293, 0.063, 0.149, 0.195, 0.128, 0.171, 0.088]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=174732)[0m rmse: 0.18085627257823944
[2m[36m(func pid=174732)[0m mae:  0.1326736956834793
[2m[36m(func pid=174732)[0m rmse_per_class: [0.106, 0.267, 0.09, 0.324, 0.104, 0.194, 0.309, 0.154, 0.138, 0.121]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.5268 | Steps: 2 | Val loss: 0.3884 | Batch size: 32 | lr: 0.001 | Duration: 3.09s
[2m[36m(func pid=167906)[0m rmse: 0.14231137931346893
[2m[36m(func pid=167906)[0m mae:  0.09521040320396423
[2m[36m(func pid=167906)[0m rmse_per_class: [0.083, 0.232, 0.035, 0.282, 0.059, 0.165, 0.213, 0.113, 0.147, 0.094]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.2350 | Steps: 2 | Val loss: 0.2653 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
== Status ==
Current time: 2024-01-07 09:01:27 (running for 00:29:28.63)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.235 |  0.142 |                   41 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.229 |  0.141 |                   33 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.834 |  0.181 |                   12 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.527 |  0.178 |                    7 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=176115)[0m rmse: 0.17813393473625183
[2m[36m(func pid=176115)[0m mae:  0.1299014538526535
[2m[36m(func pid=176115)[0m rmse_per_class: [0.105, 0.269, 0.093, 0.326, 0.096, 0.193, 0.296, 0.15, 0.141, 0.112]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.8020 | Steps: 2 | Val loss: 0.6219 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.2354 | Steps: 2 | Val loss: 0.2788 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=169734)[0m rmse: 0.14183059334754944
[2m[36m(func pid=169734)[0m mae:  0.08899438381195068
[2m[36m(func pid=169734)[0m rmse_per_class: [0.085, 0.22, 0.029, 0.292, 0.067, 0.149, 0.192, 0.124, 0.173, 0.087]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=174732)[0m rmse: 0.18077893555164337
[2m[36m(func pid=174732)[0m mae:  0.1325695812702179
[2m[36m(func pid=174732)[0m rmse_per_class: [0.106, 0.267, 0.09, 0.324, 0.103, 0.194, 0.309, 0.155, 0.138, 0.122]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.4539 | Steps: 2 | Val loss: 0.3470 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=167906)[0m rmse: 0.14237430691719055
[2m[36m(func pid=167906)[0m mae:  0.09530343860387802
[2m[36m(func pid=167906)[0m rmse_per_class: [0.083, 0.232, 0.035, 0.282, 0.059, 0.165, 0.213, 0.113, 0.146, 0.095]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.2280 | Steps: 2 | Val loss: 0.2630 | Batch size: 32 | lr: 0.1 | Duration: 3.17s
== Status ==
Current time: 2024-01-07 09:01:33 (running for 00:29:34.21)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.235 |  0.142 |                   42 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.235 |  0.142 |                   34 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.802 |  0.181 |                   13 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.454 |  0.177 |                    8 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=176115)[0m rmse: 0.17718352377414703
[2m[36m(func pid=176115)[0m mae:  0.1289070099592209
[2m[36m(func pid=176115)[0m rmse_per_class: [0.106, 0.27, 0.094, 0.327, 0.093, 0.193, 0.29, 0.145, 0.143, 0.111]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.7646 | Steps: 2 | Val loss: 0.5924 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.2479 | Steps: 2 | Val loss: 0.2802 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=169734)[0m rmse: 0.1400354951620102
[2m[36m(func pid=169734)[0m mae:  0.08782355487346649
[2m[36m(func pid=169734)[0m rmse_per_class: [0.085, 0.221, 0.028, 0.285, 0.068, 0.149, 0.188, 0.117, 0.173, 0.086]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=174732)[0m rmse: 0.1807214319705963
[2m[36m(func pid=174732)[0m mae:  0.13246574997901917
[2m[36m(func pid=174732)[0m rmse_per_class: [0.106, 0.268, 0.09, 0.324, 0.103, 0.194, 0.308, 0.154, 0.138, 0.122]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.14275053143501282
[2m[36m(func pid=167906)[0m mae:  0.0955081358551979
[2m[36m(func pid=167906)[0m rmse_per_class: [0.084, 0.232, 0.035, 0.285, 0.058, 0.164, 0.212, 0.113, 0.147, 0.098]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.4159 | Steps: 2 | Val loss: 0.3258 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.2291 | Steps: 2 | Val loss: 0.2609 | Batch size: 32 | lr: 0.1 | Duration: 3.19s
== Status ==
Current time: 2024-01-07 09:01:38 (running for 00:29:39.57)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.248 |  0.143 |                   43 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.228 |  0.14  |                   35 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.765 |  0.181 |                   14 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.416 |  0.176 |                    9 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=176115)[0m rmse: 0.17630138993263245
[2m[36m(func pid=176115)[0m mae:  0.12791617214679718
[2m[36m(func pid=176115)[0m rmse_per_class: [0.108, 0.271, 0.097, 0.33, 0.09, 0.192, 0.283, 0.139, 0.145, 0.108]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.2384 | Steps: 2 | Val loss: 0.2797 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.7300 | Steps: 2 | Val loss: 0.5653 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=169734)[0m rmse: 0.1389821469783783
[2m[36m(func pid=169734)[0m mae:  0.08710303902626038
[2m[36m(func pid=169734)[0m rmse_per_class: [0.08, 0.222, 0.028, 0.275, 0.068, 0.148, 0.191, 0.117, 0.175, 0.086]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.1425296813249588
[2m[36m(func pid=167906)[0m mae:  0.09514274448156357
[2m[36m(func pid=167906)[0m rmse_per_class: [0.083, 0.233, 0.034, 0.285, 0.058, 0.164, 0.21, 0.115, 0.144, 0.098]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=174732)[0m rmse: 0.18070575594902039
[2m[36m(func pid=174732)[0m mae:  0.13240881264209747
[2m[36m(func pid=174732)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.103, 0.194, 0.308, 0.154, 0.139, 0.122]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.3997 | Steps: 2 | Val loss: 0.3201 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.2355 | Steps: 2 | Val loss: 0.2587 | Batch size: 32 | lr: 0.1 | Duration: 3.16s
== Status ==
Current time: 2024-01-07 09:01:44 (running for 00:29:45.20)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.238 |  0.143 |                   44 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.229 |  0.139 |                   36 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.73  |  0.181 |                   15 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.4   |  0.175 |                   10 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.2358 | Steps: 2 | Val loss: 0.2796 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=176115)[0m rmse: 0.17529693245887756
[2m[36m(func pid=176115)[0m mae:  0.12673191726207733
[2m[36m(func pid=176115)[0m rmse_per_class: [0.109, 0.271, 0.097, 0.332, 0.086, 0.192, 0.276, 0.136, 0.148, 0.106]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.6987 | Steps: 2 | Val loss: 0.5377 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=169734)[0m rmse: 0.13890033960342407
[2m[36m(func pid=169734)[0m mae:  0.08724827319383621
[2m[36m(func pid=169734)[0m rmse_per_class: [0.076, 0.22, 0.028, 0.27, 0.067, 0.148, 0.197, 0.121, 0.177, 0.085]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=174732)[0m rmse: 0.180595263838768
[2m[36m(func pid=174732)[0m mae:  0.13224077224731445
[2m[36m(func pid=174732)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.103, 0.194, 0.307, 0.153, 0.139, 0.122]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.14252105355262756
[2m[36m(func pid=167906)[0m mae:  0.09520722925662994
[2m[36m(func pid=167906)[0m rmse_per_class: [0.082, 0.233, 0.034, 0.286, 0.058, 0.164, 0.21, 0.114, 0.145, 0.098]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.3974 | Steps: 2 | Val loss: 0.3258 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.6618 | Steps: 2 | Val loss: 0.5123 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.2343 | Steps: 2 | Val loss: 0.2622 | Batch size: 32 | lr: 0.1 | Duration: 3.46s
== Status ==
Current time: 2024-01-07 09:01:49 (running for 00:29:50.83)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.236 |  0.143 |                   45 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.236 |  0.139 |                   37 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.699 |  0.181 |                   16 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.397 |  0.174 |                   11 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.2368 | Steps: 2 | Val loss: 0.2785 | Batch size: 32 | lr: 0.01 | Duration: 3.03s
[2m[36m(func pid=176115)[0m rmse: 0.17444556951522827
[2m[36m(func pid=176115)[0m mae:  0.12552715837955475
[2m[36m(func pid=176115)[0m rmse_per_class: [0.11, 0.271, 0.097, 0.335, 0.082, 0.192, 0.27, 0.134, 0.151, 0.103]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=174732)[0m rmse: 0.18055500090122223
[2m[36m(func pid=174732)[0m mae:  0.13213759660720825
[2m[36m(func pid=174732)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.325, 0.103, 0.194, 0.306, 0.153, 0.139, 0.122]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.14192049205303192
[2m[36m(func pid=167906)[0m mae:  0.09473775327205658
[2m[36m(func pid=167906)[0m rmse_per_class: [0.081, 0.233, 0.034, 0.282, 0.059, 0.164, 0.211, 0.114, 0.144, 0.098]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=169734)[0m rmse: 0.14176136255264282
[2m[36m(func pid=169734)[0m mae:  0.0890815481543541
[2m[36m(func pid=169734)[0m rmse_per_class: [0.073, 0.223, 0.029, 0.276, 0.066, 0.148, 0.201, 0.127, 0.188, 0.086]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.4047 | Steps: 2 | Val loss: 0.3385 | Batch size: 32 | lr: 0.001 | Duration: 3.04s
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.6350 | Steps: 2 | Val loss: 0.4883 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.2374 | Steps: 2 | Val loss: 0.2788 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
== Status ==
Current time: 2024-01-07 09:01:55 (running for 00:29:56.44)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.237 |  0.142 |                   46 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.234 |  0.142 |                   38 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.662 |  0.181 |                   17 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.405 |  0.174 |                   12 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=176115)[0m rmse: 0.173504039645195
[2m[36m(func pid=176115)[0m mae:  0.1240939050912857
[2m[36m(func pid=176115)[0m rmse_per_class: [0.111, 0.272, 0.095, 0.337, 0.077, 0.191, 0.265, 0.134, 0.154, 0.1]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.2354 | Steps: 2 | Val loss: 0.2674 | Batch size: 32 | lr: 0.1 | Duration: 3.36s
[2m[36m(func pid=174732)[0m rmse: 0.18041399121284485
[2m[36m(func pid=174732)[0m mae:  0.13198144733905792
[2m[36m(func pid=174732)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.101, 0.194, 0.305, 0.152, 0.139, 0.122]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.14197316765785217
[2m[36m(func pid=167906)[0m mae:  0.09483807533979416
[2m[36m(func pid=167906)[0m rmse_per_class: [0.081, 0.232, 0.034, 0.282, 0.058, 0.164, 0.212, 0.114, 0.144, 0.099]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=169734)[0m rmse: 0.1438823640346527
[2m[36m(func pid=169734)[0m mae:  0.09051351994276047
[2m[36m(func pid=169734)[0m rmse_per_class: [0.072, 0.226, 0.03, 0.294, 0.067, 0.149, 0.196, 0.125, 0.193, 0.086]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.4166 | Steps: 2 | Val loss: 0.3562 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.5978 | Steps: 2 | Val loss: 0.4642 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.2329 | Steps: 2 | Val loss: 0.2790 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
== Status ==
Current time: 2024-01-07 09:02:01 (running for 00:30:01.90)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.237 |  0.142 |                   47 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.235 |  0.144 |                   39 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.635 |  0.18  |                   18 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.417 |  0.173 |                   13 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=176115)[0m rmse: 0.17284604907035828
[2m[36m(func pid=176115)[0m mae:  0.12265951931476593
[2m[36m(func pid=176115)[0m rmse_per_class: [0.112, 0.272, 0.091, 0.34, 0.072, 0.191, 0.262, 0.135, 0.156, 0.097]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.2277 | Steps: 2 | Val loss: 0.2721 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
[2m[36m(func pid=174732)[0m rmse: 0.18027493357658386
[2m[36m(func pid=174732)[0m mae:  0.13179001212120056
[2m[36m(func pid=174732)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.101, 0.193, 0.304, 0.152, 0.14, 0.121]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.14200639724731445
[2m[36m(func pid=167906)[0m mae:  0.09489557892084122
[2m[36m(func pid=167906)[0m rmse_per_class: [0.081, 0.232, 0.034, 0.284, 0.059, 0.165, 0.212, 0.113, 0.142, 0.098]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.4348 | Steps: 2 | Val loss: 0.3755 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
[2m[36m(func pid=169734)[0m rmse: 0.14477363228797913
[2m[36m(func pid=169734)[0m mae:  0.09153401851654053
[2m[36m(func pid=169734)[0m rmse_per_class: [0.074, 0.228, 0.03, 0.311, 0.069, 0.149, 0.195, 0.118, 0.189, 0.087]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.5730 | Steps: 2 | Val loss: 0.4438 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.2371 | Steps: 2 | Val loss: 0.2794 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
== Status ==
Current time: 2024-01-07 09:02:06 (running for 00:30:07.33)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.233 |  0.142 |                   48 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.228 |  0.145 |                   40 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.598 |  0.18  |                   19 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.435 |  0.173 |                   14 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=176115)[0m rmse: 0.1726047694683075
[2m[36m(func pid=176115)[0m mae:  0.12144354730844498
[2m[36m(func pid=176115)[0m rmse_per_class: [0.112, 0.272, 0.088, 0.343, 0.068, 0.19, 0.264, 0.137, 0.158, 0.095]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.2308 | Steps: 2 | Val loss: 0.2735 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=174732)[0m rmse: 0.18019957840442657
[2m[36m(func pid=174732)[0m mae:  0.13167612254619598
[2m[36m(func pid=174732)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.326, 0.1, 0.193, 0.303, 0.151, 0.14, 0.121]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.14188775420188904
[2m[36m(func pid=167906)[0m mae:  0.0948214903473854
[2m[36m(func pid=167906)[0m rmse_per_class: [0.081, 0.231, 0.034, 0.285, 0.059, 0.165, 0.213, 0.113, 0.142, 0.097]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.4523 | Steps: 2 | Val loss: 0.3954 | Batch size: 32 | lr: 0.001 | Duration: 3.04s
[2m[36m(func pid=169734)[0m rmse: 0.14481304585933685
[2m[36m(func pid=169734)[0m mae:  0.09180989116430283
[2m[36m(func pid=169734)[0m rmse_per_class: [0.079, 0.227, 0.029, 0.314, 0.071, 0.149, 0.194, 0.116, 0.182, 0.087]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.5464 | Steps: 2 | Val loss: 0.4244 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
== Status ==
Current time: 2024-01-07 09:02:11 (running for 00:30:12.87)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.237 |  0.142 |                   49 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.231 |  0.145 |                   41 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.573 |  0.18  |                   20 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.452 |  0.173 |                   15 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.2332 | Steps: 2 | Val loss: 0.2797 | Batch size: 32 | lr: 0.01 | Duration: 3.07s
[2m[36m(func pid=176115)[0m rmse: 0.17266733944416046
[2m[36m(func pid=176115)[0m mae:  0.12038916349411011
[2m[36m(func pid=176115)[0m rmse_per_class: [0.112, 0.272, 0.084, 0.345, 0.065, 0.19, 0.268, 0.139, 0.159, 0.093]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.2374 | Steps: 2 | Val loss: 0.2701 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
[2m[36m(func pid=174732)[0m rmse: 0.1800086945295334
[2m[36m(func pid=174732)[0m mae:  0.131430983543396
[2m[36m(func pid=174732)[0m rmse_per_class: [0.108, 0.269, 0.092, 0.326, 0.1, 0.194, 0.301, 0.15, 0.14, 0.12]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.1418444663286209
[2m[36m(func pid=167906)[0m mae:  0.094754658639431
[2m[36m(func pid=167906)[0m rmse_per_class: [0.081, 0.232, 0.034, 0.284, 0.058, 0.165, 0.212, 0.112, 0.143, 0.097]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.4712 | Steps: 2 | Val loss: 0.4150 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=169734)[0m rmse: 0.14319537580013275
[2m[36m(func pid=169734)[0m mae:  0.09061448276042938
[2m[36m(func pid=169734)[0m rmse_per_class: [0.081, 0.224, 0.027, 0.304, 0.071, 0.15, 0.194, 0.12, 0.176, 0.086]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.5263 | Steps: 2 | Val loss: 0.4069 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
== Status ==
Current time: 2024-01-07 09:02:17 (running for 00:30:18.25)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.233 |  0.142 |                   50 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.237 |  0.143 |                   42 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.546 |  0.18  |                   21 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.471 |  0.173 |                   16 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=176115)[0m rmse: 0.17303012311458588
[2m[36m(func pid=176115)[0m mae:  0.11953966319561005
[2m[36m(func pid=176115)[0m rmse_per_class: [0.111, 0.272, 0.08, 0.348, 0.062, 0.189, 0.276, 0.141, 0.16, 0.092]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.2317 | Steps: 2 | Val loss: 0.2803 | Batch size: 32 | lr: 0.01 | Duration: 3.17s
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.2327 | Steps: 2 | Val loss: 0.2651 | Batch size: 32 | lr: 0.1 | Duration: 3.28s
[2m[36m(func pid=174732)[0m rmse: 0.17979200184345245
[2m[36m(func pid=174732)[0m mae:  0.13121077418327332
[2m[36m(func pid=174732)[0m rmse_per_class: [0.108, 0.269, 0.093, 0.327, 0.099, 0.193, 0.3, 0.148, 0.141, 0.12]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.14217886328697205
[2m[36m(func pid=167906)[0m mae:  0.09503723680973053
[2m[36m(func pid=167906)[0m rmse_per_class: [0.083, 0.23, 0.034, 0.288, 0.058, 0.165, 0.212, 0.112, 0.143, 0.096]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.4921 | Steps: 2 | Val loss: 0.4341 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=169734)[0m rmse: 0.14187394082546234
[2m[36m(func pid=169734)[0m mae:  0.08943112939596176
[2m[36m(func pid=169734)[0m rmse_per_class: [0.079, 0.219, 0.026, 0.296, 0.068, 0.151, 0.194, 0.13, 0.17, 0.085]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.5010 | Steps: 2 | Val loss: 0.3911 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
== Status ==
Current time: 2024-01-07 09:02:22 (running for 00:30:23.82)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.232 |  0.142 |                   51 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.233 |  0.142 |                   43 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.526 |  0.18  |                   22 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.492 |  0.174 |                   17 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=176115)[0m rmse: 0.1737208515405655
[2m[36m(func pid=176115)[0m mae:  0.11883692443370819
[2m[36m(func pid=176115)[0m rmse_per_class: [0.11, 0.272, 0.075, 0.35, 0.059, 0.189, 0.287, 0.143, 0.161, 0.091]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.2373 | Steps: 2 | Val loss: 0.2803 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=174732)[0m rmse: 0.17954519391059875
[2m[36m(func pid=174732)[0m mae:  0.1309266984462738
[2m[36m(func pid=174732)[0m rmse_per_class: [0.108, 0.27, 0.093, 0.327, 0.098, 0.193, 0.298, 0.147, 0.142, 0.119]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.2322 | Steps: 2 | Val loss: 0.2616 | Batch size: 32 | lr: 0.1 | Duration: 3.31s
[2m[36m(func pid=167906)[0m rmse: 0.14198999106884003
[2m[36m(func pid=167906)[0m mae:  0.09483753889799118
[2m[36m(func pid=167906)[0m rmse_per_class: [0.083, 0.23, 0.035, 0.287, 0.058, 0.164, 0.212, 0.112, 0.144, 0.097]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.5063 | Steps: 2 | Val loss: 0.4515 | Batch size: 32 | lr: 0.001 | Duration: 3.15s
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.4844 | Steps: 2 | Val loss: 0.3774 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=169734)[0m rmse: 0.1405058205127716
[2m[36m(func pid=169734)[0m mae:  0.08851955085992813
[2m[36m(func pid=169734)[0m rmse_per_class: [0.082, 0.216, 0.027, 0.29, 0.066, 0.151, 0.194, 0.129, 0.166, 0.084]
[2m[36m(func pid=169734)[0m 
== Status ==
Current time: 2024-01-07 09:02:28 (running for 00:30:29.33)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.237 |  0.142 |                   52 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.232 |  0.141 |                   44 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.501 |  0.18  |                   23 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.506 |  0.175 |                   18 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.2335 | Steps: 2 | Val loss: 0.2793 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
[2m[36m(func pid=176115)[0m rmse: 0.174675852060318
[2m[36m(func pid=176115)[0m mae:  0.11839544773101807
[2m[36m(func pid=176115)[0m rmse_per_class: [0.108, 0.273, 0.07, 0.352, 0.058, 0.189, 0.301, 0.144, 0.161, 0.091]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=174732)[0m rmse: 0.17935888469219208
[2m[36m(func pid=174732)[0m mae:  0.13074491918087006
[2m[36m(func pid=174732)[0m rmse_per_class: [0.108, 0.27, 0.093, 0.327, 0.098, 0.193, 0.297, 0.146, 0.142, 0.118]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.2353 | Steps: 2 | Val loss: 0.2580 | Batch size: 32 | lr: 0.1 | Duration: 3.06s
[2m[36m(func pid=167906)[0m rmse: 0.14111371338367462
[2m[36m(func pid=167906)[0m mae:  0.09399931132793427
[2m[36m(func pid=167906)[0m rmse_per_class: [0.083, 0.229, 0.035, 0.284, 0.057, 0.163, 0.21, 0.112, 0.142, 0.096]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.5276 | Steps: 2 | Val loss: 0.4692 | Batch size: 32 | lr: 0.001 | Duration: 3.13s
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.4688 | Steps: 2 | Val loss: 0.3659 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=169734)[0m rmse: 0.13803620636463165
[2m[36m(func pid=169734)[0m mae:  0.08701726049184799
[2m[36m(func pid=169734)[0m rmse_per_class: [0.077, 0.216, 0.028, 0.28, 0.065, 0.15, 0.193, 0.122, 0.166, 0.084]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.2364 | Steps: 2 | Val loss: 0.2799 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=176115)[0m rmse: 0.17579753696918488
[2m[36m(func pid=176115)[0m mae:  0.11810483038425446
[2m[36m(func pid=176115)[0m rmse_per_class: [0.107, 0.273, 0.065, 0.354, 0.057, 0.188, 0.315, 0.146, 0.162, 0.091]
[2m[36m(func pid=176115)[0m 
== Status ==
Current time: 2024-01-07 09:02:34 (running for 00:30:35.06)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.233 |  0.141 |                   53 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.235 |  0.138 |                   45 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.484 |  0.179 |                   24 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.528 |  0.176 |                   19 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=174732)[0m rmse: 0.17919766902923584
[2m[36m(func pid=174732)[0m mae:  0.13052108883857727
[2m[36m(func pid=174732)[0m rmse_per_class: [0.108, 0.27, 0.095, 0.328, 0.097, 0.193, 0.295, 0.145, 0.143, 0.118]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.2350 | Steps: 2 | Val loss: 0.2618 | Batch size: 32 | lr: 0.1 | Duration: 3.08s
[2m[36m(func pid=167906)[0m rmse: 0.14123205840587616
[2m[36m(func pid=167906)[0m mae:  0.09400072693824768
[2m[36m(func pid=167906)[0m rmse_per_class: [0.082, 0.23, 0.035, 0.285, 0.057, 0.163, 0.209, 0.112, 0.142, 0.097]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.5351 | Steps: 2 | Val loss: 0.4849 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.4565 | Steps: 2 | Val loss: 0.3564 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=169734)[0m rmse: 0.1396879404783249
[2m[36m(func pid=169734)[0m mae:  0.08849634975194931
[2m[36m(func pid=169734)[0m rmse_per_class: [0.075, 0.22, 0.027, 0.28, 0.068, 0.151, 0.196, 0.121, 0.169, 0.089]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.2368 | Steps: 2 | Val loss: 0.2805 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
== Status ==
Current time: 2024-01-07 09:02:39 (running for 00:30:40.38)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.236 |  0.141 |                   54 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.235 |  0.14  |                   46 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.469 |  0.179 |                   25 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.535 |  0.177 |                   20 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=176115)[0m rmse: 0.1770983636379242
[2m[36m(func pid=176115)[0m mae:  0.11802923679351807
[2m[36m(func pid=176115)[0m rmse_per_class: [0.106, 0.273, 0.061, 0.356, 0.056, 0.188, 0.33, 0.148, 0.162, 0.091]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=174732)[0m rmse: 0.17888042330741882
[2m[36m(func pid=174732)[0m mae:  0.13021044433116913
[2m[36m(func pid=174732)[0m rmse_per_class: [0.109, 0.27, 0.095, 0.329, 0.096, 0.193, 0.293, 0.144, 0.143, 0.117]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.2309 | Steps: 2 | Val loss: 0.2679 | Batch size: 32 | lr: 0.1 | Duration: 3.18s
[2m[36m(func pid=167906)[0m rmse: 0.14137163758277893
[2m[36m(func pid=167906)[0m mae:  0.0940123200416565
[2m[36m(func pid=167906)[0m rmse_per_class: [0.083, 0.23, 0.035, 0.285, 0.058, 0.163, 0.208, 0.112, 0.144, 0.096]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.5419 | Steps: 2 | Val loss: 0.4988 | Batch size: 32 | lr: 0.001 | Duration: 3.03s
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.4354 | Steps: 2 | Val loss: 0.3474 | Batch size: 32 | lr: 0.0001 | Duration: 3.03s
[2m[36m(func pid=169734)[0m rmse: 0.14265835285186768
[2m[36m(func pid=169734)[0m mae:  0.09061163663864136
[2m[36m(func pid=169734)[0m rmse_per_class: [0.076, 0.222, 0.028, 0.296, 0.072, 0.151, 0.194, 0.122, 0.172, 0.092]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.2311 | Steps: 2 | Val loss: 0.2804 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
== Status ==
Current time: 2024-01-07 09:02:45 (running for 00:30:45.95)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.237 |  0.141 |                   55 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.231 |  0.143 |                   47 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.456 |  0.179 |                   26 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.542 |  0.179 |                   21 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=176115)[0m rmse: 0.17860499024391174
[2m[36m(func pid=176115)[0m mae:  0.11818848550319672
[2m[36m(func pid=176115)[0m rmse_per_class: [0.105, 0.274, 0.057, 0.358, 0.055, 0.188, 0.346, 0.149, 0.163, 0.091]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=174732)[0m rmse: 0.17841216921806335
[2m[36m(func pid=174732)[0m mae:  0.12975278496742249
[2m[36m(func pid=174732)[0m rmse_per_class: [0.109, 0.27, 0.095, 0.329, 0.095, 0.193, 0.291, 0.143, 0.144, 0.116]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.2311 | Steps: 2 | Val loss: 0.2697 | Batch size: 32 | lr: 0.1 | Duration: 3.04s
[2m[36m(func pid=167906)[0m rmse: 0.14139637351036072
[2m[36m(func pid=167906)[0m mae:  0.09404954314231873
[2m[36m(func pid=167906)[0m rmse_per_class: [0.085, 0.23, 0.035, 0.286, 0.057, 0.163, 0.208, 0.112, 0.141, 0.097]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.5650 | Steps: 2 | Val loss: 0.5111 | Batch size: 32 | lr: 0.001 | Duration: 3.11s
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.4266 | Steps: 2 | Val loss: 0.3403 | Batch size: 32 | lr: 0.0001 | Duration: 3.03s
[2m[36m(func pid=169734)[0m rmse: 0.1439015120267868
[2m[36m(func pid=169734)[0m mae:  0.09130216389894485
[2m[36m(func pid=169734)[0m rmse_per_class: [0.077, 0.221, 0.028, 0.308, 0.072, 0.153, 0.192, 0.124, 0.169, 0.094]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.2336 | Steps: 2 | Val loss: 0.2802 | Batch size: 32 | lr: 0.01 | Duration: 3.06s
== Status ==
Current time: 2024-01-07 09:02:50 (running for 00:30:51.60)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.231 |  0.141 |                   56 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.231 |  0.144 |                   48 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.435 |  0.178 |                   27 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.565 |  0.18  |                   22 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=174732)[0m rmse: 0.1781696081161499
[2m[36m(func pid=174732)[0m mae:  0.1294998824596405
[2m[36m(func pid=174732)[0m rmse_per_class: [0.11, 0.271, 0.094, 0.329, 0.094, 0.193, 0.289, 0.142, 0.144, 0.115]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=176115)[0m rmse: 0.18024742603302002
[2m[36m(func pid=176115)[0m mae:  0.11847028881311417
[2m[36m(func pid=176115)[0m rmse_per_class: [0.103, 0.274, 0.054, 0.36, 0.055, 0.188, 0.365, 0.15, 0.162, 0.092]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.14125189185142517
[2m[36m(func pid=167906)[0m mae:  0.09378919750452042
[2m[36m(func pid=167906)[0m rmse_per_class: [0.084, 0.23, 0.034, 0.285, 0.057, 0.163, 0.207, 0.113, 0.142, 0.096]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.2323 | Steps: 2 | Val loss: 0.2700 | Batch size: 32 | lr: 0.1 | Duration: 3.08s
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.4184 | Steps: 2 | Val loss: 0.3342 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.5798 | Steps: 2 | Val loss: 0.5196 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 09:02:55 (running for 00:30:56.61)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.234 |  0.141 |                   57 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.232 |  0.145 |                   49 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.427 |  0.178 |                   28 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.565 |  0.18  |                   22 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.2398 | Steps: 2 | Val loss: 0.2808 | Batch size: 32 | lr: 0.01 | Duration: 2.77s
[2m[36m(func pid=169734)[0m rmse: 0.14467106759548187
[2m[36m(func pid=169734)[0m mae:  0.09161362797021866
[2m[36m(func pid=169734)[0m rmse_per_class: [0.079, 0.221, 0.029, 0.311, 0.07, 0.152, 0.193, 0.132, 0.168, 0.091]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=174732)[0m rmse: 0.17779026925563812
[2m[36m(func pid=174732)[0m mae:  0.1291210800409317
[2m[36m(func pid=174732)[0m rmse_per_class: [0.11, 0.271, 0.095, 0.33, 0.093, 0.193, 0.287, 0.14, 0.145, 0.114]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=176115)[0m rmse: 0.1817316710948944
[2m[36m(func pid=176115)[0m mae:  0.11872236430644989
[2m[36m(func pid=176115)[0m rmse_per_class: [0.101, 0.275, 0.051, 0.362, 0.055, 0.187, 0.383, 0.151, 0.161, 0.092]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.14158466458320618
[2m[36m(func pid=167906)[0m mae:  0.0939844399690628
[2m[36m(func pid=167906)[0m rmse_per_class: [0.085, 0.231, 0.035, 0.286, 0.057, 0.163, 0.207, 0.112, 0.143, 0.097]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.2333 | Steps: 2 | Val loss: 0.2660 | Batch size: 32 | lr: 0.1 | Duration: 3.05s
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.5725 | Steps: 2 | Val loss: 0.5265 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.4161 | Steps: 2 | Val loss: 0.3297 | Batch size: 32 | lr: 0.0001 | Duration: 3.05s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.2330 | Steps: 2 | Val loss: 0.2798 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
== Status ==
Current time: 2024-01-07 09:03:01 (running for 00:31:02.31)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.24  |  0.142 |                   58 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.233 |  0.143 |                   50 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.418 |  0.178 |                   29 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.58  |  0.182 |                   23 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=169734)[0m rmse: 0.14290352165699005
[2m[36m(func pid=169734)[0m mae:  0.09025667607784271
[2m[36m(func pid=169734)[0m rmse_per_class: [0.081, 0.22, 0.03, 0.301, 0.068, 0.15, 0.195, 0.131, 0.165, 0.088]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=176115)[0m rmse: 0.18312124907970428
[2m[36m(func pid=176115)[0m mae:  0.11903504282236099
[2m[36m(func pid=176115)[0m rmse_per_class: [0.099, 0.275, 0.049, 0.363, 0.055, 0.187, 0.4, 0.152, 0.16, 0.093]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=174732)[0m rmse: 0.17741423845291138
[2m[36m(func pid=174732)[0m mae:  0.12872952222824097
[2m[36m(func pid=174732)[0m rmse_per_class: [0.11, 0.271, 0.095, 0.331, 0.091, 0.193, 0.285, 0.139, 0.146, 0.113]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.14118091762065887
[2m[36m(func pid=167906)[0m mae:  0.09374138712882996
[2m[36m(func pid=167906)[0m rmse_per_class: [0.084, 0.23, 0.034, 0.286, 0.057, 0.163, 0.207, 0.112, 0.142, 0.096]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.4079 | Steps: 2 | Val loss: 0.3262 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.5851 | Steps: 2 | Val loss: 0.5323 | Batch size: 32 | lr: 0.001 | Duration: 3.06s
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.2381 | Steps: 2 | Val loss: 0.2643 | Batch size: 32 | lr: 0.1 | Duration: 3.30s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.2269 | Steps: 2 | Val loss: 0.2795 | Batch size: 32 | lr: 0.01 | Duration: 3.11s
== Status ==
Current time: 2024-01-07 09:03:06 (running for 00:31:07.80)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.233 |  0.141 |                   59 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.233 |  0.143 |                   50 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.408 |  0.177 |                   31 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.573 |  0.183 |                   24 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=174732)[0m rmse: 0.17718032002449036
[2m[36m(func pid=174732)[0m mae:  0.12843923270702362
[2m[36m(func pid=174732)[0m rmse_per_class: [0.11, 0.271, 0.095, 0.331, 0.091, 0.192, 0.283, 0.138, 0.147, 0.112]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=176115)[0m rmse: 0.1843533217906952
[2m[36m(func pid=176115)[0m mae:  0.119418203830719
[2m[36m(func pid=176115)[0m rmse_per_class: [0.098, 0.275, 0.047, 0.364, 0.055, 0.187, 0.412, 0.152, 0.161, 0.093]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=169734)[0m rmse: 0.14225906133651733
[2m[36m(func pid=169734)[0m mae:  0.0895896926522255
[2m[36m(func pid=169734)[0m rmse_per_class: [0.082, 0.22, 0.029, 0.293, 0.072, 0.15, 0.196, 0.128, 0.166, 0.086]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.1413344293832779
[2m[36m(func pid=167906)[0m mae:  0.09386809170246124
[2m[36m(func pid=167906)[0m rmse_per_class: [0.083, 0.23, 0.034, 0.287, 0.057, 0.164, 0.208, 0.112, 0.143, 0.096]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.4018 | Steps: 2 | Val loss: 0.3238 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.5741 | Steps: 2 | Val loss: 0.5342 | Batch size: 32 | lr: 0.001 | Duration: 3.05s
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.2352 | Steps: 2 | Val loss: 0.2612 | Batch size: 32 | lr: 0.1 | Duration: 3.20s
== Status ==
Current time: 2024-01-07 09:03:12 (running for 00:31:13.12)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.227 |  0.141 |                   60 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.238 |  0.142 |                   51 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.402 |  0.177 |                   32 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.585 |  0.184 |                   25 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.2294 | Steps: 2 | Val loss: 0.2804 | Batch size: 32 | lr: 0.01 | Duration: 3.09s
[2m[36m(func pid=174732)[0m rmse: 0.17701102793216705
[2m[36m(func pid=174732)[0m mae:  0.12819263339042664
[2m[36m(func pid=174732)[0m rmse_per_class: [0.111, 0.271, 0.095, 0.332, 0.09, 0.192, 0.281, 0.138, 0.148, 0.111]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=176115)[0m rmse: 0.1855924129486084
[2m[36m(func pid=176115)[0m mae:  0.11980114132165909
[2m[36m(func pid=176115)[0m rmse_per_class: [0.097, 0.275, 0.046, 0.364, 0.055, 0.187, 0.424, 0.153, 0.161, 0.093]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=169734)[0m rmse: 0.14047250151634216
[2m[36m(func pid=169734)[0m mae:  0.08823516964912415
[2m[36m(func pid=169734)[0m rmse_per_class: [0.079, 0.22, 0.029, 0.281, 0.075, 0.151, 0.195, 0.123, 0.167, 0.085]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.1417817324399948
[2m[36m(func pid=167906)[0m mae:  0.09423689544200897
[2m[36m(func pid=167906)[0m rmse_per_class: [0.083, 0.231, 0.035, 0.287, 0.057, 0.164, 0.209, 0.112, 0.144, 0.096]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.3976 | Steps: 2 | Val loss: 0.3226 | Batch size: 32 | lr: 0.0001 | Duration: 3.10s
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.5815 | Steps: 2 | Val loss: 0.5349 | Batch size: 32 | lr: 0.001 | Duration: 3.23s
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.2353 | Steps: 2 | Val loss: 0.2626 | Batch size: 32 | lr: 0.1 | Duration: 3.27s
== Status ==
Current time: 2024-01-07 09:03:17 (running for 00:31:18.69)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.142 |                   61 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.235 |  0.14  |                   52 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.398 |  0.177 |                   33 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.574 |  0.186 |                   26 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.2367 | Steps: 2 | Val loss: 0.2819 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=174732)[0m rmse: 0.1768406629562378
[2m[36m(func pid=174732)[0m mae:  0.12798495590686798
[2m[36m(func pid=174732)[0m rmse_per_class: [0.111, 0.271, 0.096, 0.333, 0.089, 0.192, 0.28, 0.137, 0.149, 0.11]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=176115)[0m rmse: 0.18692657351493835
[2m[36m(func pid=176115)[0m mae:  0.12024956941604614
[2m[36m(func pid=176115)[0m rmse_per_class: [0.095, 0.276, 0.045, 0.365, 0.055, 0.187, 0.437, 0.153, 0.162, 0.094]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=169734)[0m rmse: 0.1412259042263031
[2m[36m(func pid=169734)[0m mae:  0.0889008641242981
[2m[36m(func pid=169734)[0m rmse_per_class: [0.079, 0.222, 0.028, 0.284, 0.074, 0.152, 0.194, 0.121, 0.173, 0.086]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.14239999651908875
[2m[36m(func pid=167906)[0m mae:  0.09473288059234619
[2m[36m(func pid=167906)[0m rmse_per_class: [0.082, 0.231, 0.034, 0.29, 0.057, 0.165, 0.21, 0.112, 0.145, 0.098]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.3982 | Steps: 2 | Val loss: 0.3217 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.5835 | Steps: 2 | Val loss: 0.5333 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.2294 | Steps: 2 | Val loss: 0.2661 | Batch size: 32 | lr: 0.1 | Duration: 3.22s
== Status ==
Current time: 2024-01-07 09:03:23 (running for 00:31:24.03)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.237 |  0.142 |                   62 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.235 |  0.141 |                   53 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.398 |  0.177 |                   34 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.581 |  0.187 |                   27 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=174732)[0m rmse: 0.17651063203811646
[2m[36m(func pid=174732)[0m mae:  0.12765395641326904
[2m[36m(func pid=174732)[0m rmse_per_class: [0.111, 0.271, 0.096, 0.334, 0.088, 0.192, 0.278, 0.136, 0.149, 0.11]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.2374 | Steps: 2 | Val loss: 0.2821 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=176115)[0m rmse: 0.18795791268348694
[2m[36m(func pid=176115)[0m mae:  0.12051957845687866
[2m[36m(func pid=176115)[0m rmse_per_class: [0.093, 0.276, 0.045, 0.365, 0.056, 0.186, 0.45, 0.153, 0.162, 0.094]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=169734)[0m rmse: 0.14279377460479736
[2m[36m(func pid=169734)[0m mae:  0.09020785987377167
[2m[36m(func pid=169734)[0m rmse_per_class: [0.079, 0.223, 0.028, 0.295, 0.07, 0.153, 0.193, 0.124, 0.175, 0.087]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.14226827025413513
[2m[36m(func pid=167906)[0m mae:  0.09458760172128677
[2m[36m(func pid=167906)[0m rmse_per_class: [0.083, 0.231, 0.034, 0.287, 0.057, 0.164, 0.21, 0.112, 0.145, 0.098]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.3933 | Steps: 2 | Val loss: 0.3218 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.5684 | Steps: 2 | Val loss: 0.5311 | Batch size: 32 | lr: 0.001 | Duration: 3.05s
[2m[36m(func pid=174732)[0m rmse: 0.17631998658180237
[2m[36m(func pid=174732)[0m mae:  0.12739317119121552
[2m[36m(func pid=174732)[0m rmse_per_class: [0.111, 0.271, 0.096, 0.334, 0.087, 0.192, 0.277, 0.135, 0.15, 0.109]
[2m[36m(func pid=174732)[0m 
== Status ==
Current time: 2024-01-07 09:03:28 (running for 00:31:29.36)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.237 |  0.142 |                   63 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.229 |  0.143 |                   54 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.393 |  0.176 |                   35 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.583 |  0.188 |                   28 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.2286 | Steps: 2 | Val loss: 0.2690 | Batch size: 32 | lr: 0.1 | Duration: 3.41s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.2408 | Steps: 2 | Val loss: 0.2824 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=176115)[0m rmse: 0.18879210948944092
[2m[36m(func pid=176115)[0m mae:  0.12071473896503448
[2m[36m(func pid=176115)[0m rmse_per_class: [0.092, 0.276, 0.045, 0.365, 0.056, 0.186, 0.459, 0.154, 0.162, 0.094]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.1422685831785202
[2m[36m(func pid=167906)[0m mae:  0.09455720335245132
[2m[36m(func pid=167906)[0m rmse_per_class: [0.082, 0.232, 0.034, 0.286, 0.057, 0.164, 0.21, 0.112, 0.146, 0.099]
[2m[36m(func pid=169734)[0m rmse: 0.14396117627620697
[2m[36m(func pid=169734)[0m mae:  0.09147868305444717
[2m[36m(func pid=169734)[0m rmse_per_class: [0.079, 0.223, 0.028, 0.304, 0.069, 0.152, 0.196, 0.127, 0.174, 0.088]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.3922 | Steps: 2 | Val loss: 0.3224 | Batch size: 32 | lr: 0.0001 | Duration: 2.72s
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.5597 | Steps: 2 | Val loss: 0.5265 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 09:03:33 (running for 00:31:34.52)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.241 |  0.142 |                   64 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.229 |  0.144 |                   55 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.392 |  0.176 |                   36 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.568 |  0.189 |                   29 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=174732)[0m rmse: 0.17605547606945038
[2m[36m(func pid=174732)[0m mae:  0.1270812600851059
[2m[36m(func pid=174732)[0m rmse_per_class: [0.111, 0.271, 0.095, 0.335, 0.086, 0.192, 0.275, 0.135, 0.151, 0.108]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.2331 | Steps: 2 | Val loss: 0.2686 | Batch size: 32 | lr: 0.1 | Duration: 3.04s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.2327 | Steps: 2 | Val loss: 0.2820 | Batch size: 32 | lr: 0.01 | Duration: 3.16s
[2m[36m(func pid=176115)[0m rmse: 0.1893933266401291
[2m[36m(func pid=176115)[0m mae:  0.12085714191198349
[2m[36m(func pid=176115)[0m rmse_per_class: [0.091, 0.275, 0.045, 0.366, 0.056, 0.186, 0.466, 0.154, 0.163, 0.094]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=169734)[0m rmse: 0.14353393018245697
[2m[36m(func pid=169734)[0m mae:  0.09121377021074295
[2m[36m(func pid=169734)[0m rmse_per_class: [0.079, 0.221, 0.028, 0.299, 0.069, 0.152, 0.197, 0.129, 0.172, 0.089]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.3936 | Steps: 2 | Val loss: 0.3229 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=167906)[0m rmse: 0.14190277457237244
[2m[36m(func pid=167906)[0m mae:  0.09425677359104156
[2m[36m(func pid=167906)[0m rmse_per_class: [0.082, 0.231, 0.034, 0.285, 0.058, 0.164, 0.21, 0.112, 0.143, 0.1]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.5491 | Steps: 2 | Val loss: 0.5199 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=174732)[0m rmse: 0.17563137412071228
[2m[36m(func pid=174732)[0m mae:  0.12664805352687836
[2m[36m(func pid=174732)[0m rmse_per_class: [0.111, 0.271, 0.095, 0.335, 0.085, 0.192, 0.273, 0.135, 0.152, 0.107]
[2m[36m(func pid=174732)[0m 
== Status ==
Current time: 2024-01-07 09:03:38 (running for 00:31:39.87)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.233 |  0.142 |                   65 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.233 |  0.144 |                   56 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.394 |  0.176 |                   37 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.56  |  0.189 |                   30 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.2327 | Steps: 2 | Val loss: 0.2671 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.2366 | Steps: 2 | Val loss: 0.2816 | Batch size: 32 | lr: 0.01 | Duration: 3.12s
[2m[36m(func pid=176115)[0m rmse: 0.19001655280590057
[2m[36m(func pid=176115)[0m mae:  0.1210155040025711
[2m[36m(func pid=176115)[0m rmse_per_class: [0.089, 0.275, 0.045, 0.366, 0.056, 0.185, 0.471, 0.154, 0.164, 0.095]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.3920 | Steps: 2 | Val loss: 0.3240 | Batch size: 32 | lr: 0.0001 | Duration: 3.04s
[2m[36m(func pid=169734)[0m rmse: 0.14303287863731384
[2m[36m(func pid=169734)[0m mae:  0.0907212570309639
[2m[36m(func pid=169734)[0m rmse_per_class: [0.08, 0.219, 0.028, 0.298, 0.069, 0.151, 0.198, 0.132, 0.169, 0.088]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.14186319708824158
[2m[36m(func pid=167906)[0m mae:  0.09420810639858246
[2m[36m(func pid=167906)[0m rmse_per_class: [0.083, 0.232, 0.034, 0.284, 0.057, 0.164, 0.209, 0.112, 0.143, 0.1]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.5326 | Steps: 2 | Val loss: 0.5109 | Batch size: 32 | lr: 0.001 | Duration: 3.12s
== Status ==
Current time: 2024-01-07 09:03:44 (running for 00:31:45.37)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.237 |  0.142 |                   66 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.233 |  0.143 |                   57 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.392 |  0.175 |                   38 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.549 |  0.19  |                   31 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=174732)[0m rmse: 0.1753319948911667
[2m[36m(func pid=174732)[0m mae:  0.12632951140403748
[2m[36m(func pid=174732)[0m rmse_per_class: [0.111, 0.271, 0.096, 0.336, 0.084, 0.192, 0.272, 0.134, 0.152, 0.106]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.2303 | Steps: 2 | Val loss: 0.2642 | Batch size: 32 | lr: 0.1 | Duration: 3.14s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.2318 | Steps: 2 | Val loss: 0.2807 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
[2m[36m(func pid=176115)[0m rmse: 0.18975982069969177
[2m[36m(func pid=176115)[0m mae:  0.1206650510430336
[2m[36m(func pid=176115)[0m rmse_per_class: [0.088, 0.274, 0.045, 0.366, 0.056, 0.184, 0.472, 0.154, 0.164, 0.095]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.3933 | Steps: 2 | Val loss: 0.3259 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=167906)[0m rmse: 0.1412205994129181
[2m[36m(func pid=167906)[0m mae:  0.09359320998191833
[2m[36m(func pid=167906)[0m rmse_per_class: [0.082, 0.231, 0.034, 0.284, 0.057, 0.164, 0.208, 0.112, 0.142, 0.099]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=169734)[0m rmse: 0.14166322350502014
[2m[36m(func pid=169734)[0m mae:  0.08956123888492584
[2m[36m(func pid=169734)[0m rmse_per_class: [0.079, 0.216, 0.028, 0.295, 0.071, 0.152, 0.195, 0.128, 0.166, 0.087]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.5109 | Steps: 2 | Val loss: 0.5012 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=174732)[0m rmse: 0.17517498135566711
[2m[36m(func pid=174732)[0m mae:  0.12607724964618683
[2m[36m(func pid=174732)[0m rmse_per_class: [0.112, 0.271, 0.096, 0.337, 0.083, 0.192, 0.27, 0.134, 0.153, 0.105]
[2m[36m(func pid=174732)[0m 
== Status ==
Current time: 2024-01-07 09:03:49 (running for 00:31:50.77)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.232 |  0.141 |                   67 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.23  |  0.142 |                   58 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.393 |  0.175 |                   39 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.533 |  0.19  |                   32 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.2341 | Steps: 2 | Val loss: 0.2814 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.2267 | Steps: 2 | Val loss: 0.2615 | Batch size: 32 | lr: 0.1 | Duration: 3.16s
[2m[36m(func pid=176115)[0m rmse: 0.1898154765367508
[2m[36m(func pid=176115)[0m mae:  0.12051773071289062
[2m[36m(func pid=176115)[0m rmse_per_class: [0.087, 0.273, 0.045, 0.366, 0.056, 0.183, 0.472, 0.154, 0.167, 0.095]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.3934 | Steps: 2 | Val loss: 0.3282 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=167906)[0m rmse: 0.14159032702445984
[2m[36m(func pid=167906)[0m mae:  0.09384123235940933
[2m[36m(func pid=167906)[0m rmse_per_class: [0.082, 0.232, 0.034, 0.286, 0.057, 0.164, 0.207, 0.112, 0.143, 0.1]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=169734)[0m rmse: 0.14014628529548645
[2m[36m(func pid=169734)[0m mae:  0.08835429698228836
[2m[36m(func pid=169734)[0m rmse_per_class: [0.078, 0.216, 0.028, 0.29, 0.072, 0.151, 0.193, 0.121, 0.166, 0.086]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.5027 | Steps: 2 | Val loss: 0.4899 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 09:03:55 (running for 00:31:55.97)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.234 |  0.142 |                   68 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.227 |  0.14  |                   59 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.393 |  0.175 |                   40 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.511 |  0.19  |                   33 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=174732)[0m rmse: 0.17499825358390808
[2m[36m(func pid=174732)[0m mae:  0.12579229474067688
[2m[36m(func pid=174732)[0m rmse_per_class: [0.111, 0.272, 0.096, 0.337, 0.081, 0.192, 0.268, 0.134, 0.153, 0.105]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.2355 | Steps: 2 | Val loss: 0.2820 | Batch size: 32 | lr: 0.01 | Duration: 3.07s
[2m[36m(func pid=176115)[0m rmse: 0.18962763249874115
[2m[36m(func pid=176115)[0m mae:  0.12019488960504532
[2m[36m(func pid=176115)[0m rmse_per_class: [0.086, 0.272, 0.045, 0.365, 0.056, 0.182, 0.471, 0.154, 0.17, 0.095]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.2352 | Steps: 2 | Val loss: 0.2624 | Batch size: 32 | lr: 0.1 | Duration: 3.03s
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.4001 | Steps: 2 | Val loss: 0.3307 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=167906)[0m rmse: 0.1417922079563141
[2m[36m(func pid=167906)[0m mae:  0.0940641313791275
[2m[36m(func pid=167906)[0m rmse_per_class: [0.082, 0.232, 0.034, 0.287, 0.057, 0.163, 0.207, 0.111, 0.144, 0.101]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=169734)[0m rmse: 0.14079901576042175
[2m[36m(func pid=169734)[0m mae:  0.08876323699951172
[2m[36m(func pid=169734)[0m rmse_per_class: [0.077, 0.219, 0.028, 0.285, 0.074, 0.151, 0.194, 0.121, 0.17, 0.086]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.4888 | Steps: 2 | Val loss: 0.4776 | Batch size: 32 | lr: 0.001 | Duration: 3.10s
== Status ==
Current time: 2024-01-07 09:04:00 (running for 00:32:01.34)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.236 |  0.142 |                   69 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.235 |  0.141 |                   60 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.4   |  0.175 |                   41 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.503 |  0.19  |                   34 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=174732)[0m rmse: 0.17477676272392273
[2m[36m(func pid=174732)[0m mae:  0.12546977400779724
[2m[36m(func pid=174732)[0m rmse_per_class: [0.112, 0.272, 0.095, 0.338, 0.081, 0.192, 0.267, 0.134, 0.155, 0.104]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.2343 | Steps: 2 | Val loss: 0.2818 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
[2m[36m(func pid=176115)[0m rmse: 0.18908654153347015
[2m[36m(func pid=176115)[0m mae:  0.11965541541576385
[2m[36m(func pid=176115)[0m rmse_per_class: [0.085, 0.271, 0.046, 0.364, 0.056, 0.181, 0.466, 0.155, 0.173, 0.095]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.2346 | Steps: 2 | Val loss: 0.2641 | Batch size: 32 | lr: 0.1 | Duration: 3.13s
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.3987 | Steps: 2 | Val loss: 0.3326 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=167906)[0m rmse: 0.14158351719379425
[2m[36m(func pid=167906)[0m mae:  0.09380252659320831
[2m[36m(func pid=167906)[0m rmse_per_class: [0.081, 0.231, 0.034, 0.288, 0.058, 0.163, 0.207, 0.112, 0.143, 0.099]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.4816 | Steps: 2 | Val loss: 0.4638 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=169734)[0m rmse: 0.1420702189207077
[2m[36m(func pid=169734)[0m mae:  0.08979041874408722
[2m[36m(func pid=169734)[0m rmse_per_class: [0.076, 0.221, 0.028, 0.285, 0.078, 0.152, 0.197, 0.122, 0.172, 0.09]
[2m[36m(func pid=169734)[0m 
== Status ==
Current time: 2024-01-07 09:04:05 (running for 00:32:06.66)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.234 |  0.142 |                   70 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.235 |  0.142 |                   61 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.399 |  0.174 |                   42 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.489 |  0.189 |                   35 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=174732)[0m rmse: 0.17436115443706512
[2m[36m(func pid=174732)[0m mae:  0.12502998113632202
[2m[36m(func pid=174732)[0m rmse_per_class: [0.111, 0.271, 0.094, 0.339, 0.079, 0.192, 0.266, 0.134, 0.155, 0.103]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.2466 | Steps: 2 | Val loss: 0.2824 | Batch size: 32 | lr: 0.01 | Duration: 3.11s
[2m[36m(func pid=176115)[0m rmse: 0.1882435381412506
[2m[36m(func pid=176115)[0m mae:  0.11890008300542831
[2m[36m(func pid=176115)[0m rmse_per_class: [0.084, 0.269, 0.046, 0.362, 0.056, 0.179, 0.462, 0.155, 0.175, 0.095]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.3987 | Steps: 2 | Val loss: 0.3355 | Batch size: 32 | lr: 0.0001 | Duration: 2.72s
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.2346 | Steps: 2 | Val loss: 0.2682 | Batch size: 32 | lr: 0.1 | Duration: 3.15s
[2m[36m(func pid=167906)[0m rmse: 0.14204858243465424
[2m[36m(func pid=167906)[0m mae:  0.09415941685438156
[2m[36m(func pid=167906)[0m rmse_per_class: [0.083, 0.231, 0.034, 0.288, 0.057, 0.163, 0.207, 0.112, 0.145, 0.101]
[2m[36m(func pid=167906)[0m 
== Status ==
Current time: 2024-01-07 09:04:10 (running for 00:32:11.75)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.247 |  0.142 |                   71 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.235 |  0.142 |                   61 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.399 |  0.174 |                   43 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.482 |  0.188 |                   36 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=174732)[0m rmse: 0.1741248220205307
[2m[36m(func pid=174732)[0m mae:  0.12470085918903351
[2m[36m(func pid=174732)[0m rmse_per_class: [0.111, 0.272, 0.093, 0.339, 0.078, 0.192, 0.264, 0.134, 0.155, 0.102]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.4580 | Steps: 2 | Val loss: 0.4514 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=169734)[0m rmse: 0.14470718801021576
[2m[36m(func pid=169734)[0m mae:  0.09179064631462097
[2m[36m(func pid=169734)[0m rmse_per_class: [0.079, 0.224, 0.029, 0.297, 0.075, 0.152, 0.2, 0.126, 0.174, 0.092]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.2390 | Steps: 2 | Val loss: 0.2829 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=176115)[0m rmse: 0.187058225274086
[2m[36m(func pid=176115)[0m mae:  0.11788521707057953
[2m[36m(func pid=176115)[0m rmse_per_class: [0.083, 0.266, 0.046, 0.36, 0.056, 0.177, 0.452, 0.155, 0.18, 0.095]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.4016 | Steps: 2 | Val loss: 0.3384 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.2280 | Steps: 2 | Val loss: 0.2673 | Batch size: 32 | lr: 0.1 | Duration: 3.17s
[2m[36m(func pid=167906)[0m rmse: 0.14251843094825745
[2m[36m(func pid=167906)[0m mae:  0.09436417371034622
[2m[36m(func pid=167906)[0m rmse_per_class: [0.083, 0.231, 0.034, 0.291, 0.057, 0.163, 0.207, 0.112, 0.146, 0.101]
[2m[36m(func pid=167906)[0m 
== Status ==
Current time: 2024-01-07 09:04:16 (running for 00:32:17.04)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.239 |  0.143 |                   72 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.235 |  0.145 |                   62 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.402 |  0.174 |                   44 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.458 |  0.187 |                   37 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=174732)[0m rmse: 0.17395073175430298
[2m[36m(func pid=174732)[0m mae:  0.12440384924411774
[2m[36m(func pid=174732)[0m rmse_per_class: [0.111, 0.272, 0.093, 0.34, 0.077, 0.192, 0.264, 0.134, 0.156, 0.101]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.4567 | Steps: 2 | Val loss: 0.4390 | Batch size: 32 | lr: 0.001 | Duration: 3.03s
[2m[36m(func pid=169734)[0m rmse: 0.14458057284355164
[2m[36m(func pid=169734)[0m mae:  0.09192754328250885
[2m[36m(func pid=169734)[0m rmse_per_class: [0.084, 0.222, 0.029, 0.303, 0.074, 0.152, 0.199, 0.124, 0.169, 0.091]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.2361 | Steps: 2 | Val loss: 0.2819 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=176115)[0m rmse: 0.18580949306488037
[2m[36m(func pid=176115)[0m mae:  0.11685611307621002
[2m[36m(func pid=176115)[0m rmse_per_class: [0.082, 0.264, 0.046, 0.359, 0.056, 0.175, 0.441, 0.155, 0.184, 0.095]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.4003 | Steps: 2 | Val loss: 0.3414 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.2314 | Steps: 2 | Val loss: 0.2658 | Batch size: 32 | lr: 0.1 | Duration: 3.27s
[2m[36m(func pid=167906)[0m rmse: 0.14220069348812103
[2m[36m(func pid=167906)[0m mae:  0.09409536421298981
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=167906)[0m rmse_per_class: [0.082, 0.231, 0.034, 0.29, 0.057, 0.163, 0.207, 0.112, 0.144, 0.101]
[2m[36m(func pid=167906)[0m 
== Status ==
Current time: 2024-01-07 09:04:21 (running for 00:32:22.47)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.236 |  0.142 |                   73 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.228 |  0.145 |                   63 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.4   |  0.174 |                   45 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.457 |  0.186 |                   38 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=174732)[0m rmse: 0.1737050712108612
[2m[36m(func pid=174732)[0m mae:  0.12406784296035767
[2m[36m(func pid=174732)[0m rmse_per_class: [0.111, 0.271, 0.093, 0.34, 0.076, 0.191, 0.263, 0.134, 0.157, 0.101]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.4363 | Steps: 2 | Val loss: 0.4264 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
[2m[36m(func pid=169734)[0m rmse: 0.1436311900615692
[2m[36m(func pid=169734)[0m mae:  0.09115402400493622
[2m[36m(func pid=169734)[0m rmse_per_class: [0.082, 0.22, 0.029, 0.301, 0.072, 0.153, 0.197, 0.127, 0.167, 0.089]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.2334 | Steps: 2 | Val loss: 0.2822 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=176115)[0m rmse: 0.18401581048965454
[2m[36m(func pid=176115)[0m mae:  0.11541996151208878
[2m[36m(func pid=176115)[0m rmse_per_class: [0.082, 0.261, 0.046, 0.356, 0.056, 0.173, 0.427, 0.155, 0.189, 0.095]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.4072 | Steps: 2 | Val loss: 0.3444 | Batch size: 32 | lr: 0.0001 | Duration: 2.81s
[2m[36m(func pid=167906)[0m rmse: 0.14275676012039185
[2m[36m(func pid=167906)[0m mae:  0.0944947898387909
[2m[36m(func pid=167906)[0m rmse_per_class: [0.083, 0.232, 0.035, 0.291, 0.056, 0.164, 0.208, 0.113, 0.144, 0.1]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.2361 | Steps: 2 | Val loss: 0.2647 | Batch size: 32 | lr: 0.1 | Duration: 3.15s
== Status ==
Current time: 2024-01-07 09:04:26 (running for 00:32:27.54)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15700000524520874
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.233 |  0.143 |                   74 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.231 |  0.144 |                   64 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.407 |  0.173 |                   46 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.436 |  0.184 |                   39 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=174732)[0m rmse: 0.17331530153751373
[2m[36m(func pid=174732)[0m mae:  0.12360624969005585
[2m[36m(func pid=174732)[0m rmse_per_class: [0.111, 0.271, 0.091, 0.34, 0.075, 0.191, 0.262, 0.134, 0.157, 0.1]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.4037 | Steps: 2 | Val loss: 0.4098 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.2332 | Steps: 2 | Val loss: 0.2818 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=169734)[0m rmse: 0.14192716777324677
[2m[36m(func pid=169734)[0m mae:  0.08996240794658661
[2m[36m(func pid=169734)[0m rmse_per_class: [0.077, 0.219, 0.028, 0.299, 0.072, 0.152, 0.195, 0.12, 0.168, 0.088]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.4069 | Steps: 2 | Val loss: 0.3471 | Batch size: 32 | lr: 0.0001 | Duration: 2.71s
[2m[36m(func pid=176115)[0m rmse: 0.18155983090400696
[2m[36m(func pid=176115)[0m mae:  0.11364193260669708
[2m[36m(func pid=176115)[0m rmse_per_class: [0.081, 0.258, 0.046, 0.352, 0.056, 0.171, 0.411, 0.154, 0.191, 0.095]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.14251473546028137
[2m[36m(func pid=167906)[0m mae:  0.09439224749803543
[2m[36m(func pid=167906)[0m rmse_per_class: [0.084, 0.232, 0.035, 0.289, 0.057, 0.164, 0.209, 0.113, 0.144, 0.099]
[2m[36m(func pid=167906)[0m 
== Status ==
Current time: 2024-01-07 09:04:31 (running for 00:32:32.69)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.1562500037252903
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.233 |  0.143 |                   75 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.236 |  0.142 |                   65 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.407 |  0.173 |                   47 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.404 |  0.182 |                   40 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=174732)[0m rmse: 0.17287352681159973
[2m[36m(func pid=174732)[0m mae:  0.12310664355754852
[2m[36m(func pid=174732)[0m rmse_per_class: [0.111, 0.271, 0.09, 0.34, 0.074, 0.191, 0.26, 0.134, 0.157, 0.1]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.2310 | Steps: 2 | Val loss: 0.2646 | Batch size: 32 | lr: 0.1 | Duration: 3.16s
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.3937 | Steps: 2 | Val loss: 0.3955 | Batch size: 32 | lr: 0.001 | Duration: 3.03s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 75] | Train loss: 0.2358 | Steps: 2 | Val loss: 0.2829 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=169734)[0m rmse: 0.14171865582466125
[2m[36m(func pid=169734)[0m mae:  0.08983670175075531
[2m[36m(func pid=169734)[0m rmse_per_class: [0.075, 0.22, 0.028, 0.297, 0.075, 0.153, 0.197, 0.115, 0.171, 0.087]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.4125 | Steps: 2 | Val loss: 0.3500 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=176115)[0m rmse: 0.17956039309501648
[2m[36m(func pid=176115)[0m mae:  0.11216358840465546
[2m[36m(func pid=176115)[0m rmse_per_class: [0.08, 0.255, 0.046, 0.349, 0.056, 0.169, 0.398, 0.154, 0.194, 0.095]
[2m[36m(func pid=176115)[0m 
== Status ==
Current time: 2024-01-07 09:04:36 (running for 00:32:37.77)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.1562500037252903
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.236 |  0.143 |                   76 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.231 |  0.142 |                   66 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.407 |  0.173 |                   47 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.394 |  0.18  |                   41 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=167906)[0m rmse: 0.14276333153247833
[2m[36m(func pid=167906)[0m mae:  0.09439545124769211
[2m[36m(func pid=167906)[0m rmse_per_class: [0.084, 0.231, 0.035, 0.29, 0.057, 0.164, 0.208, 0.114, 0.145, 0.099]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=174732)[0m rmse: 0.17264650762081146
[2m[36m(func pid=174732)[0m mae:  0.12273798137903214
[2m[36m(func pid=174732)[0m rmse_per_class: [0.111, 0.271, 0.089, 0.341, 0.074, 0.191, 0.259, 0.134, 0.158, 0.099]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.2344 | Steps: 2 | Val loss: 0.2658 | Batch size: 32 | lr: 0.1 | Duration: 3.27s
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.3738 | Steps: 2 | Val loss: 0.3826 | Batch size: 32 | lr: 0.001 | Duration: 3.10s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 76] | Train loss: 0.2291 | Steps: 2 | Val loss: 0.2827 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.4128 | Steps: 2 | Val loss: 0.3526 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
[2m[36m(func pid=169734)[0m rmse: 0.1430503875017166
[2m[36m(func pid=169734)[0m mae:  0.09034891426563263
[2m[36m(func pid=169734)[0m rmse_per_class: [0.075, 0.222, 0.029, 0.292, 0.081, 0.154, 0.197, 0.114, 0.179, 0.087]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=176115)[0m rmse: 0.1766507476568222
[2m[36m(func pid=176115)[0m mae:  0.11014463007450104
[2m[36m(func pid=176115)[0m rmse_per_class: [0.08, 0.251, 0.046, 0.346, 0.056, 0.166, 0.374, 0.154, 0.198, 0.095]
[2m[36m(func pid=176115)[0m 
== Status ==
Current time: 2024-01-07 09:04:42 (running for 00:32:43.07)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.1562500037252903
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.142 |                   77 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.234 |  0.143 |                   67 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.412 |  0.173 |                   48 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.374 |  0.177 |                   42 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=167906)[0m rmse: 0.14248956739902496
[2m[36m(func pid=167906)[0m mae:  0.09423725306987762
[2m[36m(func pid=167906)[0m rmse_per_class: [0.084, 0.231, 0.035, 0.289, 0.057, 0.164, 0.208, 0.114, 0.144, 0.098]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=174732)[0m rmse: 0.17245665192604065
[2m[36m(func pid=174732)[0m mae:  0.12245529890060425
[2m[36m(func pid=174732)[0m rmse_per_class: [0.11, 0.271, 0.088, 0.341, 0.073, 0.191, 0.259, 0.134, 0.159, 0.098]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.3703 | Steps: 2 | Val loss: 0.3695 | Batch size: 32 | lr: 0.001 | Duration: 3.06s
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.2323 | Steps: 2 | Val loss: 0.2663 | Batch size: 32 | lr: 0.1 | Duration: 3.23s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 77] | Train loss: 0.2284 | Steps: 2 | Val loss: 0.2822 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.4093 | Steps: 2 | Val loss: 0.3562 | Batch size: 32 | lr: 0.0001 | Duration: 2.73s
[2m[36m(func pid=176115)[0m rmse: 0.17312470078468323
[2m[36m(func pid=176115)[0m mae:  0.10773377120494843
[2m[36m(func pid=176115)[0m rmse_per_class: [0.082, 0.245, 0.045, 0.34, 0.056, 0.165, 0.347, 0.154, 0.202, 0.095]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=169734)[0m rmse: 0.14418227970600128
[2m[36m(func pid=169734)[0m mae:  0.09112747013568878
[2m[36m(func pid=169734)[0m rmse_per_class: [0.083, 0.223, 0.029, 0.295, 0.083, 0.154, 0.195, 0.114, 0.179, 0.086]
[2m[36m(func pid=169734)[0m 
== Status ==
Current time: 2024-01-07 09:04:47 (running for 00:32:48.52)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.1562500037252903
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.228 |  0.142 |                   78 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.232 |  0.144 |                   68 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.413 |  0.172 |                   49 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.37  |  0.173 |                   43 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=167906)[0m rmse: 0.1422303169965744
[2m[36m(func pid=167906)[0m mae:  0.0941590890288353
[2m[36m(func pid=167906)[0m rmse_per_class: [0.085, 0.231, 0.034, 0.288, 0.058, 0.164, 0.209, 0.114, 0.144, 0.096]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=174732)[0m rmse: 0.17235226929187775
[2m[36m(func pid=174732)[0m mae:  0.12220907211303711
[2m[36m(func pid=174732)[0m rmse_per_class: [0.111, 0.271, 0.087, 0.342, 0.072, 0.191, 0.259, 0.135, 0.159, 0.098]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.3566 | Steps: 2 | Val loss: 0.3558 | Batch size: 32 | lr: 0.001 | Duration: 3.04s
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.2388 | Steps: 2 | Val loss: 0.2637 | Batch size: 32 | lr: 0.1 | Duration: 3.21s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 78] | Train loss: 0.2375 | Steps: 2 | Val loss: 0.2812 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.4220 | Steps: 2 | Val loss: 0.3591 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=176115)[0m rmse: 0.16979444026947021
[2m[36m(func pid=176115)[0m mae:  0.10546622425317764
[2m[36m(func pid=176115)[0m rmse_per_class: [0.082, 0.241, 0.045, 0.333, 0.056, 0.164, 0.324, 0.154, 0.204, 0.094]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=169734)[0m rmse: 0.1431712806224823
[2m[36m(func pid=169734)[0m mae:  0.09046073257923126
[2m[36m(func pid=169734)[0m rmse_per_class: [0.084, 0.222, 0.029, 0.292, 0.078, 0.155, 0.194, 0.117, 0.174, 0.087]
[2m[36m(func pid=169734)[0m 
== Status ==
Current time: 2024-01-07 09:04:52 (running for 00:32:53.79)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.1562500037252903
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.237 |  0.142 |                   79 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.239 |  0.143 |                   69 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.409 |  0.172 |                   50 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.357 |  0.17  |                   44 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=167906)[0m rmse: 0.1416059285402298
[2m[36m(func pid=167906)[0m mae:  0.09376604855060577
[2m[36m(func pid=167906)[0m rmse_per_class: [0.086, 0.23, 0.035, 0.283, 0.057, 0.163, 0.209, 0.112, 0.145, 0.096]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=174732)[0m rmse: 0.17219020426273346
[2m[36m(func pid=174732)[0m mae:  0.12196037918329239
[2m[36m(func pid=174732)[0m rmse_per_class: [0.111, 0.271, 0.086, 0.342, 0.071, 0.191, 0.259, 0.135, 0.159, 0.097]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.3406 | Steps: 2 | Val loss: 0.3428 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.2369 | Steps: 2 | Val loss: 0.2619 | Batch size: 32 | lr: 0.1 | Duration: 3.29s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 79] | Train loss: 0.2305 | Steps: 2 | Val loss: 0.2801 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.4188 | Steps: 2 | Val loss: 0.3618 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=176115)[0m rmse: 0.16621044278144836
[2m[36m(func pid=176115)[0m mae:  0.10315781831741333
[2m[36m(func pid=176115)[0m rmse_per_class: [0.081, 0.237, 0.044, 0.327, 0.056, 0.164, 0.302, 0.153, 0.202, 0.094]
[2m[36m(func pid=176115)[0m 
== Status ==
Current time: 2024-01-07 09:04:58 (running for 00:32:59.05)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.1562500037252903
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.237 |  0.142 |                   79 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.237 |  0.142 |                   70 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.422 |  0.172 |                   51 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.341 |  0.166 |                   45 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=169734)[0m rmse: 0.1419312059879303
[2m[36m(func pid=169734)[0m mae:  0.08967280387878418
[2m[36m(func pid=169734)[0m rmse_per_class: [0.08, 0.218, 0.028, 0.292, 0.071, 0.154, 0.195, 0.127, 0.167, 0.086]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.14101958274841309
[2m[36m(func pid=167906)[0m mae:  0.09320186078548431
[2m[36m(func pid=167906)[0m rmse_per_class: [0.084, 0.231, 0.035, 0.279, 0.056, 0.163, 0.209, 0.112, 0.146, 0.095]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=174732)[0m rmse: 0.17195579409599304
[2m[36m(func pid=174732)[0m mae:  0.12161503732204437
[2m[36m(func pid=174732)[0m rmse_per_class: [0.111, 0.27, 0.085, 0.342, 0.07, 0.191, 0.258, 0.135, 0.159, 0.097]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.3320 | Steps: 2 | Val loss: 0.3317 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 80] | Train loss: 0.2310 | Steps: 2 | Val loss: 0.2805 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.2274 | Steps: 2 | Val loss: 0.2626 | Batch size: 32 | lr: 0.1 | Duration: 3.30s
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.4242 | Steps: 2 | Val loss: 0.3640 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=176115)[0m rmse: 0.16324321925640106
[2m[36m(func pid=176115)[0m mae:  0.10127584636211395
[2m[36m(func pid=176115)[0m rmse_per_class: [0.082, 0.235, 0.044, 0.321, 0.056, 0.166, 0.279, 0.152, 0.204, 0.094]
[2m[36m(func pid=176115)[0m 
== Status ==
Current time: 2024-01-07 09:05:04 (running for 00:33:04.91)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.1562500037252903
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.231 |  0.141 |                   81 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.237 |  0.142 |                   70 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.419 |  0.172 |                   52 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.332 |  0.163 |                   46 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=167906)[0m rmse: 0.14075182378292084
[2m[36m(func pid=167906)[0m mae:  0.09289325773715973
[2m[36m(func pid=167906)[0m rmse_per_class: [0.083, 0.231, 0.034, 0.278, 0.056, 0.162, 0.208, 0.113, 0.147, 0.095]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=169734)[0m rmse: 0.14119955897331238
[2m[36m(func pid=169734)[0m mae:  0.08996783941984177
[2m[36m(func pid=169734)[0m rmse_per_class: [0.079, 0.216, 0.027, 0.296, 0.071, 0.151, 0.201, 0.123, 0.161, 0.086]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=174732)[0m rmse: 0.17169640958309174
[2m[36m(func pid=174732)[0m mae:  0.1212739497423172
[2m[36m(func pid=174732)[0m rmse_per_class: [0.11, 0.27, 0.084, 0.343, 0.069, 0.191, 0.258, 0.135, 0.16, 0.096]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.3284 | Steps: 2 | Val loss: 0.3229 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 81] | Train loss: 0.2331 | Steps: 2 | Val loss: 0.2801 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.4303 | Steps: 2 | Val loss: 0.3666 | Batch size: 32 | lr: 0.0001 | Duration: 3.05s
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.2315 | Steps: 2 | Val loss: 0.2658 | Batch size: 32 | lr: 0.1 | Duration: 3.18s
[2m[36m(func pid=176115)[0m rmse: 0.16061273217201233
[2m[36m(func pid=176115)[0m mae:  0.09995175898075104
[2m[36m(func pid=176115)[0m rmse_per_class: [0.083, 0.232, 0.043, 0.316, 0.056, 0.17, 0.249, 0.152, 0.211, 0.094]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.14014826714992523
[2m[36m(func pid=167906)[0m mae:  0.09237048029899597
[2m[36m(func pid=167906)[0m rmse_per_class: [0.081, 0.231, 0.034, 0.276, 0.055, 0.162, 0.207, 0.113, 0.147, 0.096]
== Status ==
Current time: 2024-01-07 09:05:09 (running for 00:33:10.49)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.1562500037252903
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.233 |  0.14  |                   82 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.227 |  0.141 |                   71 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.424 |  0.172 |                   53 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.328 |  0.161 |                   47 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=174732)[0m rmse: 0.17163313925266266
[2m[36m(func pid=174732)[0m mae:  0.12114693969488144
[2m[36m(func pid=174732)[0m rmse_per_class: [0.11, 0.27, 0.084, 0.343, 0.069, 0.191, 0.258, 0.135, 0.16, 0.096]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=169734)[0m rmse: 0.14215126633644104
[2m[36m(func pid=169734)[0m mae:  0.09089112281799316
[2m[36m(func pid=169734)[0m rmse_per_class: [0.077, 0.216, 0.027, 0.301, 0.072, 0.156, 0.206, 0.118, 0.161, 0.088]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.3276 | Steps: 2 | Val loss: 0.3127 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 82] | Train loss: 0.2361 | Steps: 2 | Val loss: 0.2805 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.4285 | Steps: 2 | Val loss: 0.3695 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.2360 | Steps: 2 | Val loss: 0.2652 | Batch size: 32 | lr: 0.1 | Duration: 3.16s
[2m[36m(func pid=176115)[0m rmse: 0.1572188436985016
[2m[36m(func pid=176115)[0m mae:  0.09790488332509995
[2m[36m(func pid=176115)[0m rmse_per_class: [0.084, 0.228, 0.043, 0.307, 0.056, 0.173, 0.227, 0.151, 0.209, 0.093]
[2m[36m(func pid=176115)[0m 
== Status ==
Current time: 2024-01-07 09:05:14 (running for 00:33:15.76)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.1562500037252903
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.236 |  0.14  |                   83 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.232 |  0.142 |                   72 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.43  |  0.172 |                   54 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.328 |  0.157 |                   48 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=167906)[0m rmse: 0.14018693566322327
[2m[36m(func pid=167906)[0m mae:  0.09221057593822479
[2m[36m(func pid=167906)[0m rmse_per_class: [0.08, 0.231, 0.034, 0.277, 0.055, 0.161, 0.206, 0.114, 0.146, 0.098]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=174732)[0m rmse: 0.1714668720960617
[2m[36m(func pid=174732)[0m mae:  0.12082544714212418
[2m[36m(func pid=174732)[0m rmse_per_class: [0.11, 0.27, 0.083, 0.343, 0.068, 0.19, 0.258, 0.136, 0.16, 0.096]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=169734)[0m rmse: 0.14154458045959473
[2m[36m(func pid=169734)[0m mae:  0.09025470167398453
[2m[36m(func pid=169734)[0m rmse_per_class: [0.078, 0.217, 0.029, 0.297, 0.078, 0.153, 0.198, 0.113, 0.164, 0.089]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.3038 | Steps: 2 | Val loss: 0.3043 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 83] | Train loss: 0.2403 | Steps: 2 | Val loss: 0.2798 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.4279 | Steps: 2 | Val loss: 0.3717 | Batch size: 32 | lr: 0.0001 | Duration: 2.81s
[2m[36m(func pid=176115)[0m rmse: 0.15502379834651947
[2m[36m(func pid=176115)[0m mae:  0.09690122306346893
[2m[36m(func pid=176115)[0m rmse_per_class: [0.084, 0.226, 0.042, 0.302, 0.056, 0.179, 0.212, 0.15, 0.207, 0.093]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.2327 | Steps: 2 | Val loss: 0.2657 | Batch size: 32 | lr: 0.1 | Duration: 3.21s
== Status ==
Current time: 2024-01-07 09:05:20 (running for 00:33:21.07)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.1562500037252903
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.24  |  0.14  |                   84 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.236 |  0.142 |                   73 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.429 |  0.171 |                   55 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.304 |  0.155 |                   49 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=167906)[0m rmse: 0.13965490460395813
[2m[36m(func pid=167906)[0m mae:  0.09168799221515656
[2m[36m(func pid=167906)[0m rmse_per_class: [0.08, 0.23, 0.034, 0.274, 0.055, 0.161, 0.205, 0.114, 0.146, 0.097]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=174732)[0m rmse: 0.17124240100383759
[2m[36m(func pid=174732)[0m mae:  0.12048733234405518
[2m[36m(func pid=174732)[0m rmse_per_class: [0.11, 0.27, 0.081, 0.343, 0.067, 0.19, 0.259, 0.136, 0.161, 0.095]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=169734)[0m rmse: 0.1427454650402069
[2m[36m(func pid=169734)[0m mae:  0.0904974415898323
[2m[36m(func pid=169734)[0m rmse_per_class: [0.084, 0.22, 0.03, 0.301, 0.079, 0.153, 0.192, 0.112, 0.168, 0.088]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.3322 | Steps: 2 | Val loss: 0.2991 | Batch size: 32 | lr: 0.001 | Duration: 3.05s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 84] | Train loss: 0.2409 | Steps: 2 | Val loss: 0.2807 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.4272 | Steps: 2 | Val loss: 0.3739 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=176115)[0m rmse: 0.1536906510591507
[2m[36m(func pid=176115)[0m mae:  0.09645573049783707
[2m[36m(func pid=176115)[0m rmse_per_class: [0.087, 0.225, 0.042, 0.296, 0.056, 0.182, 0.199, 0.149, 0.209, 0.093]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.2385 | Steps: 2 | Val loss: 0.2676 | Batch size: 32 | lr: 0.1 | Duration: 3.16s
[2m[36m(func pid=167906)[0m rmse: 0.14012280106544495
[2m[36m(func pid=167906)[0m mae:  0.09198286384344101
[2m[36m(func pid=167906)[0m rmse_per_class: [0.08, 0.231, 0.034, 0.278, 0.055, 0.161, 0.204, 0.114, 0.147, 0.098]
[2m[36m(func pid=174732)[0m rmse: 0.17110675573349
[2m[36m(func pid=174732)[0m mae:  0.12020455300807953
[2m[36m(func pid=174732)[0m rmse_per_class: [0.11, 0.27, 0.08, 0.343, 0.066, 0.19, 0.259, 0.136, 0.161, 0.095]
[2m[36m(func pid=174732)[0m 
== Status ==
Current time: 2024-01-07 09:05:25 (running for 00:33:26.47)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.1562500037252903
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.24  |  0.14  |                   84 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.233 |  0.143 |                   74 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.427 |  0.171 |                   57 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.332 |  0.154 |                   50 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.3118 | Steps: 2 | Val loss: 0.2924 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=169734)[0m rmse: 0.14459958672523499
[2m[36m(func pid=169734)[0m mae:  0.09160517156124115
[2m[36m(func pid=169734)[0m rmse_per_class: [0.084, 0.222, 0.03, 0.305, 0.075, 0.153, 0.193, 0.122, 0.174, 0.087]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.4309 | Steps: 2 | Val loss: 0.3758 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 85] | Train loss: 0.2387 | Steps: 2 | Val loss: 0.2815 | Batch size: 32 | lr: 0.01 | Duration: 3.06s
[2m[36m(func pid=176115)[0m rmse: 0.15178562700748444
[2m[36m(func pid=176115)[0m mae:  0.09542869031429291
[2m[36m(func pid=176115)[0m rmse_per_class: [0.087, 0.223, 0.041, 0.289, 0.056, 0.187, 0.195, 0.146, 0.202, 0.092]
[2m[36m(func pid=176115)[0m 
== Status ==
Current time: 2024-01-07 09:05:30 (running for 00:33:31.74)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15049999952316284
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.241 |  0.14  |                   85 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.239 |  0.145 |                   75 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.431 |  0.171 |                   58 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.312 |  0.152 |                   51 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=174732)[0m rmse: 0.1708395630121231
[2m[36m(func pid=174732)[0m mae:  0.11979930102825165
[2m[36m(func pid=174732)[0m rmse_per_class: [0.11, 0.269, 0.079, 0.344, 0.066, 0.19, 0.259, 0.136, 0.161, 0.095]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 75] | Train loss: 0.2238 | Steps: 2 | Val loss: 0.2667 | Batch size: 32 | lr: 0.1 | Duration: 3.17s
[2m[36m(func pid=167906)[0m rmse: 0.14056234061717987
[2m[36m(func pid=167906)[0m mae:  0.09237376600503922
[2m[36m(func pid=167906)[0m rmse_per_class: [0.081, 0.23, 0.033, 0.281, 0.055, 0.162, 0.204, 0.113, 0.146, 0.1]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.3116 | Steps: 2 | Val loss: 0.2887 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
[2m[36m(func pid=169734)[0m rmse: 0.1444186270236969
[2m[36m(func pid=169734)[0m mae:  0.09186826646327972
[2m[36m(func pid=169734)[0m rmse_per_class: [0.081, 0.217, 0.029, 0.307, 0.075, 0.153, 0.199, 0.129, 0.169, 0.085]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.4307 | Steps: 2 | Val loss: 0.3780 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 86] | Train loss: 0.2262 | Steps: 2 | Val loss: 0.2809 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=176115)[0m rmse: 0.1509295552968979
[2m[36m(func pid=176115)[0m mae:  0.0953429788351059
[2m[36m(func pid=176115)[0m rmse_per_class: [0.086, 0.222, 0.039, 0.286, 0.056, 0.192, 0.194, 0.144, 0.198, 0.091]
[2m[36m(func pid=176115)[0m 
== Status ==
Current time: 2024-01-07 09:05:36 (running for 00:33:37.06)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15049999952316284
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.239 |  0.141 |                   86 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.224 |  0.144 |                   76 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.431 |  0.171 |                   59 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.312 |  0.151 |                   52 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=174732)[0m rmse: 0.17065851390361786
[2m[36m(func pid=174732)[0m mae:  0.1194886565208435
[2m[36m(func pid=174732)[0m rmse_per_class: [0.11, 0.269, 0.077, 0.344, 0.065, 0.189, 0.26, 0.136, 0.161, 0.094]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.14064793288707733
[2m[36m(func pid=167906)[0m mae:  0.0925050899386406
[2m[36m(func pid=167906)[0m rmse_per_class: [0.081, 0.23, 0.034, 0.284, 0.057, 0.163, 0.204, 0.112, 0.144, 0.097]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 76] | Train loss: 0.2351 | Steps: 2 | Val loss: 0.2649 | Batch size: 32 | lr: 0.1 | Duration: 3.22s
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.3207 | Steps: 2 | Val loss: 0.2855 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.4360 | Steps: 2 | Val loss: 0.3800 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 87] | Train loss: 0.2321 | Steps: 2 | Val loss: 0.2817 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=169734)[0m rmse: 0.1429075002670288
[2m[36m(func pid=169734)[0m mae:  0.09103819727897644
[2m[36m(func pid=169734)[0m rmse_per_class: [0.077, 0.216, 0.028, 0.298, 0.074, 0.152, 0.204, 0.127, 0.166, 0.086]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=176115)[0m rmse: 0.15010610222816467
[2m[36m(func pid=176115)[0m mae:  0.09509226679801941
[2m[36m(func pid=176115)[0m rmse_per_class: [0.085, 0.221, 0.038, 0.282, 0.056, 0.195, 0.196, 0.141, 0.195, 0.091]
[2m[36m(func pid=176115)[0m 
== Status ==
Current time: 2024-01-07 09:05:41 (running for 00:33:42.50)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15049999952316284
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.226 |  0.141 |                   87 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.235 |  0.143 |                   77 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.436 |  0.17  |                   60 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.321 |  0.15  |                   53 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=174732)[0m rmse: 0.17042379081249237
[2m[36m(func pid=174732)[0m mae:  0.119114950299263
[2m[36m(func pid=174732)[0m rmse_per_class: [0.11, 0.269, 0.076, 0.344, 0.064, 0.189, 0.26, 0.136, 0.161, 0.094]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.14120742678642273
[2m[36m(func pid=167906)[0m mae:  0.09295957535505295
[2m[36m(func pid=167906)[0m rmse_per_class: [0.081, 0.23, 0.034, 0.287, 0.058, 0.164, 0.205, 0.113, 0.144, 0.098]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 77] | Train loss: 0.2365 | Steps: 2 | Val loss: 0.2639 | Batch size: 32 | lr: 0.1 | Duration: 3.09s
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.3095 | Steps: 2 | Val loss: 0.2842 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.4323 | Steps: 2 | Val loss: 0.3818 | Batch size: 32 | lr: 0.0001 | Duration: 3.04s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 88] | Train loss: 0.2306 | Steps: 2 | Val loss: 0.2810 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=169734)[0m rmse: 0.14120101928710938
[2m[36m(func pid=169734)[0m mae:  0.08991722762584686
[2m[36m(func pid=169734)[0m rmse_per_class: [0.079, 0.215, 0.027, 0.296, 0.073, 0.152, 0.198, 0.119, 0.165, 0.087]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=176115)[0m rmse: 0.14974935352802277
[2m[36m(func pid=176115)[0m mae:  0.09519883990287781
[2m[36m(func pid=176115)[0m rmse_per_class: [0.084, 0.22, 0.036, 0.279, 0.056, 0.198, 0.201, 0.138, 0.194, 0.09]
[2m[36m(func pid=176115)[0m 
== Status ==
Current time: 2024-01-07 09:05:47 (running for 00:33:48.04)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15049999952316284
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.232 |  0.141 |                   88 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.237 |  0.141 |                   78 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.432 |  0.17  |                   61 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.309 |  0.15  |                   54 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=174732)[0m rmse: 0.17030787467956543
[2m[36m(func pid=174732)[0m mae:  0.11893685162067413
[2m[36m(func pid=174732)[0m rmse_per_class: [0.11, 0.269, 0.075, 0.344, 0.064, 0.189, 0.26, 0.137, 0.162, 0.094]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.14080986380577087
[2m[36m(func pid=167906)[0m mae:  0.09265721589326859
[2m[36m(func pid=167906)[0m rmse_per_class: [0.082, 0.229, 0.034, 0.286, 0.058, 0.164, 0.204, 0.112, 0.143, 0.096]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 78] | Train loss: 0.2298 | Steps: 2 | Val loss: 0.2624 | Batch size: 32 | lr: 0.1 | Duration: 3.28s
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.3196 | Steps: 2 | Val loss: 0.2821 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.4391 | Steps: 2 | Val loss: 0.3826 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 89] | Train loss: 0.2340 | Steps: 2 | Val loss: 0.2815 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=169734)[0m rmse: 0.14001241326332092
[2m[36m(func pid=169734)[0m mae:  0.08886455744504929
[2m[36m(func pid=169734)[0m rmse_per_class: [0.078, 0.216, 0.028, 0.298, 0.071, 0.154, 0.192, 0.115, 0.163, 0.087]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=176115)[0m rmse: 0.14903029799461365
[2m[36m(func pid=176115)[0m mae:  0.09503866732120514
[2m[36m(func pid=176115)[0m rmse_per_class: [0.083, 0.22, 0.035, 0.277, 0.056, 0.2, 0.206, 0.134, 0.19, 0.089]
[2m[36m(func pid=176115)[0m 
== Status ==
Current time: 2024-01-07 09:05:52 (running for 00:33:53.28)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15049999952316284
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.231 |  0.141 |                   89 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.23  |  0.14  |                   79 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.439 |  0.17  |                   62 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.32  |  0.149 |                   55 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=174732)[0m rmse: 0.17014087736606598
[2m[36m(func pid=174732)[0m mae:  0.11869311332702637
[2m[36m(func pid=174732)[0m rmse_per_class: [0.109, 0.269, 0.074, 0.344, 0.064, 0.189, 0.26, 0.137, 0.162, 0.094]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.14115236699581146
[2m[36m(func pid=167906)[0m mae:  0.09295108169317245
[2m[36m(func pid=167906)[0m rmse_per_class: [0.082, 0.23, 0.034, 0.287, 0.058, 0.164, 0.205, 0.112, 0.143, 0.096]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 79] | Train loss: 0.2294 | Steps: 2 | Val loss: 0.2632 | Batch size: 32 | lr: 0.1 | Duration: 3.16s
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.3085 | Steps: 2 | Val loss: 0.2801 | Batch size: 32 | lr: 0.001 | Duration: 3.19s
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.4390 | Steps: 2 | Val loss: 0.3848 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 90] | Train loss: 0.2327 | Steps: 2 | Val loss: 0.2819 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=169734)[0m rmse: 0.14071349799633026
[2m[36m(func pid=169734)[0m mae:  0.08929723501205444
[2m[36m(func pid=169734)[0m rmse_per_class: [0.078, 0.219, 0.028, 0.296, 0.071, 0.155, 0.193, 0.117, 0.163, 0.088]
[2m[36m(func pid=169734)[0m 
== Status ==
Current time: 2024-01-07 09:05:57 (running for 00:33:58.67)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15049999952316284
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.234 |  0.141 |                   90 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.229 |  0.141 |                   80 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.439 |  0.17  |                   63 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.32  |  0.149 |                   55 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=174732)[0m rmse: 0.16999202966690063
[2m[36m(func pid=174732)[0m mae:  0.11843496561050415
[2m[36m(func pid=174732)[0m rmse_per_class: [0.11, 0.268, 0.073, 0.344, 0.063, 0.189, 0.26, 0.137, 0.163, 0.093]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=176115)[0m rmse: 0.14779861271381378
[2m[36m(func pid=176115)[0m mae:  0.09456196427345276
[2m[36m(func pid=176115)[0m rmse_per_class: [0.079, 0.219, 0.034, 0.272, 0.056, 0.202, 0.214, 0.129, 0.184, 0.089]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.1414521187543869
[2m[36m(func pid=167906)[0m mae:  0.0932929664850235
[2m[36m(func pid=167906)[0m rmse_per_class: [0.083, 0.23, 0.034, 0.287, 0.058, 0.165, 0.206, 0.111, 0.144, 0.097]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 80] | Train loss: 0.2278 | Steps: 2 | Val loss: 0.2648 | Batch size: 32 | lr: 0.1 | Duration: 3.23s
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.3285 | Steps: 2 | Val loss: 0.2793 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.4485 | Steps: 2 | Val loss: 0.3867 | Batch size: 32 | lr: 0.0001 | Duration: 3.15s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 91] | Train loss: 0.2331 | Steps: 2 | Val loss: 0.2816 | Batch size: 32 | lr: 0.01 | Duration: 3.06s
== Status ==
Current time: 2024-01-07 09:06:03 (running for 00:34:03.89)
Memory usage on this node: 26.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15049999952316284
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.233 |  0.141 |                   91 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.229 |  0.141 |                   80 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.439 |  0.17  |                   63 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.309 |  0.148 |                   56 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=169734)[0m rmse: 0.14218106865882874
[2m[36m(func pid=169734)[0m mae:  0.09045575559139252
[2m[36m(func pid=169734)[0m rmse_per_class: [0.079, 0.222, 0.028, 0.292, 0.072, 0.153, 0.196, 0.124, 0.164, 0.091]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=174732)[0m rmse: 0.16994920372962952
[2m[36m(func pid=174732)[0m mae:  0.11819981038570404
[2m[36m(func pid=174732)[0m rmse_per_class: [0.109, 0.268, 0.072, 0.344, 0.062, 0.189, 0.26, 0.138, 0.163, 0.093]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=176115)[0m rmse: 0.14716094732284546
[2m[36m(func pid=176115)[0m mae:  0.09447617828845978
[2m[36m(func pid=176115)[0m rmse_per_class: [0.079, 0.219, 0.034, 0.269, 0.056, 0.198, 0.222, 0.125, 0.182, 0.088]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.14128592610359192
[2m[36m(func pid=167906)[0m mae:  0.09318254142999649
[2m[36m(func pid=167906)[0m rmse_per_class: [0.084, 0.229, 0.034, 0.286, 0.058, 0.164, 0.206, 0.111, 0.144, 0.096]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.4371 | Steps: 2 | Val loss: 0.3883 | Batch size: 32 | lr: 0.0001 | Duration: 3.04s
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.3183 | Steps: 2 | Val loss: 0.2792 | Batch size: 32 | lr: 0.001 | Duration: 3.05s
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 81] | Train loss: 0.2346 | Steps: 2 | Val loss: 0.2667 | Batch size: 32 | lr: 0.1 | Duration: 3.20s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 92] | Train loss: 0.2355 | Steps: 2 | Val loss: 0.2820 | Batch size: 32 | lr: 0.01 | Duration: 3.13s
== Status ==
Current time: 2024-01-07 09:06:08 (running for 00:34:09.32)
Memory usage on this node: 25.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15049999952316284
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.233 |  0.141 |                   92 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.228 |  0.142 |                   81 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.449 |  0.17  |                   64 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.329 |  0.147 |                   57 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=174732)[0m rmse: 0.16978703439235687
[2m[36m(func pid=174732)[0m mae:  0.11790899187326431
[2m[36m(func pid=174732)[0m rmse_per_class: [0.109, 0.268, 0.072, 0.344, 0.062, 0.189, 0.261, 0.138, 0.164, 0.093]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=176115)[0m rmse: 0.146710604429245
[2m[36m(func pid=176115)[0m mae:  0.09445832669734955
[2m[36m(func pid=176115)[0m rmse_per_class: [0.077, 0.218, 0.033, 0.267, 0.056, 0.198, 0.23, 0.121, 0.179, 0.087]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.14146611094474792
[2m[36m(func pid=167906)[0m mae:  0.09334740042686462
[2m[36m(func pid=167906)[0m rmse_per_class: [0.083, 0.23, 0.034, 0.286, 0.058, 0.164, 0.207, 0.112, 0.144, 0.098]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=169734)[0m rmse: 0.14349748194217682
[2m[36m(func pid=169734)[0m mae:  0.09155453741550446
[2m[36m(func pid=169734)[0m rmse_per_class: [0.08, 0.222, 0.028, 0.297, 0.072, 0.153, 0.2, 0.126, 0.165, 0.091]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.4399 | Steps: 2 | Val loss: 0.3889 | Batch size: 32 | lr: 0.0001 | Duration: 3.03s
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.3139 | Steps: 2 | Val loss: 0.2782 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 93] | Train loss: 0.2327 | Steps: 2 | Val loss: 0.2839 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 82] | Train loss: 0.2275 | Steps: 2 | Val loss: 0.2634 | Batch size: 32 | lr: 0.1 | Duration: 3.24s
== Status ==
Current time: 2024-01-07 09:06:14 (running for 00:34:15.03)
Memory usage on this node: 26.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15049999952316284
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.235 |  0.141 |                   93 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.235 |  0.143 |                   82 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.437 |  0.17  |                   65 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.318 |  0.147 |                   58 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=174732)[0m rmse: 0.16955097019672394
[2m[36m(func pid=174732)[0m mae:  0.11758808046579361
[2m[36m(func pid=174732)[0m rmse_per_class: [0.108, 0.268, 0.07, 0.344, 0.061, 0.189, 0.262, 0.138, 0.164, 0.092]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=176115)[0m rmse: 0.14597538113594055
[2m[36m(func pid=176115)[0m mae:  0.0943259745836258
[2m[36m(func pid=176115)[0m rmse_per_class: [0.075, 0.218, 0.032, 0.266, 0.056, 0.197, 0.236, 0.116, 0.179, 0.086]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.14237767457962036
[2m[36m(func pid=167906)[0m mae:  0.09411970525979996
[2m[36m(func pid=167906)[0m rmse_per_class: [0.084, 0.23, 0.035, 0.288, 0.058, 0.164, 0.207, 0.112, 0.145, 0.101]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=169734)[0m rmse: 0.14126941561698914
[2m[36m(func pid=169734)[0m mae:  0.08982827514410019
[2m[36m(func pid=169734)[0m rmse_per_class: [0.076, 0.22, 0.029, 0.296, 0.069, 0.152, 0.195, 0.121, 0.165, 0.09]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.4339 | Steps: 2 | Val loss: 0.3890 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.3137 | Steps: 2 | Val loss: 0.2774 | Batch size: 32 | lr: 0.001 | Duration: 3.06s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 94] | Train loss: 0.2352 | Steps: 2 | Val loss: 0.2843 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 83] | Train loss: 0.2259 | Steps: 2 | Val loss: 0.2616 | Batch size: 32 | lr: 0.1 | Duration: 2.98s
[2m[36m(func pid=174732)[0m rmse: 0.16939763724803925
[2m[36m(func pid=174732)[0m mae:  0.11736144125461578
[2m[36m(func pid=174732)[0m rmse_per_class: [0.108, 0.267, 0.069, 0.344, 0.061, 0.188, 0.262, 0.138, 0.164, 0.092]
== Status ==
Current time: 2024-01-07 09:06:19 (running for 00:34:20.48)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15049999952316284
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.233 |  0.142 |                   94 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.228 |  0.141 |                   83 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.434 |  0.169 |                   67 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.314 |  0.146 |                   59 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=176115)[0m rmse: 0.14522181451320648
[2m[36m(func pid=176115)[0m mae:  0.09406356513500214
[2m[36m(func pid=176115)[0m rmse_per_class: [0.073, 0.218, 0.031, 0.266, 0.056, 0.194, 0.242, 0.111, 0.178, 0.085]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.1423533856868744
[2m[36m(func pid=167906)[0m mae:  0.09405561536550522
[2m[36m(func pid=167906)[0m rmse_per_class: [0.083, 0.231, 0.035, 0.286, 0.058, 0.164, 0.207, 0.111, 0.146, 0.102]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=169734)[0m rmse: 0.14014166593551636
[2m[36m(func pid=169734)[0m mae:  0.08881723880767822
[2m[36m(func pid=169734)[0m rmse_per_class: [0.074, 0.219, 0.028, 0.297, 0.069, 0.153, 0.193, 0.117, 0.165, 0.087]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.4415 | Steps: 2 | Val loss: 0.3905 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.3261 | Steps: 2 | Val loss: 0.2770 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 95] | Train loss: 0.2257 | Steps: 2 | Val loss: 0.2843 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 84] | Train loss: 0.2376 | Steps: 2 | Val loss: 0.2618 | Batch size: 32 | lr: 0.1 | Duration: 3.16s
[2m[36m(func pid=174732)[0m rmse: 0.16929742693901062
[2m[36m(func pid=174732)[0m mae:  0.11714448034763336
[2m[36m(func pid=174732)[0m rmse_per_class: [0.107, 0.267, 0.069, 0.344, 0.061, 0.188, 0.262, 0.139, 0.164, 0.092]
[2m[36m(func pid=174732)[0m 
== Status ==
Current time: 2024-01-07 09:06:24 (running for 00:34:25.77)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15049999952316284
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.235 |  0.142 |                   95 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.226 |  0.14  |                   84 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.442 |  0.169 |                   68 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.314 |  0.145 |                   60 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=167906)[0m rmse: 0.14245453476905823
[2m[36m(func pid=167906)[0m mae:  0.09408555924892426
[2m[36m(func pid=167906)[0m rmse_per_class: [0.083, 0.232, 0.034, 0.288, 0.057, 0.164, 0.206, 0.112, 0.145, 0.104]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=176115)[0m rmse: 0.1446480005979538
[2m[36m(func pid=176115)[0m mae:  0.0937485471367836
[2m[36m(func pid=176115)[0m rmse_per_class: [0.071, 0.217, 0.031, 0.264, 0.056, 0.19, 0.247, 0.107, 0.179, 0.085]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=169734)[0m rmse: 0.14049330353736877
[2m[36m(func pid=169734)[0m mae:  0.08889696002006531
[2m[36m(func pid=169734)[0m rmse_per_class: [0.073, 0.22, 0.028, 0.295, 0.071, 0.153, 0.193, 0.119, 0.167, 0.086]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.4340 | Steps: 2 | Val loss: 0.3911 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 96] | Train loss: 0.2376 | Steps: 2 | Val loss: 0.2842 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.3199 | Steps: 2 | Val loss: 0.2756 | Batch size: 32 | lr: 0.001 | Duration: 3.03s
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 85] | Train loss: 0.2293 | Steps: 2 | Val loss: 0.2633 | Batch size: 32 | lr: 0.1 | Duration: 3.14s
== Status ==
Current time: 2024-01-07 09:06:30 (running for 00:34:31.02)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15049999952316284
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.226 |  0.142 |                   96 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.238 |  0.14  |                   85 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.434 |  0.169 |                   69 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.326 |  0.145 |                   61 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=174732)[0m rmse: 0.16920796036720276
[2m[36m(func pid=174732)[0m mae:  0.11695834249258041
[2m[36m(func pid=174732)[0m rmse_per_class: [0.107, 0.267, 0.067, 0.344, 0.06, 0.188, 0.262, 0.139, 0.165, 0.092]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.14233142137527466
[2m[36m(func pid=167906)[0m mae:  0.09381832927465439
[2m[36m(func pid=167906)[0m rmse_per_class: [0.082, 0.233, 0.035, 0.288, 0.056, 0.163, 0.205, 0.113, 0.145, 0.105]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=176115)[0m rmse: 0.14354772865772247
[2m[36m(func pid=176115)[0m mae:  0.09322106838226318
[2m[36m(func pid=176115)[0m rmse_per_class: [0.07, 0.215, 0.03, 0.262, 0.055, 0.184, 0.253, 0.105, 0.176, 0.084]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=169734)[0m rmse: 0.1415715217590332
[2m[36m(func pid=169734)[0m mae:  0.08969327807426453
[2m[36m(func pid=169734)[0m rmse_per_class: [0.077, 0.223, 0.027, 0.293, 0.073, 0.153, 0.195, 0.121, 0.167, 0.086]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.4430 | Steps: 2 | Val loss: 0.3922 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 97] | Train loss: 0.2317 | Steps: 2 | Val loss: 0.2837 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.3163 | Steps: 2 | Val loss: 0.2744 | Batch size: 32 | lr: 0.001 | Duration: 3.03s
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 86] | Train loss: 0.2236 | Steps: 2 | Val loss: 0.2655 | Batch size: 32 | lr: 0.1 | Duration: 3.16s
== Status ==
Current time: 2024-01-07 09:06:35 (running for 00:34:36.43)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15049999952316284
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.238 |  0.142 |                   97 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.229 |  0.142 |                   86 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.169 |                   70 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.32  |  0.144 |                   62 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=174732)[0m rmse: 0.16917577385902405
[2m[36m(func pid=174732)[0m mae:  0.11678948253393173
[2m[36m(func pid=174732)[0m rmse_per_class: [0.107, 0.267, 0.066, 0.344, 0.06, 0.188, 0.263, 0.139, 0.165, 0.092]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.14199477434158325
[2m[36m(func pid=167906)[0m mae:  0.09353361278772354
[2m[36m(func pid=167906)[0m rmse_per_class: [0.084, 0.232, 0.034, 0.287, 0.056, 0.162, 0.204, 0.113, 0.145, 0.103]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=176115)[0m rmse: 0.14300233125686646
[2m[36m(func pid=176115)[0m mae:  0.09286176413297653
[2m[36m(func pid=176115)[0m rmse_per_class: [0.069, 0.214, 0.029, 0.261, 0.055, 0.181, 0.257, 0.104, 0.175, 0.084]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=169734)[0m rmse: 0.14307060837745667
[2m[36m(func pid=169734)[0m mae:  0.09091615676879883
[2m[36m(func pid=169734)[0m rmse_per_class: [0.078, 0.224, 0.027, 0.294, 0.078, 0.154, 0.199, 0.123, 0.167, 0.087]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.4360 | Steps: 2 | Val loss: 0.3921 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 98] | Train loss: 0.2348 | Steps: 2 | Val loss: 0.2827 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.3072 | Steps: 2 | Val loss: 0.2735 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=174732)[0m rmse: 0.16881319880485535
[2m[36m(func pid=174732)[0m mae:  0.11645404249429703
[2m[36m(func pid=174732)[0m rmse_per_class: [0.107, 0.266, 0.065, 0.344, 0.059, 0.188, 0.263, 0.139, 0.165, 0.092]
[2m[36m(func pid=174732)[0m 
== Status ==
Current time: 2024-01-07 09:06:40 (running for 00:34:41.69)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15049999952316284
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.232 |  0.142 |                   98 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.224 |  0.143 |                   87 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.436 |  0.169 |                   71 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.316 |  0.143 |                   63 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 87] | Train loss: 0.2312 | Steps: 2 | Val loss: 0.2650 | Batch size: 32 | lr: 0.1 | Duration: 3.30s
[2m[36m(func pid=167906)[0m rmse: 0.1412600576877594
[2m[36m(func pid=167906)[0m mae:  0.09294512122869492
[2m[36m(func pid=167906)[0m rmse_per_class: [0.084, 0.232, 0.034, 0.284, 0.055, 0.162, 0.205, 0.113, 0.143, 0.101]
[2m[36m(func pid=167906)[0m 
[2m[36m(func pid=176115)[0m rmse: 0.1426467001438141
[2m[36m(func pid=176115)[0m mae:  0.0926174744963646
[2m[36m(func pid=176115)[0m rmse_per_class: [0.068, 0.213, 0.028, 0.26, 0.055, 0.179, 0.26, 0.105, 0.174, 0.085]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.4388 | Steps: 2 | Val loss: 0.3918 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=169734)[0m rmse: 0.14285461604595184
[2m[36m(func pid=169734)[0m mae:  0.0908074826002121
[2m[36m(func pid=169734)[0m rmse_per_class: [0.079, 0.224, 0.028, 0.294, 0.077, 0.153, 0.197, 0.121, 0.168, 0.087]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=167906)[0m [N0-GPU0] | [Epoch: 99] | Train loss: 0.2288 | Steps: 2 | Val loss: 0.2829 | Batch size: 32 | lr: 0.01 | Duration: 3.07s
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.3076 | Steps: 2 | Val loss: 0.2735 | Batch size: 32 | lr: 0.001 | Duration: 3.12s
== Status ==
Current time: 2024-01-07 09:06:46 (running for 00:34:46.91)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15049999952316284
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 6 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00014 | RUNNING    | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.235 |  0.141 |                   99 |
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.231 |  0.143 |                   88 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.439 |  0.169 |                   72 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.307 |  0.143 |                   64 |
| train_d77f6_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=174732)[0m rmse: 0.1687227338552475
[2m[36m(func pid=174732)[0m mae:  0.11627618968486786
[2m[36m(func pid=174732)[0m rmse_per_class: [0.107, 0.266, 0.064, 0.344, 0.059, 0.188, 0.263, 0.139, 0.166, 0.091]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=167906)[0m rmse: 0.1413956582546234
[2m[36m(func pid=167906)[0m mae:  0.09301353991031647
[2m[36m(func pid=167906)[0m rmse_per_class: [0.084, 0.232, 0.034, 0.285, 0.055, 0.162, 0.205, 0.113, 0.143, 0.101]
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 88] | Train loss: 0.2299 | Steps: 2 | Val loss: 0.2630 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
[2m[36m(func pid=176115)[0m rmse: 0.14305023849010468
[2m[36m(func pid=176115)[0m mae:  0.09289681911468506
[2m[36m(func pid=176115)[0m rmse_per_class: [0.067, 0.213, 0.027, 0.26, 0.055, 0.177, 0.264, 0.108, 0.174, 0.086]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.4388 | Steps: 2 | Val loss: 0.3919 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=169734)[0m rmse: 0.1420043706893921
[2m[36m(func pid=169734)[0m mae:  0.09006578475236893
[2m[36m(func pid=169734)[0m rmse_per_class: [0.078, 0.222, 0.029, 0.291, 0.072, 0.153, 0.195, 0.126, 0.167, 0.087]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.3246 | Steps: 2 | Val loss: 0.2742 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=174732)[0m rmse: 0.16853632032871246
[2m[36m(func pid=174732)[0m mae:  0.11602475494146347
[2m[36m(func pid=174732)[0m rmse_per_class: [0.106, 0.266, 0.063, 0.344, 0.059, 0.188, 0.263, 0.139, 0.166, 0.091]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 89] | Train loss: 0.2293 | Steps: 2 | Val loss: 0.2611 | Batch size: 32 | lr: 0.1 | Duration: 3.17s
[2m[36m(func pid=176115)[0m rmse: 0.14390239119529724
[2m[36m(func pid=176115)[0m mae:  0.09326386451721191
[2m[36m(func pid=176115)[0m rmse_per_class: [0.067, 0.213, 0.028, 0.26, 0.055, 0.173, 0.268, 0.111, 0.178, 0.087]
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.4409 | Steps: 2 | Val loss: 0.3926 | Batch size: 32 | lr: 0.0001 | Duration: 3.07s
[2m[36m(func pid=169734)[0m rmse: 0.14062444865703583
[2m[36m(func pid=169734)[0m mae:  0.08918945491313934
[2m[36m(func pid=169734)[0m rmse_per_class: [0.076, 0.221, 0.03, 0.289, 0.07, 0.152, 0.195, 0.122, 0.166, 0.087]
== Status ==
Current time: 2024-01-07 09:06:51 (running for 00:34:52.22)
Memory usage on this node: 22.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.15049999952316284
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 5 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.23  |  0.142 |                   89 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.439 |  0.169 |                   73 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.308 |  0.143 |                   65 |
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=2617)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=2617)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=2617)[0m Configuration completed!
[2m[36m(func pid=2617)[0m New optimizer parameters:
[2m[36m(func pid=2617)[0m SGD (
[2m[36m(func pid=2617)[0m Parameter Group 0
[2m[36m(func pid=2617)[0m     dampening: 0
[2m[36m(func pid=2617)[0m     differentiable: False
[2m[36m(func pid=2617)[0m     foreach: None
[2m[36m(func pid=2617)[0m     lr: 0.01
[2m[36m(func pid=2617)[0m     maximize: False
[2m[36m(func pid=2617)[0m     momentum: 0.99
[2m[36m(func pid=2617)[0m     nesterov: False
[2m[36m(func pid=2617)[0m     weight_decay: 1e-05
[2m[36m(func pid=2617)[0m )
[2m[36m(func pid=2617)[0m 
== Status ==
Current time: 2024-01-07 09:06:56 (running for 00:34:57.65)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.15049999952316284
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 5 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.229 |  0.141 |                   90 |
| train_d77f6_00016 | RUNNING    | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.441 |  0.168 |                   74 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.325 |  0.144 |                   66 |
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=174732)[0m rmse: 0.16833613812923431
[2m[36m(func pid=174732)[0m mae:  0.11575382947921753
[2m[36m(func pid=174732)[0m rmse_per_class: [0.106, 0.265, 0.063, 0.343, 0.058, 0.187, 0.263, 0.139, 0.167, 0.091]
[2m[36m(func pid=174732)[0m 
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.3041 | Steps: 2 | Val loss: 0.2741 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 90] | Train loss: 0.2282 | Steps: 2 | Val loss: 0.2617 | Batch size: 32 | lr: 0.1 | Duration: 3.12s
[2m[36m(func pid=174732)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.4435 | Steps: 2 | Val loss: 0.3933 | Batch size: 32 | lr: 0.0001 | Duration: 3.04s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 1.0290 | Steps: 2 | Val loss: 0.6447 | Batch size: 32 | lr: 0.01 | Duration: 4.77s
[2m[36m(func pid=176115)[0m rmse: 0.14434973895549774
[2m[36m(func pid=176115)[0m mae:  0.0931943878531456
[2m[36m(func pid=176115)[0m rmse_per_class: [0.066, 0.212, 0.028, 0.259, 0.055, 0.171, 0.27, 0.117, 0.177, 0.089]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=169734)[0m rmse: 0.14070597290992737
[2m[36m(func pid=169734)[0m mae:  0.08953128755092621
[2m[36m(func pid=169734)[0m rmse_per_class: [0.077, 0.221, 0.03, 0.292, 0.068, 0.151, 0.195, 0.119, 0.167, 0.087]
[2m[36m(func pid=169734)[0m 
== Status ==
Current time: 2024-01-07 09:07:02 (running for 00:35:03.08)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: -0.15325000137090683
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 5 PENDING, 3 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.228 |  0.141 |                   91 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.304 |  0.144 |                   67 |
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=174732)[0m rmse: 0.16818661987781525
[2m[36m(func pid=174732)[0m mae:  0.11549974977970123
[2m[36m(func pid=174732)[0m rmse_per_class: [0.106, 0.265, 0.061, 0.343, 0.058, 0.188, 0.263, 0.14, 0.167, 0.091]
[2m[36m(func pid=2617)[0m rmse: 0.17793455719947815
[2m[36m(func pid=2617)[0m mae:  0.13041141629219055
[2m[36m(func pid=2617)[0m rmse_per_class: [0.104, 0.267, 0.085, 0.325, 0.097, 0.192, 0.301, 0.155, 0.139, 0.114]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.3054 | Steps: 2 | Val loss: 0.2744 | Batch size: 32 | lr: 0.001 | Duration: 3.11s
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 91] | Train loss: 0.2329 | Steps: 2 | Val loss: 0.2654 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.6997 | Steps: 2 | Val loss: 0.4161 | Batch size: 32 | lr: 0.01 | Duration: 3.03s
[2m[36m(func pid=176115)[0m rmse: 0.14468695223331451
[2m[36m(func pid=176115)[0m mae:  0.09313313663005829
[2m[36m(func pid=176115)[0m rmse_per_class: [0.065, 0.212, 0.029, 0.258, 0.055, 0.168, 0.274, 0.122, 0.176, 0.09]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=169734)[0m rmse: 0.1425180733203888
[2m[36m(func pid=169734)[0m mae:  0.0908760353922844
[2m[36m(func pid=169734)[0m rmse_per_class: [0.08, 0.223, 0.029, 0.301, 0.069, 0.151, 0.196, 0.12, 0.168, 0.088]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=2617)[0m rmse: 0.17627090215682983
[2m[36m(func pid=2617)[0m mae:  0.1287500113248825
[2m[36m(func pid=2617)[0m rmse_per_class: [0.104, 0.269, 0.086, 0.326, 0.092, 0.192, 0.292, 0.152, 0.142, 0.108]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.3048 | Steps: 2 | Val loss: 0.2756 | Batch size: 32 | lr: 0.001 | Duration: 3.06s
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 92] | Train loss: 0.2289 | Steps: 2 | Val loss: 0.2682 | Batch size: 32 | lr: 0.1 | Duration: 3.05s
== Status ==
Current time: 2024-01-07 09:07:08 (running for 00:35:09.10)
Memory usage on this node: 22.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: -0.15325000137090683
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 4 PENDING, 4 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.233 |  0.143 |                   92 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.305 |  0.145 |                   68 |
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.7   |  0.176 |                    2 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=3873)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=3873)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=3873)[0m Configuration completed!
[2m[36m(func pid=3873)[0m New optimizer parameters:
[2m[36m(func pid=3873)[0m SGD (
[2m[36m(func pid=3873)[0m Parameter Group 0
[2m[36m(func pid=3873)[0m     dampening: 0
[2m[36m(func pid=3873)[0m     differentiable: False
[2m[36m(func pid=3873)[0m     foreach: None
[2m[36m(func pid=3873)[0m     lr: 0.1
[2m[36m(func pid=3873)[0m     maximize: False
[2m[36m(func pid=3873)[0m     momentum: 0.99
[2m[36m(func pid=3873)[0m     nesterov: False
[2m[36m(func pid=3873)[0m     weight_decay: 1e-05
[2m[36m(func pid=3873)[0m )
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.4353 | Steps: 2 | Val loss: 0.3200 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=176115)[0m rmse: 0.14604367315769196
[2m[36m(func pid=176115)[0m mae:  0.09383636713027954
[2m[36m(func pid=176115)[0m rmse_per_class: [0.065, 0.213, 0.028, 0.258, 0.054, 0.167, 0.275, 0.126, 0.18, 0.094]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=169734)[0m rmse: 0.14383195340633392
[2m[36m(func pid=169734)[0m mae:  0.09172652661800385
[2m[36m(func pid=169734)[0m rmse_per_class: [0.08, 0.224, 0.028, 0.305, 0.069, 0.153, 0.197, 0.125, 0.169, 0.089]
[2m[36m(func pid=169734)[0m 
== Status ==
Current time: 2024-01-07 09:07:13 (running for 00:35:14.72)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: -0.15325000137090683
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 4 PENDING, 4 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.229 |  0.144 |                   93 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.305 |  0.146 |                   69 |
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.435 |  0.173 |                    3 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=2617)[0m rmse: 0.17327821254730225
[2m[36m(func pid=2617)[0m mae:  0.1256534904241562
[2m[36m(func pid=2617)[0m rmse_per_class: [0.106, 0.271, 0.09, 0.332, 0.083, 0.19, 0.275, 0.138, 0.148, 0.1]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.2947 | Steps: 2 | Val loss: 0.2768 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 93] | Train loss: 0.2284 | Steps: 2 | Val loss: 0.2678 | Batch size: 32 | lr: 0.1 | Duration: 3.14s
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 0.7686 | Steps: 2 | Val loss: 0.3278 | Batch size: 32 | lr: 0.1 | Duration: 4.73s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.4040 | Steps: 2 | Val loss: 0.3432 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=176115)[0m rmse: 0.14735205471515656
[2m[36m(func pid=176115)[0m mae:  0.09447459876537323
[2m[36m(func pid=176115)[0m rmse_per_class: [0.064, 0.214, 0.028, 0.257, 0.054, 0.167, 0.276, 0.135, 0.178, 0.1]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=169734)[0m rmse: 0.14352582395076752
[2m[36m(func pid=169734)[0m mae:  0.0913943350315094
[2m[36m(func pid=169734)[0m rmse_per_class: [0.078, 0.224, 0.028, 0.3, 0.07, 0.153, 0.198, 0.125, 0.168, 0.089]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=3873)[0m rmse: 0.17135192453861237
[2m[36m(func pid=3873)[0m mae:  0.12295790761709213
[2m[36m(func pid=3873)[0m rmse_per_class: [0.11, 0.274, 0.084, 0.339, 0.071, 0.189, 0.267, 0.13, 0.152, 0.097]
[2m[36m(func pid=3873)[0m 
== Status ==
Current time: 2024-01-07 09:07:19 (running for 00:35:20.30)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: -0.15325000137090683
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 4 PENDING, 4 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.228 |  0.144 |                   94 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.295 |  0.147 |                   70 |
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.404 |  0.172 |                    4 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.769 |  0.171 |                    1 |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=2617)[0m rmse: 0.17160889506340027
[2m[36m(func pid=2617)[0m mae:  0.122011199593544
[2m[36m(func pid=2617)[0m rmse_per_class: [0.108, 0.272, 0.087, 0.341, 0.071, 0.189, 0.263, 0.134, 0.157, 0.094]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.2970 | Steps: 2 | Val loss: 0.2787 | Batch size: 32 | lr: 0.001 | Duration: 3.06s
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.5417 | Steps: 2 | Val loss: 0.5581 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 94] | Train loss: 0.2297 | Steps: 2 | Val loss: 0.2649 | Batch size: 32 | lr: 0.1 | Duration: 3.27s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.4704 | Steps: 2 | Val loss: 0.4127 | Batch size: 32 | lr: 0.01 | Duration: 3.05s
[2m[36m(func pid=176115)[0m rmse: 0.14890266954898834
[2m[36m(func pid=176115)[0m mae:  0.09513767063617706
[2m[36m(func pid=176115)[0m rmse_per_class: [0.064, 0.215, 0.029, 0.258, 0.054, 0.167, 0.276, 0.143, 0.178, 0.106]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=3873)[0m rmse: 0.18716996908187866
[2m[36m(func pid=3873)[0m mae:  0.12370134890079498
[2m[36m(func pid=3873)[0m rmse_per_class: [0.121, 0.286, 0.05, 0.369, 0.055, 0.191, 0.377, 0.152, 0.176, 0.094]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=169734)[0m rmse: 0.1417301744222641
[2m[36m(func pid=169734)[0m mae:  0.09009308367967606
[2m[36m(func pid=169734)[0m rmse_per_class: [0.079, 0.222, 0.029, 0.293, 0.072, 0.153, 0.196, 0.12, 0.165, 0.09]
[2m[36m(func pid=169734)[0m 
== Status ==
Current time: 2024-01-07 09:07:24 (running for 00:35:25.87)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: -0.15325000137090683
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 4 PENDING, 4 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.23  |  0.142 |                   95 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.297 |  0.149 |                   71 |
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.47  |  0.174 |                    5 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.542 |  0.187 |                    2 |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=2617)[0m rmse: 0.1737070381641388
[2m[36m(func pid=2617)[0m mae:  0.11928077042102814
[2m[36m(func pid=2617)[0m rmse_per_class: [0.106, 0.273, 0.076, 0.352, 0.06, 0.188, 0.287, 0.142, 0.163, 0.092]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.3023 | Steps: 2 | Val loss: 0.2802 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.7778 | Steps: 2 | Val loss: 0.7446 | Batch size: 32 | lr: 0.1 | Duration: 2.99s
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 95] | Train loss: 0.2252 | Steps: 2 | Val loss: 0.2635 | Batch size: 32 | lr: 0.1 | Duration: 3.18s
[2m[36m(func pid=176115)[0m rmse: 0.15014171600341797
[2m[36m(func pid=176115)[0m mae:  0.09568989276885986
[2m[36m(func pid=176115)[0m rmse_per_class: [0.064, 0.216, 0.03, 0.257, 0.054, 0.166, 0.277, 0.149, 0.175, 0.112]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.5421 | Steps: 2 | Val loss: 0.4850 | Batch size: 32 | lr: 0.01 | Duration: 3.12s
[2m[36m(func pid=3873)[0m rmse: 0.2109849900007248
[2m[36m(func pid=3873)[0m mae:  0.13592752814292908
[2m[36m(func pid=3873)[0m rmse_per_class: [0.087, 0.298, 0.047, 0.386, 0.056, 0.215, 0.595, 0.156, 0.173, 0.097]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=169734)[0m rmse: 0.14082765579223633
[2m[36m(func pid=169734)[0m mae:  0.08946342766284943
[2m[36m(func pid=169734)[0m rmse_per_class: [0.08, 0.22, 0.029, 0.293, 0.071, 0.153, 0.195, 0.116, 0.163, 0.088]
[2m[36m(func pid=169734)[0m 
== Status ==
Current time: 2024-01-07 09:07:30 (running for 00:35:31.58)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: -0.15325000137090683
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 4 PENDING, 4 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.141 |                   96 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.302 |  0.15  |                   72 |
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.542 |  0.18  |                    6 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.778 |  0.211 |                    3 |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=2617)[0m rmse: 0.17974653840065002
[2m[36m(func pid=2617)[0m mae:  0.11949095875024796
[2m[36m(func pid=2617)[0m rmse_per_class: [0.101, 0.274, 0.059, 0.361, 0.056, 0.189, 0.35, 0.149, 0.166, 0.092]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.2875 | Steps: 2 | Val loss: 0.2819 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.7428 | Steps: 2 | Val loss: 0.8057 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 96] | Train loss: 0.2256 | Steps: 2 | Val loss: 0.2639 | Batch size: 32 | lr: 0.1 | Duration: 3.09s
[2m[36m(func pid=176115)[0m rmse: 0.15147744119167328
[2m[36m(func pid=176115)[0m mae:  0.09627263247966766
[2m[36m(func pid=176115)[0m rmse_per_class: [0.064, 0.217, 0.031, 0.257, 0.053, 0.167, 0.277, 0.158, 0.173, 0.117]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.6034 | Steps: 2 | Val loss: 0.5468 | Batch size: 32 | lr: 0.01 | Duration: 3.05s
[2m[36m(func pid=3873)[0m rmse: 0.222455695271492
[2m[36m(func pid=3873)[0m mae:  0.1402294933795929
[2m[36m(func pid=3873)[0m rmse_per_class: [0.077, 0.301, 0.049, 0.389, 0.056, 0.224, 0.623, 0.156, 0.252, 0.097]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=169734)[0m rmse: 0.14153189957141876
[2m[36m(func pid=169734)[0m mae:  0.0900341048836708
[2m[36m(func pid=169734)[0m rmse_per_class: [0.079, 0.219, 0.029, 0.295, 0.072, 0.153, 0.196, 0.12, 0.162, 0.089]
[2m[36m(func pid=169734)[0m 
== Status ==
Current time: 2024-01-07 09:07:36 (running for 00:35:37.25)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: -0.15325000137090683
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 4 PENDING, 4 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.226 |  0.142 |                   97 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.287 |  0.151 |                   73 |
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.603 |  0.188 |                    7 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.743 |  0.222 |                    4 |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=2617)[0m rmse: 0.18758444488048553
[2m[36m(func pid=2617)[0m mae:  0.12199389934539795
[2m[36m(func pid=2617)[0m rmse_per_class: [0.096, 0.276, 0.048, 0.368, 0.055, 0.193, 0.428, 0.153, 0.166, 0.094]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.2933 | Steps: 2 | Val loss: 0.2854 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.5775 | Steps: 2 | Val loss: 0.8012 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=176115)[0m rmse: 0.1539970338344574
[2m[36m(func pid=176115)[0m mae:  0.09749926626682281
[2m[36m(func pid=176115)[0m rmse_per_class: [0.065, 0.219, 0.032, 0.258, 0.053, 0.168, 0.277, 0.168, 0.174, 0.126]
[2m[36m(func pid=176115)[0m 
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 97] | Train loss: 0.2268 | Steps: 2 | Val loss: 0.2649 | Batch size: 32 | lr: 0.1 | Duration: 3.35s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.6479 | Steps: 2 | Val loss: 0.5933 | Batch size: 32 | lr: 0.01 | Duration: 3.11s
[2m[36m(func pid=3873)[0m rmse: 0.2241634577512741
[2m[36m(func pid=3873)[0m mae:  0.1351289451122284
[2m[36m(func pid=3873)[0m rmse_per_class: [0.168, 0.299, 0.049, 0.385, 0.056, 0.208, 0.385, 0.156, 0.439, 0.097]
[2m[36m(func pid=3873)[0m 
== Status ==
Current time: 2024-01-07 09:07:41 (running for 00:35:42.69)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: -0.15325000137090683
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 4 PENDING, 4 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.227 |  0.142 |                   98 |
| train_d77f6_00017 | RUNNING    | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.293 |  0.154 |                   74 |
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.603 |  0.188 |                    7 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.577 |  0.224 |                    5 |
| train_d77f6_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=169734)[0m rmse: 0.14245888590812683
[2m[36m(func pid=169734)[0m mae:  0.09055808186531067
[2m[36m(func pid=169734)[0m rmse_per_class: [0.078, 0.22, 0.029, 0.297, 0.073, 0.153, 0.197, 0.123, 0.164, 0.09]
[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=176115)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.2922 | Steps: 2 | Val loss: 0.2897 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=2617)[0m rmse: 0.19552677869796753
[2m[36m(func pid=2617)[0m mae:  0.1257651448249817
[2m[36m(func pid=2617)[0m rmse_per_class: [0.092, 0.28, 0.044, 0.373, 0.056, 0.197, 0.499, 0.154, 0.165, 0.095]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.4364 | Steps: 2 | Val loss: 0.7705 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=176115)[0m rmse: 0.15679529309272766
[2m[36m(func pid=176115)[0m mae:  0.0991600900888443
[2m[36m(func pid=176115)[0m rmse_per_class: [0.065, 0.222, 0.033, 0.26, 0.053, 0.169, 0.276, 0.176, 0.176, 0.138]
[2m[36m(func pid=3873)[0m rmse: 0.20239289104938507
[2m[36m(func pid=3873)[0m mae:  0.12194035202264786
[2m[36m(func pid=3873)[0m rmse_per_class: [0.139, 0.272, 0.032, 0.327, 0.056, 0.223, 0.244, 0.156, 0.477, 0.097]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.6493 | Steps: 2 | Val loss: 0.6175 | Batch size: 32 | lr: 0.01 | Duration: 3.06s
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 98] | Train loss: 0.2250 | Steps: 2 | Val loss: 0.2653 | Batch size: 32 | lr: 0.1 | Duration: 3.33s
[2m[36m(func pid=2617)[0m rmse: 0.20220470428466797
[2m[36m(func pid=2617)[0m mae:  0.12946441769599915
[2m[36m(func pid=2617)[0m rmse_per_class: [0.089, 0.282, 0.045, 0.377, 0.056, 0.201, 0.555, 0.155, 0.165, 0.096]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=169734)[0m rmse: 0.1425715982913971
[2m[36m(func pid=169734)[0m mae:  0.0905689150094986
[2m[36m(func pid=169734)[0m rmse_per_class: [0.077, 0.22, 0.029, 0.3, 0.072, 0.153, 0.196, 0.124, 0.166, 0.09]
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.3818 | Steps: 2 | Val loss: 0.9951 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
[2m[36m(func pid=3873)[0m rmse: 0.22125621140003204
[2m[36m(func pid=3873)[0m mae:  0.13309723138809204
[2m[36m(func pid=3873)[0m rmse_per_class: [0.095, 0.259, 0.077, 0.328, 0.056, 0.303, 0.323, 0.156, 0.517, 0.097]
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.6561 | Steps: 2 | Val loss: 0.6227 | Batch size: 32 | lr: 0.01 | Duration: 3.06s
[2m[36m(func pid=2617)[0m rmse: 0.20775870978832245
[2m[36m(func pid=2617)[0m mae:  0.13279098272323608
[2m[36m(func pid=2617)[0m rmse_per_class: [0.089, 0.285, 0.046, 0.38, 0.056, 0.204, 0.598, 0.156, 0.167, 0.097]
== Status ==
Current time: 2024-01-07 09:07:47 (running for 00:35:48.51)
Memory usage on this node: 22.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=16
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 3 PENDING, 4 RUNNING, 16 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.227 |  0.142 |                   98 |
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.649 |  0.202 |                    9 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.436 |  0.202 |                    6 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

== Status ==
Current time: 2024-01-07 09:07:53 (running for 00:35:54.25)
Memory usage on this node: 23.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=16
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 3 PENDING, 4 RUNNING, 16 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.143 |                   99 |
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.649 |  0.202 |                    9 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.436 |  0.202 |                    6 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=169734)[0m 
[2m[36m(func pid=5776)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=5776)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=5776)[0m Configuration completed!
[2m[36m(func pid=5776)[0m New optimizer parameters:
[2m[36m(func pid=5776)[0m SGD (
[2m[36m(func pid=5776)[0m Parameter Group 0
[2m[36m(func pid=5776)[0m     dampening: 0
[2m[36m(func pid=5776)[0m     differentiable: False
[2m[36m(func pid=5776)[0m     foreach: None
[2m[36m(func pid=5776)[0m     lr: 0.0001
[2m[36m(func pid=5776)[0m     maximize: False
[2m[36m(func pid=5776)[0m     momentum: 0.9
[2m[36m(func pid=5776)[0m     nesterov: False
[2m[36m(func pid=5776)[0m     weight_decay: 1e-05
[2m[36m(func pid=5776)[0m )
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.4031 | Steps: 2 | Val loss: 1.4861 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.6311 | Steps: 2 | Val loss: 0.6084 | Batch size: 32 | lr: 0.01 | Duration: 3.16s
[2m[36m(func pid=169734)[0m [N0-GPU0] | [Epoch: 99] | Train loss: 0.2249 | Steps: 2 | Val loss: 0.2646 | Batch size: 32 | lr: 0.1 | Duration: 3.18s
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 1.0808 | Steps: 2 | Val loss: 0.8094 | Batch size: 32 | lr: 0.0001 | Duration: 4.87s
== Status ==
Current time: 2024-01-07 09:07:58 (running for 00:35:59.30)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=16
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 3 PENDING, 4 RUNNING, 16 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00015 | RUNNING    | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.143 |                   99 |
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.656 |  0.208 |                   10 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.382 |  0.221 |                    7 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=3873)[0m rmse: 0.24541445076465607
[2m[36m(func pid=3873)[0m mae:  0.15000228583812714
[2m[36m(func pid=3873)[0m rmse_per_class: [0.111, 0.291, 0.088, 0.341, 0.056, 0.44, 0.339, 0.156, 0.533, 0.097]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=169734)[0m rmse: 0.14201444387435913
[2m[36m(func pid=169734)[0m mae:  0.09019073098897934
[2m[36m(func pid=169734)[0m rmse_per_class: [0.079, 0.22, 0.029, 0.296, 0.071, 0.153, 0.195, 0.122, 0.167, 0.089]
[2m[36m(func pid=2617)[0m rmse: 0.21069562435150146
[2m[36m(func pid=2617)[0m mae:  0.13416627049446106
[2m[36m(func pid=2617)[0m rmse_per_class: [0.088, 0.285, 0.047, 0.381, 0.056, 0.204, 0.614, 0.156, 0.177, 0.097]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=5776)[0m rmse: 0.17862462997436523
[2m[36m(func pid=5776)[0m mae:  0.1311684101819992
[2m[36m(func pid=5776)[0m rmse_per_class: [0.105, 0.265, 0.087, 0.325, 0.1, 0.192, 0.304, 0.153, 0.139, 0.116]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.3913 | Steps: 2 | Val loss: 1.5891 | Batch size: 32 | lr: 0.1 | Duration: 3.02s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.5870 | Steps: 2 | Val loss: 0.5767 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 1.0780 | Steps: 2 | Val loss: 0.8103 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=3873)[0m rmse: 0.25241321325302124
[2m[36m(func pid=3873)[0m mae:  0.1550678163766861
[2m[36m(func pid=3873)[0m rmse_per_class: [0.111, 0.337, 0.086, 0.361, 0.056, 0.536, 0.338, 0.157, 0.444, 0.097]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=2617)[0m rmse: 0.20988306403160095
[2m[36m(func pid=2617)[0m mae:  0.1324891746044159
[2m[36m(func pid=2617)[0m rmse_per_class: [0.085, 0.28, 0.048, 0.38, 0.056, 0.201, 0.593, 0.156, 0.203, 0.097]
[2m[36m(func pid=5776)[0m rmse: 0.1791239082813263
[2m[36m(func pid=5776)[0m mae:  0.13155362010002136
[2m[36m(func pid=5776)[0m rmse_per_class: [0.104, 0.265, 0.089, 0.325, 0.102, 0.193, 0.305, 0.154, 0.139, 0.116]
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.3679 | Steps: 2 | Val loss: 1.3296 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
== Status ==
Current time: 2024-01-07 09:08:04 (running for 00:36:05.09)
Memory usage on this node: 22.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.631 |  0.211 |                   11 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.391 |  0.252 |                    9 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  1.081 |  0.179 |                    1 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=6501)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=6501)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=6501)[0m Configuration completed!
[2m[36m(func pid=6501)[0m New optimizer parameters:
[2m[36m(func pid=6501)[0m SGD (
[2m[36m(func pid=6501)[0m Parameter Group 0
[2m[36m(func pid=6501)[0m     dampening: 0
[2m[36m(func pid=6501)[0m     differentiable: False
[2m[36m(func pid=6501)[0m     foreach: None
[2m[36m(func pid=6501)[0m     lr: 0.001
[2m[36m(func pid=6501)[0m     maximize: False
[2m[36m(func pid=6501)[0m     momentum: 0.9
[2m[36m(func pid=6501)[0m     nesterov: False
[2m[36m(func pid=6501)[0m     weight_decay: 1e-05
[2m[36m(func pid=6501)[0m )
[2m[36m(func pid=6501)[0m 
== Status ==
Current time: 2024-01-07 09:08:09 (running for 00:36:10.38)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.587 |  0.21  |                   12 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.368 |  0.228 |                   10 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  1.078 |  0.179 |                    2 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=3873)[0m rmse: 0.2281109094619751
[2m[36m(func pid=3873)[0m mae:  0.13484716415405273
[2m[36m(func pid=3873)[0m rmse_per_class: [0.109, 0.297, 0.094, 0.364, 0.056, 0.474, 0.293, 0.159, 0.308, 0.126]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.5190 | Steps: 2 | Val loss: 0.5289 | Batch size: 32 | lr: 0.01 | Duration: 3.07s
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 1.0672 | Steps: 2 | Val loss: 0.8129 | Batch size: 32 | lr: 0.0001 | Duration: 3.17s
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 1.0807 | Steps: 2 | Val loss: 0.7934 | Batch size: 32 | lr: 0.001 | Duration: 4.98s
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.3286 | Steps: 2 | Val loss: 1.3420 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
[2m[36m(func pid=2617)[0m rmse: 0.20516128838062286
[2m[36m(func pid=2617)[0m mae:  0.1280042827129364
[2m[36m(func pid=2617)[0m rmse_per_class: [0.079, 0.27, 0.048, 0.375, 0.056, 0.193, 0.55, 0.156, 0.227, 0.097]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=5776)[0m rmse: 0.1795330047607422
[2m[36m(func pid=5776)[0m mae:  0.13185414671897888
[2m[36m(func pid=5776)[0m rmse_per_class: [0.104, 0.266, 0.089, 0.325, 0.103, 0.193, 0.306, 0.154, 0.139, 0.116]
[2m[36m(func pid=5776)[0m 
== Status ==
Current time: 2024-01-07 09:08:14 (running for 00:36:15.54)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.519 |  0.205 |                   13 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.368 |  0.228 |                   10 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  1.067 |  0.18  |                    3 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  1.081 |  0.179 |                    1 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=6501)[0m rmse: 0.17860811948776245
[2m[36m(func pid=6501)[0m mae:  0.1311112344264984
[2m[36m(func pid=6501)[0m rmse_per_class: [0.105, 0.266, 0.087, 0.325, 0.1, 0.192, 0.304, 0.153, 0.139, 0.116]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=3873)[0m rmse: 0.22990682721138
[2m[36m(func pid=3873)[0m mae:  0.1280222237110138
[2m[36m(func pid=3873)[0m rmse_per_class: [0.109, 0.284, 0.142, 0.355, 0.056, 0.276, 0.341, 0.157, 0.186, 0.393]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 1.0584 | Steps: 2 | Val loss: 0.8108 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.4621 | Steps: 2 | Val loss: 0.4805 | Batch size: 32 | lr: 0.01 | Duration: 3.07s
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.2979 | Steps: 2 | Val loss: 1.8048 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 1.0412 | Steps: 2 | Val loss: 0.7591 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=5776)[0m rmse: 0.1799224317073822
[2m[36m(func pid=5776)[0m mae:  0.13215892016887665
[2m[36m(func pid=5776)[0m rmse_per_class: [0.104, 0.266, 0.09, 0.325, 0.104, 0.193, 0.308, 0.154, 0.139, 0.117]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=2617)[0m rmse: 0.1958802491426468
[2m[36m(func pid=2617)[0m mae:  0.12026228755712509
[2m[36m(func pid=2617)[0m rmse_per_class: [0.075, 0.255, 0.047, 0.366, 0.056, 0.179, 0.47, 0.156, 0.258, 0.097]
[2m[36m(func pid=2617)[0m 
== Status ==
Current time: 2024-01-07 09:08:20 (running for 00:36:20.90)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.462 |  0.196 |                   14 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.298 |  0.25  |                   12 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  1.058 |  0.18  |                    4 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  1.081 |  0.179 |                    1 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=3873)[0m rmse: 0.25024181604385376
[2m[36m(func pid=3873)[0m mae:  0.15864916145801544
[2m[36m(func pid=3873)[0m rmse_per_class: [0.107, 0.281, 0.139, 0.351, 0.056, 0.228, 0.32, 0.156, 0.142, 0.722]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=6501)[0m rmse: 0.17894676327705383
[2m[36m(func pid=6501)[0m mae:  0.13133201003074646
[2m[36m(func pid=6501)[0m rmse_per_class: [0.104, 0.266, 0.088, 0.325, 0.101, 0.192, 0.305, 0.155, 0.139, 0.115]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 1.0457 | Steps: 2 | Val loss: 0.8068 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.4181 | Steps: 2 | Val loss: 0.4339 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.2975 | Steps: 2 | Val loss: 2.3992 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.9621 | Steps: 2 | Val loss: 0.7092 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=5776)[0m rmse: 0.18022334575653076
[2m[36m(func pid=5776)[0m mae:  0.13237865269184113
[2m[36m(func pid=5776)[0m rmse_per_class: [0.105, 0.266, 0.09, 0.325, 0.105, 0.194, 0.308, 0.154, 0.138, 0.118]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=2617)[0m rmse: 0.18244798481464386
[2m[36m(func pid=2617)[0m mae:  0.11005717515945435
[2m[36m(func pid=2617)[0m rmse_per_class: [0.077, 0.24, 0.044, 0.347, 0.056, 0.164, 0.355, 0.156, 0.287, 0.097]
[2m[36m(func pid=2617)[0m 
== Status ==
Current time: 2024-01-07 09:08:25 (running for 00:36:26.12)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.418 |  0.182 |                   15 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.297 |  0.246 |                   13 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  1.046 |  0.18  |                    5 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  1.041 |  0.179 |                    2 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=3873)[0m rmse: 0.2456834763288498
[2m[36m(func pid=3873)[0m mae:  0.16164596378803253
[2m[36m(func pid=3873)[0m rmse_per_class: [0.105, 0.277, 0.09, 0.35, 0.056, 0.231, 0.3, 0.156, 0.146, 0.746]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=6501)[0m rmse: 0.17921234667301178
[2m[36m(func pid=6501)[0m mae:  0.13143977522850037
[2m[36m(func pid=6501)[0m rmse_per_class: [0.104, 0.266, 0.089, 0.324, 0.101, 0.193, 0.305, 0.155, 0.138, 0.115]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 1.0325 | Steps: 2 | Val loss: 0.8000 | Batch size: 32 | lr: 0.0001 | Duration: 3.03s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.3811 | Steps: 2 | Val loss: 0.3972 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.3339 | Steps: 2 | Val loss: 1.7742 | Batch size: 32 | lr: 0.1 | Duration: 2.98s
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.8731 | Steps: 2 | Val loss: 0.6486 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=5776)[0m rmse: 0.1804628074169159
[2m[36m(func pid=5776)[0m mae:  0.13257601857185364
[2m[36m(func pid=5776)[0m rmse_per_class: [0.105, 0.266, 0.091, 0.324, 0.105, 0.194, 0.309, 0.154, 0.138, 0.118]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=2617)[0m rmse: 0.17047622799873352
[2m[36m(func pid=2617)[0m mae:  0.10191172361373901
[2m[36m(func pid=2617)[0m rmse_per_class: [0.085, 0.234, 0.04, 0.322, 0.056, 0.169, 0.242, 0.155, 0.305, 0.096]
[2m[36m(func pid=2617)[0m 
== Status ==
Current time: 2024-01-07 09:08:30 (running for 00:36:31.49)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.381 |  0.17  |                   16 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.334 |  0.248 |                   14 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  1.032 |  0.18  |                    6 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.962 |  0.179 |                    3 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=3873)[0m rmse: 0.24773621559143066
[2m[36m(func pid=3873)[0m mae:  0.15604260563850403
[2m[36m(func pid=3873)[0m rmse_per_class: [0.104, 0.278, 0.104, 0.372, 0.056, 0.231, 0.308, 0.156, 0.244, 0.625]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=6501)[0m rmse: 0.17936500906944275
[2m[36m(func pid=6501)[0m mae:  0.13145937025547028
[2m[36m(func pid=6501)[0m rmse_per_class: [0.104, 0.267, 0.089, 0.324, 0.101, 0.193, 0.305, 0.156, 0.138, 0.115]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 1.0128 | Steps: 2 | Val loss: 0.7923 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.3543 | Steps: 2 | Val loss: 0.3731 | Batch size: 32 | lr: 0.01 | Duration: 3.19s
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.3757 | Steps: 2 | Val loss: 1.2561 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.7790 | Steps: 2 | Val loss: 0.5846 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=5776)[0m rmse: 0.1806490570306778
[2m[36m(func pid=5776)[0m mae:  0.13271814584732056
[2m[36m(func pid=5776)[0m rmse_per_class: [0.105, 0.266, 0.091, 0.324, 0.105, 0.194, 0.31, 0.154, 0.138, 0.119]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=2617)[0m rmse: 0.16424638032913208
[2m[36m(func pid=2617)[0m mae:  0.09867466241121292
[2m[36m(func pid=2617)[0m rmse_per_class: [0.086, 0.229, 0.035, 0.299, 0.056, 0.195, 0.194, 0.155, 0.299, 0.096]
[2m[36m(func pid=2617)[0m 
== Status ==
Current time: 2024-01-07 09:08:35 (running for 00:36:36.63)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.354 |  0.164 |                   17 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.376 |  0.241 |                   15 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  1.013 |  0.181 |                    7 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.873 |  0.179 |                    4 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=3873)[0m rmse: 0.2407342493534088
[2m[36m(func pid=3873)[0m mae:  0.14649882912635803
[2m[36m(func pid=3873)[0m rmse_per_class: [0.103, 0.287, 0.142, 0.377, 0.056, 0.229, 0.295, 0.148, 0.56, 0.209]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=6501)[0m rmse: 0.17939873039722443
[2m[36m(func pid=6501)[0m mae:  0.13136103749275208
[2m[36m(func pid=6501)[0m rmse_per_class: [0.104, 0.267, 0.09, 0.324, 0.101, 0.193, 0.304, 0.156, 0.138, 0.115]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.9989 | Steps: 2 | Val loss: 0.7836 | Batch size: 32 | lr: 0.0001 | Duration: 3.06s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.3613 | Steps: 2 | Val loss: 0.3647 | Batch size: 32 | lr: 0.01 | Duration: 3.08s
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.3384 | Steps: 2 | Val loss: 1.2895 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.6954 | Steps: 2 | Val loss: 0.5242 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=5776)[0m rmse: 0.1807711273431778
[2m[36m(func pid=5776)[0m mae:  0.13279424607753754
[2m[36m(func pid=5776)[0m rmse_per_class: [0.106, 0.266, 0.091, 0.324, 0.105, 0.194, 0.31, 0.154, 0.138, 0.12]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=2617)[0m rmse: 0.1638633906841278
[2m[36m(func pid=2617)[0m mae:  0.09953424334526062
[2m[36m(func pid=2617)[0m rmse_per_class: [0.085, 0.224, 0.031, 0.286, 0.056, 0.221, 0.2, 0.151, 0.29, 0.095]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=3873)[0m rmse: 0.23858387768268585
[2m[36m(func pid=3873)[0m mae:  0.14246465265750885
[2m[36m(func pid=3873)[0m rmse_per_class: [0.22, 0.284, 0.176, 0.379, 0.055, 0.224, 0.327, 0.197, 0.365, 0.158]
[2m[36m(func pid=3873)[0m 
== Status ==
Current time: 2024-01-07 09:08:41 (running for 00:36:41.94)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.361 |  0.164 |                   18 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.338 |  0.239 |                   16 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.999 |  0.181 |                    8 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.779 |  0.179 |                    5 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=6501)[0m rmse: 0.1794102042913437
[2m[36m(func pid=6501)[0m mae:  0.13124749064445496
[2m[36m(func pid=6501)[0m rmse_per_class: [0.105, 0.268, 0.091, 0.325, 0.101, 0.193, 0.303, 0.155, 0.139, 0.115]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.3700 | Steps: 2 | Val loss: 0.3622 | Batch size: 32 | lr: 0.01 | Duration: 3.07s
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.9821 | Steps: 2 | Val loss: 0.7722 | Batch size: 32 | lr: 0.0001 | Duration: 3.10s
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.3303 | Steps: 2 | Val loss: 1.3814 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.6184 | Steps: 2 | Val loss: 0.4707 | Batch size: 32 | lr: 0.001 | Duration: 3.06s
[2m[36m(func pid=2617)[0m rmse: 0.16355159878730774
[2m[36m(func pid=2617)[0m mae:  0.1004178375005722
[2m[36m(func pid=2617)[0m rmse_per_class: [0.08, 0.218, 0.028, 0.28, 0.056, 0.231, 0.225, 0.143, 0.28, 0.094]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=5776)[0m rmse: 0.18087831139564514
[2m[36m(func pid=5776)[0m mae:  0.13287648558616638
[2m[36m(func pid=5776)[0m rmse_per_class: [0.106, 0.266, 0.09, 0.324, 0.106, 0.194, 0.31, 0.154, 0.138, 0.121]
[2m[36m(func pid=5776)[0m 
== Status ==
Current time: 2024-01-07 09:08:46 (running for 00:36:47.10)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.37  |  0.164 |                   19 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.33  |  0.23  |                   17 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.982 |  0.181 |                    9 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.695 |  0.179 |                    6 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=3873)[0m rmse: 0.23026248812675476
[2m[36m(func pid=3873)[0m mae:  0.1434515416622162
[2m[36m(func pid=3873)[0m rmse_per_class: [0.216, 0.262, 0.162, 0.386, 0.054, 0.224, 0.273, 0.225, 0.408, 0.094]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=6501)[0m rmse: 0.1792110800743103
[2m[36m(func pid=6501)[0m mae:  0.13095703721046448
[2m[36m(func pid=6501)[0m rmse_per_class: [0.105, 0.268, 0.092, 0.325, 0.1, 0.193, 0.301, 0.154, 0.139, 0.115]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.9645 | Steps: 2 | Val loss: 0.7605 | Batch size: 32 | lr: 0.0001 | Duration: 3.04s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.3752 | Steps: 2 | Val loss: 0.3636 | Batch size: 32 | lr: 0.01 | Duration: 3.17s
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.3035 | Steps: 2 | Val loss: 1.5480 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.5590 | Steps: 2 | Val loss: 0.4278 | Batch size: 32 | lr: 0.001 | Duration: 3.13s
[2m[36m(func pid=2617)[0m rmse: 0.1634286344051361
[2m[36m(func pid=2617)[0m mae:  0.10166158527135849
[2m[36m(func pid=2617)[0m rmse_per_class: [0.073, 0.215, 0.027, 0.283, 0.056, 0.227, 0.25, 0.13, 0.281, 0.092]
[2m[36m(func pid=5776)[0m rmse: 0.18098871409893036
[2m[36m(func pid=5776)[0m mae:  0.13295423984527588
[2m[36m(func pid=5776)[0m rmse_per_class: [0.106, 0.266, 0.09, 0.324, 0.106, 0.194, 0.31, 0.154, 0.138, 0.121]
[2m[36m(func pid=5776)[0m 
== Status ==
Current time: 2024-01-07 09:08:51 (running for 00:36:52.48)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.37  |  0.164 |                   19 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.33  |  0.23  |                   17 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.964 |  0.181 |                   10 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.618 |  0.179 |                    7 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=3873)[0m rmse: 0.2288971245288849
[2m[36m(func pid=3873)[0m mae:  0.143242746591568
[2m[36m(func pid=3873)[0m rmse_per_class: [0.097, 0.252, 0.154, 0.384, 0.055, 0.223, 0.259, 0.197, 0.582, 0.085]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=6501)[0m rmse: 0.1789213865995407
[2m[36m(func pid=6501)[0m mae:  0.1306050568819046
[2m[36m(func pid=6501)[0m rmse_per_class: [0.106, 0.269, 0.092, 0.326, 0.099, 0.193, 0.299, 0.151, 0.14, 0.115]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.9451 | Steps: 2 | Val loss: 0.7492 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.3582 | Steps: 2 | Val loss: 1.2677 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.3662 | Steps: 2 | Val loss: 0.3632 | Batch size: 32 | lr: 0.01 | Duration: 3.17s
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.5123 | Steps: 2 | Val loss: 0.3955 | Batch size: 32 | lr: 0.001 | Duration: 3.06s
== Status ==
Current time: 2024-01-07 09:08:56 (running for 00:36:57.87)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.375 |  0.163 |                   20 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.358 |  0.21  |                   19 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.964 |  0.181 |                   10 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.559 |  0.179 |                    8 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=3873)[0m rmse: 0.2100408971309662
[2m[36m(func pid=3873)[0m mae:  0.13129429519176483
[2m[36m(func pid=3873)[0m rmse_per_class: [0.109, 0.256, 0.148, 0.356, 0.058, 0.226, 0.242, 0.137, 0.477, 0.092]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=5776)[0m rmse: 0.1810472309589386
[2m[36m(func pid=5776)[0m mae:  0.13297109305858612
[2m[36m(func pid=5776)[0m rmse_per_class: [0.106, 0.267, 0.09, 0.324, 0.105, 0.194, 0.31, 0.154, 0.138, 0.122]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=2617)[0m rmse: 0.16310694813728333
[2m[36m(func pid=2617)[0m mae:  0.10245722532272339
[2m[36m(func pid=2617)[0m rmse_per_class: [0.064, 0.215, 0.028, 0.29, 0.056, 0.219, 0.266, 0.116, 0.288, 0.089]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=6501)[0m rmse: 0.17864738404750824
[2m[36m(func pid=6501)[0m mae:  0.13026563823223114
[2m[36m(func pid=6501)[0m rmse_per_class: [0.106, 0.269, 0.093, 0.326, 0.098, 0.193, 0.297, 0.149, 0.141, 0.115]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.3063 | Steps: 2 | Val loss: 1.3156 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.9302 | Steps: 2 | Val loss: 0.7362 | Batch size: 32 | lr: 0.0001 | Duration: 3.03s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.3893 | Steps: 2 | Val loss: 0.3662 | Batch size: 32 | lr: 0.01 | Duration: 3.06s
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.4735 | Steps: 2 | Val loss: 0.3709 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=3873)[0m rmse: 0.20696468651294708
[2m[36m(func pid=3873)[0m mae:  0.12838348746299744
[2m[36m(func pid=3873)[0m rmse_per_class: [0.108, 0.262, 0.117, 0.355, 0.057, 0.23, 0.232, 0.151, 0.453, 0.104]
== Status ==
Current time: 2024-01-07 09:09:02 (running for 00:37:03.23)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.366 |  0.163 |                   21 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.306 |  0.207 |                   20 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.945 |  0.181 |                   11 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.512 |  0.179 |                    9 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=5776)[0m rmse: 0.18110835552215576
[2m[36m(func pid=5776)[0m mae:  0.13300374150276184
[2m[36m(func pid=5776)[0m rmse_per_class: [0.106, 0.267, 0.09, 0.324, 0.105, 0.194, 0.31, 0.154, 0.138, 0.122]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=2617)[0m rmse: 0.1650138646364212
[2m[36m(func pid=2617)[0m mae:  0.10375384241342545
[2m[36m(func pid=2617)[0m rmse_per_class: [0.063, 0.218, 0.031, 0.298, 0.056, 0.211, 0.278, 0.111, 0.296, 0.089]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=6501)[0m rmse: 0.1781456470489502
[2m[36m(func pid=6501)[0m mae:  0.1297483593225479
[2m[36m(func pid=6501)[0m rmse_per_class: [0.106, 0.269, 0.094, 0.326, 0.097, 0.193, 0.294, 0.147, 0.141, 0.115]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.3127 | Steps: 2 | Val loss: 1.1422 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.9155 | Steps: 2 | Val loss: 0.7218 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.3583 | Steps: 2 | Val loss: 0.3591 | Batch size: 32 | lr: 0.01 | Duration: 3.12s
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.4503 | Steps: 2 | Val loss: 0.3534 | Batch size: 32 | lr: 0.001 | Duration: 3.15s
== Status ==
Current time: 2024-01-07 09:09:07 (running for 00:37:08.48)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.389 |  0.165 |                   22 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.313 |  0.214 |                   21 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.93  |  0.181 |                   12 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.474 |  0.178 |                   10 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=3873)[0m rmse: 0.21380515396595
[2m[36m(func pid=3873)[0m mae:  0.13183531165122986
[2m[36m(func pid=3873)[0m rmse_per_class: [0.108, 0.268, 0.064, 0.344, 0.054, 0.229, 0.307, 0.147, 0.504, 0.113]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=5776)[0m rmse: 0.1811898946762085
[2m[36m(func pid=5776)[0m mae:  0.13303352892398834
[2m[36m(func pid=5776)[0m rmse_per_class: [0.106, 0.267, 0.09, 0.324, 0.106, 0.194, 0.311, 0.154, 0.138, 0.122]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=2617)[0m rmse: 0.1670718938112259
[2m[36m(func pid=2617)[0m mae:  0.10417716205120087
[2m[36m(func pid=2617)[0m rmse_per_class: [0.068, 0.223, 0.033, 0.304, 0.056, 0.206, 0.284, 0.118, 0.289, 0.091]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=6501)[0m rmse: 0.1776544153690338
[2m[36m(func pid=6501)[0m mae:  0.12924113869667053
[2m[36m(func pid=6501)[0m rmse_per_class: [0.107, 0.27, 0.094, 0.327, 0.095, 0.192, 0.291, 0.145, 0.142, 0.114]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.2977 | Steps: 2 | Val loss: 1.4587 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.8958 | Steps: 2 | Val loss: 0.7088 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.3388 | Steps: 2 | Val loss: 0.3647 | Batch size: 32 | lr: 0.01 | Duration: 3.16s
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.4261 | Steps: 2 | Val loss: 0.3412 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=3873)[0m rmse: 0.22438721358776093
[2m[36m(func pid=3873)[0m mae:  0.1434759497642517
[2m[36m(func pid=3873)[0m rmse_per_class: [0.112, 0.266, 0.033, 0.355, 0.056, 0.227, 0.268, 0.138, 0.666, 0.122]
[2m[36m(func pid=3873)[0m 
== Status ==
Current time: 2024-01-07 09:09:12 (running for 00:37:13.66)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.358 |  0.167 |                   23 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.298 |  0.224 |                   22 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.915 |  0.181 |                   13 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.45  |  0.178 |                   11 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=5776)[0m rmse: 0.18111763894557953
[2m[36m(func pid=5776)[0m mae:  0.13295568525791168
[2m[36m(func pid=5776)[0m rmse_per_class: [0.106, 0.267, 0.09, 0.324, 0.105, 0.194, 0.311, 0.154, 0.138, 0.123]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=2617)[0m rmse: 0.17319326102733612
[2m[36m(func pid=2617)[0m mae:  0.10729365050792694
[2m[36m(func pid=2617)[0m rmse_per_class: [0.074, 0.234, 0.036, 0.311, 0.056, 0.208, 0.288, 0.133, 0.293, 0.1]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=6501)[0m rmse: 0.17718027532100677
[2m[36m(func pid=6501)[0m mae:  0.12875984609127045
[2m[36m(func pid=6501)[0m rmse_per_class: [0.107, 0.27, 0.094, 0.328, 0.093, 0.192, 0.288, 0.143, 0.142, 0.114]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.3294 | Steps: 2 | Val loss: 3.4923 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.8792 | Steps: 2 | Val loss: 0.6944 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.3402 | Steps: 2 | Val loss: 0.3702 | Batch size: 32 | lr: 0.01 | Duration: 3.16s
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.4157 | Steps: 2 | Val loss: 0.3326 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
== Status ==
Current time: 2024-01-07 09:09:18 (running for 00:37:18.93)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.339 |  0.173 |                   24 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.329 |  0.243 |                   23 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.896 |  0.181 |                   14 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.426 |  0.177 |                   12 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=3873)[0m rmse: 0.2426568567752838
[2m[36m(func pid=3873)[0m mae:  0.15599581599235535
[2m[36m(func pid=3873)[0m rmse_per_class: [0.112, 0.274, 0.039, 0.381, 0.056, 0.224, 0.285, 0.154, 0.748, 0.153]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=5776)[0m rmse: 0.1811562180519104
[2m[36m(func pid=5776)[0m mae:  0.13296952843666077
[2m[36m(func pid=5776)[0m rmse_per_class: [0.106, 0.267, 0.09, 0.324, 0.106, 0.194, 0.311, 0.154, 0.138, 0.123]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=2617)[0m rmse: 0.17837437987327576
[2m[36m(func pid=2617)[0m mae:  0.10992681980133057
[2m[36m(func pid=2617)[0m rmse_per_class: [0.077, 0.243, 0.036, 0.318, 0.055, 0.206, 0.293, 0.149, 0.29, 0.116]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=6501)[0m rmse: 0.17664915323257446
[2m[36m(func pid=6501)[0m mae:  0.12825146317481995
[2m[36m(func pid=6501)[0m rmse_per_class: [0.108, 0.27, 0.094, 0.328, 0.092, 0.192, 0.286, 0.141, 0.143, 0.114]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.2987 | Steps: 2 | Val loss: 4.5906 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.8635 | Steps: 2 | Val loss: 0.6816 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.3560 | Steps: 2 | Val loss: 0.3756 | Batch size: 32 | lr: 0.01 | Duration: 3.07s
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.4134 | Steps: 2 | Val loss: 0.3265 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 09:09:23 (running for 00:37:24.25)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.34  |  0.178 |                   25 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.299 |  0.246 |                   24 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.879 |  0.181 |                   15 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.416 |  0.177 |                   13 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=3873)[0m rmse: 0.2461603581905365
[2m[36m(func pid=3873)[0m mae:  0.15725961327552795
[2m[36m(func pid=3873)[0m rmse_per_class: [0.112, 0.282, 0.04, 0.386, 0.055, 0.223, 0.281, 0.151, 0.739, 0.193]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=5776)[0m rmse: 0.1811610609292984
[2m[36m(func pid=5776)[0m mae:  0.13294567167758942
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.267, 0.09, 0.324, 0.106, 0.194, 0.311, 0.154, 0.138, 0.123]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=2617)[0m rmse: 0.18467304110527039
[2m[36m(func pid=2617)[0m mae:  0.11266346275806427
[2m[36m(func pid=2617)[0m rmse_per_class: [0.081, 0.253, 0.04, 0.316, 0.055, 0.2, 0.297, 0.174, 0.289, 0.142]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=6501)[0m rmse: 0.17610301077365875
[2m[36m(func pid=6501)[0m mae:  0.12767167389392853
[2m[36m(func pid=6501)[0m rmse_per_class: [0.108, 0.27, 0.094, 0.328, 0.09, 0.191, 0.284, 0.14, 0.144, 0.113]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.3274 | Steps: 2 | Val loss: 2.3019 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.8459 | Steps: 2 | Val loss: 0.6696 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.3587 | Steps: 2 | Val loss: 0.3829 | Batch size: 32 | lr: 0.01 | Duration: 3.08s
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.3986 | Steps: 2 | Val loss: 0.3226 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 09:09:28 (running for 00:37:29.55)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.356 |  0.185 |                   26 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.327 |  0.239 |                   25 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.864 |  0.181 |                   16 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.413 |  0.176 |                   14 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=3873)[0m rmse: 0.23900237679481506
[2m[36m(func pid=3873)[0m mae:  0.14803168177604675
[2m[36m(func pid=3873)[0m rmse_per_class: [0.113, 0.285, 0.039, 0.383, 0.054, 0.222, 0.264, 0.144, 0.647, 0.24]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=5776)[0m rmse: 0.1811269074678421
[2m[36m(func pid=5776)[0m mae:  0.13292142748832703
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.267, 0.09, 0.324, 0.106, 0.194, 0.311, 0.154, 0.138, 0.123]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=6501)[0m rmse: 0.17558616399765015
[2m[36m(func pid=6501)[0m mae:  0.12717995047569275
[2m[36m(func pid=6501)[0m rmse_per_class: [0.108, 0.27, 0.093, 0.329, 0.088, 0.191, 0.281, 0.139, 0.145, 0.112]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=2617)[0m rmse: 0.19005249440670013
[2m[36m(func pid=2617)[0m mae:  0.11556191742420197
[2m[36m(func pid=2617)[0m rmse_per_class: [0.082, 0.263, 0.039, 0.316, 0.055, 0.194, 0.302, 0.197, 0.287, 0.165]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.2931 | Steps: 2 | Val loss: 0.5925 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.8311 | Steps: 2 | Val loss: 0.6579 | Batch size: 32 | lr: 0.0001 | Duration: 3.06s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.3374 | Steps: 2 | Val loss: 0.3773 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
[2m[36m(func pid=3873)[0m rmse: 0.214870423078537
[2m[36m(func pid=3873)[0m mae:  0.12458308786153793
[2m[36m(func pid=3873)[0m rmse_per_class: [0.145, 0.284, 0.235, 0.36, 0.052, 0.219, 0.234, 0.139, 0.207, 0.274]
[2m[36m(func pid=3873)[0m 
== Status ==
Current time: 2024-01-07 09:09:34 (running for 00:37:34.92)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.359 |  0.19  |                   27 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.293 |  0.215 |                   26 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.846 |  0.181 |                   17 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.399 |  0.176 |                   15 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.3899 | Steps: 2 | Val loss: 0.3198 | Batch size: 32 | lr: 0.001 | Duration: 3.08s
[2m[36m(func pid=5776)[0m rmse: 0.181108757853508
[2m[36m(func pid=5776)[0m mae:  0.13289475440979004
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.267, 0.089, 0.324, 0.105, 0.194, 0.31, 0.154, 0.138, 0.123]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=2617)[0m rmse: 0.1917332410812378
[2m[36m(func pid=2617)[0m mae:  0.11659685522317886
[2m[36m(func pid=2617)[0m rmse_per_class: [0.081, 0.266, 0.036, 0.316, 0.055, 0.189, 0.304, 0.221, 0.264, 0.186]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=6501)[0m rmse: 0.17514082789421082
[2m[36m(func pid=6501)[0m mae:  0.1267329901456833
[2m[36m(func pid=6501)[0m rmse_per_class: [0.108, 0.27, 0.092, 0.329, 0.087, 0.191, 0.28, 0.138, 0.145, 0.112]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.3182 | Steps: 2 | Val loss: 0.4250 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.8185 | Steps: 2 | Val loss: 0.6457 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 09:09:39 (running for 00:37:40.23)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.337 |  0.192 |                   28 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.318 |  0.199 |                   27 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.831 |  0.181 |                   18 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.39  |  0.175 |                   16 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=3873)[0m rmse: 0.1991375982761383
[2m[36m(func pid=3873)[0m mae:  0.11750167608261108
[2m[36m(func pid=3873)[0m rmse_per_class: [0.121, 0.282, 0.256, 0.332, 0.051, 0.218, 0.221, 0.143, 0.152, 0.215]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.3861 | Steps: 2 | Val loss: 0.3182 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.3501 | Steps: 2 | Val loss: 0.3795 | Batch size: 32 | lr: 0.01 | Duration: 3.09s
[2m[36m(func pid=5776)[0m rmse: 0.18112866580486298
[2m[36m(func pid=5776)[0m mae:  0.13288810849189758
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.267, 0.089, 0.324, 0.105, 0.194, 0.31, 0.154, 0.138, 0.123]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=6501)[0m rmse: 0.1746746450662613
[2m[36m(func pid=6501)[0m mae:  0.12632670998573303
[2m[36m(func pid=6501)[0m rmse_per_class: [0.108, 0.269, 0.091, 0.329, 0.086, 0.191, 0.278, 0.138, 0.145, 0.112]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=2617)[0m rmse: 0.19429954886436462
[2m[36m(func pid=2617)[0m mae:  0.11810851097106934
[2m[36m(func pid=2617)[0m rmse_per_class: [0.079, 0.269, 0.037, 0.318, 0.054, 0.186, 0.303, 0.24, 0.258, 0.198]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.2898 | Steps: 2 | Val loss: 0.4177 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.8043 | Steps: 2 | Val loss: 0.6345 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
== Status ==
Current time: 2024-01-07 09:09:44 (running for 00:37:45.62)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.35  |  0.194 |                   29 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.29  |  0.193 |                   28 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.818 |  0.181 |                   19 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.386 |  0.175 |                   17 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=3873)[0m rmse: 0.19318342208862305
[2m[36m(func pid=3873)[0m mae:  0.11525455862283707
[2m[36m(func pid=3873)[0m rmse_per_class: [0.098, 0.279, 0.241, 0.335, 0.05, 0.217, 0.214, 0.142, 0.191, 0.165]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.3864 | Steps: 2 | Val loss: 0.3169 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.3269 | Steps: 2 | Val loss: 0.3766 | Batch size: 32 | lr: 0.01 | Duration: 3.09s
[2m[36m(func pid=5776)[0m rmse: 0.1810949295759201
[2m[36m(func pid=5776)[0m mae:  0.1328350007534027
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.267, 0.089, 0.324, 0.105, 0.194, 0.31, 0.154, 0.138, 0.123]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=6501)[0m rmse: 0.17420263588428497
[2m[36m(func pid=6501)[0m mae:  0.12593695521354675
[2m[36m(func pid=6501)[0m rmse_per_class: [0.108, 0.269, 0.089, 0.329, 0.085, 0.191, 0.278, 0.137, 0.145, 0.112]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.2941 | Steps: 2 | Val loss: 0.4538 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=2617)[0m rmse: 0.1952827274799347
[2m[36m(func pid=2617)[0m mae:  0.11881694942712784
[2m[36m(func pid=2617)[0m rmse_per_class: [0.078, 0.272, 0.04, 0.319, 0.054, 0.186, 0.3, 0.259, 0.244, 0.2]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.7926 | Steps: 2 | Val loss: 0.6237 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
== Status ==
Current time: 2024-01-07 09:09:49 (running for 00:37:50.87)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.327 |  0.195 |                   30 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.294 |  0.191 |                   29 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.804 |  0.181 |                   20 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.386 |  0.174 |                   18 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=3873)[0m rmse: 0.19134490191936493
[2m[36m(func pid=3873)[0m mae:  0.11601163446903229
[2m[36m(func pid=3873)[0m rmse_per_class: [0.098, 0.269, 0.237, 0.345, 0.049, 0.216, 0.219, 0.13, 0.201, 0.148]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.3842 | Steps: 2 | Val loss: 0.3156 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.3312 | Steps: 2 | Val loss: 0.3731 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=5776)[0m rmse: 0.18112239241600037
[2m[36m(func pid=5776)[0m mae:  0.13284465670585632
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.267, 0.09, 0.324, 0.105, 0.194, 0.31, 0.154, 0.138, 0.123]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.2827 | Steps: 2 | Val loss: 0.5622 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=6501)[0m rmse: 0.173635333776474
[2m[36m(func pid=6501)[0m mae:  0.12543782591819763
[2m[36m(func pid=6501)[0m rmse_per_class: [0.108, 0.268, 0.087, 0.328, 0.084, 0.19, 0.276, 0.137, 0.145, 0.112]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=2617)[0m rmse: 0.19439247250556946
[2m[36m(func pid=2617)[0m mae:  0.11847255378961563
[2m[36m(func pid=2617)[0m rmse_per_class: [0.076, 0.271, 0.042, 0.324, 0.053, 0.187, 0.294, 0.269, 0.233, 0.194]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.7732 | Steps: 2 | Val loss: 0.6135 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
== Status ==
Current time: 2024-01-07 09:09:55 (running for 00:37:56.16)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.331 |  0.194 |                   31 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.283 |  0.201 |                   30 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.793 |  0.181 |                   21 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.384 |  0.174 |                   19 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=3873)[0m rmse: 0.2009526491165161
[2m[36m(func pid=3873)[0m mae:  0.12232065200805664
[2m[36m(func pid=3873)[0m rmse_per_class: [0.099, 0.272, 0.3, 0.362, 0.049, 0.219, 0.225, 0.121, 0.217, 0.146]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.3804 | Steps: 2 | Val loss: 0.3146 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.3292 | Steps: 2 | Val loss: 0.3645 | Batch size: 32 | lr: 0.01 | Duration: 3.08s
[2m[36m(func pid=5776)[0m rmse: 0.1810876578092575
[2m[36m(func pid=5776)[0m mae:  0.13281981647014618
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.267, 0.09, 0.324, 0.104, 0.194, 0.31, 0.154, 0.139, 0.123]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.2954 | Steps: 2 | Val loss: 0.4728 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
[2m[36m(func pid=6501)[0m rmse: 0.17309120297431946
[2m[36m(func pid=6501)[0m mae:  0.12495893239974976
[2m[36m(func pid=6501)[0m rmse_per_class: [0.108, 0.268, 0.086, 0.328, 0.083, 0.19, 0.275, 0.137, 0.146, 0.111]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=2617)[0m rmse: 0.19181114435195923
[2m[36m(func pid=2617)[0m mae:  0.11738143861293793
[2m[36m(func pid=2617)[0m rmse_per_class: [0.078, 0.269, 0.045, 0.329, 0.053, 0.188, 0.286, 0.273, 0.215, 0.182]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.7631 | Steps: 2 | Val loss: 0.6034 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 09:10:00 (running for 00:38:01.35)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.329 |  0.192 |                   32 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.295 |  0.199 |                   31 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.773 |  0.181 |                   22 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.38  |  0.173 |                   20 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=3873)[0m rmse: 0.1991138458251953
[2m[36m(func pid=3873)[0m mae:  0.1228623017668724
[2m[36m(func pid=3873)[0m rmse_per_class: [0.098, 0.283, 0.305, 0.36, 0.05, 0.218, 0.229, 0.109, 0.19, 0.15]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.3734 | Steps: 2 | Val loss: 0.3138 | Batch size: 32 | lr: 0.001 | Duration: 3.04s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.2995 | Steps: 2 | Val loss: 0.3589 | Batch size: 32 | lr: 0.01 | Duration: 3.03s
[2m[36m(func pid=5776)[0m rmse: 0.18100911378860474
[2m[36m(func pid=5776)[0m mae:  0.1327422559261322
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.104, 0.194, 0.31, 0.154, 0.139, 0.123]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.2933 | Steps: 2 | Val loss: 0.4468 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
[2m[36m(func pid=6501)[0m rmse: 0.1726016104221344
[2m[36m(func pid=6501)[0m mae:  0.12455084174871445
[2m[36m(func pid=6501)[0m rmse_per_class: [0.108, 0.268, 0.085, 0.327, 0.082, 0.19, 0.274, 0.136, 0.146, 0.111]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=2617)[0m rmse: 0.1895298808813095
[2m[36m(func pid=2617)[0m mae:  0.11661200225353241
[2m[36m(func pid=2617)[0m rmse_per_class: [0.081, 0.267, 0.046, 0.336, 0.052, 0.189, 0.274, 0.271, 0.202, 0.178]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=3873)[0m rmse: 0.20211973786354065
[2m[36m(func pid=3873)[0m mae:  0.12608513236045837
[2m[36m(func pid=3873)[0m rmse_per_class: [0.097, 0.29, 0.33, 0.356, 0.053, 0.219, 0.233, 0.108, 0.178, 0.156]
[2m[36m(func pid=3873)[0m 
== Status ==
Current time: 2024-01-07 09:10:05 (running for 00:38:06.81)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.299 |  0.19  |                   33 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.293 |  0.202 |                   32 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.763 |  0.181 |                   23 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.373 |  0.173 |                   21 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.7508 | Steps: 2 | Val loss: 0.5939 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.3735 | Steps: 2 | Val loss: 0.3129 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.2957 | Steps: 2 | Val loss: 0.3524 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
[2m[36m(func pid=5776)[0m rmse: 0.18099457025527954
[2m[36m(func pid=5776)[0m mae:  0.13268695771694183
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.268, 0.089, 0.324, 0.104, 0.194, 0.309, 0.154, 0.138, 0.122]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.3364 | Steps: 2 | Val loss: 0.4876 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=6501)[0m rmse: 0.17198078334331512
[2m[36m(func pid=6501)[0m mae:  0.1240202784538269
[2m[36m(func pid=6501)[0m rmse_per_class: [0.107, 0.267, 0.083, 0.326, 0.081, 0.19, 0.273, 0.136, 0.146, 0.111]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=2617)[0m rmse: 0.18614083528518677
[2m[36m(func pid=2617)[0m mae:  0.11474798619747162
[2m[36m(func pid=2617)[0m rmse_per_class: [0.087, 0.263, 0.047, 0.34, 0.052, 0.187, 0.267, 0.265, 0.193, 0.162]
[2m[36m(func pid=2617)[0m 
== Status ==
Current time: 2024-01-07 09:10:11 (running for 00:38:12.13)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.296 |  0.186 |                   34 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.336 |  0.205 |                   33 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.751 |  0.181 |                   24 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.374 |  0.172 |                   22 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=3873)[0m rmse: 0.20494572818279266
[2m[36m(func pid=3873)[0m mae:  0.12319016456604004
[2m[36m(func pid=3873)[0m rmse_per_class: [0.098, 0.306, 0.332, 0.357, 0.055, 0.221, 0.224, 0.11, 0.162, 0.183]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.7396 | Steps: 2 | Val loss: 0.5842 | Batch size: 32 | lr: 0.0001 | Duration: 3.08s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.2967 | Steps: 2 | Val loss: 0.3444 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.3720 | Steps: 2 | Val loss: 0.3118 | Batch size: 32 | lr: 0.001 | Duration: 3.20s
[2m[36m(func pid=5776)[0m rmse: 0.18094965815544128
[2m[36m(func pid=5776)[0m mae:  0.13264070451259613
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.268, 0.089, 0.324, 0.104, 0.194, 0.309, 0.154, 0.139, 0.123]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.2961 | Steps: 2 | Val loss: 0.8256 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=2617)[0m rmse: 0.1824956238269806
[2m[36m(func pid=2617)[0m mae:  0.11277788877487183
[2m[36m(func pid=2617)[0m rmse_per_class: [0.091, 0.258, 0.047, 0.343, 0.052, 0.186, 0.26, 0.256, 0.184, 0.15]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=6501)[0m rmse: 0.17132782936096191
[2m[36m(func pid=6501)[0m mae:  0.1234874278306961
[2m[36m(func pid=6501)[0m rmse_per_class: [0.107, 0.267, 0.081, 0.325, 0.081, 0.19, 0.272, 0.136, 0.146, 0.11]
[2m[36m(func pid=6501)[0m 
== Status ==
Current time: 2024-01-07 09:10:16 (running for 00:38:17.41)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.297 |  0.182 |                   35 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.296 |  0.223 |                   34 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.74  |  0.181 |                   25 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.372 |  0.171 |                   23 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=3873)[0m rmse: 0.22274449467658997
[2m[36m(func pid=3873)[0m mae:  0.1270967423915863
[2m[36m(func pid=3873)[0m rmse_per_class: [0.104, 0.314, 0.29, 0.377, 0.056, 0.222, 0.223, 0.125, 0.236, 0.281]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.7264 | Steps: 2 | Val loss: 0.5750 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.2824 | Steps: 2 | Val loss: 0.3353 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.3669 | Steps: 2 | Val loss: 0.3113 | Batch size: 32 | lr: 0.001 | Duration: 3.11s
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.5756 | Steps: 2 | Val loss: 0.9182 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=5776)[0m rmse: 0.1809217631816864
[2m[36m(func pid=5776)[0m mae:  0.132595032453537
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.268, 0.089, 0.324, 0.104, 0.194, 0.309, 0.153, 0.139, 0.123]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=2617)[0m rmse: 0.17816083133220673
[2m[36m(func pid=2617)[0m mae:  0.1101439967751503
[2m[36m(func pid=2617)[0m rmse_per_class: [0.093, 0.251, 0.046, 0.345, 0.052, 0.182, 0.251, 0.242, 0.177, 0.142]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=6501)[0m rmse: 0.1709628701210022
[2m[36m(func pid=6501)[0m mae:  0.12317731231451035
[2m[36m(func pid=6501)[0m rmse_per_class: [0.107, 0.267, 0.08, 0.325, 0.08, 0.19, 0.271, 0.135, 0.146, 0.11]
[2m[36m(func pid=6501)[0m 
== Status ==
Current time: 2024-01-07 09:10:21 (running for 00:38:22.73)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.282 |  0.178 |                   36 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.576 |  0.224 |                   35 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.726 |  0.181 |                   26 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.367 |  0.171 |                   24 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=3873)[0m rmse: 0.22384297847747803
[2m[36m(func pid=3873)[0m mae:  0.12712660431861877
[2m[36m(func pid=3873)[0m rmse_per_class: [0.105, 0.311, 0.208, 0.385, 0.056, 0.217, 0.227, 0.104, 0.257, 0.369]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.7171 | Steps: 2 | Val loss: 0.5665 | Batch size: 32 | lr: 0.0001 | Duration: 3.03s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.2867 | Steps: 2 | Val loss: 0.3263 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.3642 | Steps: 2 | Val loss: 0.3106 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.3242 | Steps: 2 | Val loss: 0.6811 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=5776)[0m rmse: 0.18087266385555267
[2m[36m(func pid=5776)[0m mae:  0.13253268599510193
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.268, 0.089, 0.324, 0.104, 0.194, 0.308, 0.153, 0.139, 0.123]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=2617)[0m rmse: 0.17347925901412964
[2m[36m(func pid=2617)[0m mae:  0.107091024518013
[2m[36m(func pid=2617)[0m rmse_per_class: [0.092, 0.245, 0.045, 0.343, 0.053, 0.178, 0.244, 0.231, 0.175, 0.129]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=6501)[0m rmse: 0.17049892246723175
[2m[36m(func pid=6501)[0m mae:  0.12280019372701645
[2m[36m(func pid=6501)[0m rmse_per_class: [0.106, 0.266, 0.079, 0.324, 0.08, 0.189, 0.271, 0.135, 0.146, 0.11]
[2m[36m(func pid=6501)[0m 
== Status ==
Current time: 2024-01-07 09:10:26 (running for 00:38:27.85)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.287 |  0.173 |                   37 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.324 |  0.215 |                   36 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.717 |  0.181 |                   27 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.364 |  0.17  |                   25 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=3873)[0m rmse: 0.21522918343544006
[2m[36m(func pid=3873)[0m mae:  0.12445934116840363
[2m[36m(func pid=3873)[0m rmse_per_class: [0.102, 0.31, 0.168, 0.379, 0.055, 0.206, 0.226, 0.112, 0.197, 0.397]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.7071 | Steps: 2 | Val loss: 0.5583 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.2710 | Steps: 2 | Val loss: 0.3176 | Batch size: 32 | lr: 0.01 | Duration: 3.03s
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.3572 | Steps: 2 | Val loss: 0.3101 | Batch size: 32 | lr: 0.001 | Duration: 3.17s
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.2952 | Steps: 2 | Val loss: 0.5635 | Batch size: 32 | lr: 0.1 | Duration: 3.07s
[2m[36m(func pid=5776)[0m rmse: 0.1808055341243744
[2m[36m(func pid=5776)[0m mae:  0.13245894014835358
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.268, 0.089, 0.324, 0.104, 0.194, 0.308, 0.153, 0.139, 0.123]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=2617)[0m rmse: 0.16885943710803986
[2m[36m(func pid=2617)[0m mae:  0.10420618951320648
[2m[36m(func pid=2617)[0m rmse_per_class: [0.087, 0.238, 0.043, 0.341, 0.056, 0.173, 0.236, 0.222, 0.175, 0.117]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=6501)[0m rmse: 0.1701524257659912
[2m[36m(func pid=6501)[0m mae:  0.12253010272979736
[2m[36m(func pid=6501)[0m rmse_per_class: [0.106, 0.266, 0.077, 0.324, 0.079, 0.189, 0.27, 0.135, 0.146, 0.11]
[2m[36m(func pid=6501)[0m 
== Status ==
Current time: 2024-01-07 09:10:32 (running for 00:38:33.22)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.271 |  0.169 |                   38 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.295 |  0.206 |                   37 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.707 |  0.181 |                   28 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.357 |  0.17  |                   26 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=3873)[0m rmse: 0.20599953830242157
[2m[36m(func pid=3873)[0m mae:  0.12013919651508331
[2m[36m(func pid=3873)[0m rmse_per_class: [0.098, 0.305, 0.181, 0.365, 0.054, 0.198, 0.216, 0.125, 0.195, 0.322]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.6977 | Steps: 2 | Val loss: 0.5504 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.2665 | Steps: 2 | Val loss: 0.3102 | Batch size: 32 | lr: 0.01 | Duration: 3.14s
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.3554 | Steps: 2 | Val loss: 0.3092 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.3945 | Steps: 2 | Val loss: 0.5772 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
[2m[36m(func pid=5776)[0m rmse: 0.18073849380016327
[2m[36m(func pid=5776)[0m mae:  0.13238391280174255
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.268, 0.089, 0.324, 0.104, 0.193, 0.308, 0.153, 0.139, 0.123]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=2617)[0m rmse: 0.16485051810741425
[2m[36m(func pid=2617)[0m mae:  0.10123028606176376
[2m[36m(func pid=2617)[0m rmse_per_class: [0.084, 0.234, 0.042, 0.337, 0.059, 0.169, 0.224, 0.212, 0.177, 0.11]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=6501)[0m rmse: 0.16965532302856445
[2m[36m(func pid=6501)[0m mae:  0.12214399874210358
[2m[36m(func pid=6501)[0m rmse_per_class: [0.106, 0.265, 0.076, 0.323, 0.078, 0.189, 0.27, 0.134, 0.146, 0.109]
[2m[36m(func pid=6501)[0m 
== Status ==
Current time: 2024-01-07 09:10:37 (running for 00:38:38.41)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.266 |  0.165 |                   39 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.295 |  0.206 |                   37 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.698 |  0.181 |                   29 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.355 |  0.17  |                   27 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=3873)[0m rmse: 0.20293407142162323
[2m[36m(func pid=3873)[0m mae:  0.12115862220525742
[2m[36m(func pid=3873)[0m rmse_per_class: [0.099, 0.301, 0.102, 0.367, 0.053, 0.206, 0.223, 0.132, 0.138, 0.409]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.6851 | Steps: 2 | Val loss: 0.5430 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.2786 | Steps: 2 | Val loss: 0.3043 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.4181 | Steps: 2 | Val loss: 1.8678 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.3556 | Steps: 2 | Val loss: 0.3083 | Batch size: 32 | lr: 0.001 | Duration: 3.05s
[2m[36m(func pid=5776)[0m rmse: 0.18081124126911163
[2m[36m(func pid=5776)[0m mae:  0.13241493701934814
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.103, 0.194, 0.308, 0.153, 0.139, 0.123]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=2617)[0m rmse: 0.16148081421852112
[2m[36m(func pid=2617)[0m mae:  0.09831048548221588
[2m[36m(func pid=2617)[0m rmse_per_class: [0.084, 0.231, 0.043, 0.331, 0.06, 0.166, 0.212, 0.202, 0.18, 0.106]
[2m[36m(func pid=2617)[0m 
== Status ==
Current time: 2024-01-07 09:10:42 (running for 00:38:43.77)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.279 |  0.161 |                   40 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.418 |  0.221 |                   39 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.685 |  0.181 |                   30 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.355 |  0.17  |                   27 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=3873)[0m rmse: 0.22125592827796936
[2m[36m(func pid=3873)[0m mae:  0.1336420774459839
[2m[36m(func pid=3873)[0m rmse_per_class: [0.102, 0.294, 0.071, 0.38, 0.051, 0.226, 0.26, 0.17, 0.139, 0.519]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=6501)[0m rmse: 0.1692308783531189
[2m[36m(func pid=6501)[0m mae:  0.12181200832128525
[2m[36m(func pid=6501)[0m rmse_per_class: [0.106, 0.265, 0.075, 0.322, 0.078, 0.189, 0.269, 0.134, 0.146, 0.109]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.6749 | Steps: 2 | Val loss: 0.5355 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.2647 | Steps: 2 | Val loss: 0.2994 | Batch size: 32 | lr: 0.01 | Duration: 3.09s
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.3824 | Steps: 2 | Val loss: 27.9978 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.3569 | Steps: 2 | Val loss: 0.3075 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
[2m[36m(func pid=5776)[0m rmse: 0.18082772195339203
[2m[36m(func pid=5776)[0m mae:  0.13242030143737793
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.103, 0.194, 0.307, 0.153, 0.139, 0.123]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=2617)[0m rmse: 0.15908183157444
[2m[36m(func pid=2617)[0m mae:  0.09653764218091965
[2m[36m(func pid=2617)[0m rmse_per_class: [0.086, 0.228, 0.045, 0.329, 0.065, 0.166, 0.203, 0.189, 0.183, 0.098]
[2m[36m(func pid=2617)[0m 
== Status ==
Current time: 2024-01-07 09:10:47 (running for 00:38:48.84)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.265 |  0.159 |                   41 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.418 |  0.221 |                   39 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.675 |  0.181 |                   31 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.356 |  0.169 |                   28 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=3873)[0m rmse: 0.2621302008628845
[2m[36m(func pid=3873)[0m mae:  0.1766827404499054
[2m[36m(func pid=3873)[0m rmse_per_class: [0.112, 0.299, 0.064, 0.4, 0.054, 0.233, 0.327, 0.134, 0.14, 0.86]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=6501)[0m rmse: 0.16877968609333038
[2m[36m(func pid=6501)[0m mae:  0.12142181396484375
[2m[36m(func pid=6501)[0m rmse_per_class: [0.106, 0.265, 0.073, 0.321, 0.077, 0.189, 0.269, 0.134, 0.146, 0.109]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.6680 | Steps: 2 | Val loss: 0.5288 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.2675 | Steps: 2 | Val loss: 0.2966 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.3391 | Steps: 2 | Val loss: 79.7130 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.3488 | Steps: 2 | Val loss: 0.3063 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=5776)[0m rmse: 0.18076971173286438
[2m[36m(func pid=5776)[0m mae:  0.13234420120716095
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.103, 0.194, 0.307, 0.153, 0.139, 0.122]
[2m[36m(func pid=5776)[0m 
== Status ==
Current time: 2024-01-07 09:10:53 (running for 00:38:54.30)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.267 |  0.158 |                   42 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.382 |  0.262 |                   40 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.668 |  0.181 |                   32 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.357 |  0.169 |                   29 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=2617)[0m rmse: 0.1582413613796234
[2m[36m(func pid=2617)[0m mae:  0.09574978053569794
[2m[36m(func pid=2617)[0m rmse_per_class: [0.087, 0.225, 0.046, 0.326, 0.069, 0.171, 0.198, 0.18, 0.186, 0.094]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=3873)[0m rmse: 0.27314820885658264
[2m[36m(func pid=3873)[0m mae:  0.18664534389972687
[2m[36m(func pid=3873)[0m rmse_per_class: [0.112, 0.3, 0.05, 0.392, 0.056, 0.233, 0.352, 0.156, 0.87, 0.211]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=6501)[0m rmse: 0.16814658045768738
[2m[36m(func pid=6501)[0m mae:  0.12089761346578598
[2m[36m(func pid=6501)[0m rmse_per_class: [0.106, 0.264, 0.072, 0.32, 0.077, 0.188, 0.268, 0.134, 0.145, 0.109]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.6584 | Steps: 2 | Val loss: 0.5218 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.3509 | Steps: 2 | Val loss: 203.8873 | Batch size: 32 | lr: 0.1 | Duration: 2.78s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.2837 | Steps: 2 | Val loss: 0.2971 | Batch size: 32 | lr: 0.01 | Duration: 3.12s
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.3541 | Steps: 2 | Val loss: 0.3054 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=5776)[0m rmse: 0.18074826896190643
[2m[36m(func pid=5776)[0m mae:  0.1323162168264389
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.103, 0.194, 0.307, 0.153, 0.139, 0.122]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=3873)[0m rmse: 0.2607869505882263
[2m[36m(func pid=3873)[0m mae:  0.1855982095003128
[2m[36m(func pid=3873)[0m rmse_per_class: [0.112, 0.301, 0.049, 0.387, 0.058, 0.233, 0.353, 0.156, 0.497, 0.463]
[2m[36m(func pid=3873)[0m 
== Status ==
Current time: 2024-01-07 09:10:58 (running for 00:38:59.67)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.267 |  0.158 |                   42 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.351 |  0.261 |                   42 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.658 |  0.181 |                   33 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.349 |  0.168 |                   30 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=6501)[0m rmse: 0.16766445338726044
[2m[36m(func pid=6501)[0m mae:  0.12051775306463242
[2m[36m(func pid=6501)[0m rmse_per_class: [0.105, 0.264, 0.071, 0.319, 0.076, 0.188, 0.268, 0.134, 0.145, 0.108]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=2617)[0m rmse: 0.15901847183704376
[2m[36m(func pid=2617)[0m mae:  0.09589163959026337
[2m[36m(func pid=2617)[0m rmse_per_class: [0.088, 0.224, 0.047, 0.326, 0.073, 0.178, 0.197, 0.173, 0.19, 0.093]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.6477 | Steps: 2 | Val loss: 0.5155 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.3341 | Steps: 2 | Val loss: 315.3259 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.3507 | Steps: 2 | Val loss: 0.3050 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.2898 | Steps: 2 | Val loss: 0.2971 | Batch size: 32 | lr: 0.01 | Duration: 3.19s
[2m[36m(func pid=5776)[0m rmse: 0.18070721626281738
[2m[36m(func pid=5776)[0m mae:  0.13227063417434692
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.325, 0.103, 0.193, 0.307, 0.152, 0.139, 0.122]
[2m[36m(func pid=5776)[0m 
== Status ==
Current time: 2024-01-07 09:11:04 (running for 00:39:04.91)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.284 |  0.159 |                   43 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.334 |  0.238 |                   43 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.648 |  0.181 |                   34 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.354 |  0.168 |                   31 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=3873)[0m rmse: 0.23845990002155304
[2m[36m(func pid=3873)[0m mae:  0.16884347796440125
[2m[36m(func pid=3873)[0m rmse_per_class: [0.112, 0.301, 0.049, 0.388, 0.06, 0.248, 0.353, 0.156, 0.367, 0.352]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=6501)[0m rmse: 0.16740907728672028
[2m[36m(func pid=6501)[0m mae:  0.12029843032360077
[2m[36m(func pid=6501)[0m rmse_per_class: [0.105, 0.264, 0.07, 0.318, 0.076, 0.188, 0.268, 0.134, 0.145, 0.108]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=2617)[0m rmse: 0.15982523560523987
[2m[36m(func pid=2617)[0m mae:  0.0960780456662178
[2m[36m(func pid=2617)[0m rmse_per_class: [0.089, 0.224, 0.048, 0.324, 0.076, 0.183, 0.199, 0.169, 0.193, 0.094]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.6464 | Steps: 2 | Val loss: 0.5095 | Batch size: 32 | lr: 0.0001 | Duration: 3.04s
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.3200 | Steps: 2 | Val loss: 322.4016 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.3527 | Steps: 2 | Val loss: 0.3043 | Batch size: 32 | lr: 0.001 | Duration: 3.03s
[2m[36m(func pid=5776)[0m rmse: 0.180733785033226
[2m[36m(func pid=5776)[0m mae:  0.132292702794075
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.103, 0.193, 0.306, 0.152, 0.14, 0.122]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.2863 | Steps: 2 | Val loss: 0.2992 | Batch size: 32 | lr: 0.01 | Duration: 3.08s
== Status ==
Current time: 2024-01-07 09:11:09 (running for 00:39:10.20)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.29  |  0.16  |                   44 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.32  |  0.233 |                   44 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.646 |  0.181 |                   35 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.351 |  0.167 |                   32 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=3873)[0m rmse: 0.2328893393278122
[2m[36m(func pid=3873)[0m mae:  0.16557759046554565
[2m[36m(func pid=3873)[0m rmse_per_class: [0.112, 0.299, 0.049, 0.389, 0.06, 0.272, 0.353, 0.156, 0.33, 0.309]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=6501)[0m rmse: 0.1670796275138855
[2m[36m(func pid=6501)[0m mae:  0.12001349031925201
[2m[36m(func pid=6501)[0m rmse_per_class: [0.104, 0.264, 0.069, 0.317, 0.075, 0.188, 0.267, 0.133, 0.145, 0.108]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=2617)[0m rmse: 0.1612769067287445
[2m[36m(func pid=2617)[0m mae:  0.09697945415973663
[2m[36m(func pid=2617)[0m rmse_per_class: [0.089, 0.226, 0.05, 0.324, 0.082, 0.188, 0.205, 0.159, 0.197, 0.094]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.6345 | Steps: 2 | Val loss: 0.5041 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.4809 | Steps: 2 | Val loss: 273.6086 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
[2m[36m(func pid=5776)[0m rmse: 0.18066172301769257
[2m[36m(func pid=5776)[0m mae:  0.13221606612205505
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.103, 0.193, 0.306, 0.152, 0.14, 0.122]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.3418 | Steps: 2 | Val loss: 0.3039 | Batch size: 32 | lr: 0.001 | Duration: 3.06s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.2758 | Steps: 2 | Val loss: 0.3010 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
== Status ==
Current time: 2024-01-07 09:11:14 (running for 00:39:15.39)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.286 |  0.161 |                   45 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.481 |  0.269 |                   45 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.634 |  0.181 |                   36 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.353 |  0.167 |                   33 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=3873)[0m rmse: 0.2693147659301758
[2m[36m(func pid=3873)[0m mae:  0.1883402168750763
[2m[36m(func pid=3873)[0m rmse_per_class: [0.112, 0.291, 0.049, 0.388, 0.057, 0.234, 0.353, 0.156, 0.94, 0.113]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=6501)[0m rmse: 0.16691093146800995
[2m[36m(func pid=6501)[0m mae:  0.11990003287792206
[2m[36m(func pid=6501)[0m rmse_per_class: [0.105, 0.263, 0.068, 0.317, 0.075, 0.188, 0.267, 0.133, 0.146, 0.108]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=2617)[0m rmse: 0.16239726543426514
[2m[36m(func pid=2617)[0m mae:  0.09784907847642899
[2m[36m(func pid=2617)[0m rmse_per_class: [0.089, 0.228, 0.051, 0.325, 0.085, 0.189, 0.209, 0.155, 0.198, 0.095]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.6260 | Steps: 2 | Val loss: 0.4982 | Batch size: 32 | lr: 0.0001 | Duration: 3.17s
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.3965 | Steps: 2 | Val loss: 104.4938 | Batch size: 32 | lr: 0.1 | Duration: 3.26s
[2m[36m(func pid=5776)[0m rmse: 0.18059270083904266
[2m[36m(func pid=5776)[0m mae:  0.13212990760803223
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.103, 0.193, 0.306, 0.152, 0.14, 0.122]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.3390 | Steps: 2 | Val loss: 0.3035 | Batch size: 32 | lr: 0.001 | Duration: 3.04s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.2691 | Steps: 2 | Val loss: 0.3027 | Batch size: 32 | lr: 0.01 | Duration: 3.06s
[2m[36m(func pid=3873)[0m rmse: 0.20712360739707947
[2m[36m(func pid=3873)[0m mae:  0.14173153042793274
[2m[36m(func pid=3873)[0m rmse_per_class: [0.113, 0.276, 0.049, 0.381, 0.067, 0.232, 0.26, 0.278, 0.309, 0.105]
== Status ==
Current time: 2024-01-07 09:11:20 (running for 00:39:21.08)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.276 |  0.162 |                   46 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.396 |  0.207 |                   46 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.626 |  0.181 |                   37 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.342 |  0.167 |                   34 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=6501)[0m rmse: 0.16665540635585785
[2m[36m(func pid=6501)[0m mae:  0.11969355493783951
[2m[36m(func pid=6501)[0m rmse_per_class: [0.104, 0.263, 0.068, 0.317, 0.074, 0.188, 0.266, 0.133, 0.146, 0.108]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.6202 | Steps: 2 | Val loss: 0.4921 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=2617)[0m rmse: 0.16313186287879944
[2m[36m(func pid=2617)[0m mae:  0.09845848381519318
[2m[36m(func pid=2617)[0m rmse_per_class: [0.09, 0.23, 0.053, 0.324, 0.087, 0.188, 0.212, 0.151, 0.2, 0.097]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.3417 | Steps: 2 | Val loss: 21.1054 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=5776)[0m rmse: 0.18056824803352356
[2m[36m(func pid=5776)[0m mae:  0.13208292424678802
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.102, 0.193, 0.305, 0.152, 0.14, 0.122]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.3388 | Steps: 2 | Val loss: 0.3031 | Batch size: 32 | lr: 0.001 | Duration: 3.08s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.2701 | Steps: 2 | Val loss: 0.3049 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
== Status ==
Current time: 2024-01-07 09:11:25 (running for 00:39:26.30)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.269 |  0.163 |                   47 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.342 |  0.236 |                   47 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.62  |  0.181 |                   38 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.339 |  0.167 |                   35 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=3873)[0m rmse: 0.23628024756908417
[2m[36m(func pid=3873)[0m mae:  0.15444596111774445
[2m[36m(func pid=3873)[0m rmse_per_class: [0.116, 0.367, 0.062, 0.382, 0.076, 0.228, 0.341, 0.544, 0.14, 0.107]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.6118 | Steps: 2 | Val loss: 0.4875 | Batch size: 32 | lr: 0.0001 | Duration: 3.03s
[2m[36m(func pid=6501)[0m rmse: 0.16651961207389832
[2m[36m(func pid=6501)[0m mae:  0.11955718696117401
[2m[36m(func pid=6501)[0m rmse_per_class: [0.105, 0.263, 0.067, 0.317, 0.074, 0.187, 0.266, 0.133, 0.146, 0.108]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=2617)[0m rmse: 0.16365981101989746
[2m[36m(func pid=2617)[0m mae:  0.09895658493041992
[2m[36m(func pid=2617)[0m rmse_per_class: [0.092, 0.233, 0.055, 0.325, 0.087, 0.185, 0.212, 0.149, 0.201, 0.098]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.3834 | Steps: 2 | Val loss: 6.6935 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=5776)[0m rmse: 0.1806185245513916
[2m[36m(func pid=5776)[0m mae:  0.13210242986679077
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.102, 0.194, 0.305, 0.152, 0.14, 0.122]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.3369 | Steps: 2 | Val loss: 0.3026 | Batch size: 32 | lr: 0.001 | Duration: 3.08s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.2633 | Steps: 2 | Val loss: 0.3074 | Batch size: 32 | lr: 0.01 | Duration: 3.06s
[2m[36m(func pid=3873)[0m rmse: 0.23715731501579285
[2m[36m(func pid=3873)[0m mae:  0.1495644748210907
[2m[36m(func pid=3873)[0m rmse_per_class: [0.12, 0.653, 0.087, 0.438, 0.072, 0.223, 0.347, 0.156, 0.14, 0.136]
[2m[36m(func pid=3873)[0m 
== Status ==
Current time: 2024-01-07 09:11:30 (running for 00:39:31.62)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.27  |  0.164 |                   48 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.383 |  0.237 |                   48 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.612 |  0.181 |                   39 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.339 |  0.167 |                   36 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.6061 | Steps: 2 | Val loss: 0.4823 | Batch size: 32 | lr: 0.0001 | Duration: 3.17s
[2m[36m(func pid=6501)[0m rmse: 0.16630955040454865
[2m[36m(func pid=6501)[0m mae:  0.11941389739513397
[2m[36m(func pid=6501)[0m rmse_per_class: [0.105, 0.262, 0.067, 0.316, 0.074, 0.187, 0.266, 0.132, 0.146, 0.108]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=2617)[0m rmse: 0.16426678001880646
[2m[36m(func pid=2617)[0m mae:  0.09937890619039536
[2m[36m(func pid=2617)[0m rmse_per_class: [0.097, 0.236, 0.058, 0.324, 0.087, 0.178, 0.213, 0.147, 0.199, 0.104]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.4031 | Steps: 2 | Val loss: 3.1639 | Batch size: 32 | lr: 0.1 | Duration: 3.05s
[2m[36m(func pid=5776)[0m rmse: 0.18061664700508118
[2m[36m(func pid=5776)[0m mae:  0.1320945769548416
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.103, 0.193, 0.305, 0.152, 0.14, 0.122]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.3299 | Steps: 2 | Val loss: 0.3020 | Batch size: 32 | lr: 0.001 | Duration: 3.07s
== Status ==
Current time: 2024-01-07 09:11:36 (running for 00:39:37.19)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.263 |  0.164 |                   49 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.403 |  0.242 |                   49 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.606 |  0.181 |                   40 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.337 |  0.166 |                   37 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.2637 | Steps: 2 | Val loss: 0.3106 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=3873)[0m rmse: 0.24201902747154236
[2m[36m(func pid=3873)[0m mae:  0.1474578082561493
[2m[36m(func pid=3873)[0m rmse_per_class: [0.131, 0.589, 0.135, 0.417, 0.07, 0.22, 0.344, 0.156, 0.14, 0.22]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=6501)[0m rmse: 0.16598093509674072
[2m[36m(func pid=6501)[0m mae:  0.11914285272359848
[2m[36m(func pid=6501)[0m rmse_per_class: [0.105, 0.262, 0.066, 0.315, 0.073, 0.187, 0.265, 0.132, 0.146, 0.108]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.6005 | Steps: 2 | Val loss: 0.4773 | Batch size: 32 | lr: 0.0001 | Duration: 3.15s
[2m[36m(func pid=2617)[0m rmse: 0.16501082479953766
[2m[36m(func pid=2617)[0m mae:  0.09980180114507675
[2m[36m(func pid=2617)[0m rmse_per_class: [0.107, 0.238, 0.061, 0.325, 0.086, 0.171, 0.212, 0.145, 0.195, 0.111]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.3408 | Steps: 2 | Val loss: 1.4850 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=5776)[0m rmse: 0.18054541945457458
[2m[36m(func pid=5776)[0m mae:  0.13203305006027222
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.103, 0.193, 0.305, 0.151, 0.14, 0.122]
[2m[36m(func pid=5776)[0m 
== Status ==
Current time: 2024-01-07 09:11:41 (running for 00:39:42.50)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.264 |  0.165 |                   50 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.341 |  0.249 |                   50 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.6   |  0.181 |                   41 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.33  |  0.166 |                   38 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=3873)[0m rmse: 0.2488098442554474
[2m[36m(func pid=3873)[0m mae:  0.14764095842838287
[2m[36m(func pid=3873)[0m rmse_per_class: [0.19, 0.256, 0.176, 0.379, 0.061, 0.216, 0.337, 0.153, 0.447, 0.273]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.3399 | Steps: 2 | Val loss: 0.3009 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.2608 | Steps: 2 | Val loss: 0.3161 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.5924 | Steps: 2 | Val loss: 0.4720 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=6501)[0m rmse: 0.16544470191001892
[2m[36m(func pid=6501)[0m mae:  0.11869361251592636
[2m[36m(func pid=6501)[0m rmse_per_class: [0.104, 0.261, 0.065, 0.314, 0.072, 0.187, 0.265, 0.132, 0.146, 0.108]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=2617)[0m rmse: 0.16665683686733246
[2m[36m(func pid=2617)[0m mae:  0.10089210420846939
[2m[36m(func pid=2617)[0m rmse_per_class: [0.119, 0.24, 0.064, 0.328, 0.084, 0.166, 0.21, 0.144, 0.2, 0.111]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.3845 | Steps: 2 | Val loss: 1.4256 | Batch size: 32 | lr: 0.1 | Duration: 3.05s
== Status ==
Current time: 2024-01-07 09:11:46 (running for 00:39:47.65)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.261 |  0.167 |                   51 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.341 |  0.249 |                   50 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.592 |  0.18  |                   42 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.34  |  0.165 |                   39 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=5776)[0m rmse: 0.18035933375358582
[2m[36m(func pid=5776)[0m mae:  0.1318671852350235
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.102, 0.193, 0.305, 0.151, 0.14, 0.122]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=3873)[0m rmse: 0.24654242396354675
[2m[36m(func pid=3873)[0m mae:  0.14782463014125824
[2m[36m(func pid=3873)[0m rmse_per_class: [0.252, 0.249, 0.197, 0.364, 0.056, 0.214, 0.331, 0.153, 0.372, 0.278]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.2658 | Steps: 2 | Val loss: 0.3230 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.3328 | Steps: 2 | Val loss: 0.3004 | Batch size: 32 | lr: 0.001 | Duration: 3.12s
[2m[36m(func pid=2617)[0m rmse: 0.1687471717596054
[2m[36m(func pid=2617)[0m mae:  0.10204263776540756
[2m[36m(func pid=2617)[0m rmse_per_class: [0.13, 0.241, 0.064, 0.333, 0.084, 0.165, 0.207, 0.145, 0.206, 0.112]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.5861 | Steps: 2 | Val loss: 0.4672 | Batch size: 32 | lr: 0.0001 | Duration: 3.07s
[2m[36m(func pid=6501)[0m rmse: 0.16517287492752075
[2m[36m(func pid=6501)[0m mae:  0.1184697151184082
[2m[36m(func pid=6501)[0m rmse_per_class: [0.104, 0.261, 0.065, 0.313, 0.072, 0.187, 0.265, 0.132, 0.146, 0.107]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.3944 | Steps: 2 | Val loss: 0.7079 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
== Status ==
Current time: 2024-01-07 09:11:52 (running for 00:39:53.14)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.266 |  0.169 |                   52 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.385 |  0.247 |                   51 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.586 |  0.18  |                   43 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.333 |  0.165 |                   40 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=5776)[0m rmse: 0.1802646815776825
[2m[36m(func pid=5776)[0m mae:  0.1317880004644394
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.102, 0.193, 0.304, 0.15, 0.14, 0.121]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=3873)[0m rmse: 0.2384941130876541
[2m[36m(func pid=3873)[0m mae:  0.14822569489479065
[2m[36m(func pid=3873)[0m rmse_per_class: [0.31, 0.245, 0.221, 0.372, 0.059, 0.241, 0.336, 0.156, 0.137, 0.309]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.2643 | Steps: 2 | Val loss: 0.3269 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.3247 | Steps: 2 | Val loss: 0.3002 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.5839 | Steps: 2 | Val loss: 0.4628 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=2617)[0m rmse: 0.16925445199012756
[2m[36m(func pid=2617)[0m mae:  0.10210305452346802
[2m[36m(func pid=2617)[0m rmse_per_class: [0.137, 0.242, 0.06, 0.332, 0.081, 0.165, 0.205, 0.149, 0.207, 0.114]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.4774 | Steps: 2 | Val loss: 0.6403 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=6501)[0m rmse: 0.16505227982997894
[2m[36m(func pid=6501)[0m mae:  0.11836475133895874
[2m[36m(func pid=6501)[0m rmse_per_class: [0.104, 0.261, 0.064, 0.313, 0.072, 0.186, 0.265, 0.132, 0.147, 0.107]
[2m[36m(func pid=6501)[0m 
== Status ==
Current time: 2024-01-07 09:11:57 (running for 00:39:58.63)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.264 |  0.169 |                   53 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.394 |  0.238 |                   52 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.584 |  0.18  |                   44 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.325 |  0.165 |                   41 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=5776)[0m rmse: 0.18010680377483368
[2m[36m(func pid=5776)[0m mae:  0.13166622817516327
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.102, 0.193, 0.304, 0.15, 0.14, 0.121]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=3873)[0m rmse: 0.24178512394428253
[2m[36m(func pid=3873)[0m mae:  0.15155598521232605
[2m[36m(func pid=3873)[0m rmse_per_class: [0.229, 0.243, 0.146, 0.385, 0.087, 0.256, 0.315, 0.185, 0.14, 0.432]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.3225 | Steps: 2 | Val loss: 0.2998 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.2588 | Steps: 2 | Val loss: 0.3300 | Batch size: 32 | lr: 0.01 | Duration: 3.13s
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.4668 | Steps: 2 | Val loss: 1.0557 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.5759 | Steps: 2 | Val loss: 0.4585 | Batch size: 32 | lr: 0.0001 | Duration: 3.09s
[2m[36m(func pid=6501)[0m rmse: 0.16480912268161774
[2m[36m(func pid=6501)[0m mae:  0.11816011369228363
[2m[36m(func pid=6501)[0m rmse_per_class: [0.104, 0.261, 0.064, 0.313, 0.072, 0.186, 0.264, 0.131, 0.147, 0.106]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=2617)[0m rmse: 0.1688920259475708
[2m[36m(func pid=2617)[0m mae:  0.10191600024700165
[2m[36m(func pid=2617)[0m rmse_per_class: [0.144, 0.243, 0.056, 0.331, 0.081, 0.165, 0.204, 0.147, 0.205, 0.113]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=3873)[0m rmse: 0.2454342395067215
[2m[36m(func pid=3873)[0m mae:  0.1599748134613037
[2m[36m(func pid=3873)[0m rmse_per_class: [0.113, 0.264, 0.049, 0.389, 0.101, 0.232, 0.336, 0.358, 0.14, 0.472]
[2m[36m(func pid=3873)[0m 
== Status ==
Current time: 2024-01-07 09:12:03 (running for 00:40:04.14)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.259 |  0.169 |                   54 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.467 |  0.245 |                   54 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.584 |  0.18  |                   44 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.323 |  0.165 |                   42 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=5776)[0m rmse: 0.18002305924892426
[2m[36m(func pid=5776)[0m mae:  0.13158893585205078
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.101, 0.193, 0.304, 0.151, 0.14, 0.121]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.3292 | Steps: 2 | Val loss: 0.2994 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.2578 | Steps: 2 | Val loss: 0.3341 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.4575 | Steps: 2 | Val loss: 1.9740 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.5696 | Steps: 2 | Val loss: 0.4538 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=6501)[0m rmse: 0.16462239623069763
[2m[36m(func pid=6501)[0m mae:  0.11799652874469757
[2m[36m(func pid=6501)[0m rmse_per_class: [0.103, 0.26, 0.064, 0.313, 0.071, 0.186, 0.264, 0.131, 0.148, 0.106]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=2617)[0m rmse: 0.16939762234687805
[2m[36m(func pid=2617)[0m mae:  0.1021539568901062
[2m[36m(func pid=2617)[0m rmse_per_class: [0.147, 0.246, 0.053, 0.328, 0.08, 0.166, 0.205, 0.145, 0.207, 0.118]
[2m[36m(func pid=2617)[0m 
== Status ==
Current time: 2024-01-07 09:12:08 (running for 00:40:09.42)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.258 |  0.169 |                   55 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.458 |  0.258 |                   55 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.576 |  0.18  |                   45 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.329 |  0.165 |                   43 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=3873)[0m rmse: 0.25828754901885986
[2m[36m(func pid=3873)[0m mae:  0.1736505776643753
[2m[36m(func pid=3873)[0m rmse_per_class: [0.113, 0.272, 0.049, 0.389, 0.091, 0.234, 0.367, 0.379, 0.14, 0.549]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=5776)[0m rmse: 0.18002314865589142
[2m[36m(func pid=5776)[0m mae:  0.13158002495765686
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.101, 0.193, 0.304, 0.15, 0.14, 0.121]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.3294 | Steps: 2 | Val loss: 0.2992 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.2612 | Steps: 2 | Val loss: 0.3390 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.4184 | Steps: 2 | Val loss: 2.7432 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.5656 | Steps: 2 | Val loss: 0.4506 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
[2m[36m(func pid=6501)[0m rmse: 0.16451044380664825
[2m[36m(func pid=6501)[0m mae:  0.11792145669460297
[2m[36m(func pid=6501)[0m rmse_per_class: [0.103, 0.26, 0.064, 0.313, 0.071, 0.186, 0.264, 0.131, 0.147, 0.106]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=2617)[0m rmse: 0.16891932487487793
[2m[36m(func pid=2617)[0m mae:  0.10207406431436539
[2m[36m(func pid=2617)[0m rmse_per_class: [0.146, 0.248, 0.05, 0.326, 0.077, 0.167, 0.205, 0.143, 0.211, 0.116]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=3873)[0m rmse: 0.2653244435787201
[2m[36m(func pid=3873)[0m mae:  0.18029561638832092
[2m[36m(func pid=3873)[0m rmse_per_class: [0.114, 0.274, 0.049, 0.389, 0.078, 0.234, 0.372, 0.369, 0.14, 0.636]
[2m[36m(func pid=3873)[0m 
== Status ==
Current time: 2024-01-07 09:12:14 (running for 00:40:14.94)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.261 |  0.169 |                   56 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.418 |  0.265 |                   56 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.57  |  0.18  |                   46 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.329 |  0.165 |                   44 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=5776)[0m rmse: 0.1800239086151123
[2m[36m(func pid=5776)[0m mae:  0.13157692551612854
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.101, 0.193, 0.304, 0.15, 0.14, 0.121]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.3202 | Steps: 2 | Val loss: 0.2987 | Batch size: 32 | lr: 0.001 | Duration: 3.18s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.2595 | Steps: 2 | Val loss: 0.3454 | Batch size: 32 | lr: 0.01 | Duration: 3.08s
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.4243 | Steps: 2 | Val loss: 3.5444 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.5616 | Steps: 2 | Val loss: 0.4468 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=6501)[0m rmse: 0.16425202786922455
[2m[36m(func pid=6501)[0m mae:  0.11769412457942963
[2m[36m(func pid=6501)[0m rmse_per_class: [0.102, 0.26, 0.063, 0.312, 0.071, 0.185, 0.264, 0.131, 0.148, 0.106]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=2617)[0m rmse: 0.16859404742717743
[2m[36m(func pid=2617)[0m mae:  0.10183177143335342
[2m[36m(func pid=2617)[0m rmse_per_class: [0.145, 0.25, 0.049, 0.322, 0.075, 0.168, 0.205, 0.141, 0.221, 0.11]
[2m[36m(func pid=2617)[0m 
== Status ==
Current time: 2024-01-07 09:12:19 (running for 00:40:20.18)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.259 |  0.169 |                   57 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.424 |  0.27  |                   57 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.566 |  0.18  |                   47 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.32  |  0.164 |                   45 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=3873)[0m rmse: 0.2704452574253082
[2m[36m(func pid=3873)[0m mae:  0.18526729941368103
[2m[36m(func pid=3873)[0m rmse_per_class: [0.112, 0.273, 0.049, 0.389, 0.067, 0.234, 0.368, 0.329, 0.14, 0.744]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=5776)[0m rmse: 0.1800859570503235
[2m[36m(func pid=5776)[0m mae:  0.1316128522157669
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.101, 0.193, 0.303, 0.15, 0.14, 0.121]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.2502 | Steps: 2 | Val loss: 0.3472 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.3197 | Steps: 2 | Val loss: 0.2985 | Batch size: 32 | lr: 0.001 | Duration: 3.24s
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.3165 | Steps: 2 | Val loss: 3.6715 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.5579 | Steps: 2 | Val loss: 0.4431 | Batch size: 32 | lr: 0.0001 | Duration: 3.08s
[2m[36m(func pid=2617)[0m rmse: 0.16752851009368896
[2m[36m(func pid=2617)[0m mae:  0.10120916366577148
[2m[36m(func pid=2617)[0m rmse_per_class: [0.143, 0.25, 0.049, 0.32, 0.075, 0.168, 0.204, 0.139, 0.224, 0.103]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=6501)[0m rmse: 0.16416803002357483
[2m[36m(func pid=6501)[0m mae:  0.11762219667434692
[2m[36m(func pid=6501)[0m rmse_per_class: [0.103, 0.26, 0.063, 0.312, 0.071, 0.185, 0.264, 0.131, 0.148, 0.106]
[2m[36m(func pid=6501)[0m 
== Status ==
Current time: 2024-01-07 09:12:24 (running for 00:40:25.60)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.25  |  0.168 |                   58 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.317 |  0.271 |                   58 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.562 |  0.18  |                   48 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.32  |  0.164 |                   46 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=3873)[0m rmse: 0.2705286741256714
[2m[36m(func pid=3873)[0m mae:  0.1859818696975708
[2m[36m(func pid=3873)[0m rmse_per_class: [0.112, 0.268, 0.049, 0.388, 0.072, 0.234, 0.364, 0.266, 0.14, 0.812]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=5776)[0m rmse: 0.18009579181671143
[2m[36m(func pid=5776)[0m mae:  0.1315995454788208
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.101, 0.193, 0.303, 0.15, 0.14, 0.122]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.2558 | Steps: 2 | Val loss: 0.3510 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.3225 | Steps: 2 | Val loss: 0.2978 | Batch size: 32 | lr: 0.001 | Duration: 3.11s
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.3194 | Steps: 2 | Val loss: 3.5325 | Batch size: 32 | lr: 0.1 | Duration: 3.02s
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.5507 | Steps: 2 | Val loss: 0.4400 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=2617)[0m rmse: 0.16677381098270416
[2m[36m(func pid=2617)[0m mae:  0.1006421223282814
[2m[36m(func pid=2617)[0m rmse_per_class: [0.136, 0.253, 0.049, 0.318, 0.075, 0.167, 0.204, 0.136, 0.233, 0.097]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=6501)[0m rmse: 0.16377827525138855
[2m[36m(func pid=6501)[0m mae:  0.11729004234075546
[2m[36m(func pid=6501)[0m rmse_per_class: [0.102, 0.259, 0.062, 0.311, 0.071, 0.185, 0.263, 0.131, 0.147, 0.106]
[2m[36m(func pid=6501)[0m 
== Status ==
Current time: 2024-01-07 09:12:30 (running for 00:40:31.11)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.256 |  0.167 |                   59 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.319 |  0.267 |                   59 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.558 |  0.18  |                   49 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.323 |  0.164 |                   47 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=3873)[0m rmse: 0.26746609807014465
[2m[36m(func pid=3873)[0m mae:  0.18533480167388916
[2m[36m(func pid=3873)[0m rmse_per_class: [0.111, 0.264, 0.049, 0.386, 0.075, 0.234, 0.36, 0.189, 0.14, 0.866]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=5776)[0m rmse: 0.18000440299510956
[2m[36m(func pid=5776)[0m mae:  0.13150069117546082
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.101, 0.193, 0.303, 0.15, 0.14, 0.122]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.2592 | Steps: 2 | Val loss: 0.3577 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.3222 | Steps: 2 | Val loss: 0.2977 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.3314 | Steps: 2 | Val loss: 3.0561 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.5470 | Steps: 2 | Val loss: 0.4362 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=6501)[0m rmse: 0.16370056569576263
[2m[36m(func pid=6501)[0m mae:  0.11719801276922226
[2m[36m(func pid=6501)[0m rmse_per_class: [0.101, 0.26, 0.062, 0.311, 0.071, 0.185, 0.263, 0.131, 0.148, 0.106]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=2617)[0m rmse: 0.166703999042511
[2m[36m(func pid=2617)[0m mae:  0.10050375759601593
[2m[36m(func pid=2617)[0m rmse_per_class: [0.129, 0.255, 0.049, 0.317, 0.074, 0.165, 0.204, 0.134, 0.246, 0.093]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=3873)[0m rmse: 0.2654786705970764
[2m[36m(func pid=3873)[0m mae:  0.18311911821365356
[2m[36m(func pid=3873)[0m rmse_per_class: [0.111, 0.266, 0.049, 0.384, 0.072, 0.234, 0.356, 0.165, 0.141, 0.876]
[2m[36m(func pid=3873)[0m 
== Status ==
Current time: 2024-01-07 09:12:35 (running for 00:40:36.56)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.259 |  0.167 |                   60 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.331 |  0.265 |                   60 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.551 |  0.18  |                   50 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.322 |  0.164 |                   48 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=5776)[0m rmse: 0.17992694675922394
[2m[36m(func pid=5776)[0m mae:  0.13145007193088531
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.101, 0.193, 0.303, 0.15, 0.14, 0.121]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.3223 | Steps: 2 | Val loss: 0.2977 | Batch size: 32 | lr: 0.001 | Duration: 3.03s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.2456 | Steps: 2 | Val loss: 0.3583 | Batch size: 32 | lr: 0.01 | Duration: 3.05s
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.3251 | Steps: 2 | Val loss: 2.4873 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.5452 | Steps: 2 | Val loss: 0.4333 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=6501)[0m rmse: 0.16363805532455444
[2m[36m(func pid=6501)[0m mae:  0.11710250377655029
[2m[36m(func pid=6501)[0m rmse_per_class: [0.101, 0.26, 0.062, 0.311, 0.07, 0.185, 0.262, 0.131, 0.148, 0.106]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=2617)[0m rmse: 0.16602551937103271
[2m[36m(func pid=2617)[0m mae:  0.10026933252811432
[2m[36m(func pid=2617)[0m rmse_per_class: [0.124, 0.256, 0.049, 0.317, 0.075, 0.162, 0.206, 0.132, 0.25, 0.089]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=3873)[0m rmse: 0.26276522874832153
[2m[36m(func pid=3873)[0m mae:  0.17871105670928955
[2m[36m(func pid=3873)[0m rmse_per_class: [0.111, 0.272, 0.049, 0.386, 0.064, 0.233, 0.353, 0.163, 0.141, 0.857]
== Status ==
Current time: 2024-01-07 09:12:40 (running for 00:40:41.77)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.246 |  0.166 |                   61 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.325 |  0.263 |                   61 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.547 |  0.18  |                   51 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.322 |  0.164 |                   49 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=5776)[0m rmse: 0.17990240454673767
[2m[36m(func pid=5776)[0m mae:  0.13140499591827393
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.101, 0.193, 0.302, 0.149, 0.14, 0.121]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.3170 | Steps: 2 | Val loss: 0.2974 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.2583 | Steps: 2 | Val loss: 0.3626 | Batch size: 32 | lr: 0.01 | Duration: 3.06s
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.6865 | Steps: 2 | Val loss: 1.8945 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.5376 | Steps: 2 | Val loss: 0.4301 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
[2m[36m(func pid=6501)[0m rmse: 0.16351616382598877
[2m[36m(func pid=6501)[0m mae:  0.11698968708515167
[2m[36m(func pid=6501)[0m rmse_per_class: [0.101, 0.259, 0.062, 0.311, 0.07, 0.185, 0.262, 0.131, 0.148, 0.107]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=2617)[0m rmse: 0.16572065651416779
[2m[36m(func pid=2617)[0m mae:  0.09978792816400528
[2m[36m(func pid=2617)[0m rmse_per_class: [0.114, 0.259, 0.048, 0.317, 0.075, 0.16, 0.207, 0.132, 0.26, 0.086]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=3873)[0m rmse: 0.25274404883384705
[2m[36m(func pid=3873)[0m mae:  0.1659267693758011
[2m[36m(func pid=3873)[0m rmse_per_class: [0.111, 0.255, 0.049, 0.351, 0.083, 0.231, 0.351, 0.176, 0.14, 0.781]
[2m[36m(func pid=3873)[0m 
== Status ==
Current time: 2024-01-07 09:12:46 (running for 00:40:47.10)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.258 |  0.166 |                   62 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.687 |  0.253 |                   62 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.545 |  0.18  |                   52 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.317 |  0.164 |                   50 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=5776)[0m rmse: 0.17978236079216003
[2m[36m(func pid=5776)[0m mae:  0.13129374384880066
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.101, 0.193, 0.302, 0.149, 0.14, 0.121]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.3092 | Steps: 2 | Val loss: 0.2969 | Batch size: 32 | lr: 0.001 | Duration: 3.06s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.2553 | Steps: 2 | Val loss: 0.3573 | Batch size: 32 | lr: 0.01 | Duration: 3.03s
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.3244 | Steps: 2 | Val loss: 1.5566 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.5347 | Steps: 2 | Val loss: 0.4273 | Batch size: 32 | lr: 0.0001 | Duration: 3.14s
[2m[36m(func pid=6501)[0m rmse: 0.16326236724853516
[2m[36m(func pid=6501)[0m mae:  0.11676684767007828
[2m[36m(func pid=6501)[0m rmse_per_class: [0.101, 0.259, 0.061, 0.311, 0.07, 0.185, 0.262, 0.13, 0.147, 0.106]
[2m[36m(func pid=6501)[0m 
== Status ==
Current time: 2024-01-07 09:12:51 (running for 00:40:52.20)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.255 |  0.164 |                   63 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.687 |  0.253 |                   62 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.538 |  0.18  |                   53 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.309 |  0.163 |                   51 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=2617)[0m rmse: 0.16408364474773407
[2m[36m(func pid=2617)[0m mae:  0.09867404401302338
[2m[36m(func pid=2617)[0m rmse_per_class: [0.107, 0.259, 0.047, 0.314, 0.077, 0.157, 0.209, 0.129, 0.256, 0.085]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=3873)[0m rmse: 0.25116652250289917
[2m[36m(func pid=3873)[0m mae:  0.15903893113136292
[2m[36m(func pid=3873)[0m rmse_per_class: [0.123, 0.256, 0.049, 0.328, 0.114, 0.229, 0.355, 0.213, 0.149, 0.696]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=5776)[0m rmse: 0.17969471216201782
[2m[36m(func pid=5776)[0m mae:  0.13121704757213593
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.1, 0.193, 0.302, 0.149, 0.14, 0.121]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.3130 | Steps: 2 | Val loss: 0.2968 | Batch size: 32 | lr: 0.001 | Duration: 3.15s
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.3332 | Steps: 2 | Val loss: 1.2396 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.2441 | Steps: 2 | Val loss: 0.3528 | Batch size: 32 | lr: 0.01 | Duration: 3.19s
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.5318 | Steps: 2 | Val loss: 0.4239 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
== Status ==
Current time: 2024-01-07 09:12:56 (running for 00:40:57.35)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.255 |  0.164 |                   63 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.324 |  0.251 |                   63 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.535 |  0.18  |                   54 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.313 |  0.163 |                   52 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=6501)[0m rmse: 0.1631782352924347
[2m[36m(func pid=6501)[0m mae:  0.11668536812067032
[2m[36m(func pid=6501)[0m rmse_per_class: [0.102, 0.259, 0.061, 0.31, 0.07, 0.184, 0.262, 0.13, 0.147, 0.107]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=3873)[0m rmse: 0.24605783820152283
[2m[36m(func pid=3873)[0m mae:  0.15218167006969452
[2m[36m(func pid=3873)[0m rmse_per_class: [0.114, 0.263, 0.049, 0.332, 0.082, 0.228, 0.359, 0.243, 0.178, 0.613]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=2617)[0m rmse: 0.1632107049226761
[2m[36m(func pid=2617)[0m mae:  0.09827669709920883
[2m[36m(func pid=2617)[0m rmse_per_class: [0.105, 0.257, 0.047, 0.315, 0.079, 0.155, 0.211, 0.127, 0.252, 0.085]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=5776)[0m rmse: 0.1796199530363083
[2m[36m(func pid=5776)[0m mae:  0.13115175068378448
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.1, 0.193, 0.302, 0.149, 0.14, 0.121]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.3165 | Steps: 2 | Val loss: 0.2963 | Batch size: 32 | lr: 0.001 | Duration: 3.06s
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.3777 | Steps: 2 | Val loss: 1.6968 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.2595 | Steps: 2 | Val loss: 0.3513 | Batch size: 32 | lr: 0.01 | Duration: 3.10s
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.5276 | Steps: 2 | Val loss: 0.4208 | Batch size: 32 | lr: 0.0001 | Duration: 3.04s
== Status ==
Current time: 2024-01-07 09:13:01 (running for 00:41:02.85)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.244 |  0.163 |                   64 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.378 |  0.251 |                   65 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.532 |  0.18  |                   55 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.313 |  0.163 |                   52 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=3873)[0m rmse: 0.2508372664451599
[2m[36m(func pid=3873)[0m mae:  0.14895209670066833
[2m[36m(func pid=3873)[0m rmse_per_class: [0.121, 0.27, 0.049, 0.354, 0.057, 0.226, 0.354, 0.237, 0.335, 0.504]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=6501)[0m rmse: 0.1629123091697693
[2m[36m(func pid=6501)[0m mae:  0.11643383651971817
[2m[36m(func pid=6501)[0m rmse_per_class: [0.101, 0.259, 0.06, 0.31, 0.07, 0.184, 0.261, 0.13, 0.147, 0.107]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=2617)[0m rmse: 0.1628803312778473
[2m[36m(func pid=2617)[0m mae:  0.09824413061141968
[2m[36m(func pid=2617)[0m rmse_per_class: [0.103, 0.256, 0.046, 0.316, 0.082, 0.153, 0.214, 0.123, 0.249, 0.085]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=5776)[0m rmse: 0.1795986145734787
[2m[36m(func pid=5776)[0m mae:  0.1311245709657669
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.1, 0.193, 0.301, 0.149, 0.14, 0.121]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.3471 | Steps: 2 | Val loss: 2.7048 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.3071 | Steps: 2 | Val loss: 0.2958 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.2460 | Steps: 2 | Val loss: 0.3478 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.5269 | Steps: 2 | Val loss: 0.4183 | Batch size: 32 | lr: 0.0001 | Duration: 3.13s
== Status ==
Current time: 2024-01-07 09:13:07 (running for 00:41:08.08)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.26  |  0.163 |                   65 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.347 |  0.238 |                   66 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.528 |  0.18  |                   56 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.316 |  0.163 |                   53 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=3873)[0m rmse: 0.23841893672943115
[2m[36m(func pid=3873)[0m mae:  0.13726234436035156
[2m[36m(func pid=3873)[0m rmse_per_class: [0.154, 0.272, 0.049, 0.362, 0.056, 0.225, 0.417, 0.223, 0.474, 0.153]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=6501)[0m rmse: 0.16263775527477264
[2m[36m(func pid=6501)[0m mae:  0.11619488894939423
[2m[36m(func pid=6501)[0m rmse_per_class: [0.101, 0.259, 0.059, 0.309, 0.07, 0.184, 0.262, 0.13, 0.147, 0.106]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=2617)[0m rmse: 0.16298571228981018
[2m[36m(func pid=2617)[0m mae:  0.09869621694087982
[2m[36m(func pid=2617)[0m rmse_per_class: [0.103, 0.255, 0.045, 0.321, 0.085, 0.153, 0.218, 0.121, 0.245, 0.085]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=5776)[0m rmse: 0.17966501414775848
[2m[36m(func pid=5776)[0m mae:  0.13115713000297546
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.326, 0.1, 0.193, 0.301, 0.149, 0.141, 0.12]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.3263 | Steps: 2 | Val loss: 3.3157 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.3077 | Steps: 2 | Val loss: 0.2956 | Batch size: 32 | lr: 0.001 | Duration: 3.09s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.2540 | Steps: 2 | Val loss: 0.3436 | Batch size: 32 | lr: 0.01 | Duration: 3.14s
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.5155 | Steps: 2 | Val loss: 0.4153 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
== Status ==
Current time: 2024-01-07 09:13:12 (running for 00:41:13.33)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.246 |  0.163 |                   66 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.326 |  0.246 |                   67 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.527 |  0.18  |                   57 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.307 |  0.163 |                   54 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=3873)[0m rmse: 0.24592295289039612
[2m[36m(func pid=3873)[0m mae:  0.1419222354888916
[2m[36m(func pid=3873)[0m rmse_per_class: [0.199, 0.279, 0.049, 0.358, 0.057, 0.225, 0.435, 0.213, 0.506, 0.138]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=6501)[0m rmse: 0.16247984766960144
[2m[36m(func pid=6501)[0m mae:  0.1160583347082138
[2m[36m(func pid=6501)[0m rmse_per_class: [0.101, 0.258, 0.059, 0.308, 0.07, 0.184, 0.262, 0.13, 0.147, 0.106]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=2617)[0m rmse: 0.16333791613578796
[2m[36m(func pid=2617)[0m mae:  0.09935635328292847
[2m[36m(func pid=2617)[0m rmse_per_class: [0.103, 0.253, 0.046, 0.325, 0.089, 0.153, 0.222, 0.118, 0.237, 0.086]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=5776)[0m rmse: 0.17968246340751648
[2m[36m(func pid=5776)[0m mae:  0.13114044070243835
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.326, 0.101, 0.193, 0.301, 0.148, 0.141, 0.12]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.3397 | Steps: 2 | Val loss: 2.8526 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.3093 | Steps: 2 | Val loss: 0.2955 | Batch size: 32 | lr: 0.001 | Duration: 3.05s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.2511 | Steps: 2 | Val loss: 0.3403 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.5144 | Steps: 2 | Val loss: 0.4129 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
== Status ==
Current time: 2024-01-07 09:13:17 (running for 00:41:18.70)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 ERROR, 2 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.254 |  0.163 |                   67 |
| train_d77f6_00019 | RUNNING    | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.515 |  0.18  |                   58 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.308 |  0.162 |                   55 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 1
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=3873)[0m rmse: 0.24741414189338684
[2m[36m(func pid=3873)[0m mae:  0.1405230164527893
[2m[36m(func pid=3873)[0m rmse_per_class: [0.281, 0.292, 0.049, 0.354, 0.057, 0.222, 0.439, 0.219, 0.439, 0.122]
[2m[36m(func pid=3873)[0m 
[2m[36m(func pid=6501)[0m rmse: 0.16244132816791534
[2m[36m(func pid=6501)[0m mae:  0.1160261407494545
[2m[36m(func pid=6501)[0m rmse_per_class: [0.101, 0.258, 0.059, 0.309, 0.07, 0.184, 0.261, 0.13, 0.147, 0.106]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=2617)[0m rmse: 0.16318412125110626
[2m[36m(func pid=2617)[0m mae:  0.09950586408376694
[2m[36m(func pid=2617)[0m rmse_per_class: [0.102, 0.248, 0.045, 0.328, 0.092, 0.154, 0.224, 0.117, 0.234, 0.086]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=5776)[0m rmse: 0.17959055304527283
[2m[36m(func pid=5776)[0m mae:  0.13104400038719177
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.101, 0.193, 0.301, 0.148, 0.141, 0.12]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=3873)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.3451 | Steps: 2 | Val loss: 3.0819 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.3101 | Steps: 2 | Val loss: 0.2951 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.2478 | Steps: 2 | Val loss: 0.3358 | Batch size: 32 | lr: 0.01 | Duration: 3.06s
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.5142 | Steps: 2 | Val loss: 0.4104 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
2024-01-07 09:13:23,065	ERROR trial_runner.py:1062 -- Trial train_d77f6_00019: Error processing event.
ray.exceptions.RayTaskError(ValueError): [36mray::ImplicitFunc.train()[39m (pid=3873, ip=192.168.7.53, repr=func)
  File "/home/ajsanchez/anaconda3/envs/ssl-bsu-conda/lib/python3.10/site-packages/ray/tune/trainable/trainable.py", line 368, in train
    raise skipped from exception_cause(skipped)
  File "/home/ajsanchez/anaconda3/envs/ssl-bsu-conda/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py", line 337, in entrypoint
    return self._trainable_func(
  File "/home/ajsanchez/anaconda3/envs/ssl-bsu-conda/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py", line 654, in _trainable_func
    output = fn()
  File "/home/ajsanchez/GitHub/ssl-bsu/trainer.py", line 447, in train
    acc_results = accuracy(self.model,
  File "/home/ajsanchez/GitHub/ssl-bsu/trainer.py", line 104, in accuracy
    rmse = mean_squared_error(y_true_cpu, y_pred_cpu, squared=False)
  File "/home/ajsanchez/anaconda3/envs/ssl-bsu-conda/lib/python3.10/site-packages/sklearn/metrics/_regression.py", line 442, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/ajsanchez/anaconda3/envs/ssl-bsu-conda/lib/python3.10/site-packages/sklearn/metrics/_regression.py", line 102, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/ajsanchez/anaconda3/envs/ssl-bsu-conda/lib/python3.10/site-packages/sklearn/utils/validation.py", line 919, in check_array
    _assert_all_finite(
  File "/home/ajsanchez/anaconda3/envs/ssl-bsu-conda/lib/python3.10/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.
== Status ==
Current time: 2024-01-07 09:13:23 (running for 00:41:23.96)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 PENDING, 3 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.251 |  0.163 |                   68 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.514 |  0.18  |                   59 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.309 |  0.162 |                   56 |
| train_d77f6_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=6501)[0m rmse: 0.16216500103473663
[2m[36m(func pid=6501)[0m mae:  0.11580011993646622
[2m[36m(func pid=6501)[0m rmse_per_class: [0.1, 0.258, 0.059, 0.308, 0.07, 0.184, 0.261, 0.129, 0.147, 0.105]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=2617)[0m rmse: 0.1634352207183838
[2m[36m(func pid=2617)[0m mae:  0.10005486011505127
[2m[36m(func pid=2617)[0m rmse_per_class: [0.102, 0.244, 0.046, 0.332, 0.095, 0.155, 0.226, 0.117, 0.228, 0.088]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=5776)[0m rmse: 0.17952154576778412
[2m[36m(func pid=5776)[0m mae:  0.13098837435245514
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.1, 0.193, 0.3, 0.148, 0.141, 0.12]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.3016 | Steps: 2 | Val loss: 0.2947 | Batch size: 32 | lr: 0.001 | Duration: 3.15s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.2463 | Steps: 2 | Val loss: 0.3345 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.5098 | Steps: 2 | Val loss: 0.4076 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=6501)[0m rmse: 0.16196107864379883
[2m[36m(func pid=6501)[0m mae:  0.11562631279230118
[2m[36m(func pid=6501)[0m rmse_per_class: [0.1, 0.257, 0.059, 0.308, 0.07, 0.183, 0.261, 0.129, 0.147, 0.106]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=2617)[0m rmse: 0.16400781273841858
[2m[36m(func pid=2617)[0m mae:  0.100611612200737
[2m[36m(func pid=2617)[0m rmse_per_class: [0.102, 0.24, 0.047, 0.334, 0.099, 0.155, 0.228, 0.119, 0.227, 0.09]
[2m[36m(func pid=5776)[0m rmse: 0.17944256961345673
[2m[36m(func pid=5776)[0m mae:  0.13091596961021423
[2m[36m(func pid=5776)[0m rmse_per_class: [0.108, 0.269, 0.09, 0.325, 0.1, 0.193, 0.3, 0.148, 0.141, 0.12]
== Status ==
Current time: 2024-01-07 09:13:29 (running for 00:41:30.33)
Memory usage on this node: 23.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 1 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.248 |  0.163 |                   69 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.514 |  0.18  |                   60 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.302 |  0.162 |                   58 |
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=19271)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=19271)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=19271)[0m Configuration completed!
[2m[36m(func pid=19271)[0m New optimizer parameters:
[2m[36m(func pid=19271)[0m SGD (
[2m[36m(func pid=19271)[0m Parameter Group 0
[2m[36m(func pid=19271)[0m     dampening: 0
[2m[36m(func pid=19271)[0m     differentiable: False
[2m[36m(func pid=19271)[0m     foreach: None
[2m[36m(func pid=19271)[0m     lr: 0.01
[2m[36m(func pid=19271)[0m     maximize: False
[2m[36m(func pid=19271)[0m     momentum: 0.9
[2m[36m(func pid=19271)[0m     nesterov: False
[2m[36m(func pid=19271)[0m     weight_decay: 1e-05
[2m[36m(func pid=19271)[0m )
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.2983 | Steps: 2 | Val loss: 0.2945 | Batch size: 32 | lr: 0.001 | Duration: 3.10s
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.5032 | Steps: 2 | Val loss: 0.4047 | Batch size: 32 | lr: 0.0001 | Duration: 3.01s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.2506 | Steps: 2 | Val loss: 0.3332 | Batch size: 32 | lr: 0.01 | Duration: 3.09s
== Status ==
Current time: 2024-01-07 09:13:35 (running for 00:41:35.98)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 1 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.246 |  0.164 |                   70 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.51  |  0.179 |                   61 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.298 |  0.162 |                   59 |
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=6501)[0m rmse: 0.1618061512708664
[2m[36m(func pid=6501)[0m mae:  0.1155082955956459
[2m[36m(func pid=6501)[0m rmse_per_class: [0.1, 0.257, 0.059, 0.308, 0.07, 0.183, 0.261, 0.129, 0.146, 0.106]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 1.0297 | Steps: 2 | Val loss: 0.6492 | Batch size: 32 | lr: 0.01 | Duration: 4.66s
[2m[36m(func pid=5776)[0m rmse: 0.17943266034126282
[2m[36m(func pid=5776)[0m mae:  0.13088317215442657
[2m[36m(func pid=5776)[0m rmse_per_class: [0.108, 0.269, 0.09, 0.325, 0.1, 0.193, 0.3, 0.148, 0.141, 0.121]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=2617)[0m rmse: 0.16448937356472015
[2m[36m(func pid=2617)[0m mae:  0.10099343955516815
[2m[36m(func pid=2617)[0m rmse_per_class: [0.102, 0.236, 0.047, 0.337, 0.101, 0.156, 0.228, 0.121, 0.224, 0.094]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.3040 | Steps: 2 | Val loss: 0.2939 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=19271)[0m rmse: 0.17789418995380402
[2m[36m(func pid=19271)[0m mae:  0.13038323819637299
[2m[36m(func pid=19271)[0m rmse_per_class: [0.104, 0.267, 0.085, 0.325, 0.097, 0.192, 0.301, 0.155, 0.139, 0.114]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.2447 | Steps: 2 | Val loss: 0.3289 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.5038 | Steps: 2 | Val loss: 0.4031 | Batch size: 32 | lr: 0.0001 | Duration: 3.07s
== Status ==
Current time: 2024-01-07 09:13:40 (running for 00:41:41.37)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 1 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.251 |  0.164 |                   71 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.503 |  0.179 |                   62 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.304 |  0.161 |                   60 |
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  1.03  |  0.178 |                    1 |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=6501)[0m rmse: 0.161464661359787
[2m[36m(func pid=6501)[0m mae:  0.11517582088708878
[2m[36m(func pid=6501)[0m rmse_per_class: [0.099, 0.257, 0.058, 0.307, 0.07, 0.183, 0.26, 0.129, 0.145, 0.106]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.7113 | Steps: 2 | Val loss: 0.4377 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
[2m[36m(func pid=2617)[0m rmse: 0.16440710425376892
[2m[36m(func pid=2617)[0m mae:  0.10126403719186783
[2m[36m(func pid=2617)[0m rmse_per_class: [0.104, 0.231, 0.046, 0.338, 0.104, 0.156, 0.228, 0.121, 0.217, 0.099]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=5776)[0m rmse: 0.179430291056633
[2m[36m(func pid=5776)[0m mae:  0.13088534772396088
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.1, 0.193, 0.3, 0.148, 0.141, 0.121]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.3059 | Steps: 2 | Val loss: 0.2938 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=19271)[0m rmse: 0.1768440157175064
[2m[36m(func pid=19271)[0m mae:  0.12922123074531555
[2m[36m(func pid=19271)[0m rmse_per_class: [0.104, 0.268, 0.087, 0.326, 0.092, 0.192, 0.294, 0.154, 0.141, 0.11]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.2478 | Steps: 2 | Val loss: 0.3259 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.4973 | Steps: 2 | Val loss: 0.4009 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
[2m[36m(func pid=6501)[0m rmse: 0.16138526797294617
[2m[36m(func pid=6501)[0m mae:  0.11510561406612396
[2m[36m(func pid=6501)[0m rmse_per_class: [0.099, 0.257, 0.058, 0.306, 0.071, 0.183, 0.26, 0.128, 0.146, 0.106]
== Status ==
Current time: 2024-01-07 09:13:46 (running for 00:41:46.93)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 1 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.245 |  0.164 |                   72 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.504 |  0.179 |                   63 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.306 |  0.161 |                   61 |
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.711 |  0.177 |                    2 |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
[2m[36m(func pid=6501)[0m 

[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.4611 | Steps: 2 | Val loss: 0.3343 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=2617)[0m rmse: 0.16432859003543854
[2m[36m(func pid=2617)[0m mae:  0.10133007913827896
[2m[36m(func pid=2617)[0m rmse_per_class: [0.108, 0.229, 0.046, 0.338, 0.105, 0.155, 0.227, 0.121, 0.212, 0.102]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=5776)[0m rmse: 0.1794411689043045
[2m[36m(func pid=5776)[0m mae:  0.13089218735694885
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.1, 0.193, 0.3, 0.148, 0.141, 0.121]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=19271)[0m rmse: 0.17491643130779266
[2m[36m(func pid=19271)[0m mae:  0.12728217244148254
[2m[36m(func pid=19271)[0m rmse_per_class: [0.105, 0.27, 0.091, 0.332, 0.087, 0.191, 0.281, 0.142, 0.145, 0.105]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.3036 | Steps: 2 | Val loss: 0.2933 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.2487 | Steps: 2 | Val loss: 0.3245 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.4947 | Steps: 2 | Val loss: 0.3983 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
== Status ==
Current time: 2024-01-07 09:13:51 (running for 00:41:52.47)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 1 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.248 |  0.164 |                   73 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.497 |  0.179 |                   64 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.304 |  0.161 |                   62 |
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.461 |  0.175 |                    3 |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=6501)[0m rmse: 0.16112786531448364
[2m[36m(func pid=6501)[0m mae:  0.11486055701971054
[2m[36m(func pid=6501)[0m rmse_per_class: [0.099, 0.256, 0.058, 0.306, 0.07, 0.183, 0.26, 0.128, 0.146, 0.106]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.3917 | Steps: 2 | Val loss: 0.3194 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=2617)[0m rmse: 0.16467538475990295
[2m[36m(func pid=2617)[0m mae:  0.10168321430683136
[2m[36m(func pid=2617)[0m rmse_per_class: [0.111, 0.227, 0.046, 0.339, 0.106, 0.155, 0.225, 0.12, 0.209, 0.109]
[2m[36m(func pid=2617)[0m 
[2m[36m(func pid=5776)[0m rmse: 0.17935825884342194
[2m[36m(func pid=5776)[0m mae:  0.13082142174243927
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.099, 0.193, 0.3, 0.147, 0.141, 0.121]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=19271)[0m rmse: 0.17238089442253113
[2m[36m(func pid=19271)[0m mae:  0.1243511214852333
[2m[36m(func pid=19271)[0m rmse_per_class: [0.107, 0.271, 0.091, 0.335, 0.08, 0.19, 0.268, 0.134, 0.15, 0.099]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.2963 | Steps: 2 | Val loss: 0.2930 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=2617)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.2435 | Steps: 2 | Val loss: 0.3228 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.4968 | Steps: 2 | Val loss: 0.3966 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
== Status ==
Current time: 2024-01-07 09:13:57 (running for 00:41:57.95)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 1 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00018 | RUNNING    | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.249 |  0.165 |                   74 |
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.495 |  0.179 |                   65 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.296 |  0.161 |                   63 |
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.392 |  0.172 |                    4 |
| train_d77f6_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=6501)[0m rmse: 0.1609695702791214
[2m[36m(func pid=6501)[0m mae:  0.11472014337778091
[2m[36m(func pid=6501)[0m rmse_per_class: [0.099, 0.256, 0.057, 0.305, 0.07, 0.182, 0.26, 0.128, 0.146, 0.106]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.4089 | Steps: 2 | Val loss: 0.3375 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=2617)[0m rmse: 0.16456031799316406
[2m[36m(func pid=2617)[0m mae:  0.10159201920032501
[2m[36m(func pid=2617)[0m rmse_per_class: [0.112, 0.225, 0.047, 0.339, 0.105, 0.154, 0.222, 0.12, 0.209, 0.113]
[2m[36m(func pid=5776)[0m rmse: 0.17930153012275696
[2m[36m(func pid=5776)[0m mae:  0.1307901293039322
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.099, 0.193, 0.3, 0.147, 0.141, 0.121]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=19271)[0m rmse: 0.17009535431861877
[2m[36m(func pid=19271)[0m mae:  0.12105460464954376
[2m[36m(func pid=19271)[0m rmse_per_class: [0.107, 0.271, 0.084, 0.336, 0.071, 0.188, 0.259, 0.134, 0.155, 0.096]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.2994 | Steps: 2 | Val loss: 0.2925 | Batch size: 32 | lr: 0.001 | Duration: 3.10s
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.4922 | Steps: 2 | Val loss: 0.3946 | Batch size: 32 | lr: 0.0001 | Duration: 3.03s
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.4241 | Steps: 2 | Val loss: 0.3572 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=6501)[0m rmse: 0.16067174077033997
[2m[36m(func pid=6501)[0m mae:  0.11445937305688858
[2m[36m(func pid=6501)[0m rmse_per_class: [0.099, 0.256, 0.057, 0.304, 0.071, 0.182, 0.259, 0.128, 0.145, 0.106]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=5776)[0m rmse: 0.17922547459602356
[2m[36m(func pid=5776)[0m mae:  0.13071444630622864
[2m[36m(func pid=5776)[0m rmse_per_class: [0.108, 0.269, 0.09, 0.325, 0.099, 0.193, 0.299, 0.147, 0.141, 0.121]
[2m[36m(func pid=19271)[0m rmse: 0.16821543872356415
[2m[36m(func pid=19271)[0m mae:  0.11797212064266205
[2m[36m(func pid=19271)[0m rmse_per_class: [0.107, 0.269, 0.073, 0.337, 0.064, 0.186, 0.258, 0.136, 0.158, 0.093]
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.3009 | Steps: 2 | Val loss: 0.2922 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 09:14:02 (running for 00:42:03.50)
Memory usage on this node: 22.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.1562500037252903
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.497 |  0.179 |                   66 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.299 |  0.161 |                   64 |
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.409 |  0.17  |                    5 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=20925)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=20925)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=20925)[0m Configuration completed!
[2m[36m(func pid=20925)[0m New optimizer parameters:
[2m[36m(func pid=20925)[0m SGD (
[2m[36m(func pid=20925)[0m Parameter Group 0
[2m[36m(func pid=20925)[0m     dampening: 0
[2m[36m(func pid=20925)[0m     differentiable: False
[2m[36m(func pid=20925)[0m     foreach: None
[2m[36m(func pid=20925)[0m     lr: 0.1
[2m[36m(func pid=20925)[0m     maximize: False
[2m[36m(func pid=20925)[0m     momentum: 0.9
[2m[36m(func pid=20925)[0m     nesterov: False
[2m[36m(func pid=20925)[0m     weight_decay: 1e-05
[2m[36m(func pid=20925)[0m )
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=6501)[0m rmse: 0.16052760183811188
[2m[36m(func pid=6501)[0m mae:  0.1143142580986023
== Status ==
Current time: 2024-01-07 09:14:08 (running for 00:42:09.02)
Memory usage on this node: 24.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.1562500037252903
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.492 |  0.179 |                   67 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.301 |  0.161 |                   65 |
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.424 |  0.168 |                    6 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=6501)[0m rmse_per_class: [0.099, 0.256, 0.056, 0.303, 0.071, 0.182, 0.259, 0.127, 0.145, 0.106]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.4952 | Steps: 2 | Val loss: 0.3928 | Batch size: 32 | lr: 0.0001 | Duration: 3.01s
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.4377 | Steps: 2 | Val loss: 0.3683 | Batch size: 32 | lr: 0.01 | Duration: 3.09s
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.2964 | Steps: 2 | Val loss: 0.2920 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 0.7679 | Steps: 2 | Val loss: 0.3213 | Batch size: 32 | lr: 0.1 | Duration: 4.78s
[2m[36m(func pid=5776)[0m rmse: 0.1791982352733612
[2m[36m(func pid=5776)[0m mae:  0.13068458437919617
[2m[36m(func pid=5776)[0m rmse_per_class: [0.108, 0.269, 0.091, 0.325, 0.098, 0.193, 0.299, 0.147, 0.141, 0.121]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=19271)[0m rmse: 0.1669686734676361
[2m[36m(func pid=19271)[0m mae:  0.11544133722782135
[2m[36m(func pid=19271)[0m rmse_per_class: [0.106, 0.267, 0.063, 0.336, 0.059, 0.184, 0.26, 0.139, 0.163, 0.092]
[2m[36m(func pid=19271)[0m 
== Status ==
Current time: 2024-01-07 09:14:13 (running for 00:42:14.53)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.1562500037252903
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.495 |  0.179 |                   68 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.296 |  0.16  |                   66 |
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.438 |  0.167 |                    7 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=6501)[0m rmse: 0.16041848063468933
[2m[36m(func pid=6501)[0m mae:  0.11421241611242294
[2m[36m(func pid=6501)[0m rmse_per_class: [0.099, 0.256, 0.056, 0.303, 0.071, 0.182, 0.259, 0.127, 0.145, 0.106]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=20925)[0m rmse: 0.17095908522605896
[2m[36m(func pid=20925)[0m mae:  0.12291945517063141
[2m[36m(func pid=20925)[0m rmse_per_class: [0.108, 0.273, 0.085, 0.338, 0.072, 0.188, 0.268, 0.131, 0.151, 0.096]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.4879 | Steps: 2 | Val loss: 0.3909 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.4268 | Steps: 2 | Val loss: 0.3668 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.2962 | Steps: 2 | Val loss: 0.2914 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.5075 | Steps: 2 | Val loss: 0.4530 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=5776)[0m rmse: 0.17920412123203278
[2m[36m(func pid=5776)[0m mae:  0.13067644834518433
[2m[36m(func pid=5776)[0m rmse_per_class: [0.108, 0.269, 0.091, 0.325, 0.098, 0.193, 0.299, 0.147, 0.141, 0.121]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=19271)[0m rmse: 0.16531194746494293
[2m[36m(func pid=19271)[0m mae:  0.1128530278801918
[2m[36m(func pid=19271)[0m rmse_per_class: [0.104, 0.263, 0.055, 0.332, 0.057, 0.183, 0.263, 0.14, 0.166, 0.091]
[2m[36m(func pid=19271)[0m 
== Status ==
Current time: 2024-01-07 09:14:19 (running for 00:42:20.06)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.1562500037252903
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.488 |  0.179 |                   69 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.296 |  0.16  |                   67 |
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.427 |  0.165 |                    8 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.768 |  0.171 |                    1 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=6501)[0m rmse: 0.16002342104911804
[2m[36m(func pid=6501)[0m mae:  0.1137838214635849
[2m[36m(func pid=6501)[0m rmse_per_class: [0.098, 0.256, 0.056, 0.303, 0.071, 0.182, 0.257, 0.127, 0.145, 0.107]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=20925)[0m rmse: 0.17865023016929626
[2m[36m(func pid=20925)[0m mae:  0.11879044771194458
[2m[36m(func pid=20925)[0m rmse_per_class: [0.116, 0.277, 0.05, 0.358, 0.055, 0.183, 0.349, 0.148, 0.156, 0.094]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.4861 | Steps: 2 | Val loss: 0.3899 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.4076 | Steps: 2 | Val loss: 0.3560 | Batch size: 32 | lr: 0.01 | Duration: 3.03s
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.2938 | Steps: 2 | Val loss: 0.2909 | Batch size: 32 | lr: 0.001 | Duration: 3.05s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.6492 | Steps: 2 | Val loss: 0.5083 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=5776)[0m rmse: 0.1791803389787674
[2m[36m(func pid=5776)[0m mae:  0.13064312934875488
[2m[36m(func pid=5776)[0m rmse_per_class: [0.108, 0.269, 0.091, 0.325, 0.099, 0.193, 0.299, 0.147, 0.141, 0.12]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=19271)[0m rmse: 0.16315825283527374
[2m[36m(func pid=19271)[0m mae:  0.11032907664775848
[2m[36m(func pid=19271)[0m rmse_per_class: [0.101, 0.26, 0.049, 0.326, 0.055, 0.181, 0.261, 0.141, 0.169, 0.09]
[2m[36m(func pid=19271)[0m 
== Status ==
Current time: 2024-01-07 09:14:24 (running for 00:42:25.59)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.1562500037252903
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.486 |  0.179 |                   70 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.294 |  0.16  |                   68 |
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.408 |  0.163 |                    9 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.507 |  0.179 |                    2 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=6501)[0m rmse: 0.15971776843070984
[2m[36m(func pid=6501)[0m mae:  0.11349805444478989
[2m[36m(func pid=6501)[0m rmse_per_class: [0.097, 0.255, 0.055, 0.302, 0.071, 0.182, 0.257, 0.127, 0.144, 0.106]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=20925)[0m rmse: 0.1938016265630722
[2m[36m(func pid=20925)[0m mae:  0.12372802197933197
[2m[36m(func pid=20925)[0m rmse_per_class: [0.106, 0.286, 0.046, 0.367, 0.056, 0.185, 0.498, 0.155, 0.142, 0.097]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.4843 | Steps: 2 | Val loss: 0.3882 | Batch size: 32 | lr: 0.0001 | Duration: 3.08s
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.3734 | Steps: 2 | Val loss: 0.3376 | Batch size: 32 | lr: 0.01 | Duration: 3.09s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.5309 | Steps: 2 | Val loss: 0.4545 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.2888 | Steps: 2 | Val loss: 0.2905 | Batch size: 32 | lr: 0.001 | Duration: 3.06s
[2m[36m(func pid=5776)[0m rmse: 0.1791030615568161
[2m[36m(func pid=5776)[0m mae:  0.1305731236934662
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.098, 0.193, 0.299, 0.147, 0.141, 0.12]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=19271)[0m rmse: 0.16025736927986145
[2m[36m(func pid=19271)[0m mae:  0.10770062357187271
[2m[36m(func pid=19271)[0m rmse_per_class: [0.098, 0.255, 0.046, 0.317, 0.055, 0.179, 0.254, 0.14, 0.169, 0.089]
[2m[36m(func pid=19271)[0m 
== Status ==
Current time: 2024-01-07 09:14:30 (running for 00:42:31.22)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.1562500037252903
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.484 |  0.179 |                   71 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.289 |  0.159 |                   69 |
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.373 |  0.16  |                   10 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.649 |  0.194 |                    3 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=6501)[0m rmse: 0.15942156314849854
[2m[36m(func pid=6501)[0m mae:  0.11321830749511719
[2m[36m(func pid=6501)[0m rmse_per_class: [0.097, 0.255, 0.055, 0.302, 0.07, 0.182, 0.256, 0.127, 0.144, 0.106]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=20925)[0m rmse: 0.1915334165096283
[2m[36m(func pid=20925)[0m mae:  0.11987821012735367
[2m[36m(func pid=20925)[0m rmse_per_class: [0.119, 0.285, 0.047, 0.367, 0.056, 0.171, 0.406, 0.156, 0.212, 0.097]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.4776 | Steps: 2 | Val loss: 0.3859 | Batch size: 32 | lr: 0.0001 | Duration: 3.03s
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.3416 | Steps: 2 | Val loss: 0.3158 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.3824 | Steps: 2 | Val loss: 0.3950 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.3039 | Steps: 2 | Val loss: 0.2906 | Batch size: 32 | lr: 0.001 | Duration: 3.04s
[2m[36m(func pid=5776)[0m rmse: 0.17899596691131592
[2m[36m(func pid=5776)[0m mae:  0.1304628849029541
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.098, 0.193, 0.299, 0.147, 0.141, 0.12]
[2m[36m(func pid=5776)[0m 
[2m[36m(func pid=19271)[0m rmse: 0.15648379921913147
[2m[36m(func pid=19271)[0m mae:  0.10496648401021957
[2m[36m(func pid=19271)[0m rmse_per_class: [0.094, 0.249, 0.044, 0.307, 0.055, 0.178, 0.242, 0.138, 0.17, 0.089]
[2m[36m(func pid=19271)[0m 
== Status ==
Current time: 2024-01-07 09:14:35 (running for 00:42:36.63)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.1562500037252903
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.478 |  0.179 |                   72 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.289 |  0.159 |                   69 |
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.342 |  0.156 |                   11 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.382 |  0.185 |                    5 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.1852877289056778
[2m[36m(func pid=20925)[0m mae:  0.11948313564062119
[2m[36m(func pid=20925)[0m rmse_per_class: [0.137, 0.258, 0.038, 0.328, 0.056, 0.188, 0.208, 0.154, 0.388, 0.097]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=6501)[0m rmse: 0.1594841182231903
[2m[36m(func pid=6501)[0m mae:  0.11328423023223877
[2m[36m(func pid=6501)[0m rmse_per_class: [0.097, 0.255, 0.055, 0.301, 0.07, 0.182, 0.257, 0.127, 0.144, 0.106]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.4810 | Steps: 2 | Val loss: 0.3841 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.3193 | Steps: 2 | Val loss: 0.2966 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.3329 | Steps: 2 | Val loss: 0.3505 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.2854 | Steps: 2 | Val loss: 0.2904 | Batch size: 32 | lr: 0.001 | Duration: 3.07s
[2m[36m(func pid=19271)[0m rmse: 0.1527688205242157
[2m[36m(func pid=19271)[0m mae:  0.10261758416891098
[2m[36m(func pid=19271)[0m rmse_per_class: [0.093, 0.244, 0.042, 0.297, 0.055, 0.176, 0.229, 0.135, 0.169, 0.088]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=5776)[0m rmse: 0.17894475162029266
[2m[36m(func pid=5776)[0m mae:  0.1304192692041397
[2m[36m(func pid=5776)[0m rmse_per_class: [0.108, 0.269, 0.09, 0.325, 0.098, 0.193, 0.298, 0.147, 0.141, 0.121]
[2m[36m(func pid=5776)[0m 
== Status ==
Current time: 2024-01-07 09:14:40 (running for 00:42:41.87)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.1562500037252903
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.481 |  0.179 |                   73 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.304 |  0.159 |                   70 |
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.319 |  0.153 |                   12 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.333 |  0.174 |                    6 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.17413391172885895
[2m[36m(func pid=20925)[0m mae:  0.11265493929386139
[2m[36m(func pid=20925)[0m rmse_per_class: [0.077, 0.225, 0.034, 0.304, 0.056, 0.188, 0.261, 0.133, 0.37, 0.093]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=6501)[0m rmse: 0.15932264924049377
[2m[36m(func pid=6501)[0m mae:  0.1131480485200882
[2m[36m(func pid=6501)[0m rmse_per_class: [0.097, 0.255, 0.055, 0.302, 0.07, 0.181, 0.256, 0.127, 0.144, 0.106]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.2959 | Steps: 2 | Val loss: 0.2819 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.4783 | Steps: 2 | Val loss: 0.3822 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.3153 | Steps: 2 | Val loss: 0.3311 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.2924 | Steps: 2 | Val loss: 0.2897 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=19271)[0m rmse: 0.14959856867790222
[2m[36m(func pid=19271)[0m mae:  0.10083027184009552
[2m[36m(func pid=19271)[0m rmse_per_class: [0.09, 0.24, 0.041, 0.288, 0.054, 0.175, 0.223, 0.13, 0.167, 0.088]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=5776)[0m rmse: 0.17880572378635406
[2m[36m(func pid=5776)[0m mae:  0.13031545281410217
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.097, 0.193, 0.298, 0.147, 0.141, 0.121]
[2m[36m(func pid=5776)[0m 
== Status ==
Current time: 2024-01-07 09:14:46 (running for 00:42:47.32)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.1562500037252903
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00020 | RUNNING    | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.478 |  0.179 |                   74 |
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.285 |  0.159 |                   71 |
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.296 |  0.15  |                   13 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.315 |  0.167 |                    7 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.16700419783592224
[2m[36m(func pid=20925)[0m mae:  0.10335131734609604
[2m[36m(func pid=20925)[0m rmse_per_class: [0.092, 0.23, 0.043, 0.293, 0.056, 0.166, 0.264, 0.13, 0.313, 0.083]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=6501)[0m rmse: 0.15887336432933807
[2m[36m(func pid=6501)[0m mae:  0.11268416792154312
[2m[36m(func pid=6501)[0m rmse_per_class: [0.096, 0.255, 0.054, 0.301, 0.07, 0.181, 0.255, 0.127, 0.143, 0.105]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.2770 | Steps: 2 | Val loss: 0.2724 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=5776)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.4721 | Steps: 2 | Val loss: 0.3810 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.3048 | Steps: 2 | Val loss: 0.3449 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.2889 | Steps: 2 | Val loss: 0.2896 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=19271)[0m rmse: 0.1474214792251587
[2m[36m(func pid=19271)[0m mae:  0.09986374527215958
[2m[36m(func pid=19271)[0m rmse_per_class: [0.09, 0.237, 0.04, 0.28, 0.054, 0.174, 0.225, 0.125, 0.163, 0.087]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=5776)[0m rmse: 0.17870593070983887
[2m[36m(func pid=5776)[0m mae:  0.13023148477077484
[2m[36m(func pid=5776)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.098, 0.193, 0.298, 0.147, 0.141, 0.12]
== Status ==
Current time: 2024-01-07 09:14:51 (running for 00:42:52.53)
Memory usage on this node: 22.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=19
Bracket: Iter 75.000: -0.15650000423192978
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 3 RUNNING, 19 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.292 |  0.159 |                   72 |
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.277 |  0.147 |                   14 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.305 |  0.179 |                    8 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.17910489439964294
[2m[36m(func pid=20925)[0m mae:  0.10811944305896759
[2m[36m(func pid=20925)[0m rmse_per_class: [0.088, 0.26, 0.045, 0.299, 0.055, 0.169, 0.316, 0.177, 0.251, 0.132]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=6501)[0m rmse: 0.15881529450416565
[2m[36m(func pid=6501)[0m mae:  0.11260149627923965
[2m[36m(func pid=6501)[0m rmse_per_class: [0.096, 0.254, 0.054, 0.302, 0.07, 0.181, 0.255, 0.127, 0.143, 0.106]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.2727 | Steps: 2 | Val loss: 0.2681 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.2993 | Steps: 2 | Val loss: 0.3281 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.2882 | Steps: 2 | Val loss: 0.2892 | Batch size: 32 | lr: 0.001 | Duration: 3.05s
[2m[36m(func pid=19271)[0m rmse: 0.14601576328277588
[2m[36m(func pid=19271)[0m mae:  0.09930557012557983
[2m[36m(func pid=19271)[0m rmse_per_class: [0.089, 0.234, 0.038, 0.275, 0.054, 0.173, 0.231, 0.117, 0.161, 0.087]
[2m[36m(func pid=19271)[0m 
== Status ==
Current time: 2024-01-07 09:14:57 (running for 00:42:58.00)
Memory usage on this node: 22.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=19
Bracket: Iter 75.000: -0.15650000423192978
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 3 RUNNING, 19 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.289 |  0.159 |                   73 |
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.273 |  0.146 |                   15 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.299 |  0.175 |                    9 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.17464342713356018
[2m[36m(func pid=20925)[0m mae:  0.10667671263217926
[2m[36m(func pid=20925)[0m rmse_per_class: [0.075, 0.276, 0.046, 0.303, 0.053, 0.172, 0.329, 0.178, 0.205, 0.109]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=6501)[0m rmse: 0.15857574343681335
[2m[36m(func pid=6501)[0m mae:  0.11243876069784164
[2m[36m(func pid=6501)[0m rmse_per_class: [0.096, 0.254, 0.054, 0.301, 0.071, 0.181, 0.255, 0.126, 0.143, 0.105]
[2m[36m(func pid=6501)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.2721 | Steps: 2 | Val loss: 0.2671 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.2681 | Steps: 2 | Val loss: 0.3024 | Batch size: 32 | lr: 0.1 | Duration: 3.13s
[2m[36m(func pid=19271)[0m rmse: 0.145428866147995
[2m[36m(func pid=19271)[0m mae:  0.09944967925548553
[2m[36m(func pid=19271)[0m rmse_per_class: [0.087, 0.233, 0.037, 0.272, 0.054, 0.172, 0.24, 0.113, 0.159, 0.089]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=6501)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.2911 | Steps: 2 | Val loss: 0.2891 | Batch size: 32 | lr: 0.001 | Duration: 3.14s
== Status ==
Current time: 2024-01-07 09:15:02 (running for 00:43:03.55)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=19
Bracket: Iter 75.000: -0.15650000423192978
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 3 RUNNING, 19 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00021 | RUNNING    | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.288 |  0.159 |                   74 |
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.272 |  0.145 |                   16 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.268 |  0.162 |                   10 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.16194382309913635
[2m[36m(func pid=20925)[0m mae:  0.09925594925880432
[2m[36m(func pid=20925)[0m rmse_per_class: [0.103, 0.267, 0.045, 0.292, 0.05, 0.161, 0.273, 0.151, 0.192, 0.085]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.2704 | Steps: 2 | Val loss: 0.2668 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=6501)[0m rmse: 0.15849345922470093
[2m[36m(func pid=6501)[0m mae:  0.1123470664024353
[2m[36m(func pid=6501)[0m rmse_per_class: [0.096, 0.254, 0.054, 0.301, 0.071, 0.181, 0.254, 0.126, 0.143, 0.105]
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.2549 | Steps: 2 | Val loss: 0.2824 | Batch size: 32 | lr: 0.1 | Duration: 2.99s
[2m[36m(func pid=19271)[0m rmse: 0.14491018652915955
[2m[36m(func pid=19271)[0m mae:  0.09932515770196915
[2m[36m(func pid=19271)[0m rmse_per_class: [0.084, 0.232, 0.036, 0.269, 0.053, 0.17, 0.247, 0.111, 0.154, 0.092]
[2m[36m(func pid=19271)[0m 
== Status ==
Current time: 2024-01-07 09:15:08 (running for 00:43:09.03)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.27  |  0.145 |                   17 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.255 |  0.149 |                   11 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14944559335708618
[2m[36m(func pid=20925)[0m mae:  0.09181666374206543
[2m[36m(func pid=20925)[0m rmse_per_class: [0.081, 0.242, 0.046, 0.267, 0.048, 0.155, 0.215, 0.147, 0.208, 0.084]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.2635 | Steps: 2 | Val loss: 0.2682 | Batch size: 32 | lr: 0.01 | Duration: 3.19s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.2561 | Steps: 2 | Val loss: 0.2835 | Batch size: 32 | lr: 0.1 | Duration: 3.02s
[2m[36m(func pid=19271)[0m rmse: 0.14561757445335388
[2m[36m(func pid=19271)[0m mae:  0.10001017153263092
[2m[36m(func pid=19271)[0m rmse_per_class: [0.084, 0.232, 0.036, 0.269, 0.053, 0.17, 0.252, 0.114, 0.151, 0.097]
[2m[36m(func pid=19271)[0m 
== Status ==
Current time: 2024-01-07 09:15:13 (running for 00:43:14.38)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.264 |  0.146 |                   18 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.256 |  0.151 |                   12 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.15136735141277313
[2m[36m(func pid=20925)[0m mae:  0.09295203536748886
[2m[36m(func pid=20925)[0m rmse_per_class: [0.076, 0.233, 0.044, 0.259, 0.048, 0.157, 0.213, 0.145, 0.254, 0.086]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.2576 | Steps: 2 | Val loss: 0.2697 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.2466 | Steps: 2 | Val loss: 0.2914 | Batch size: 32 | lr: 0.1 | Duration: 3.11s
[2m[36m(func pid=19271)[0m rmse: 0.14635242521762848
[2m[36m(func pid=19271)[0m mae:  0.1004994735121727
[2m[36m(func pid=19271)[0m rmse_per_class: [0.083, 0.233, 0.035, 0.268, 0.054, 0.169, 0.253, 0.118, 0.149, 0.101]
[2m[36m(func pid=19271)[0m 
== Status ==
Current time: 2024-01-07 09:15:19 (running for 00:43:19.89)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.258 |  0.146 |                   19 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.247 |  0.158 |                   13 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.1582249104976654
[2m[36m(func pid=20925)[0m mae:  0.09777778387069702
[2m[36m(func pid=20925)[0m rmse_per_class: [0.081, 0.241, 0.042, 0.272, 0.047, 0.158, 0.237, 0.145, 0.274, 0.085]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.2582 | Steps: 2 | Val loss: 0.2718 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.2435 | Steps: 2 | Val loss: 0.2927 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=19271)[0m rmse: 0.14703591167926788
[2m[36m(func pid=19271)[0m mae:  0.1008424162864685
[2m[36m(func pid=19271)[0m rmse_per_class: [0.082, 0.234, 0.035, 0.268, 0.056, 0.169, 0.25, 0.121, 0.148, 0.106]
[2m[36m(func pid=19271)[0m 
== Status ==
Current time: 2024-01-07 09:15:24 (running for 00:43:25.20)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.258 |  0.147 |                   20 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.244 |  0.158 |                   14 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.15813568234443665
[2m[36m(func pid=20925)[0m mae:  0.09872271865606308
[2m[36m(func pid=20925)[0m rmse_per_class: [0.078, 0.251, 0.038, 0.284, 0.048, 0.164, 0.238, 0.141, 0.254, 0.085]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.2512 | Steps: 2 | Val loss: 0.2746 | Batch size: 32 | lr: 0.01 | Duration: 3.11s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.2474 | Steps: 2 | Val loss: 0.2867 | Batch size: 32 | lr: 0.1 | Duration: 3.09s
[2m[36m(func pid=19271)[0m rmse: 0.14768505096435547
[2m[36m(func pid=19271)[0m mae:  0.10103517770767212
[2m[36m(func pid=19271)[0m rmse_per_class: [0.081, 0.237, 0.036, 0.271, 0.058, 0.169, 0.244, 0.123, 0.148, 0.109]
[2m[36m(func pid=19271)[0m 
== Status ==
Current time: 2024-01-07 09:15:29 (running for 00:43:30.83)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.251 |  0.148 |                   21 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.247 |  0.153 |                   15 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.15295597910881042
[2m[36m(func pid=20925)[0m mae:  0.0968366265296936
[2m[36m(func pid=20925)[0m rmse_per_class: [0.099, 0.249, 0.035, 0.28, 0.049, 0.166, 0.224, 0.136, 0.204, 0.089]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.2527 | Steps: 2 | Val loss: 0.2776 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.2427 | Steps: 2 | Val loss: 0.2794 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
[2m[36m(func pid=19271)[0m rmse: 0.1478426605463028
[2m[36m(func pid=19271)[0m mae:  0.10085757076740265
[2m[36m(func pid=19271)[0m rmse_per_class: [0.08, 0.239, 0.036, 0.274, 0.062, 0.17, 0.236, 0.123, 0.148, 0.111]
[2m[36m(func pid=19271)[0m 
== Status ==
Current time: 2024-01-07 09:15:35 (running for 00:43:36.26)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.253 |  0.148 |                   22 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.243 |  0.149 |                   16 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.1488783210515976
[2m[36m(func pid=20925)[0m mae:  0.09414327889680862
[2m[36m(func pid=20925)[0m rmse_per_class: [0.118, 0.24, 0.033, 0.28, 0.049, 0.159, 0.217, 0.13, 0.173, 0.091]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.2456 | Steps: 2 | Val loss: 0.2816 | Batch size: 32 | lr: 0.01 | Duration: 3.20s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.2559 | Steps: 2 | Val loss: 0.2701 | Batch size: 32 | lr: 0.1 | Duration: 3.04s
[2m[36m(func pid=19271)[0m rmse: 0.14826197922229767
[2m[36m(func pid=19271)[0m mae:  0.10092736780643463
[2m[36m(func pid=19271)[0m rmse_per_class: [0.081, 0.241, 0.036, 0.281, 0.066, 0.17, 0.229, 0.121, 0.15, 0.109]
[2m[36m(func pid=19271)[0m 
== Status ==
Current time: 2024-01-07 09:15:40 (running for 00:43:41.80)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.246 |  0.148 |                   23 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.256 |  0.144 |                   17 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.1439874768257141
[2m[36m(func pid=20925)[0m mae:  0.0907353013753891
[2m[36m(func pid=20925)[0m rmse_per_class: [0.107, 0.228, 0.031, 0.283, 0.049, 0.154, 0.21, 0.118, 0.169, 0.089]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.2430 | Steps: 2 | Val loss: 0.2833 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.2434 | Steps: 2 | Val loss: 0.2699 | Batch size: 32 | lr: 0.1 | Duration: 3.04s
[2m[36m(func pid=19271)[0m rmse: 0.1474558562040329
[2m[36m(func pid=19271)[0m mae:  0.10018877685070038
[2m[36m(func pid=19271)[0m rmse_per_class: [0.081, 0.241, 0.036, 0.285, 0.068, 0.169, 0.222, 0.117, 0.148, 0.107]
[2m[36m(func pid=19271)[0m 
== Status ==
Current time: 2024-01-07 09:15:46 (running for 00:43:47.21)
Memory usage on this node: 19.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.243 |  0.147 |                   24 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.243 |  0.144 |                   18 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14386773109436035
[2m[36m(func pid=20925)[0m mae:  0.09020990133285522
[2m[36m(func pid=20925)[0m rmse_per_class: [0.092, 0.226, 0.032, 0.282, 0.051, 0.151, 0.21, 0.113, 0.194, 0.086]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.2414 | Steps: 2 | Val loss: 0.2840 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.2371 | Steps: 2 | Val loss: 0.2720 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=19271)[0m rmse: 0.14657357335090637
[2m[36m(func pid=19271)[0m mae:  0.09928281605243683
[2m[36m(func pid=19271)[0m rmse_per_class: [0.081, 0.241, 0.036, 0.287, 0.07, 0.169, 0.217, 0.115, 0.148, 0.102]
[2m[36m(func pid=19271)[0m 
== Status ==
Current time: 2024-01-07 09:15:51 (running for 00:43:52.57)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.241 |  0.147 |                   25 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.237 |  0.146 |                   19 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14589126408100128
[2m[36m(func pid=20925)[0m mae:  0.09054997563362122
[2m[36m(func pid=20925)[0m rmse_per_class: [0.076, 0.223, 0.035, 0.278, 0.053, 0.154, 0.213, 0.121, 0.221, 0.084]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.2447 | Steps: 2 | Val loss: 0.2841 | Batch size: 32 | lr: 0.01 | Duration: 3.07s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.2418 | Steps: 2 | Val loss: 0.2718 | Batch size: 32 | lr: 0.1 | Duration: 3.05s
[2m[36m(func pid=19271)[0m rmse: 0.14616581797599792
[2m[36m(func pid=19271)[0m mae:  0.09870907664299011
[2m[36m(func pid=19271)[0m rmse_per_class: [0.081, 0.24, 0.037, 0.289, 0.07, 0.169, 0.213, 0.113, 0.151, 0.098]
[2m[36m(func pid=19271)[0m 
== Status ==
Current time: 2024-01-07 09:15:57 (running for 00:43:58.01)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.245 |  0.146 |                   26 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.242 |  0.146 |                   20 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14626066386699677
[2m[36m(func pid=20925)[0m mae:  0.09017998725175858
[2m[36m(func pid=20925)[0m rmse_per_class: [0.073, 0.223, 0.034, 0.271, 0.053, 0.162, 0.207, 0.123, 0.231, 0.085]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.2388 | Steps: 2 | Val loss: 0.2823 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.2404 | Steps: 2 | Val loss: 0.2687 | Batch size: 32 | lr: 0.1 | Duration: 3.13s
[2m[36m(func pid=19271)[0m rmse: 0.14506864547729492
[2m[36m(func pid=19271)[0m mae:  0.09762822091579437
[2m[36m(func pid=19271)[0m rmse_per_class: [0.081, 0.239, 0.037, 0.288, 0.069, 0.168, 0.211, 0.113, 0.15, 0.095]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=20925)[0m rmse: 0.14343973994255066
[2m[36m(func pid=20925)[0m mae:  0.08838572353124619
[2m[36m(func pid=20925)[0m rmse_per_class: [0.073, 0.226, 0.031, 0.27, 0.052, 0.16, 0.204, 0.114, 0.217, 0.086]
== Status ==
Current time: 2024-01-07 09:16:02 (running for 00:44:03.53)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.239 |  0.145 |                   27 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.24  |  0.143 |                   21 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.2471 | Steps: 2 | Val loss: 0.2807 | Batch size: 32 | lr: 0.01 | Duration: 3.11s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.2368 | Steps: 2 | Val loss: 0.2661 | Batch size: 32 | lr: 0.1 | Duration: 3.19s
[2m[36m(func pid=19271)[0m rmse: 0.1443937122821808
[2m[36m(func pid=19271)[0m mae:  0.09703229367733002
[2m[36m(func pid=19271)[0m rmse_per_class: [0.082, 0.236, 0.037, 0.286, 0.068, 0.168, 0.21, 0.112, 0.15, 0.094]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=20925)[0m rmse: 0.14077860116958618
[2m[36m(func pid=20925)[0m mae:  0.08732298761606216
[2m[36m(func pid=20925)[0m rmse_per_class: [0.078, 0.224, 0.033, 0.278, 0.052, 0.151, 0.2, 0.11, 0.194, 0.089]
[2m[36m(func pid=20925)[0m 
== Status ==
Current time: 2024-01-07 09:16:08 (running for 00:44:09.14)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.247 |  0.144 |                   28 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.237 |  0.141 |                   22 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.2385 | Steps: 2 | Val loss: 0.2789 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=19271)[0m rmse: 0.14383549988269806
[2m[36m(func pid=19271)[0m mae:  0.09656714648008347
[2m[36m(func pid=19271)[0m rmse_per_class: [0.083, 0.235, 0.037, 0.286, 0.066, 0.167, 0.21, 0.111, 0.15, 0.093]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.2346 | Steps: 2 | Val loss: 0.2643 | Batch size: 32 | lr: 0.1 | Duration: 3.11s
== Status ==
Current time: 2024-01-07 09:16:13 (running for 00:44:14.71)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.239 |  0.144 |                   29 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.235 |  0.14  |                   23 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14010825753211975
[2m[36m(func pid=20925)[0m mae:  0.08750671148300171
[2m[36m(func pid=20925)[0m rmse_per_class: [0.093, 0.218, 0.036, 0.284, 0.052, 0.148, 0.197, 0.109, 0.174, 0.091]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.2391 | Steps: 2 | Val loss: 0.2770 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=19271)[0m rmse: 0.1428842842578888
[2m[36m(func pid=19271)[0m mae:  0.09579161554574966
[2m[36m(func pid=19271)[0m rmse_per_class: [0.083, 0.233, 0.037, 0.284, 0.063, 0.167, 0.21, 0.111, 0.148, 0.092]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.2356 | Steps: 2 | Val loss: 0.2632 | Batch size: 32 | lr: 0.1 | Duration: 3.14s
== Status ==
Current time: 2024-01-07 09:16:19 (running for 00:44:20.32)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.239 |  0.143 |                   30 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.236 |  0.14  |                   24 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14014136791229248
[2m[36m(func pid=20925)[0m mae:  0.08770598471164703
[2m[36m(func pid=20925)[0m rmse_per_class: [0.095, 0.216, 0.035, 0.286, 0.054, 0.149, 0.201, 0.11, 0.164, 0.091]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.2383 | Steps: 2 | Val loss: 0.2760 | Batch size: 32 | lr: 0.01 | Duration: 3.09s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.2444 | Steps: 2 | Val loss: 0.2621 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=19271)[0m rmse: 0.14249253273010254
[2m[36m(func pid=19271)[0m mae:  0.09552647918462753
[2m[36m(func pid=19271)[0m rmse_per_class: [0.083, 0.232, 0.037, 0.283, 0.062, 0.167, 0.212, 0.111, 0.146, 0.092]
[2m[36m(func pid=19271)[0m 
== Status ==
Current time: 2024-01-07 09:16:24 (running for 00:44:25.54)
Memory usage on this node: 19.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.238 |  0.142 |                   31 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.244 |  0.14  |                   25 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.13953594863414764
[2m[36m(func pid=20925)[0m mae:  0.08724580705165863
[2m[36m(func pid=20925)[0m rmse_per_class: [0.084, 0.219, 0.03, 0.285, 0.057, 0.149, 0.197, 0.115, 0.169, 0.092]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.2357 | Steps: 2 | Val loss: 0.2748 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.2382 | Steps: 2 | Val loss: 0.2586 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
[2m[36m(func pid=19271)[0m rmse: 0.1421796977519989
[2m[36m(func pid=19271)[0m mae:  0.09528987109661102
[2m[36m(func pid=19271)[0m rmse_per_class: [0.083, 0.232, 0.037, 0.279, 0.061, 0.167, 0.215, 0.111, 0.146, 0.091]
[2m[36m(func pid=19271)[0m 
== Status ==
Current time: 2024-01-07 09:16:30 (running for 00:44:31.01)
Memory usage on this node: 19.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.236 |  0.142 |                   32 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.238 |  0.138 |                   26 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
[2m[36m(func pid=20925)[0m rmse: 0.1380816251039505

[2m[36m(func pid=20925)[0m mae:  0.08563293516635895
[2m[36m(func pid=20925)[0m rmse_per_class: [0.075, 0.219, 0.029, 0.279, 0.058, 0.154, 0.19, 0.116, 0.174, 0.087]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.2383 | Steps: 2 | Val loss: 0.2746 | Batch size: 32 | lr: 0.01 | Duration: 3.09s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.2408 | Steps: 2 | Val loss: 0.2602 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=19271)[0m rmse: 0.14194196462631226
[2m[36m(func pid=19271)[0m mae:  0.09507528692483902
[2m[36m(func pid=19271)[0m rmse_per_class: [0.083, 0.231, 0.036, 0.277, 0.06, 0.167, 0.217, 0.112, 0.145, 0.092]
[2m[36m(func pid=19271)[0m 
== Status ==
Current time: 2024-01-07 09:16:35 (running for 00:44:36.40)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.238 |  0.142 |                   33 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.241 |  0.139 |                   27 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.1387423276901245
[2m[36m(func pid=20925)[0m mae:  0.08558036386966705
[2m[36m(func pid=20925)[0m rmse_per_class: [0.074, 0.22, 0.031, 0.276, 0.059, 0.155, 0.193, 0.114, 0.18, 0.085]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.2413 | Steps: 2 | Val loss: 0.2747 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.2301 | Steps: 2 | Val loss: 0.2690 | Batch size: 32 | lr: 0.1 | Duration: 3.01s
[2m[36m(func pid=19271)[0m rmse: 0.14176537096500397
[2m[36m(func pid=19271)[0m mae:  0.09486736357212067
[2m[36m(func pid=19271)[0m rmse_per_class: [0.082, 0.231, 0.036, 0.276, 0.059, 0.167, 0.217, 0.113, 0.144, 0.092]
[2m[36m(func pid=19271)[0m 
== Status ==
Current time: 2024-01-07 09:16:40 (running for 00:44:41.81)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.241 |  0.142 |                   34 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.23  |  0.143 |                   28 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14333771169185638
[2m[36m(func pid=20925)[0m mae:  0.08957702666521072
[2m[36m(func pid=20925)[0m rmse_per_class: [0.088, 0.225, 0.032, 0.29, 0.069, 0.154, 0.195, 0.115, 0.181, 0.085]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.2443 | Steps: 2 | Val loss: 0.2739 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.2315 | Steps: 2 | Val loss: 0.2760 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
[2m[36m(func pid=19271)[0m rmse: 0.14112445712089539
[2m[36m(func pid=19271)[0m mae:  0.09433648735284805
[2m[36m(func pid=19271)[0m rmse_per_class: [0.081, 0.231, 0.035, 0.272, 0.058, 0.166, 0.218, 0.113, 0.144, 0.092]
[2m[36m(func pid=19271)[0m 
== Status ==
Current time: 2024-01-07 09:16:46 (running for 00:44:47.11)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.244 |  0.141 |                   35 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.231 |  0.147 |                   29 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.1472485214471817
[2m[36m(func pid=20925)[0m mae:  0.09275920689105988
[2m[36m(func pid=20925)[0m rmse_per_class: [0.093, 0.226, 0.032, 0.299, 0.075, 0.158, 0.206, 0.116, 0.182, 0.085]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.2330 | Steps: 2 | Val loss: 0.2734 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.2376 | Steps: 2 | Val loss: 0.2729 | Batch size: 32 | lr: 0.1 | Duration: 3.02s
[2m[36m(func pid=19271)[0m rmse: 0.14097920060157776
[2m[36m(func pid=19271)[0m mae:  0.09425441920757294
[2m[36m(func pid=19271)[0m rmse_per_class: [0.08, 0.231, 0.035, 0.272, 0.058, 0.166, 0.218, 0.114, 0.143, 0.093]
[2m[36m(func pid=19271)[0m 
== Status ==
Current time: 2024-01-07 09:16:51 (running for 00:44:52.64)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.233 |  0.141 |                   36 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.238 |  0.145 |                   30 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14535026252269745
[2m[36m(func pid=20925)[0m mae:  0.09140369296073914
[2m[36m(func pid=20925)[0m rmse_per_class: [0.08, 0.226, 0.031, 0.305, 0.075, 0.156, 0.201, 0.118, 0.177, 0.086]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.2386 | Steps: 2 | Val loss: 0.2737 | Batch size: 32 | lr: 0.01 | Duration: 3.06s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.2305 | Steps: 2 | Val loss: 0.2678 | Batch size: 32 | lr: 0.1 | Duration: 3.06s
[2m[36m(func pid=19271)[0m rmse: 0.1407352089881897
[2m[36m(func pid=19271)[0m mae:  0.09411437064409256
[2m[36m(func pid=19271)[0m rmse_per_class: [0.08, 0.23, 0.035, 0.272, 0.058, 0.165, 0.218, 0.114, 0.143, 0.093]
[2m[36m(func pid=19271)[0m 
== Status ==
Current time: 2024-01-07 09:16:57 (running for 00:44:58.17)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.239 |  0.141 |                   37 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.23  |  0.143 |                   31 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14265626668930054
[2m[36m(func pid=20925)[0m mae:  0.08926980942487717
[2m[36m(func pid=20925)[0m rmse_per_class: [0.072, 0.224, 0.029, 0.304, 0.073, 0.155, 0.195, 0.116, 0.172, 0.086]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.2352 | Steps: 2 | Val loss: 0.2748 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.2361 | Steps: 2 | Val loss: 0.2641 | Batch size: 32 | lr: 0.1 | Duration: 3.05s
[2m[36m(func pid=19271)[0m rmse: 0.1408500075340271
[2m[36m(func pid=19271)[0m mae:  0.0940917581319809
[2m[36m(func pid=19271)[0m rmse_per_class: [0.08, 0.23, 0.035, 0.274, 0.058, 0.165, 0.216, 0.115, 0.142, 0.094]
[2m[36m(func pid=19271)[0m 
== Status ==
Current time: 2024-01-07 09:17:02 (running for 00:45:03.65)
Memory usage on this node: 19.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.235 |  0.141 |                   38 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.236 |  0.141 |                   32 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14088796079158783
[2m[36m(func pid=20925)[0m mae:  0.08779457956552505
[2m[36m(func pid=20925)[0m rmse_per_class: [0.071, 0.22, 0.028, 0.294, 0.073, 0.156, 0.194, 0.114, 0.171, 0.087]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.2354 | Steps: 2 | Val loss: 0.2757 | Batch size: 32 | lr: 0.01 | Duration: 3.18s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.2371 | Steps: 2 | Val loss: 0.2633 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
[2m[36m(func pid=19271)[0m rmse: 0.14079460501670837
[2m[36m(func pid=19271)[0m mae:  0.09398481994867325
[2m[36m(func pid=19271)[0m rmse_per_class: [0.081, 0.231, 0.035, 0.274, 0.058, 0.165, 0.215, 0.115, 0.142, 0.093]
[2m[36m(func pid=19271)[0m 
== Status ==
Current time: 2024-01-07 09:17:08 (running for 00:45:09.03)
Memory usage on this node: 19.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.235 |  0.141 |                   39 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.237 |  0.14  |                   33 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14036881923675537
[2m[36m(func pid=20925)[0m mae:  0.08731462061405182
[2m[36m(func pid=20925)[0m rmse_per_class: [0.073, 0.219, 0.029, 0.288, 0.072, 0.155, 0.194, 0.116, 0.171, 0.086]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.2341 | Steps: 2 | Val loss: 0.2776 | Batch size: 32 | lr: 0.01 | Duration: 3.10s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.2344 | Steps: 2 | Val loss: 0.2664 | Batch size: 32 | lr: 0.1 | Duration: 3.09s
[2m[36m(func pid=19271)[0m rmse: 0.14136631786823273
[2m[36m(func pid=19271)[0m mae:  0.0944218710064888
[2m[36m(func pid=19271)[0m rmse_per_class: [0.08, 0.232, 0.034, 0.278, 0.059, 0.166, 0.214, 0.115, 0.142, 0.094]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=20925)[0m rmse: 0.14176806807518005
[2m[36m(func pid=20925)[0m mae:  0.0888119786977768
[2m[36m(func pid=20925)[0m rmse_per_class: [0.083, 0.219, 0.031, 0.29, 0.074, 0.154, 0.198, 0.116, 0.167, 0.086]
== Status ==
Current time: 2024-01-07 09:17:13 (running for 00:45:14.60)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.234 |  0.141 |                   40 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.234 |  0.142 |                   34 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.2328 | Steps: 2 | Val loss: 0.2783 | Batch size: 32 | lr: 0.01 | Duration: 3.14s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.2392 | Steps: 2 | Val loss: 0.2689 | Batch size: 32 | lr: 0.1 | Duration: 3.15s
[2m[36m(func pid=19271)[0m rmse: 0.1413247138261795
[2m[36m(func pid=19271)[0m mae:  0.09441274404525757
[2m[36m(func pid=19271)[0m rmse_per_class: [0.08, 0.232, 0.034, 0.279, 0.059, 0.165, 0.213, 0.115, 0.142, 0.094]
[2m[36m(func pid=19271)[0m 
== Status ==
Current time: 2024-01-07 09:17:19 (running for 00:45:20.15)
Memory usage on this node: 19.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.233 |  0.141 |                   41 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.239 |  0.143 |                   35 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14345213770866394
[2m[36m(func pid=20925)[0m mae:  0.09041183441877365
[2m[36m(func pid=20925)[0m rmse_per_class: [0.094, 0.22, 0.03, 0.297, 0.075, 0.155, 0.202, 0.113, 0.163, 0.085]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.2372 | Steps: 2 | Val loss: 0.2787 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.2290 | Steps: 2 | Val loss: 0.2648 | Batch size: 32 | lr: 0.1 | Duration: 3.05s
[2m[36m(func pid=19271)[0m rmse: 0.14114734530448914
[2m[36m(func pid=19271)[0m mae:  0.0943114310503006
[2m[36m(func pid=19271)[0m rmse_per_class: [0.081, 0.231, 0.034, 0.28, 0.059, 0.165, 0.212, 0.114, 0.141, 0.095]
[2m[36m(func pid=19271)[0m 
== Status ==
Current time: 2024-01-07 09:17:24 (running for 00:45:25.51)
Memory usage on this node: 19.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.237 |  0.141 |                   42 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.229 |  0.141 |                   36 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14068642258644104
[2m[36m(func pid=20925)[0m mae:  0.08856455236673355
[2m[36m(func pid=20925)[0m rmse_per_class: [0.084, 0.219, 0.028, 0.297, 0.072, 0.153, 0.195, 0.111, 0.164, 0.084]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.2350 | Steps: 2 | Val loss: 0.2792 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.2361 | Steps: 2 | Val loss: 0.2636 | Batch size: 32 | lr: 0.1 | Duration: 3.02s
[2m[36m(func pid=19271)[0m rmse: 0.14121538400650024
[2m[36m(func pid=19271)[0m mae:  0.09432341158390045
[2m[36m(func pid=19271)[0m rmse_per_class: [0.082, 0.232, 0.034, 0.28, 0.059, 0.165, 0.212, 0.113, 0.141, 0.095]
[2m[36m(func pid=19271)[0m 
== Status ==
Current time: 2024-01-07 09:17:30 (running for 00:45:30.95)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.235 |  0.141 |                   43 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.236 |  0.14  |                   37 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14016631245613098
[2m[36m(func pid=20925)[0m mae:  0.08799885213375092
[2m[36m(func pid=20925)[0m rmse_per_class: [0.073, 0.22, 0.027, 0.295, 0.068, 0.155, 0.196, 0.114, 0.168, 0.085]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.2355 | Steps: 2 | Val loss: 0.2801 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.2310 | Steps: 2 | Val loss: 0.2649 | Batch size: 32 | lr: 0.1 | Duration: 3.03s
[2m[36m(func pid=19271)[0m rmse: 0.14167270064353943
[2m[36m(func pid=19271)[0m mae:  0.09467894583940506
[2m[36m(func pid=19271)[0m rmse_per_class: [0.083, 0.232, 0.034, 0.282, 0.059, 0.165, 0.212, 0.113, 0.141, 0.096]
[2m[36m(func pid=19271)[0m 
== Status ==
Current time: 2024-01-07 09:17:35 (running for 00:45:36.32)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.235 |  0.142 |                   44 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.231 |  0.141 |                   38 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.1409982293844223
[2m[36m(func pid=20925)[0m mae:  0.08846050500869751
[2m[36m(func pid=20925)[0m rmse_per_class: [0.07, 0.22, 0.027, 0.295, 0.071, 0.155, 0.198, 0.115, 0.172, 0.086]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.2341 | Steps: 2 | Val loss: 0.2804 | Batch size: 32 | lr: 0.01 | Duration: 3.05s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.2328 | Steps: 2 | Val loss: 0.2667 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=19271)[0m rmse: 0.14175374805927277
[2m[36m(func pid=19271)[0m mae:  0.09459324181079865
[2m[36m(func pid=19271)[0m rmse_per_class: [0.083, 0.232, 0.035, 0.283, 0.058, 0.165, 0.211, 0.114, 0.141, 0.095]
[2m[36m(func pid=19271)[0m 
== Status ==
Current time: 2024-01-07 09:17:40 (running for 00:45:41.67)
Memory usage on this node: 19.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.234 |  0.142 |                   45 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.233 |  0.141 |                   39 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
[2m[36m(func pid=20925)[0m rmse: 0.14149390161037445

[2m[36m(func pid=20925)[0m mae:  0.08879297971725464
[2m[36m(func pid=20925)[0m rmse_per_class: [0.071, 0.221, 0.028, 0.287, 0.074, 0.155, 0.198, 0.118, 0.177, 0.086]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.2393 | Steps: 2 | Val loss: 0.2809 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.2337 | Steps: 2 | Val loss: 0.2683 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=19271)[0m rmse: 0.14200091361999512
[2m[36m(func pid=19271)[0m mae:  0.09469278156757355
[2m[36m(func pid=19271)[0m rmse_per_class: [0.083, 0.232, 0.034, 0.285, 0.058, 0.165, 0.211, 0.114, 0.142, 0.096]
[2m[36m(func pid=19271)[0m 
== Status ==
Current time: 2024-01-07 09:17:46 (running for 00:45:46.94)
Memory usage on this node: 19.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.239 |  0.142 |                   46 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.234 |  0.142 |                   40 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14206281304359436
[2m[36m(func pid=20925)[0m mae:  0.08946973830461502
[2m[36m(func pid=20925)[0m rmse_per_class: [0.075, 0.225, 0.029, 0.281, 0.078, 0.155, 0.2, 0.115, 0.175, 0.087]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.2382 | Steps: 2 | Val loss: 0.2805 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.2329 | Steps: 2 | Val loss: 0.2683 | Batch size: 32 | lr: 0.1 | Duration: 3.12s
[2m[36m(func pid=19271)[0m rmse: 0.14218977093696594
[2m[36m(func pid=19271)[0m mae:  0.09468570351600647
[2m[36m(func pid=19271)[0m rmse_per_class: [0.082, 0.232, 0.034, 0.287, 0.058, 0.165, 0.211, 0.116, 0.142, 0.095]
[2m[36m(func pid=19271)[0m 
== Status ==
Current time: 2024-01-07 09:17:51 (running for 00:45:52.71)
Memory usage on this node: 19.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.238 |  0.142 |                   47 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.233 |  0.142 |                   41 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.1421545296907425
[2m[36m(func pid=20925)[0m mae:  0.08963329344987869
[2m[36m(func pid=20925)[0m rmse_per_class: [0.082, 0.224, 0.03, 0.287, 0.077, 0.155, 0.199, 0.111, 0.173, 0.084]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.2335 | Steps: 2 | Val loss: 0.2803 | Batch size: 32 | lr: 0.01 | Duration: 3.12s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.2297 | Steps: 2 | Val loss: 0.2658 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=19271)[0m rmse: 0.14230825006961823
[2m[36m(func pid=19271)[0m mae:  0.0947316363453865
[2m[36m(func pid=19271)[0m rmse_per_class: [0.082, 0.231, 0.035, 0.289, 0.058, 0.165, 0.211, 0.115, 0.141, 0.096]
[2m[36m(func pid=19271)[0m 
== Status ==
Current time: 2024-01-07 09:17:57 (running for 00:45:58.22)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.233 |  0.142 |                   48 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.23  |  0.141 |                   42 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14108313620090485
[2m[36m(func pid=20925)[0m mae:  0.08873001486063004
[2m[36m(func pid=20925)[0m rmse_per_class: [0.078, 0.22, 0.029, 0.291, 0.075, 0.155, 0.196, 0.11, 0.173, 0.083]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.2423 | Steps: 2 | Val loss: 0.2801 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.2342 | Steps: 2 | Val loss: 0.2630 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=19271)[0m rmse: 0.1423463076353073
[2m[36m(func pid=19271)[0m mae:  0.09463880956172943
[2m[36m(func pid=19271)[0m rmse_per_class: [0.082, 0.231, 0.035, 0.287, 0.058, 0.165, 0.21, 0.115, 0.143, 0.097]
[2m[36m(func pid=19271)[0m 
== Status ==
Current time: 2024-01-07 09:18:02 (running for 00:46:03.44)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.242 |  0.142 |                   49 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.234 |  0.14  |                   43 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.13992197811603546
[2m[36m(func pid=20925)[0m mae:  0.08765823394060135
[2m[36m(func pid=20925)[0m rmse_per_class: [0.072, 0.219, 0.029, 0.286, 0.074, 0.155, 0.196, 0.111, 0.176, 0.082]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.2281 | Steps: 2 | Val loss: 0.2783 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.2319 | Steps: 2 | Val loss: 0.2655 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
[2m[36m(func pid=19271)[0m rmse: 0.14186429977416992
[2m[36m(func pid=19271)[0m mae:  0.09430184960365295
[2m[36m(func pid=19271)[0m rmse_per_class: [0.083, 0.23, 0.035, 0.285, 0.058, 0.164, 0.21, 0.115, 0.143, 0.095]
[2m[36m(func pid=19271)[0m 
== Status ==
Current time: 2024-01-07 09:18:08 (running for 00:46:08.96)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.228 |  0.142 |                   50 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.232 |  0.142 |                   44 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14158429205417633
[2m[36m(func pid=20925)[0m mae:  0.08896519243717194
[2m[36m(func pid=20925)[0m rmse_per_class: [0.073, 0.222, 0.029, 0.283, 0.076, 0.155, 0.197, 0.113, 0.186, 0.083]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.2345 | Steps: 2 | Val loss: 0.2772 | Batch size: 32 | lr: 0.01 | Duration: 3.15s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.2327 | Steps: 2 | Val loss: 0.2711 | Batch size: 32 | lr: 0.1 | Duration: 3.01s
[2m[36m(func pid=19271)[0m rmse: 0.14145806431770325
[2m[36m(func pid=19271)[0m mae:  0.09396182745695114
[2m[36m(func pid=19271)[0m rmse_per_class: [0.082, 0.229, 0.035, 0.284, 0.058, 0.164, 0.21, 0.115, 0.143, 0.095]
[2m[36m(func pid=19271)[0m 
== Status ==
Current time: 2024-01-07 09:18:13 (running for 00:46:14.51)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.235 |  0.141 |                   51 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.233 |  0.144 |                   45 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.1444258987903595
[2m[36m(func pid=20925)[0m mae:  0.09115888923406601
[2m[36m(func pid=20925)[0m rmse_per_class: [0.075, 0.225, 0.029, 0.293, 0.077, 0.156, 0.199, 0.117, 0.19, 0.083]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.2334 | Steps: 2 | Val loss: 0.2769 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.2318 | Steps: 2 | Val loss: 0.2742 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=19271)[0m rmse: 0.1411224901676178
[2m[36m(func pid=19271)[0m mae:  0.09375312924385071
[2m[36m(func pid=19271)[0m rmse_per_class: [0.081, 0.229, 0.035, 0.282, 0.058, 0.164, 0.21, 0.114, 0.143, 0.095]
[2m[36m(func pid=19271)[0m 
== Status ==
Current time: 2024-01-07 09:18:19 (running for 00:46:19.89)
Memory usage on this node: 19.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.233 |  0.141 |                   52 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.232 |  0.146 |                   46 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14552226662635803
[2m[36m(func pid=20925)[0m mae:  0.09255556762218475
[2m[36m(func pid=20925)[0m rmse_per_class: [0.083, 0.226, 0.03, 0.307, 0.076, 0.157, 0.198, 0.114, 0.179, 0.085]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.2349 | Steps: 2 | Val loss: 0.2768 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.2336 | Steps: 2 | Val loss: 0.2765 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
[2m[36m(func pid=19271)[0m rmse: 0.14087843894958496
[2m[36m(func pid=19271)[0m mae:  0.0936364009976387
[2m[36m(func pid=19271)[0m rmse_per_class: [0.081, 0.23, 0.035, 0.278, 0.057, 0.163, 0.211, 0.113, 0.144, 0.095]
[2m[36m(func pid=19271)[0m 
== Status ==
Current time: 2024-01-07 09:18:24 (running for 00:46:25.24)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.235 |  0.141 |                   53 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.234 |  0.146 |                   47 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14635172486305237
[2m[36m(func pid=20925)[0m mae:  0.09341229498386383
[2m[36m(func pid=20925)[0m rmse_per_class: [0.089, 0.225, 0.03, 0.319, 0.077, 0.157, 0.197, 0.112, 0.169, 0.088]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.2368 | Steps: 2 | Val loss: 0.2773 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.2286 | Steps: 2 | Val loss: 0.2744 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=19271)[0m rmse: 0.14065337181091309
[2m[36m(func pid=19271)[0m mae:  0.09345810860395432
[2m[36m(func pid=19271)[0m rmse_per_class: [0.081, 0.23, 0.035, 0.277, 0.058, 0.163, 0.211, 0.112, 0.146, 0.095]
[2m[36m(func pid=19271)[0m 
== Status ==
Current time: 2024-01-07 09:18:29 (running for 00:46:30.60)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.237 |  0.141 |                   54 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.229 |  0.146 |                   48 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14561140537261963
[2m[36m(func pid=20925)[0m mae:  0.09280262887477875
[2m[36m(func pid=20925)[0m rmse_per_class: [0.093, 0.222, 0.03, 0.319, 0.08, 0.157, 0.196, 0.112, 0.162, 0.087]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.2338 | Steps: 2 | Val loss: 0.2777 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.2309 | Steps: 2 | Val loss: 0.2697 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=19271)[0m rmse: 0.1406365931034088
[2m[36m(func pid=19271)[0m mae:  0.0933430939912796
[2m[36m(func pid=19271)[0m rmse_per_class: [0.08, 0.23, 0.035, 0.277, 0.057, 0.163, 0.21, 0.112, 0.146, 0.095]
[2m[36m(func pid=19271)[0m 
== Status ==
Current time: 2024-01-07 09:18:34 (running for 00:46:35.87)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.234 |  0.141 |                   55 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.231 |  0.143 |                   49 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14323581755161285
[2m[36m(func pid=20925)[0m mae:  0.09089745581150055
[2m[36m(func pid=20925)[0m rmse_per_class: [0.084, 0.22, 0.03, 0.307, 0.083, 0.156, 0.195, 0.11, 0.163, 0.085]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.2316 | Steps: 2 | Val loss: 0.2780 | Batch size: 32 | lr: 0.01 | Duration: 3.09s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.2361 | Steps: 2 | Val loss: 0.2662 | Batch size: 32 | lr: 0.1 | Duration: 3.05s
[2m[36m(func pid=19271)[0m rmse: 0.14056150615215302
[2m[36m(func pid=19271)[0m mae:  0.09328167140483856
[2m[36m(func pid=19271)[0m rmse_per_class: [0.08, 0.23, 0.035, 0.276, 0.058, 0.163, 0.21, 0.112, 0.147, 0.095]
[2m[36m(func pid=19271)[0m 
== Status ==
Current time: 2024-01-07 09:18:40 (running for 00:46:41.33)
Memory usage on this node: 19.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.232 |  0.141 |                   56 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.236 |  0.141 |                   50 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14128831028938293
[2m[36m(func pid=20925)[0m mae:  0.08920370042324066
[2m[36m(func pid=20925)[0m rmse_per_class: [0.076, 0.218, 0.03, 0.297, 0.081, 0.155, 0.194, 0.107, 0.17, 0.084]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.2445 | Steps: 2 | Val loss: 0.2778 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.2275 | Steps: 2 | Val loss: 0.2661 | Batch size: 32 | lr: 0.1 | Duration: 2.98s
[2m[36m(func pid=19271)[0m rmse: 0.14017300307750702
[2m[36m(func pid=19271)[0m mae:  0.09279777109622955
[2m[36m(func pid=19271)[0m rmse_per_class: [0.079, 0.231, 0.035, 0.273, 0.057, 0.163, 0.209, 0.113, 0.146, 0.097]
[2m[36m(func pid=19271)[0m 
== Status ==
Current time: 2024-01-07 09:18:45 (running for 00:46:46.79)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.245 |  0.14  |                   57 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.228 |  0.142 |                   51 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14165152609348297
[2m[36m(func pid=20925)[0m mae:  0.08943799883127213
[2m[36m(func pid=20925)[0m rmse_per_class: [0.073, 0.218, 0.029, 0.302, 0.078, 0.155, 0.195, 0.108, 0.175, 0.083]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.2363 | Steps: 2 | Val loss: 0.2775 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.2355 | Steps: 2 | Val loss: 0.2691 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=19271)[0m rmse: 0.13998554646968842
[2m[36m(func pid=19271)[0m mae:  0.09266756474971771
[2m[36m(func pid=19271)[0m rmse_per_class: [0.08, 0.23, 0.035, 0.274, 0.056, 0.163, 0.208, 0.112, 0.145, 0.097]
[2m[36m(func pid=19271)[0m 
== Status ==
Current time: 2024-01-07 09:18:51 (running for 00:46:52.03)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.236 |  0.14  |                   58 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.235 |  0.144 |                   52 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.143602654337883
[2m[36m(func pid=20925)[0m mae:  0.09065817296504974
[2m[36m(func pid=20925)[0m rmse_per_class: [0.073, 0.219, 0.029, 0.306, 0.078, 0.155, 0.196, 0.114, 0.182, 0.084]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.2380 | Steps: 2 | Val loss: 0.2780 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.2300 | Steps: 2 | Val loss: 0.2691 | Batch size: 32 | lr: 0.1 | Duration: 3.05s
[2m[36m(func pid=19271)[0m rmse: 0.140179842710495
[2m[36m(func pid=19271)[0m mae:  0.09274567663669586
[2m[36m(func pid=19271)[0m rmse_per_class: [0.079, 0.231, 0.034, 0.276, 0.057, 0.163, 0.208, 0.113, 0.144, 0.097]
[2m[36m(func pid=19271)[0m 
== Status ==
Current time: 2024-01-07 09:18:56 (running for 00:46:57.35)
Memory usage on this node: 19.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.238 |  0.14  |                   59 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.23  |  0.144 |                   53 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14364033937454224
[2m[36m(func pid=20925)[0m mae:  0.09102600067853928
[2m[36m(func pid=20925)[0m rmse_per_class: [0.074, 0.219, 0.029, 0.3, 0.082, 0.155, 0.199, 0.115, 0.179, 0.084]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.2436 | Steps: 2 | Val loss: 0.2785 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.2332 | Steps: 2 | Val loss: 0.2698 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
[2m[36m(func pid=19271)[0m rmse: 0.14049604535102844
[2m[36m(func pid=19271)[0m mae:  0.09304400533437729
[2m[36m(func pid=19271)[0m rmse_per_class: [0.081, 0.231, 0.033, 0.279, 0.057, 0.163, 0.207, 0.112, 0.144, 0.098]
[2m[36m(func pid=19271)[0m 
== Status ==
Current time: 2024-01-07 09:19:01 (running for 00:47:02.85)
Memory usage on this node: 19.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.244 |  0.14  |                   60 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.233 |  0.144 |                   54 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14368779957294464
[2m[36m(func pid=20925)[0m mae:  0.0911695584654808
[2m[36m(func pid=20925)[0m rmse_per_class: [0.078, 0.219, 0.029, 0.301, 0.086, 0.156, 0.198, 0.11, 0.174, 0.085]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.2321 | Steps: 2 | Val loss: 0.2789 | Batch size: 32 | lr: 0.01 | Duration: 3.28s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.2326 | Steps: 2 | Val loss: 0.2679 | Batch size: 32 | lr: 0.1 | Duration: 3.08s
[2m[36m(func pid=19271)[0m rmse: 0.14101409912109375
[2m[36m(func pid=19271)[0m mae:  0.0934211015701294
[2m[36m(func pid=19271)[0m rmse_per_class: [0.083, 0.231, 0.034, 0.284, 0.057, 0.163, 0.206, 0.112, 0.142, 0.098]
[2m[36m(func pid=19271)[0m 
== Status ==
Current time: 2024-01-07 09:19:07 (running for 00:47:08.18)
Memory usage on this node: 19.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.232 |  0.141 |                   61 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.233 |  0.143 |                   55 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14267531037330627
[2m[36m(func pid=20925)[0m mae:  0.09022768586874008
[2m[36m(func pid=20925)[0m rmse_per_class: [0.079, 0.22, 0.03, 0.298, 0.082, 0.156, 0.198, 0.108, 0.168, 0.087]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.2390 | Steps: 2 | Val loss: 0.2794 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.2308 | Steps: 2 | Val loss: 0.2691 | Batch size: 32 | lr: 0.1 | Duration: 3.08s
[2m[36m(func pid=19271)[0m rmse: 0.1413596272468567
[2m[36m(func pid=19271)[0m mae:  0.09359867870807648
[2m[36m(func pid=19271)[0m rmse_per_class: [0.083, 0.231, 0.034, 0.286, 0.057, 0.163, 0.206, 0.114, 0.143, 0.097]
[2m[36m(func pid=19271)[0m 
== Status ==
Current time: 2024-01-07 09:19:12 (running for 00:47:13.64)
Memory usage on this node: 19.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.239 |  0.141 |                   62 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.231 |  0.143 |                   56 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14309516549110413
[2m[36m(func pid=20925)[0m mae:  0.09088501334190369
[2m[36m(func pid=20925)[0m rmse_per_class: [0.077, 0.221, 0.029, 0.304, 0.081, 0.155, 0.198, 0.109, 0.168, 0.088]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.2319 | Steps: 2 | Val loss: 0.2793 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.2346 | Steps: 2 | Val loss: 0.2715 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=19271)[0m rmse: 0.14119988679885864
[2m[36m(func pid=19271)[0m mae:  0.09340153634548187
[2m[36m(func pid=19271)[0m rmse_per_class: [0.082, 0.231, 0.034, 0.285, 0.057, 0.164, 0.206, 0.115, 0.142, 0.096]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=20925)[0m rmse: 0.1439148485660553
[2m[36m(func pid=20925)[0m mae:  0.09136857092380524
[2m[36m(func pid=20925)[0m rmse_per_class: [0.075, 0.222, 0.027, 0.309, 0.08, 0.155, 0.199, 0.112, 0.175, 0.086]
== Status ==
Current time: 2024-01-07 09:19:17 (running for 00:47:18.81)
Memory usage on this node: 19.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.232 |  0.141 |                   63 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.235 |  0.144 |                   57 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.2316 | Steps: 2 | Val loss: 0.2799 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.2331 | Steps: 2 | Val loss: 0.2728 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=19271)[0m rmse: 0.14123813807964325
[2m[36m(func pid=19271)[0m mae:  0.09350806474685669
[2m[36m(func pid=19271)[0m rmse_per_class: [0.081, 0.231, 0.034, 0.286, 0.057, 0.164, 0.207, 0.115, 0.142, 0.096]
[2m[36m(func pid=19271)[0m 
== Status ==
Current time: 2024-01-07 09:19:23 (running for 00:47:24.18)
Memory usage on this node: 19.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.232 |  0.141 |                   64 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.233 |  0.145 |                   58 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14457985758781433
[2m[36m(func pid=20925)[0m mae:  0.0917869284749031
[2m[36m(func pid=20925)[0m rmse_per_class: [0.076, 0.224, 0.027, 0.314, 0.079, 0.155, 0.198, 0.113, 0.175, 0.085]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.2353 | Steps: 2 | Val loss: 0.2802 | Batch size: 32 | lr: 0.01 | Duration: 3.22s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.2342 | Steps: 2 | Val loss: 0.2710 | Batch size: 32 | lr: 0.1 | Duration: 3.01s
== Status ==
Current time: 2024-01-07 09:19:28 (running for 00:47:29.21)
Memory usage on this node: 19.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.232 |  0.141 |                   64 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.233 |  0.145 |                   58 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=19271)[0m rmse: 0.1412101536989212
[2m[36m(func pid=19271)[0m mae:  0.0935056135058403
[2m[36m(func pid=19271)[0m rmse_per_class: [0.08, 0.231, 0.034, 0.285, 0.057, 0.164, 0.208, 0.115, 0.141, 0.097]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=20925)[0m rmse: 0.14399337768554688
[2m[36m(func pid=20925)[0m mae:  0.09089192003011703
[2m[36m(func pid=20925)[0m rmse_per_class: [0.075, 0.225, 0.028, 0.309, 0.076, 0.155, 0.194, 0.114, 0.179, 0.084]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.2324 | Steps: 2 | Val loss: 0.2706 | Batch size: 32 | lr: 0.1 | Duration: 3.06s
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.2286 | Steps: 2 | Val loss: 0.2809 | Batch size: 32 | lr: 0.01 | Duration: 3.17s
== Status ==
Current time: 2024-01-07 09:19:33 (running for 00:47:34.54)
Memory usage on this node: 19.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.235 |  0.141 |                   65 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.234 |  0.144 |                   59 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14347775280475616
[2m[36m(func pid=20925)[0m mae:  0.0902659147977829
[2m[36m(func pid=20925)[0m rmse_per_class: [0.074, 0.225, 0.03, 0.307, 0.074, 0.155, 0.193, 0.113, 0.179, 0.085]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m rmse: 0.1414460688829422
[2m[36m(func pid=19271)[0m mae:  0.09370376169681549
[2m[36m(func pid=19271)[0m rmse_per_class: [0.081, 0.231, 0.034, 0.285, 0.056, 0.164, 0.209, 0.116, 0.14, 0.099]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.2330 | Steps: 2 | Val loss: 0.2700 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.2344 | Steps: 2 | Val loss: 0.2816 | Batch size: 32 | lr: 0.01 | Duration: 3.11s
== Status ==
Current time: 2024-01-07 09:19:39 (running for 00:47:40.19)
Memory usage on this node: 19.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.229 |  0.141 |                   66 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.232 |  0.143 |                   60 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14275246858596802
[2m[36m(func pid=20925)[0m mae:  0.0898863822221756
[2m[36m(func pid=20925)[0m rmse_per_class: [0.076, 0.226, 0.031, 0.301, 0.077, 0.155, 0.192, 0.107, 0.175, 0.087]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m rmse: 0.14144489169120789
[2m[36m(func pid=19271)[0m mae:  0.09366551041603088
[2m[36m(func pid=19271)[0m rmse_per_class: [0.083, 0.231, 0.034, 0.283, 0.056, 0.163, 0.209, 0.115, 0.141, 0.099]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.2295 | Steps: 2 | Val loss: 0.2699 | Batch size: 32 | lr: 0.1 | Duration: 3.14s
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.2391 | Steps: 2 | Val loss: 0.2824 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
== Status ==
Current time: 2024-01-07 09:19:44 (running for 00:47:45.78)
Memory usage on this node: 19.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.234 |  0.141 |                   67 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.233 |  0.143 |                   61 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=19271)[0m rmse: 0.14149722456932068
[2m[36m(func pid=19271)[0m mae:  0.09381001442670822
[2m[36m(func pid=19271)[0m rmse_per_class: [0.082, 0.231, 0.035, 0.281, 0.056, 0.163, 0.21, 0.114, 0.141, 0.102]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=20925)[0m rmse: 0.1427767276763916
[2m[36m(func pid=20925)[0m mae:  0.0903903990983963
[2m[36m(func pid=20925)[0m rmse_per_class: [0.08, 0.227, 0.03, 0.3, 0.077, 0.155, 0.194, 0.106, 0.167, 0.089]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.2306 | Steps: 2 | Val loss: 0.2830 | Batch size: 32 | lr: 0.01 | Duration: 3.07s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.2397 | Steps: 2 | Val loss: 0.2697 | Batch size: 32 | lr: 0.1 | Duration: 3.09s
== Status ==
Current time: 2024-01-07 09:19:50 (running for 00:47:51.16)
Memory usage on this node: 19.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.239 |  0.141 |                   68 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.23  |  0.143 |                   62 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=19271)[0m rmse: 0.14174620807170868
[2m[36m(func pid=19271)[0m mae:  0.09400410950183868
[2m[36m(func pid=19271)[0m rmse_per_class: [0.083, 0.23, 0.035, 0.283, 0.056, 0.163, 0.211, 0.114, 0.141, 0.102]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=20925)[0m rmse: 0.1430637538433075
[2m[36m(func pid=20925)[0m mae:  0.09091626852750778
[2m[36m(func pid=20925)[0m rmse_per_class: [0.083, 0.227, 0.03, 0.301, 0.077, 0.155, 0.195, 0.106, 0.166, 0.091]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.2287 | Steps: 2 | Val loss: 0.2692 | Batch size: 32 | lr: 0.1 | Duration: 2.98s
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.2315 | Steps: 2 | Val loss: 0.2826 | Batch size: 32 | lr: 0.01 | Duration: 3.14s
== Status ==
Current time: 2024-01-07 09:19:55 (running for 00:47:56.60)
Memory usage on this node: 19.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.231 |  0.142 |                   69 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.24  |  0.143 |                   63 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14295607805252075
[2m[36m(func pid=20925)[0m mae:  0.09090171009302139
[2m[36m(func pid=20925)[0m rmse_per_class: [0.081, 0.226, 0.029, 0.308, 0.073, 0.154, 0.195, 0.108, 0.167, 0.089]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m rmse: 0.14175893366336823
[2m[36m(func pid=19271)[0m mae:  0.0940149649977684
[2m[36m(func pid=19271)[0m rmse_per_class: [0.085, 0.23, 0.035, 0.284, 0.056, 0.164, 0.21, 0.113, 0.141, 0.1]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.2444 | Steps: 2 | Val loss: 0.2819 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.2308 | Steps: 2 | Val loss: 0.2703 | Batch size: 32 | lr: 0.1 | Duration: 3.01s
== Status ==
Current time: 2024-01-07 09:20:01 (running for 00:48:02.26)
Memory usage on this node: 19.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.232 |  0.142 |                   70 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.229 |  0.143 |                   64 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14358389377593994
[2m[36m(func pid=20925)[0m mae:  0.09121868759393692
[2m[36m(func pid=20925)[0m rmse_per_class: [0.073, 0.226, 0.029, 0.313, 0.071, 0.155, 0.196, 0.113, 0.17, 0.089]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m rmse: 0.14131735265254974
[2m[36m(func pid=19271)[0m mae:  0.09350700676441193
[2m[36m(func pid=19271)[0m rmse_per_class: [0.084, 0.23, 0.035, 0.283, 0.055, 0.163, 0.208, 0.112, 0.143, 0.099]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.2324 | Steps: 2 | Val loss: 0.2686 | Batch size: 32 | lr: 0.1 | Duration: 3.02s
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.2390 | Steps: 2 | Val loss: 0.2805 | Batch size: 32 | lr: 0.01 | Duration: 3.05s
== Status ==
Current time: 2024-01-07 09:20:06 (running for 00:48:07.82)
Memory usage on this node: 19.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.244 |  0.141 |                   71 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.231 |  0.144 |                   65 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.1429290473461151
[2m[36m(func pid=20925)[0m mae:  0.09046251326799393
[2m[36m(func pid=20925)[0m rmse_per_class: [0.072, 0.225, 0.03, 0.305, 0.069, 0.154, 0.196, 0.113, 0.177, 0.087]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m rmse: 0.14063143730163574
[2m[36m(func pid=19271)[0m mae:  0.09270556271076202
[2m[36m(func pid=19271)[0m rmse_per_class: [0.08, 0.229, 0.035, 0.283, 0.055, 0.163, 0.206, 0.113, 0.142, 0.099]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.2263 | Steps: 2 | Val loss: 0.2684 | Batch size: 32 | lr: 0.1 | Duration: 3.02s
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.2304 | Steps: 2 | Val loss: 0.2794 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 09:20:12 (running for 00:48:13.28)
Memory usage on this node: 19.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.239 |  0.141 |                   72 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.226 |  0.142 |                   67 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.1424422711133957
[2m[36m(func pid=20925)[0m mae:  0.09032759815454483
[2m[36m(func pid=20925)[0m rmse_per_class: [0.074, 0.224, 0.03, 0.301, 0.071, 0.154, 0.197, 0.112, 0.175, 0.086]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m rmse: 0.14062687754631042
[2m[36m(func pid=19271)[0m mae:  0.09276969730854034
[2m[36m(func pid=19271)[0m rmse_per_class: [0.082, 0.229, 0.035, 0.284, 0.055, 0.163, 0.206, 0.113, 0.143, 0.097]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.2317 | Steps: 2 | Val loss: 0.2673 | Batch size: 32 | lr: 0.1 | Duration: 3.01s
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.2315 | Steps: 2 | Val loss: 0.2784 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
== Status ==
Current time: 2024-01-07 09:20:17 (running for 00:48:18.50)
Memory usage on this node: 19.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.23  |  0.141 |                   73 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.226 |  0.142 |                   67 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14152619242668152
[2m[36m(func pid=20925)[0m mae:  0.0897398293018341
[2m[36m(func pid=20925)[0m rmse_per_class: [0.078, 0.224, 0.029, 0.292, 0.072, 0.154, 0.197, 0.11, 0.172, 0.086]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m rmse: 0.14041611552238464
[2m[36m(func pid=19271)[0m mae:  0.09261808544397354
[2m[36m(func pid=19271)[0m rmse_per_class: [0.082, 0.229, 0.035, 0.282, 0.055, 0.163, 0.205, 0.112, 0.145, 0.096]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.2331 | Steps: 2 | Val loss: 0.2686 | Batch size: 32 | lr: 0.1 | Duration: 3.14s
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.2302 | Steps: 2 | Val loss: 0.2772 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 09:20:23 (running for 00:48:23.98)
Memory usage on this node: 19.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15675000473856926
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.232 |  0.14  |                   74 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.232 |  0.142 |                   68 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=19271)[0m rmse: 0.1398564875125885
[2m[36m(func pid=19271)[0m mae:  0.09210839867591858
[2m[36m(func pid=19271)[0m rmse_per_class: [0.082, 0.229, 0.035, 0.279, 0.056, 0.162, 0.205, 0.111, 0.145, 0.094]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=20925)[0m rmse: 0.14250102639198303
[2m[36m(func pid=20925)[0m mae:  0.09040902554988861
[2m[36m(func pid=20925)[0m rmse_per_class: [0.085, 0.226, 0.029, 0.297, 0.072, 0.155, 0.196, 0.109, 0.172, 0.085]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 75] | Train loss: 0.2324 | Steps: 2 | Val loss: 0.2764 | Batch size: 32 | lr: 0.01 | Duration: 3.10s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.2345 | Steps: 2 | Val loss: 0.2676 | Batch size: 32 | lr: 0.1 | Duration: 3.07s
== Status ==
Current time: 2024-01-07 09:20:28 (running for 00:48:29.29)
Memory usage on this node: 19.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.23  |  0.14  |                   75 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.233 |  0.143 |                   69 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=19271)[0m rmse: 0.1394205093383789
[2m[36m(func pid=19271)[0m mae:  0.09175457805395126
[2m[36m(func pid=19271)[0m rmse_per_class: [0.082, 0.228, 0.035, 0.277, 0.055, 0.162, 0.205, 0.112, 0.144, 0.094]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=20925)[0m rmse: 0.14220033586025238
[2m[36m(func pid=20925)[0m mae:  0.0900593250989914
[2m[36m(func pid=20925)[0m rmse_per_class: [0.081, 0.224, 0.028, 0.301, 0.074, 0.155, 0.195, 0.11, 0.169, 0.085]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.2279 | Steps: 2 | Val loss: 0.2672 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 76] | Train loss: 0.2350 | Steps: 2 | Val loss: 0.2771 | Batch size: 32 | lr: 0.01 | Duration: 3.07s
== Status ==
Current time: 2024-01-07 09:20:33 (running for 00:48:34.87)
Memory usage on this node: 19.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.232 |  0.139 |                   76 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.235 |  0.142 |                   70 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14231058955192566
[2m[36m(func pid=20925)[0m mae:  0.09026030451059341
[2m[36m(func pid=20925)[0m rmse_per_class: [0.076, 0.222, 0.028, 0.306, 0.077, 0.156, 0.196, 0.112, 0.164, 0.085]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m rmse: 0.13953588902950287
[2m[36m(func pid=19271)[0m mae:  0.09181348979473114
[2m[36m(func pid=19271)[0m rmse_per_class: [0.081, 0.229, 0.035, 0.276, 0.056, 0.163, 0.205, 0.112, 0.144, 0.095]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.2321 | Steps: 2 | Val loss: 0.2684 | Batch size: 32 | lr: 0.1 | Duration: 3.06s
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 77] | Train loss: 0.2336 | Steps: 2 | Val loss: 0.2782 | Batch size: 32 | lr: 0.01 | Duration: 3.07s
== Status ==
Current time: 2024-01-07 09:20:39 (running for 00:48:40.53)
Memory usage on this node: 19.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.235 |  0.14  |                   77 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.228 |  0.142 |                   71 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.1426781713962555
[2m[36m(func pid=20925)[0m mae:  0.09045641124248505
[2m[36m(func pid=20925)[0m rmse_per_class: [0.074, 0.222, 0.029, 0.305, 0.077, 0.156, 0.197, 0.114, 0.166, 0.088]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m rmse: 0.13970494270324707
[2m[36m(func pid=19271)[0m mae:  0.09199152886867523
[2m[36m(func pid=19271)[0m rmse_per_class: [0.081, 0.229, 0.035, 0.278, 0.055, 0.163, 0.205, 0.112, 0.142, 0.097]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 78] | Train loss: 0.2380 | Steps: 2 | Val loss: 0.2793 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.2291 | Steps: 2 | Val loss: 0.2694 | Batch size: 32 | lr: 0.1 | Duration: 3.02s
== Status ==
Current time: 2024-01-07 09:20:45 (running for 00:48:46.02)
Memory usage on this node: 19.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.234 |  0.14  |                   78 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.232 |  0.143 |                   72 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14293557405471802
[2m[36m(func pid=20925)[0m mae:  0.09066561609506607
[2m[36m(func pid=20925)[0m rmse_per_class: [0.075, 0.223, 0.03, 0.306, 0.078, 0.156, 0.196, 0.112, 0.166, 0.089]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m rmse: 0.13998426496982574
[2m[36m(func pid=19271)[0m mae:  0.09224238246679306
[2m[36m(func pid=19271)[0m rmse_per_class: [0.082, 0.229, 0.034, 0.278, 0.055, 0.163, 0.205, 0.113, 0.143, 0.098]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.2352 | Steps: 2 | Val loss: 0.2687 | Batch size: 32 | lr: 0.1 | Duration: 2.99s
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 79] | Train loss: 0.2331 | Steps: 2 | Val loss: 0.2789 | Batch size: 32 | lr: 0.01 | Duration: 3.08s
== Status ==
Current time: 2024-01-07 09:20:50 (running for 00:48:51.58)
Memory usage on this node: 19.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.238 |  0.14  |                   79 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.229 |  0.143 |                   73 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14235980808734894
[2m[36m(func pid=20925)[0m mae:  0.09020661562681198
[2m[36m(func pid=20925)[0m rmse_per_class: [0.077, 0.223, 0.029, 0.302, 0.074, 0.156, 0.195, 0.11, 0.166, 0.089]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m rmse: 0.13974878191947937
[2m[36m(func pid=19271)[0m mae:  0.09207655489444733
[2m[36m(func pid=19271)[0m rmse_per_class: [0.082, 0.229, 0.034, 0.278, 0.055, 0.163, 0.205, 0.113, 0.142, 0.097]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.2343 | Steps: 2 | Val loss: 0.2690 | Batch size: 32 | lr: 0.1 | Duration: 3.02s
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 80] | Train loss: 0.2371 | Steps: 2 | Val loss: 0.2803 | Batch size: 32 | lr: 0.01 | Duration: 3.06s
== Status ==
Current time: 2024-01-07 09:20:56 (running for 00:48:57.30)
Memory usage on this node: 19.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.15600000321865082
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.233 |  0.14  |                   80 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.235 |  0.142 |                   74 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14274872839450836
[2m[36m(func pid=20925)[0m mae:  0.09058539569377899
[2m[36m(func pid=20925)[0m rmse_per_class: [0.081, 0.224, 0.029, 0.302, 0.075, 0.156, 0.195, 0.109, 0.169, 0.088]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m rmse: 0.14029647409915924
[2m[36m(func pid=19271)[0m mae:  0.0925447940826416
[2m[36m(func pid=19271)[0m rmse_per_class: [0.082, 0.229, 0.034, 0.28, 0.055, 0.164, 0.206, 0.113, 0.143, 0.097]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 75] | Train loss: 0.2285 | Steps: 2 | Val loss: 0.2669 | Batch size: 32 | lr: 0.1 | Duration: 3.11s
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 81] | Train loss: 0.2298 | Steps: 2 | Val loss: 0.2797 | Batch size: 32 | lr: 0.01 | Duration: 3.05s
== Status ==
Current time: 2024-01-07 09:21:01 (running for 00:49:02.72)
Memory usage on this node: 19.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.14774999767541885
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.237 |  0.14  |                   81 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.234 |  0.143 |                   75 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.142503023147583
[2m[36m(func pid=20925)[0m mae:  0.0902344211935997
[2m[36m(func pid=20925)[0m rmse_per_class: [0.08, 0.223, 0.029, 0.298, 0.079, 0.157, 0.196, 0.109, 0.168, 0.086]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m rmse: 0.13980044424533844
[2m[36m(func pid=19271)[0m mae:  0.09214085340499878
[2m[36m(func pid=19271)[0m rmse_per_class: [0.081, 0.228, 0.034, 0.279, 0.056, 0.164, 0.206, 0.112, 0.142, 0.096]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 76] | Train loss: 0.2331 | Steps: 2 | Val loss: 0.2643 | Batch size: 32 | lr: 0.1 | Duration: 3.08s
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 82] | Train loss: 0.2312 | Steps: 2 | Val loss: 0.2807 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
== Status ==
Current time: 2024-01-07 09:21:07 (running for 00:49:08.20)
Memory usage on this node: 19.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.14774999767541885
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.23  |  0.14  |                   82 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.229 |  0.143 |                   76 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14123034477233887
[2m[36m(func pid=20925)[0m mae:  0.08900529146194458
[2m[36m(func pid=20925)[0m rmse_per_class: [0.075, 0.221, 0.03, 0.295, 0.075, 0.156, 0.194, 0.112, 0.17, 0.085]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m rmse: 0.1400091052055359
[2m[36m(func pid=19271)[0m mae:  0.09234202653169632
[2m[36m(func pid=19271)[0m rmse_per_class: [0.08, 0.229, 0.034, 0.279, 0.056, 0.165, 0.207, 0.112, 0.142, 0.097]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 77] | Train loss: 0.2269 | Steps: 2 | Val loss: 0.2631 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 83] | Train loss: 0.2338 | Steps: 2 | Val loss: 0.2812 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
== Status ==
Current time: 2024-01-07 09:21:12 (running for 00:49:13.57)
Memory usage on this node: 19.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.14774999767541885
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.231 |  0.14  |                   83 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.227 |  0.14  |                   78 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14048823714256287
[2m[36m(func pid=20925)[0m mae:  0.08840706199407578
[2m[36m(func pid=20925)[0m rmse_per_class: [0.074, 0.22, 0.03, 0.293, 0.071, 0.156, 0.195, 0.113, 0.168, 0.085]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m rmse: 0.1402892768383026
[2m[36m(func pid=19271)[0m mae:  0.09254658222198486
[2m[36m(func pid=19271)[0m rmse_per_class: [0.081, 0.229, 0.033, 0.281, 0.056, 0.165, 0.207, 0.112, 0.142, 0.098]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 78] | Train loss: 0.2273 | Steps: 2 | Val loss: 0.2649 | Batch size: 32 | lr: 0.1 | Duration: 3.27s
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 84] | Train loss: 0.2288 | Steps: 2 | Val loss: 0.2804 | Batch size: 32 | lr: 0.01 | Duration: 3.33s
== Status ==
Current time: 2024-01-07 09:21:17 (running for 00:49:18.85)
Memory usage on this node: 19.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.14774999767541885
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.234 |  0.14  |                   84 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.227 |  0.14  |                   78 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14093628525733948
[2m[36m(func pid=20925)[0m mae:  0.08908405154943466
[2m[36m(func pid=20925)[0m rmse_per_class: [0.074, 0.221, 0.03, 0.294, 0.068, 0.156, 0.195, 0.115, 0.169, 0.088]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m rmse: 0.140003502368927
[2m[36m(func pid=19271)[0m mae:  0.09222953021526337
[2m[36m(func pid=19271)[0m rmse_per_class: [0.081, 0.23, 0.034, 0.278, 0.055, 0.164, 0.206, 0.112, 0.142, 0.097]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 79] | Train loss: 0.2335 | Steps: 2 | Val loss: 0.2662 | Batch size: 32 | lr: 0.1 | Duration: 3.16s
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 85] | Train loss: 0.2323 | Steps: 2 | Val loss: 0.2804 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
== Status ==
Current time: 2024-01-07 09:21:23 (running for 00:49:24.55)
Memory usage on this node: 19.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.14774999767541885
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.229 |  0.14  |                   85 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.227 |  0.141 |                   79 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14152978360652924
[2m[36m(func pid=20925)[0m mae:  0.08986011892557144
[2m[36m(func pid=20925)[0m rmse_per_class: [0.076, 0.222, 0.029, 0.297, 0.069, 0.155, 0.196, 0.112, 0.171, 0.088]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m rmse: 0.1400558054447174
[2m[36m(func pid=19271)[0m mae:  0.09217134118080139
[2m[36m(func pid=19271)[0m rmse_per_class: [0.081, 0.231, 0.034, 0.278, 0.055, 0.163, 0.205, 0.113, 0.142, 0.098]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 80] | Train loss: 0.2328 | Steps: 2 | Val loss: 0.2653 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 86] | Train loss: 0.2367 | Steps: 2 | Val loss: 0.2808 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
== Status ==
Current time: 2024-01-07 09:21:29 (running for 00:49:30.04)
Memory usage on this node: 19.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.14774999767541885
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.232 |  0.14  |                   86 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.233 |  0.142 |                   80 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14118196070194244
[2m[36m(func pid=20925)[0m mae:  0.08974973857402802
[2m[36m(func pid=20925)[0m rmse_per_class: [0.077, 0.221, 0.028, 0.299, 0.068, 0.156, 0.196, 0.108, 0.171, 0.087]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m rmse: 0.1401759684085846
[2m[36m(func pid=19271)[0m mae:  0.09220026433467865
[2m[36m(func pid=19271)[0m rmse_per_class: [0.081, 0.23, 0.034, 0.279, 0.055, 0.163, 0.205, 0.114, 0.142, 0.098]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 81] | Train loss: 0.2316 | Steps: 2 | Val loss: 0.2639 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 87] | Train loss: 0.2321 | Steps: 2 | Val loss: 0.2809 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
== Status ==
Current time: 2024-01-07 09:21:34 (running for 00:49:35.43)
Memory usage on this node: 19.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.14774999767541885
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.237 |  0.14  |                   87 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.233 |  0.141 |                   81 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=19271)[0m rmse: 0.14022083580493927
[2m[36m(func pid=19271)[0m mae:  0.09222333878278732
[2m[36m(func pid=19271)[0m rmse_per_class: [0.08, 0.231, 0.034, 0.278, 0.055, 0.163, 0.206, 0.114, 0.142, 0.1]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=20925)[0m rmse: 0.1406702697277069
[2m[36m(func pid=20925)[0m mae:  0.08889561891555786
[2m[36m(func pid=20925)[0m rmse_per_class: [0.076, 0.22, 0.029, 0.296, 0.074, 0.156, 0.195, 0.105, 0.171, 0.085]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 88] | Train loss: 0.2356 | Steps: 2 | Val loss: 0.2816 | Batch size: 32 | lr: 0.01 | Duration: 3.09s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 82] | Train loss: 0.2308 | Steps: 2 | Val loss: 0.2629 | Batch size: 32 | lr: 0.1 | Duration: 3.12s
== Status ==
Current time: 2024-01-07 09:21:39 (running for 00:49:40.87)
Memory usage on this node: 19.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.14774999767541885
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.232 |  0.14  |                   88 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.232 |  0.141 |                   82 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=19271)[0m rmse: 0.1402559131383896
[2m[36m(func pid=19271)[0m mae:  0.09232447296380997
[2m[36m(func pid=19271)[0m rmse_per_class: [0.081, 0.23, 0.034, 0.278, 0.055, 0.162, 0.205, 0.113, 0.143, 0.101]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=20925)[0m rmse: 0.14019867777824402
[2m[36m(func pid=20925)[0m mae:  0.08828108757734299
[2m[36m(func pid=20925)[0m rmse_per_class: [0.077, 0.219, 0.029, 0.29, 0.079, 0.157, 0.194, 0.105, 0.169, 0.083]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 83] | Train loss: 0.2253 | Steps: 2 | Val loss: 0.2664 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 89] | Train loss: 0.2312 | Steps: 2 | Val loss: 0.2824 | Batch size: 32 | lr: 0.01 | Duration: 3.06s
== Status ==
Current time: 2024-01-07 09:21:45 (running for 00:49:46.30)
Memory usage on this node: 19.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.14774999767541885
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.236 |  0.14  |                   89 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.231 |  0.14  |                   83 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14188827574253082
[2m[36m(func pid=20925)[0m mae:  0.08964474499225616
[2m[36m(func pid=20925)[0m rmse_per_class: [0.078, 0.22, 0.029, 0.296, 0.085, 0.157, 0.195, 0.107, 0.168, 0.083]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m rmse: 0.14063355326652527
[2m[36m(func pid=19271)[0m mae:  0.09262014180421829
[2m[36m(func pid=19271)[0m rmse_per_class: [0.082, 0.23, 0.034, 0.281, 0.055, 0.162, 0.205, 0.113, 0.143, 0.101]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 84] | Train loss: 0.2278 | Steps: 2 | Val loss: 0.2695 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 90] | Train loss: 0.2282 | Steps: 2 | Val loss: 0.2821 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
== Status ==
Current time: 2024-01-07 09:21:50 (running for 00:49:51.69)
Memory usage on this node: 19.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.14774999767541885
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.231 |  0.141 |                   90 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.225 |  0.142 |                   84 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14362458884716034
[2m[36m(func pid=20925)[0m mae:  0.09105910360813141
[2m[36m(func pid=20925)[0m rmse_per_class: [0.079, 0.222, 0.028, 0.303, 0.083, 0.157, 0.197, 0.11, 0.174, 0.083]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m rmse: 0.14054568111896515
[2m[36m(func pid=19271)[0m mae:  0.09267989546060562
[2m[36m(func pid=19271)[0m rmse_per_class: [0.083, 0.229, 0.034, 0.282, 0.055, 0.163, 0.206, 0.112, 0.142, 0.101]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 91] | Train loss: 0.2325 | Steps: 2 | Val loss: 0.2824 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 85] | Train loss: 0.2269 | Steps: 2 | Val loss: 0.2693 | Batch size: 32 | lr: 0.1 | Duration: 3.05s
== Status ==
Current time: 2024-01-07 09:21:56 (running for 00:49:57.09)
Memory usage on this node: 19.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.14774999767541885
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.228 |  0.141 |                   91 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.228 |  0.144 |                   85 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14353609085083008
[2m[36m(func pid=20925)[0m mae:  0.0909835621714592
[2m[36m(func pid=20925)[0m rmse_per_class: [0.078, 0.222, 0.028, 0.304, 0.081, 0.157, 0.196, 0.112, 0.173, 0.083]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m rmse: 0.14059486985206604
[2m[36m(func pid=19271)[0m mae:  0.09274676442146301
[2m[36m(func pid=19271)[0m rmse_per_class: [0.084, 0.229, 0.034, 0.282, 0.055, 0.163, 0.206, 0.111, 0.142, 0.101]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 86] | Train loss: 0.2276 | Steps: 2 | Val loss: 0.2680 | Batch size: 32 | lr: 0.1 | Duration: 3.04s
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 92] | Train loss: 0.2305 | Steps: 2 | Val loss: 0.2819 | Batch size: 32 | lr: 0.01 | Duration: 3.28s
== Status ==
Current time: 2024-01-07 09:22:01 (running for 00:50:02.46)
Memory usage on this node: 19.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.14774999767541885
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.232 |  0.141 |                   92 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.227 |  0.144 |                   86 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14286059141159058
[2m[36m(func pid=20925)[0m mae:  0.09068884700536728
[2m[36m(func pid=20925)[0m rmse_per_class: [0.077, 0.222, 0.029, 0.304, 0.079, 0.156, 0.196, 0.11, 0.172, 0.084]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m rmse: 0.1402694582939148
[2m[36m(func pid=19271)[0m mae:  0.09238208830356598
[2m[36m(func pid=19271)[0m rmse_per_class: [0.084, 0.229, 0.034, 0.28, 0.055, 0.163, 0.206, 0.111, 0.14, 0.101]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 87] | Train loss: 0.2312 | Steps: 2 | Val loss: 0.2662 | Batch size: 32 | lr: 0.1 | Duration: 3.02s
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 93] | Train loss: 0.2379 | Steps: 2 | Val loss: 0.2809 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
== Status ==
Current time: 2024-01-07 09:22:07 (running for 00:50:08.09)
Memory usage on this node: 19.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.14774999767541885
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.23  |  0.14  |                   93 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.231 |  0.142 |                   88 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14171531796455383
[2m[36m(func pid=20925)[0m mae:  0.08984155207872391
[2m[36m(func pid=20925)[0m rmse_per_class: [0.075, 0.222, 0.029, 0.297, 0.078, 0.156, 0.196, 0.107, 0.171, 0.085]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m rmse: 0.13978229463100433
[2m[36m(func pid=19271)[0m mae:  0.09188947826623917
[2m[36m(func pid=19271)[0m rmse_per_class: [0.084, 0.229, 0.035, 0.278, 0.054, 0.162, 0.205, 0.112, 0.14, 0.099]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 88] | Train loss: 0.2305 | Steps: 2 | Val loss: 0.2667 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 94] | Train loss: 0.2412 | Steps: 2 | Val loss: 0.2815 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
== Status ==
Current time: 2024-01-07 09:22:12 (running for 00:50:13.44)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.14774999767541885
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.238 |  0.14  |                   94 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.23  |  0.142 |                   89 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.1416383534669876
[2m[36m(func pid=20925)[0m mae:  0.08987145870923996
[2m[36m(func pid=20925)[0m rmse_per_class: [0.075, 0.223, 0.029, 0.297, 0.077, 0.155, 0.196, 0.107, 0.17, 0.087]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m rmse: 0.14005029201507568
[2m[36m(func pid=19271)[0m mae:  0.0921216830611229
[2m[36m(func pid=19271)[0m rmse_per_class: [0.084, 0.229, 0.034, 0.28, 0.055, 0.162, 0.204, 0.111, 0.142, 0.099]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 89] | Train loss: 0.2310 | Steps: 2 | Val loss: 0.2669 | Batch size: 32 | lr: 0.1 | Duration: 3.15s
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 95] | Train loss: 0.2268 | Steps: 2 | Val loss: 0.2801 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
[2m[36m(func pid=20925)[0m rmse: 0.1415782868862152
[2m[36m(func pid=20925)[0m mae:  0.08973464369773865
[2m[36m(func pid=20925)[0m rmse_per_class: [0.077, 0.222, 0.029, 0.297, 0.079, 0.155, 0.196, 0.108, 0.167, 0.086]
== Status ==
Current time: 2024-01-07 09:22:18 (running for 00:50:18.95)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.14774999767541885
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.241 |  0.14  |                   95 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.231 |  0.142 |                   90 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m rmse: 0.13983312249183655
[2m[36m(func pid=19271)[0m mae:  0.09188418090343475
[2m[36m(func pid=19271)[0m rmse_per_class: [0.083, 0.229, 0.034, 0.28, 0.055, 0.163, 0.204, 0.112, 0.141, 0.098]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 90] | Train loss: 0.2292 | Steps: 2 | Val loss: 0.2657 | Batch size: 32 | lr: 0.1 | Duration: 3.10s
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 96] | Train loss: 0.2343 | Steps: 2 | Val loss: 0.2802 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
== Status ==
Current time: 2024-01-07 09:22:23 (running for 00:50:24.47)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.14774999767541885
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.227 |  0.14  |                   96 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.229 |  0.141 |                   91 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.1410675048828125
[2m[36m(func pid=20925)[0m mae:  0.08924046903848648
[2m[36m(func pid=20925)[0m rmse_per_class: [0.08, 0.22, 0.028, 0.297, 0.079, 0.154, 0.195, 0.108, 0.165, 0.084]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m rmse: 0.1399349421262741
[2m[36m(func pid=19271)[0m mae:  0.09188257157802582
[2m[36m(func pid=19271)[0m rmse_per_class: [0.082, 0.23, 0.034, 0.281, 0.055, 0.163, 0.204, 0.112, 0.142, 0.097]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 91] | Train loss: 0.2302 | Steps: 2 | Val loss: 0.2637 | Batch size: 32 | lr: 0.1 | Duration: 3.06s
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 97] | Train loss: 0.2259 | Steps: 2 | Val loss: 0.2803 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
== Status ==
Current time: 2024-01-07 09:22:28 (running for 00:50:29.87)
Memory usage on this node: 19.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.14774999767541885
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.234 |  0.14  |                   97 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.229 |  0.141 |                   91 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.1403125673532486
[2m[36m(func pid=20925)[0m mae:  0.08834971487522125
[2m[36m(func pid=20925)[0m rmse_per_class: [0.075, 0.22, 0.028, 0.293, 0.078, 0.155, 0.194, 0.111, 0.166, 0.084]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m rmse: 0.1403648853302002
[2m[36m(func pid=19271)[0m mae:  0.09226106107234955
[2m[36m(func pid=19271)[0m rmse_per_class: [0.084, 0.23, 0.034, 0.283, 0.055, 0.163, 0.204, 0.112, 0.143, 0.096]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 92] | Train loss: 0.2254 | Steps: 2 | Val loss: 0.2654 | Batch size: 32 | lr: 0.1 | Duration: 3.14s
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 98] | Train loss: 0.2325 | Steps: 2 | Val loss: 0.2804 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
== Status ==
Current time: 2024-01-07 09:22:34 (running for 00:50:35.31)
Memory usage on this node: 19.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.14774999767541885
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.226 |  0.14  |                   98 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.23  |  0.14  |                   92 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14071358740329742
[2m[36m(func pid=20925)[0m mae:  0.08876758068799973
[2m[36m(func pid=20925)[0m rmse_per_class: [0.076, 0.221, 0.028, 0.294, 0.08, 0.154, 0.193, 0.106, 0.169, 0.085]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=19271)[0m rmse: 0.14013537764549255
[2m[36m(func pid=19271)[0m mae:  0.09197987616062164
[2m[36m(func pid=19271)[0m rmse_per_class: [0.084, 0.23, 0.034, 0.281, 0.055, 0.163, 0.204, 0.113, 0.141, 0.097]
[2m[36m(func pid=19271)[0m 
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 93] | Train loss: 0.2285 | Steps: 2 | Val loss: 0.2677 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
[2m[36m(func pid=19271)[0m [N0-GPU0] | [Epoch: 99] | Train loss: 0.2367 | Steps: 2 | Val loss: 0.2806 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
== Status ==
Current time: 2024-01-07 09:22:40 (running for 00:50:40.91)
Memory usage on this node: 19.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.14774999767541885
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 2 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00022 | RUNNING    | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.233 |  0.14  |                   99 |
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.225 |  0.141 |                   93 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=19271)[0m rmse: 0.14006389677524567
[2m[36m(func pid=19271)[0m mae:  0.0918792113661766
[2m[36m(func pid=19271)[0m rmse_per_class: [0.083, 0.23, 0.034, 0.28, 0.055, 0.163, 0.204, 0.113, 0.142, 0.097]
[2m[36m(func pid=20925)[0m rmse: 0.14203374087810516
[2m[36m(func pid=20925)[0m mae:  0.08960969746112823
[2m[36m(func pid=20925)[0m rmse_per_class: [0.075, 0.222, 0.03, 0.297, 0.083, 0.155, 0.194, 0.105, 0.174, 0.085]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 94] | Train loss: 0.2298 | Steps: 2 | Val loss: 0.2674 | Batch size: 32 | lr: 0.1 | Duration: 3.08s
== Status ==
Current time: 2024-01-07 09:22:45 (running for 00:50:46.40)
Memory usage on this node: 16.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14774999767541885
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 1 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.229 |  0.142 |                   94 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00017 | TERMINATED | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.292 |  0.157 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.1421177089214325
[2m[36m(func pid=20925)[0m mae:  0.08979550749063492
[2m[36m(func pid=20925)[0m rmse_per_class: [0.076, 0.223, 0.03, 0.298, 0.08, 0.155, 0.195, 0.105, 0.174, 0.085]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 95] | Train loss: 0.2335 | Steps: 2 | Val loss: 0.2675 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
== Status ==
Current time: 2024-01-07 09:22:51 (running for 00:50:51.96)
Memory usage on this node: 16.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14774999767541885
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 1 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.23  |  0.142 |                   95 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00017 | TERMINATED | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.292 |  0.157 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.1421043872833252
[2m[36m(func pid=20925)[0m mae:  0.08985545486211777
[2m[36m(func pid=20925)[0m rmse_per_class: [0.076, 0.223, 0.031, 0.298, 0.078, 0.156, 0.196, 0.107, 0.171, 0.086]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 96] | Train loss: 0.2305 | Steps: 2 | Val loss: 0.2663 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 09:22:56 (running for 00:50:57.32)
Memory usage on this node: 16.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14774999767541885
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 1 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.234 |  0.142 |                   96 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00017 | TERMINATED | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.292 |  0.157 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14112652838230133
[2m[36m(func pid=20925)[0m mae:  0.08916173130273819
[2m[36m(func pid=20925)[0m rmse_per_class: [0.078, 0.222, 0.03, 0.296, 0.074, 0.155, 0.196, 0.106, 0.168, 0.087]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 97] | Train loss: 0.2284 | Steps: 2 | Val loss: 0.2665 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 09:23:01 (running for 00:51:02.57)
Memory usage on this node: 16.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14774999767541885
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 1 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.23  |  0.141 |                   97 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00017 | TERMINATED | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.292 |  0.157 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.14103159308433533
[2m[36m(func pid=20925)[0m mae:  0.08915041387081146
[2m[36m(func pid=20925)[0m rmse_per_class: [0.08, 0.221, 0.029, 0.295, 0.075, 0.155, 0.195, 0.108, 0.166, 0.086]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 98] | Train loss: 0.2265 | Steps: 2 | Val loss: 0.2679 | Batch size: 32 | lr: 0.1 | Duration: 3.02s
== Status ==
Current time: 2024-01-07 09:23:07 (running for 00:51:07.99)
Memory usage on this node: 16.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14774999767541885
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 1 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.228 |  0.141 |                   98 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00017 | TERMINATED | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.292 |  0.157 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

[2m[36m(func pid=20925)[0m rmse: 0.141682967543602
[2m[36m(func pid=20925)[0m mae:  0.08959023654460907
[2m[36m(func pid=20925)[0m rmse_per_class: [0.077, 0.22, 0.028, 0.296, 0.082, 0.156, 0.195, 0.108, 0.167, 0.086]
[2m[36m(func pid=20925)[0m 
[2m[36m(func pid=20925)[0m [N0-GPU0] | [Epoch: 99] | Train loss: 0.2286 | Steps: 2 | Val loss: 0.2694 | Batch size: 32 | lr: 0.1 | Duration: 3.31s
== Status ==
Current time: 2024-01-07 09:23:12 (running for 00:51:13.63)
Memory usage on this node: 16.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14774999767541885
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 1 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00023 | RUNNING    | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.227 |  0.142 |                   99 |
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00017 | TERMINATED | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.292 |  0.157 |                   75 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

== Status ==
Current time: 2024-01-07 09:23:13 (running for 00:51:14.22)
Memory usage on this node: 16.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14774999767541885
Resources requested: 0/72 CPUs, 0/4 GPUs, 0.0/120.06 GiB heap, 0.0/55.45 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 ERROR, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_d77f6_00000 | TERMINATED | 192.168.7.53:104469 | 0.0001 |       0.99 |         0      |  0.434 |  0.168 |                   75 |
| train_d77f6_00001 | TERMINATED | 192.168.7.53:104843 | 0.001  |       0.99 |         0      |  0.274 |  0.159 |                  100 |
| train_d77f6_00002 | TERMINATED | 192.168.7.53:105266 | 0.01   |       0.99 |         0      |  0.241 |  0.153 |                  100 |
| train_d77f6_00003 | TERMINATED | 192.168.7.53:105685 | 0.1    |       0.99 |         0      |  0.336 |  0.208 |                   75 |
| train_d77f6_00004 | TERMINATED | 192.168.7.53:122279 | 0.0001 |       0.9  |         0      |  0.471 |  0.179 |                   75 |
| train_d77f6_00005 | TERMINATED | 192.168.7.53:122389 | 0.001  |       0.9  |         0      |  0.273 |  0.156 |                  100 |
| train_d77f6_00006 | TERMINATED | 192.168.7.53:127565 | 0.01   |       0.9  |         0      |  0.232 |  0.141 |                  100 |
| train_d77f6_00007 | TERMINATED | 192.168.7.53:128390 | 0.1    |       0.9  |         0      |  0.228 |  0.146 |                  100 |
| train_d77f6_00008 | TERMINATED | 192.168.7.53:139738 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.168 |                   75 |
| train_d77f6_00009 | TERMINATED | 192.168.7.53:145749 | 0.001  |       0.99 |         0.0001 |  0.258 |  0.16  |                  100 |
| train_d77f6_00010 | TERMINATED | 192.168.7.53:150254 | 0.01   |       0.99 |         0.0001 |  0.251 |  0.157 |                   75 |
| train_d77f6_00012 | TERMINATED | 192.168.7.53:157328 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   75 |
| train_d77f6_00013 | TERMINATED | 192.168.7.53:158989 | 0.001  |       0.9  |         0.0001 |  0.288 |  0.158 |                   75 |
| train_d77f6_00014 | TERMINATED | 192.168.7.53:167906 | 0.01   |       0.9  |         0.0001 |  0.229 |  0.141 |                  100 |
| train_d77f6_00015 | TERMINATED | 192.168.7.53:169734 | 0.1    |       0.9  |         0.0001 |  0.225 |  0.142 |                  100 |
| train_d77f6_00016 | TERMINATED | 192.168.7.53:174732 | 0.0001 |       0.99 |         1e-05  |  0.443 |  0.168 |                   75 |
| train_d77f6_00017 | TERMINATED | 192.168.7.53:176115 | 0.001  |       0.99 |         1e-05  |  0.292 |  0.157 |                   75 |
| train_d77f6_00018 | TERMINATED | 192.168.7.53:2617   | 0.01   |       0.99 |         1e-05  |  0.243 |  0.165 |                   75 |
| train_d77f6_00020 | TERMINATED | 192.168.7.53:5776   | 0.0001 |       0.9  |         1e-05  |  0.472 |  0.179 |                   75 |
| train_d77f6_00021 | TERMINATED | 192.168.7.53:6501   | 0.001  |       0.9  |         1e-05  |  0.291 |  0.158 |                   75 |
| train_d77f6_00022 | TERMINATED | 192.168.7.53:19271  | 0.01   |       0.9  |         1e-05  |  0.237 |  0.14  |                  100 |
| train_d77f6_00023 | TERMINATED | 192.168.7.53:20925  | 0.1    |       0.9  |         1e-05  |  0.229 |  0.143 |                  100 |
| train_d77f6_00011 | ERROR      | 192.168.7.53:151230 | 0.1    |       0.99 |         0.0001 |  0.508 |  0.2   |                   32 |
| train_d77f6_00019 | ERROR      | 192.168.7.53:3873   | 0.1    |       0.99 |         1e-05  |  0.34  |  0.247 |                   68 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
Number of errored trials: 2
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Trial name        |   # failures | error file                                                                                                                                                            |
|-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| train_d77f6_00011 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00011_11_lr=0.1000,momentum=0.9900,weight_decay=0.0001_2024-01-07_08-50-43/error.txt |
| train_d77f6_00019 |            1 | /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised/train_d77f6_00019_19_lr=0.1000,momentum=0.9900,weight_decay=0.0000_2024-01-07_09-07-03/error.txt |
+-------------------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+

2024-01-07 09:23:13,346	ERROR tune.py:794 -- Trials did not complete: [train_d77f6_00011, train_d77f6_00019]
2024-01-07 09:23:13,346	INFO tune.py:798 -- Total run time: 3075.36 seconds (3074.20 seconds for the tuning loop).
[2m[36m(func pid=20925)[0m rmse: 0.14325901865959167
[2m[36m(func pid=20925)[0m mae:  0.09046018123626709
[2m[36m(func pid=20925)[0m rmse_per_class: [0.076, 0.221, 0.029, 0.301, 0.085, 0.157, 0.196, 0.109, 0.173, 0.085]
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** STEP 1341343.1 ON aap04 CANCELLED AT 2024-01-07T09:23:18 ***
srun: error: aap04: task 0: Exited with exit code 1
