{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "293858ae-5611-498e-afd6-acddd993850f",
   "metadata": {},
   "source": [
    "**USING RESNET18 WITH AND WITHOUT PRETRAINED WEIGHTS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90375b5c-0b66-445d-9260-f68b8bf991df",
   "metadata": {},
   "source": [
    "**LOADING THE SSL MODEL AND TRAINING A CLASSIFIER ON TOP OF IT**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e9469c-2666-4529-9eaf-1a1925b6eef0",
   "metadata": {},
   "source": [
    "Reference 1: https://pytorch.org/tutorials/beginner/introyt/trainingyt.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26195bb6-2965-4abd-b858-161c062294b6",
   "metadata": {},
   "source": [
    "Reference 2: https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3e0369-a80d-44d1-b6cf-339cefc3c97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_notebook() -> bool:\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "\n",
    "        if shell == 'ZMQInteractiveShell':\n",
    "            return True   # Jupyter notebook or qtconsole\n",
    "        elif shell == 'TerminalInteractiveShell':\n",
    "            return False  # Terminal running IPython\n",
    "        else:\n",
    "            return False  # Other type (?)\n",
    "\n",
    "    except NameError:\n",
    "        return False      # Probably standard Python interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b7dd78-3b06-441e-9cb8-4ca54a7b955c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if is_notebook():\n",
    "#     %load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d06a82-af2e-4dc0-a873-1a2a225e284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if is_notebook():\n",
    "#     %pycodestyle_on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24803b53-5c6f-4603-9e46-74b468dc6a4b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3123cba7-2168-4887-bf98-a65fa199db70",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d3b8f7-6c4c-47ec-a517-76e02872c1a6",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c4791a-9d48-4508-8338-79dabc7c1754",
   "metadata": {},
   "source": [
    "## Libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017c251f-635b-4c62-a485-7a7783aed523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom modules.\n",
    "from utils.computation import Experiment, pca_computation, tsne_computation\n",
    "from utils.dataset import load_dataset_based_on_ratio\n",
    "\n",
    "# OS module.\n",
    "import os\n",
    "\n",
    "# PyTorch.\n",
    "import torch\n",
    "import torchvision\n",
    "from torchinfo import summary\n",
    "\n",
    "# Data management.\n",
    "import numpy as np\n",
    "\n",
    "# import lightly\n",
    "\n",
    "# Training checks.\n",
    "from datetime import datetime\n",
    "import copy\n",
    "import time\n",
    "import math\n",
    "\n",
    "# import random\n",
    "\n",
    "# For plotting.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Showing images in the notebook.\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "# from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c253e418-09b4-4dbe-a981-eff60e2f981a",
   "metadata": {},
   "source": [
    "## Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddfb34f-1fbe-4add-9202-4cc35d9aee21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workaround to make bool options work as expected.\n",
    "def str2bool(v):\n",
    "    if isinstance(v, bool):\n",
    "        return v\n",
    "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "        return True\n",
    "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "        return False\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError('Boolean value expected.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05856067-f415-40be-9864-a4bbf307c1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parser (get arguments).\n",
    "if __name__ == '__main__':\n",
    "    import argparse\n",
    "    import sys\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=(\"Script for evaluating the self-supervised learning\"\n",
    "                     \" models and compare them to standard approaches.\")\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--dataset',\n",
    "        type=str,\n",
    "        default='Sentinel2GlobalLULC',\n",
    "        choices=['Sentinel2GlobalLULC', 'Sentinel2AndaluciaLULC'],\n",
    "        help='Dataset name for evaluation.'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--ratio',\n",
    "        type=str,\n",
    "        default='(0.700,0.0900,0.2100)',\n",
    "        help='Dataset ratio for evaluation.'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--epochs',\n",
    "        type=int,\n",
    "        default=15,\n",
    "        help='Number of epochs for training.'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--batch_size',\n",
    "        type=int,\n",
    "        default=64,\n",
    "        help='Number of images in a batch during training.'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--show_fig',\n",
    "        type=str2bool,\n",
    "        default=True,\n",
    "        help='Whether the images should appear.'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--cluster',\n",
    "        type=str2bool,\n",
    "        default=False,\n",
    "        help=('Whether the script runs on a cluster '\n",
    "              '(large memory space available).')\n",
    "    )\n",
    "\n",
    "if is_notebook():\n",
    "    args = parser.parse_args(args=['--dataset', 'Sentinel2AndaluciaLULC', '--ratio', '(0.700,0.0900,0.2100)'])\n",
    "else:\n",
    "    args = parser.parse_args(sys.argv[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80aa854-ce45-46ef-806a-18a1fac093f7",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb597468-acb3-4683-8b29-20be68742de3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Target dataset name.\n",
    "dataset_name = args.dataset\n",
    "print(f'Target dataset name: {dataset_name}')\n",
    "\n",
    "# Target dataset ratio.\n",
    "dataset_ratio = args.ratio\n",
    "print(f'Target dataset ratio: {dataset_ratio}')\n",
    "\n",
    "# Setting number of epochs.\n",
    "epochs = args.epochs\n",
    "print(f'Number of epochs: {epochs}')\n",
    "\n",
    "# Setting batch size.\n",
    "batch_size = args.batch_size\n",
    "print(f'Batch size: {batch_size}')\n",
    "\n",
    "# Show figures.\n",
    "show = args.show_fig\n",
    "print(f'Showing figures: {show}')\n",
    "\n",
    "# Supercomputer?.\n",
    "cluster = args.cluster\n",
    "print(f'\\nExecution on cluster: {cluster}')\n",
    "\n",
    "# Avoiding the runtimeError: Too many open files.\n",
    "# Communication with the workers is no longer possible.\n",
    "if is_notebook() or cluster:\n",
    "    print(f'Execution on jupyter or cluster: '\n",
    "          f'Torch sharing strategy set to file_system (default)')\n",
    "    torch.multiprocessing.set_sharing_strategy('file_descriptor')\n",
    "else:\n",
    "    print(f'Execution on shell with few resources: '\n",
    "          'Torch sharing strategy set to file_system')\n",
    "    torch.multiprocessing.set_sharing_strategy('file_system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1964900e-5f35-4ca5-af59-14bfedf11387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparamenters.\n",
    "exp = Experiment(epochs=epochs,\n",
    "                 batch_size=batch_size)\n",
    "print(f'\\nDevice: {exp.device}\\n')\n",
    "\n",
    "# Get current directory.\n",
    "cwd = os.getcwd()\n",
    "print(f'Working directory: {cwd}')\n",
    "\n",
    "# Input directory where the datasets are stored.\n",
    "input_dir_datasets = os.path.join(cwd, 'datasets')\n",
    "print(f'\\nInput directory for datasets: {input_dir_datasets}')\n",
    "\n",
    "# Output directory.\n",
    "output_dir = os.path.join(cwd, 'output')\n",
    "\n",
    "# Output directory to save the model checkpoint.\n",
    "output_dir_models = os.path.join(os.path.join(output_dir, 'pytorch_models'),\n",
    "                                 'finetuning')\n",
    "print(f'Output directory for model checkpoints: {output_dir_models}')\n",
    "\n",
    "# Folder to save the figures.\n",
    "output_dir_figs = os.path.join(os.path.join(output_dir, 'figures'),\n",
    "                               'finetuning')\n",
    "fig_format = '.png'  # .pdf\n",
    "print(f'Output directory for figures ({fig_format} format): {output_dir_figs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977f3f16-a19f-48f2-beab-cb5c97159106",
   "metadata": {},
   "source": [
    "## Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785a5121-5498-4692-a9cc-b2ce6f2687ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.reproducibility()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d940bd-cf06-40e7-aedd-65ff1f9980d7",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bcd19d-b8ff-423a-a2de-5ed81895d678",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce58376-03c3-4e2d-be6d-8e5d50072143",
   "metadata": {},
   "source": [
    "# Loading dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a51c36-0e9a-42c5-bb7a-198550e30af4",
   "metadata": {},
   "source": [
    "## Path and normalization values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4363738-70ae-45c3-b0fd-a35c5bb0a019",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_target, mean, std = load_dataset_based_on_ratio(\n",
    "    input_dir_datasets,\n",
    "    dataset_name,\n",
    "    dataset_ratio\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11965017-e45d-4475-94df-3f7ab14a386b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255780a8-903c-4dfd-a5ca-010e0f4d455e",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6f2baf-4a21-4fae-8935-e0ee7656a31d",
   "metadata": {},
   "source": [
    "UP TO HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68a1daa-ce5d-47ee-b179-7abfb2066b8d",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249490a6-7fc7-45bd-a99f-4d8f85eee838",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4022454b-8858-4b93-98b7-742b14ffbe51",
   "metadata": {},
   "source": [
    "## Custom transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e0cc09-236f-4120-ad7b-e90136363863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentations for the train dataset.\n",
    "train_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((exp.input_size, exp.input_size)),\n",
    "    torchvision.transforms.RandomResizedCrop(224, scale=(0.2, 1.)),\n",
    "    torchvision.transforms.RandomApply([\n",
    "            torchvision.transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)\n",
    "        ], p=0.8),  # not strengthened\n",
    "    torchvision.transforms.RandomGrayscale(p=0.2),\n",
    "    # torchvision.transforms.RandomApply([\n",
    "    #     simsiam.loader.GaussianBlur([.1, 2.])\n",
    "    # ], p=0.5),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean['train'], std['train'])\n",
    "])\n",
    "\n",
    "# Data augmentations for the val and test datasets.\n",
    "val_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((exp.input_size, exp.input_size)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean['val'], std['val'])\n",
    "])\n",
    "\n",
    "# Data augmentations for the val and test datasets.\n",
    "test_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((exp.input_size, exp.input_size)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean['test'], std['test'])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac31fc9-ef1b-49ff-bce1-6b913422346d",
   "metadata": {},
   "source": [
    "## ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b48ae6-b974-41a3-99b0-4fccdd6a62fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the three datasets.\n",
    "train_data = torchvision.datasets.ImageFolder(data_dir_target + '/train/',\n",
    "                                              transform=train_transform)\n",
    "\n",
    "val_data = torchvision.datasets.ImageFolder(data_dir_target + '/val/',\n",
    "                                            transform=val_transform)\n",
    "\n",
    "test_data = torchvision.datasets.ImageFolder(data_dir_target + '/test/',\n",
    "                                             transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3518a1-2aeb-4e8d-bfde-7c30f4df195a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get classes and number.\n",
    "class_names = train_data.classes\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660ba5f0-e15f-47c3-b614-bf44c75c67e3",
   "metadata": {},
   "source": [
    "## PyTorch dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a77009-440f-45af-8bd1-feaa61adef9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader for training.\n",
    "dataloader_train = torch.utils.data.DataLoader(\n",
    "    train_data,\n",
    "    batch_size=exp.batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=exp.num_workers,\n",
    "    worker_init_fn=exp.seed_worker,\n",
    "    generator=exp.g\n",
    ")\n",
    "\n",
    "# Dataloader for validating.\n",
    "dataloader_val = torch.utils.data.DataLoader(\n",
    "    val_data,\n",
    "    batch_size=exp.batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=exp.num_workers,\n",
    "    worker_init_fn=exp.seed_worker,\n",
    "    generator=exp.g\n",
    ")\n",
    "\n",
    "# Dataloader for embedding.\n",
    "dataloader_test = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=exp.batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=exp.num_workers,\n",
    "    worker_init_fn=exp.seed_worker,\n",
    "    generator=exp.g\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edeaaff0-6d50-4888-85cd-63de0902668d",
   "metadata": {},
   "source": [
    "## Check the balance and size of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1aa664a-1c20-4aef-876a-327fdaee8c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check samples per class in train dataset.\n",
    "print(np.unique(train_data.targets, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259c5f14-2cc4-4867-9bcf-a053e94d082c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check samples per class in test dataset.\n",
    "print(np.unique(test_data.targets, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1562cd9-5ba7-4e07-aa5b-143c703a644a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print some stats from the train dataset.\n",
    "print(len(train_data.targets))\n",
    "\n",
    "# Print some stats from the train dataloader.\n",
    "print('N samples in train dataset: ' + str(len(dataloader_train.sampler)))\n",
    "print('N samples in train dataset: ' + str(len(dataloader_train.dataset)))\n",
    "print('N batches in train dataset: ' + str(len(dataloader_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069e5780-0557-4a29-834b-41f00cf56ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print some stats from the val dataset.\n",
    "print(len(val_data.targets))\n",
    "\n",
    "# Print some stats from the val dataloader.\n",
    "print('N samples in val dataset: ' + str(len(dataloader_val.dataset)))\n",
    "print('N batches in val dataset: ' + str(len(dataloader_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1ca802-c715-45e4-93cc-62eaaab062b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print some stats from the test dataset.\n",
    "print(len(test_data.targets))\n",
    "\n",
    "# Print some stats from the test dataloader.\n",
    "print('N samples in test dataset: ' + str(len(dataloader_test.dataset)))\n",
    "print('N batches in test dataset: ' + str(len(dataloader_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc00d03-ff40-4c82-8982-27aff5d9927f",
   "metadata": {},
   "source": [
    "## See some samples (pytorch dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e34469-dddd-42fa-ba43-6f5da105f6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display image and label.\n",
    "train_features, train_labels = next(iter(dataloader_train))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(torch.permute(img, (1, 2, 0)), cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {class_names[label]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06196e35-2417-40f2-9bad-f197103911de",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb2512f-dd8c-4bcf-b5b6-fbb648845fd5",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c8e405-4183-4e6b-97f6-34edd7fbf17b",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437632b1-b33e-46a7-9c0c-5c0046318faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function.\n",
    "def train_model(model, criterion, optimizer, device,\n",
    "                epochs=10, save_best_model=False):\n",
    "    \"\"\"\n",
    "    Main training function.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Using {exp.device} device\")\n",
    "\n",
    "    # Avoiding \"CUDA out of memory\" in PyTorch.\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Loss history.\n",
    "    loss_values = {}\n",
    "    loss_values['train'] = []\n",
    "    loss_values['val'] = []\n",
    "    total_time = 0\n",
    "\n",
    "    # Saving best model's weights.\n",
    "    best_model_val_wts = copy.deepcopy(model.state_dict())\n",
    "    lowest_val_loss = 10000\n",
    "\n",
    "    # Model to GPU if available.\n",
    "    model.to(exp.device)\n",
    "\n",
    "    # Iterating over the epochs.\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # Initialize training loss.\n",
    "        running_train_loss = 0.0\n",
    "\n",
    "        # Start timer.\n",
    "        since = time.time()\n",
    "\n",
    "        # Enable training.\n",
    "        model.train()\n",
    "\n",
    "        for i, data in enumerate(dataloader_train):\n",
    "\n",
    "            # Get the inputs; data is a list of [inputs, labels].\n",
    "            inputs, labels = data[0].to(exp.device), data[1].to(exp.device)\n",
    "\n",
    "            # Zero the parameter gradients.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward: make predictions.\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Compute the loss and its gradients.\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            # Averaged loss across all training examples * batch_size.\n",
    "            running_train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            if i % 200 == 199:\n",
    "                print(f'T[{epoch + 1}, {i + 1:5d}] | '\n",
    "                      f'Running loss: '\n",
    "                      f'{running_train_loss/(i*inputs.size(0)):.4f}')\n",
    "\n",
    "            # Adjust learning weights.\n",
    "            optimizer.step()\n",
    "\n",
    "        # Loss averaged across all training examples for the current epoch.\n",
    "        epoch_train_loss = running_train_loss / len(dataloader_train.sampler)\n",
    "\n",
    "        # Change model to evaluation mode.\n",
    "        model.eval()\n",
    "\n",
    "        # Initialize validating loss.\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for j, vdata in enumerate(dataloader_val):\n",
    "\n",
    "                # Get the inputs; data is a list of [inputs, labels].\n",
    "                vinputs, vlabels = vdata[0].to(exp.device), vdata[1].to(exp.device)\n",
    "\n",
    "                # Forward: make predictions.\n",
    "                voutputs = model(vinputs)\n",
    "\n",
    "                # Compute the loss (w/o gradients).\n",
    "                vloss = criterion(voutputs, vlabels)\n",
    "\n",
    "                # Averaged loss across all validating examples * batch_size.\n",
    "                running_val_loss += vloss.item() * vinputs.size(0)\n",
    "\n",
    "                if j % 50 == 49:\n",
    "                    print(f'V[{epoch + 1}, {j + 1:5d}] | '\n",
    "                          f'Running loss: '\n",
    "                          f'{running_val_loss/(j*inputs.size(0)):.4f}')\n",
    "\n",
    "        # Loss averaged across all validating examples for the current epoch.\n",
    "        epoch_val_loss = running_val_loss / len(dataloader_val.sampler)\n",
    "\n",
    "        # Append loss values.\n",
    "        loss_values['train'].append(epoch_train_loss)\n",
    "        loss_values['val'].append(epoch_val_loss)\n",
    "\n",
    "        # Deep copy the weights of the model.\n",
    "        save_weights = epoch_val_loss < lowest_val_loss\n",
    "        if save_weights:\n",
    "            lowest_val_loss = epoch_val_loss\n",
    "            best_model_train_loss = epoch_train_loss\n",
    "            best_model_val_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        # End timer.\n",
    "        time_elapsed = time.time() - since\n",
    "        total_time += time_elapsed\n",
    "\n",
    "        # Show stats.\n",
    "        print(f'Epoch: {epoch} | '\n",
    "              f'Train loss: {epoch_train_loss:.4f} | '\n",
    "              f'Val loss: {epoch_val_loss:.4f} | '\n",
    "              f'Elapsed: {time_elapsed // 60:.0f}m '\n",
    "              f'{time_elapsed % 60:.0f}s | '\n",
    "              f'Save weights: {save_weights}')\n",
    "\n",
    "    print(f'\\nTraining completed in {total_time // 60:.0f}m '\n",
    "          f'{total_time % 60:.0f}s')\n",
    "\n",
    "    # Load best model weights.\n",
    "    model.load_state_dict(best_model_val_wts)\n",
    "\n",
    "    if save_best_model:\n",
    "\n",
    "        # Move to CPU before saving it.\n",
    "        model.to('cpu')\n",
    "\n",
    "        # Filename with stats.\n",
    "        save_path = f'pytorch_models/resnet18' \\\n",
    "                    f'-losses={best_model_train_loss:.2f}' \\\n",
    "                    f'_{lowest_val_loss:.2f}' \\\n",
    "                    f'-time={datetime.now():%Y_%m_%d-%H_%M_%S}'\n",
    "\n",
    "        # Save this pretrained model (recommended approach).\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "\n",
    "        print('Model successfuly saved')\n",
    "\n",
    "        # Move back to the GPU.\n",
    "        model.to(exp.device)\n",
    "\n",
    "    return model, loss_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3a7f82-4423-4d81-85a8-0ecbaba41c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(loss_history, title='', save_fig=False):\n",
    "    \"\"\"\n",
    "    Function for plotting the training and validation losses\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    plt.plot(loss_history['train'], label='Train')\n",
    "    plt.plot(loss_history['val'], label='Validation')\n",
    "    plt.xlabel('Epoch', labelpad=15)\n",
    "    plt.ylabel('Loss', labelpad=15)\n",
    "    plt.title(title)\n",
    "    plt.gcf().subplots_adjust(bottom=0.15)\n",
    "    plt.gcf().subplots_adjust(left=0.15)\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    if save_fig:\n",
    "        fig.savefig('plt_loss_values.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ff272e-4786-4a49-b7fc-73ce774a88af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_on_test(model, device):\n",
    "    \"\"\"\n",
    "    Function to evaluate the performance\n",
    "    of the model on the test dataset.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Avoiding \"CUDA out of memory\" in PyTorch.\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Since we're not training, we don't need to calculate\n",
    "    # the gradients for our outputs with torch.no_grad():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(dataloader_test):\n",
    "\n",
    "            # Dataset.\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # Calculate outputs by running images through the network.\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # The class with the highest energy is what we\n",
    "            # choose as prediction.\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Progress bar.\n",
    "            if i % 50 == 49:\n",
    "                print(f'Progress: {100 * i // len(dataloader_test)}%',\n",
    "                      end='\\r',\n",
    "                      flush=True)\n",
    "\n",
    "    print(f'Accuracy of the network on the {total} '\n",
    "          f'test images: {100 * correct // total}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4c48da-0289-4350-8641-62c207d44143",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18762958-4bb5-4a9e-a642-e5cecbc0f8f1",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce24b86-e4e5-442a-876a-782db427e0c3",
   "metadata": {},
   "source": [
    "# ResNet18 from scrath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5b72a3-8fd8-45fe-8353-e77cdc5f99d6",
   "metadata": {},
   "source": [
    "## Definition and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b373932-506b-45a0-9301-d182e038d965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model: resnet with random weights.\n",
    "model = torchvision.models.resnet18(weights=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8627587-6558-4637-b5b2-f8e0cdc7b3ea",
   "metadata": {},
   "source": [
    "## Adjust final layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d714e83-002f-4f1a-b240-cf7e80ae41ca",
   "metadata": {},
   "source": [
    "Type: linear not softmax for the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974ad1ef-8697-41ab-a1af-1b6f615715c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check old final layer.\n",
    "print(model.fc)\n",
    "\n",
    "# Get the number of input features to the layer.\n",
    "num_ftrs = model.fc.in_features\n",
    "print(num_ftrs)\n",
    "\n",
    "# Adjust the final layer to the current number of classes.\n",
    "model.fc = torch.nn.Linear(num_ftrs, len(class_names))\n",
    "\n",
    "# Check new final layer.\n",
    "print(model.fc)\n",
    "\n",
    "# Freezing all the network except the final layer.\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Model structure.\n",
    "summary(\n",
    "    model,\n",
    "    input_size=(exp.batch_size, 3, exp.input_size, exp.input_size),\n",
    "    device=exp.device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fdf194-24c8-45c3-bf12-d6ac176df30e",
   "metadata": {},
   "source": [
    "## Loss fcn and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ea9cdf-c59e-4e10-94b5-f6017bda668c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function: cross-entropy loss.\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizers: specified in the torch.optim package\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ee9848-8c21-489d-8adc-2fc0e0bff9b0",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba464d96-1913-43ef-96c4-59b5fdf9b65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, loss_history = train_model(\n",
    "    model,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    exp.device,\n",
    "    epochs=exp.epochs,\n",
    "    save_best_model=True\n",
    ")\n",
    "\n",
    "plot_losses(loss_history, 'Model w/o pretrained weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0504b3-ae1c-4836-87e9-3c45e93b92d7",
   "metadata": {},
   "source": [
    "## Check performance on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5515fcfa-ed16-42f9-8b70-992fde11c8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_on_test(model, exp.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978fc629-e5a5-4608-bab6-ceee0b554bed",
   "metadata": {
    "tags": []
   },
   "source": [
    "## F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5d0dd0-1d74-45aa-b3ca-0b12d79ca712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "conf_mat, class_accuracy = utils.create_confusion_matrix(\n",
    "    model,\n",
    "    dataloader_test,\n",
    "    exp.device,\n",
    "    class_names\n",
    ")\n",
    "\n",
    "# Bar plot for accuracy values.\n",
    "utils.simple_bar_plot(range(len(class_names)),\n",
    "                      class_accuracy,\n",
    "                      'Classes',\n",
    "                      'Accuracy (%)',\n",
    "                      'class_accuracy',\n",
    "                      fig_size=(15, 5),\n",
    "                      save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d101e8-426c-408d-a5fc-345d08a4434d",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d76c1c-8bf2-4b5e-ae24-9fd71ab6b7b0",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4b22ad-185d-4251-8545-744f9e403c59",
   "metadata": {},
   "source": [
    "# ResNet18 with pretrained weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e46b01-7e1d-4215-b2ae-c0afa84c82ac",
   "metadata": {},
   "source": [
    "## Definition and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472cdf9a-2854-4bd0-8ef5-4e5d179f0019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model: resnet with pretrained weights.\n",
    "del model\n",
    "model = torchvision.models.resnet18(\n",
    "    weights=torchvision.models.ResNet18_Weights.DEFAULT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb9f8c6-dc14-4557-9ed2-b9d6084093b5",
   "metadata": {},
   "source": [
    "## Adjust final layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a63f366-3feb-40fa-bbcf-117fbca74817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check old final layer.\n",
    "print(model.fc)\n",
    "\n",
    "# Get the number of input features to the layer.\n",
    "num_ftrs = model.fc.in_features\n",
    "print(num_ftrs)\n",
    "\n",
    "# Adjust the final layer to the current number of classes.\n",
    "model.fc = torch.nn.Linear(num_ftrs, len(class_names))\n",
    "\n",
    "# Parameters of newly constructed modules\n",
    "# have requires_grad=True by default.\n",
    "# Check new final layer.\n",
    "print(model.fc)\n",
    "\n",
    "# Freezing all the network except the final layer.\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Model structure.\n",
    "summary(\n",
    "    model,\n",
    "    input_size=(exp.batch_size, 3, exp.input_size, exp.input_size),\n",
    "    device=exp.device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e916e25-8b38-4e14-beb4-f311126e01f1",
   "metadata": {},
   "source": [
    "## Loss fcn and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaccb2dc-7957-4857-9bf7-b9eab949bee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function: cross-entropy loss.\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizers: specified in the torch.optim package\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425ec5c5-ddc4-4938-9720-8e07068997d0",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ea3d48-0270-41dc-a48d-15953ffb23e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, loss_history = train_model(\n",
    "    model,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    exp.device,\n",
    "    epochs=exp.epochs,\n",
    "    save_best_model=True\n",
    ")\n",
    "\n",
    "plot_losses(loss_history, 'Model w/ pretrained weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a40815-9743-42c6-8643-a963ce8533e6",
   "metadata": {},
   "source": [
    "## Check performance on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d9e847-5b2e-49fc-ad8e-92529b5410e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_on_test(model, exp.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9ab91b-c609-44a1-bfd7-61a456c6a22b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4790a3a2-2350-49a7-9461-dbcca50335e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "conf_mat, class_accuracy = utils.create_confusion_matrix(\n",
    "    model,\n",
    "    dataloader_test,\n",
    "    exp.device,\n",
    "    class_names\n",
    ")\n",
    "\n",
    "# Bar plot for accuracy values.\n",
    "utils.simple_bar_plot(range(len(class_names)),\n",
    "                      class_accuracy,\n",
    "                      'Classes',\n",
    "                      'Accuracy (%)',\n",
    "                      'class_accuracy',\n",
    "                      fig_size=(15, 5),\n",
    "                      save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bba927-e499-45b7-9d32-bd5e83b8d257",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a486bc-8b38-451a-9424-477585524559",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f806d186-1c7c-4423-8337-5d7f9433c746",
   "metadata": {},
   "source": [
    "# SSL model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1839bbef-1ec9-4899-972b-9d6db8f2613c",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42234674-8005-4fcd-a76f-5d54f586fb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# State model class.\n",
    "resnet18 = torchvision.models.resnet18(weights=None)\n",
    "\n",
    "# Only backbone (w/o final fc layer).\n",
    "pt_backbone = torch.nn.Sequential(*list(resnet18.children())[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147bd03f-ee69-4664-a0f3-57ea6aa78331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of trained models.\n",
    "model_list = []\n",
    "for root, dirs, files in os.walk('pytorch_models/history_log/'):\n",
    "    for i, filename in enumerate(sorted(files, reverse=True)):\n",
    "        model_list.append(root + filename)\n",
    "        print(f'{i:02}: {filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad21f18d-da7d-4007-a8be-edd49331ed69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model.\n",
    "idx = 0\n",
    "print(model_list[idx])\n",
    "pt_backbone.load_state_dict(torch.load(model_list[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b953213-478a-41fc-8f77-c418c5cf9def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model is loaded on GPU.\n",
    "next(pt_backbone.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bebf71e-7453-442a-898a-1a38825e025b",
   "metadata": {},
   "source": [
    "## Checking the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d413d46-02cf-49a2-9a86-b39fbfaac08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First convolutional layer weights.\n",
    "# print(backbone)\n",
    "print(pt_backbone[0])\n",
    "print(pt_backbone[0].weight[63])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bd91df-abe1-42d3-ace9-8a8b45fbb0f8",
   "metadata": {},
   "source": [
    "## Adding a final linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b768a0a1-85c5-40a4-b843-4d50d44fd161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a linear layer on top of the model (linear classifier).\n",
    "model_ssl = torch.nn.Sequential(\n",
    "    pt_backbone,\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(in_features=512, out_features=len(class_names), bias=True),\n",
    "    # torch.nn.Softmax(dim=1)\n",
    ")\n",
    "\n",
    "# Freezing all the network except the final layer.\n",
    "for param in model_ssl.parameters():\n",
    "    param.requires_grad = False\n",
    "# for param in model_ssl[0][7].parameters():\n",
    "#     param.requires_grad = True\n",
    "for param in model_ssl[2].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Model structure.\n",
    "summary(\n",
    "    model_ssl,\n",
    "    input_size=(exp.batch_size, 3, exp.input_size, exp.input_size),\n",
    "    device=exp.device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80c0096-fb2f-4183-bdab-dfc345be59c7",
   "metadata": {},
   "source": [
    "## Loss fcn and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f3ed4b-1948-4843-96ca-b4cced958a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function: cross-entropy loss.\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizers: specified in the torch.optim package\n",
    "optimizer = torch.optim.Adam(model_ssl.parameters(),\n",
    "                             lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a106ebc3-d159-45f8-b956-abd33add0552",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c9d4f1-bc8a-45fe-88f5-dbcb71b0c8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ssl, loss_history = train_model(\n",
    "    model_ssl,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    exp.device,\n",
    "    epochs=exp.epochs,\n",
    "    save_best_model=True\n",
    ")\n",
    "\n",
    "plot_losses(loss_history, 'Model w/ ssl pretrained weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7815545a-4949-41fa-b208-774516170576",
   "metadata": {},
   "source": [
    "## Checking the weights after training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ea1ae5-4c44-4c2a-8efe-ac210a30ed79",
   "metadata": {},
   "source": [
    "They should have remained the same (frozen) except for the final layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87f242c-38db-4d11-b84b-4bbab655297b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First convolutional layer weights.\n",
    "# print(backbone)\n",
    "print(pt_backbone[0])\n",
    "print(pt_backbone[0].weight[63])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9dff9a-1277-4301-b08e-8152110abe26",
   "metadata": {},
   "source": [
    "## Check performance on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2636a4a8-8ee4-4861-9aa8-920f0df40b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_on_test(model_ssl, exp.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fc6156-7506-449e-bc56-873c23aaf091",
   "metadata": {
    "tags": []
   },
   "source": [
    "## F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5024fea-751f-40a7-93ac-3a897285f89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "conf_mat, class_accuracy = utils.create_confusion_matrix(\n",
    "    model_ssl,\n",
    "    dataloader_test,\n",
    "    exp.device,\n",
    "    class_names\n",
    ")\n",
    "\n",
    "# Bar plot for accuracy values.\n",
    "utils.simple_bar_plot(range(len(class_names)),\n",
    "                      class_accuracy,\n",
    "                      'Classes',\n",
    "                      'Accuracy (%)',\n",
    "                      'class_accuracy',\n",
    "                      fig_size=(15, 5),\n",
    "                      save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788ad0aa-d143-42dd-96f9-63c9cf6ad81f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d238c6eb-d2e8-419d-b24c-1c828f995abe",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lulc-conda",
   "language": "python",
   "name": "lulc-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
