<!-- PROJECT SHIELDS -->
<!--
*** I'm using markdown "reference style" links for readability.
*** Reference links are enclosed in brackets [ ] instead of parentheses ( ).
*** See the bottom of this document for the declaration of the reference variables
*** for contributors-url, forks-url, etc. This is an optional, concise syntax you may use.
*** https://www.markdownguide.org/basic-syntax/#reference-style-links
-->
[![LinkedIn][linkedin-shield]][linkedin-url]

# SSL Evaluation on Fraction Estimation
Official repo of the self-supervised learning research paper:<br>
* <i>Evaluation of Self-Supervised Learning Models for Land-Use and Land-Cover Fraction Estimation on RGB Satellite Tiles</i>

Current status: <i>Undergoing review</i>.

## Table of contents
* [Getting started](#getting-started)
  * [Prerequisites](#prerequisites)
  * [Installation](#installation)
  * [Usage](#usage)
* [Pretraining SSL models](#pretraining-ssl-models)
* [Downstream tasks](#downstream-tasks-lulc-fraction-estimation-and-scene-classification)
* [License](#license)

## Getting started

### Prerequisites
Anaconda distribution is recommended. You can install it following the [official installation guide](https://docs.anaconda.com/anaconda/install/linux/).

Check if Anaconda is installed:
```
conda --version
conda -V
```

### Installation
The environment.yml file contains all the necessary packages to use this project inside the environment with the name `ssl-conda` provided. You can create a conda environment from the [env.yml](env.yml) file provided as follows:
```
conda env create -f env.yml
```

### Usage
Activate the conda environment:
```
conda activate ssl-conda
```

Now you can run any Python script.

## Pretraining SSL models
Four SSL models are considered: Barlow Twins, MoCov2, SimCLR, and SimSiam. The ResNet18 is selected as the backbone of each network. The pretraining on the Sentinel2GlobalLULC pure-pixels dataset is launched via a SLURM job script by running:
```
./ssl_pretraining_slurm_launch_loop.sh <option>
```
For the `<option>` argument, four types of experiments can be selected: `RayTune`, `DDP`, `Imbalanced` (default), or `Balanced`.

If `RayTune` is selected, the script generates a csv file including the best configurations sorted according to the lowest training loss with the following format: `ray_tune_<backbone>_<model>.csv`. This file must be included in the path `./input/best_configs/` for the other types of experiments to start with the pseudo-optimal hyperparameters found.

## Downstream tasks: LULC fraction estimation and scene classification
```
sbatch finetuning_slurm.sh
```

This script runs the [finetuning_run_localhost.sh](finetuning_run_localhost.sh). It should be configured with only one or two `train_rates` to launch several Slurm jobs. The Python script accepts the desired number of samples per class as input. Upon completion of the jobs, several files will be generated (one per seed) inside the output folder.

* The mean and std values per trial can be generated using the script [sc_1_compute_mean_std_from_csv.py](scripts/sc_1_compute_mean_std_from_csv.py) (see the `-h` for help) as follows:
```
python3 sc_1_compute_mean_std_from_csv.py -i <parent_folder_of_the_csv_files> -o <desired_output_folder>
```
where `parent_folder_of_the_csv_files` should target the `multiclass/` and then `multilabel/` folders following the structure below:
```
csv_results/
├── multiclass/
│   ├── multiclass_tr=0.010_resnet18_BarlowTwins_bd=False_tl=FT_iw=random_s=05_lr=0.001_m=0.9_wd=0.0_do=None.csv
│   ├── multiclass_tr=0.010_resnet18_BarlowTwins_bd=False_tl=FT_iw=random_s=42_lr=0.001_m=0.9_wd=0.0_do=None.csv
│   ├── ...
├── multilabel/
│   ├── multilabel_tr=0.010_resnet18_BarlowTwins_bd=False_tl=FT_iw=random_s=05_lr=0.01_m=0.9_wd=1e-05_do=None.csv
│   ├── multilabel_tr=0.010_resnet18_BarlowTwins_bd=False_tl=FT_iw=random_s=42_lr=0.01_m=0.9_wd=1e-05_do=None.csv
│   ├── ...
```

* The output files generated by the previous script should be manually arranged in folders as follows:
```
both_mean_std_csv_files/
├── multiclass/
│   ├── 001p/
│      ├── pp_mean_multiclass_tr=0.010_resnet18_BarlowTwins_bd=False_tl=FT_iw=random.csv
│      ├── ...
│      ├── pp_std_multiclass_tr=0.010_resnet18_BarlowTwins_bd=False_tl=FT_iw=random.csv
│      ├── ...
├── multilabel/
│   ├── 001p/
│      ├── pp_mean_multilabel_tr=0.010_resnet18_BarlowTwins_bd=False_tl=FT_iw=random.csv
│      ├── ...
│      ├── pp_std_multilabel_tr=0.010_resnet18_BarlowTwins_bd=False_tl=FT_iw=random.csv
│      ├── ...
```

* The generated csv file can be plotted using the script [sc_2_plot_final_graphs_v2.py](scripts/sc_2_plot_final_graphs_v2.py). This script requires inputting the parent folder (`multiclass/` or `multilabel/`) and adjusting the hard-coded `x` variable to the current number of percentages available. It searches for the best results obtained in the validation dataset and then generates a **new *dataframe* with the final results used for the graphs**, as well as the **final line graphs** showing the training ratios versus the results of the desired final metric:
```
python3 scripts/sc_2_plot_final_graphs_v2.py -i ~/Documents/Experiments/SSL-BSU/02_v3_R1_Fine-tuning_new_results_val_test/02_avg_csv_files/multiclass/ -o ~/Documents/Experiments/SSL-BSU/02_v3_R1_Fine-tuning_new_results_val_test/03_dfs_final_results/ -m f1_macro -sf pdf
python3 scripts/sc_2_plot_final_graphs_v2.py -i ~/Documents/Experiments/SSL-BSU/02_v3_R1_Fine-tuning_new_results_val_test/02_avg_csv_files/multilabel/ -o ~/Documents/Experiments/SSL-BSU/02_v3_R1_Fine-tuning_new_results_val_test/03_dfs_final_results/ -m rmse -sf pdf
```

To obtain the bar plots related to the F1 and RMSE results per class, run the following commands:
```
python3 scripts/sc_3_plot_final_bar_graphs_v2.py -i ~/Documents/Experiments/SSL-BSU/02_v3_R1_Fine-tuning_new_results_val_test/03_dfs_final_results/exp_multiclass_best_results_means.csv -o ~/Documents/Experiments/SSL-BSU/02_v3_R1_Fine-tuning_new_results_val_test/03_dfs_final_results/ -sf pdf
python3 scripts/sc_3_plot_final_bar_graphs_v2.py -i ~/Documents/Experiments/SSL-BSU/02_v3_R1_Fine-tuning_new_results_val_test/03_dfs_final_results/exp_multilabel_best_results_means.csv -o ~/Documents/Experiments/SSL-BSU/02_v3_R1_Fine-tuning_new_results_val_test/03_dfs_final_results/ -sf pdf

```



---
---




Some examples of the above command follow:
* Experiment 1:
```
python3 scripts/plot_final_graphs.py -i ~/Documents/Experiments_2024_TESSL/02_Fine-tuning_imbalanced_dataloader/02_2_avg_csv_files_truncated_100e/multiclass/ --metric f1_macro --save_fig pdf --ref Random
```
* Experiment 2:
```
python3 scripts/plot_final_graphs.py -i ~/Documents/Experiments_2024_TESSL/02_Fine-tuning_imbalanced_dataloader/02_2_avg_csv_files_truncated_100e/multiclass/ --metric f1_per_class --save_fig pdf --ref ImageNet --bar best
```
* Experiment 3:
```
python3 scripts/plot_final_graphs.py -i ~/Documents/Experiments_2024_TESSL/02_Fine-tuning_imbalanced_dataloader/02_2_avg_csv_files_truncated_100e/multiclass/ --metric f1_per_class --save_fig pdf --ref ImageNet --bar diff
```

To generate the tables with all values, the script `take_acc_values_from_csv_v2.py` is used. A use example follows:
```
python3 scripts/take_acc_values_from_csv_tables.py -i ~/Documents/Experiments_2024_TESSL/02_Fine-tuning_imbalanced_dataloader/02_2_avg_csv_files_truncated_100e/multilabel/ -o ~/Downloads/
```

## License
This project is licensed under the GNU General Public License v3.0 - see the [LICENSE](LICENSE) file for details.

<!-- MARKDOWN LINKS & IMAGES -->
<!-- https://www.markdownguide.org/basic-syntax/#reference-style-links -->
[linkedin-shield]: https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white
[linkedin-url]: https://linkedin.com/in/sfandres
